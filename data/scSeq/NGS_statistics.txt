NGS statistics 统计学和统计学参数

统计学尽量不写，因为太多参数
paper中常见的统计学，还是要硬啃的。


本文记录paper中遇到的统计学。
还有一个R和数理统计学: R/R03-statistics.txt 
一个纯粹统计学: Math/Math-statistics.txt



========================================
权威统计学资料
----------------------------------------
《Introduction to Statistics With Python》 https://github.com/thomas-haslwanter/statsintro_python

有很多统计学和基本R使用案例: http://www.instantr.com/

R与统计学(卡方检验等)： http://www.sthda.com/english/wiki/r-basic-statistics


多组的比较 kruskal-wallis http://www.sthda.com/english/wiki/kruskal-wallis-test-in-r


推荐统计学和R教程：
1.An R Companion for the Handbook of Biological Statistics https://rcompanion.org/rcompanion/index.html
2.配套  The Handbook of Biological Statistics.  http://www.biostathandbook.com/
3. https://rcompanion.org/documents/RCompanionBioStatistics.pdf



PPT:
1.两个以上比例的检验 (卡方检验)
https://max.book118.com/html/2017/1207/143188823.shtm







========================================
k-means k均值聚类的弱点/缺点
----------------------------------------
http://www.cnblogs.com/emanlee/archive/2012/03/06/2381617.html

Similar to other algorithm, K-mean clustering has many weaknesses:

1 When the numbers of data are not so many, initial grouping will determine the cluster significantly.  当数据数量不是足够大时，初始化分组很大程度上决定了聚类，影响聚类结果。 
2 The number of cluster, K, must be determined before hand.  要事先指定K的值。 
3 We never know the real cluster, using the same data, if it is inputted in a different order may produce different cluster if the number of data is a few. 数据数量不多时，输入的数据的顺序不同会导致结果不同。 
4 Sensitive to initial condition. Different initial condition may produce different result of cluster. The algorithm may be trapped in the local optimum. 对初始化条件敏感。 
5 We never know which attribute contributes more to the grouping process since we assume that each attribute has the same weight. 无法确定哪个属性对聚类的贡献更大。 
6 weakness of arithmetic mean is not robust to outliers. Very far data from the centroid may pull the centroid away from the real one. 使用算术平均值对outlier不鲁棒。 
7 The result is circular cluster shape because based on distance.  因为基于距离，故结果是圆形的聚类形状。

 

One way to overcome those weaknesses is to use K-mean clustering only if there are available many data. To overcome outliers problem, we can use median instead of mean.  克服缺点的方法： 使用尽量多的数据；使用中位数代替均值来克服outlier的问题。

Some people pointed out that K means clustering cannot be used for other type of data rather than quantitative data. This is not true! See how you can use multivariate data up to n dimensions (even mixed data type) here. The key to use other type of dissimilarity is in the distance matrix.

 

http://people.revoledu.com/kardi/tutorial/kMean/Weakness.htm










========================================
多重比较的p值校正: Adjust P-values for Multiple Comparisons
----------------------------------------

根据NCBI GEO官网，p值校正方法包括： https://www.ncbi.nlm.nih.gov/geo/info/geo2r.html#adjustment_references

Apply adjustment to the P-values. 
 Benjamini & Hochberg (False discovery rate)
 Benjamini & Yekutieli
 Bonferroni
 Hochberg
 Holm
 Hommel
 None
#

https://stat.ethz.ch/R-manual/R-devel/library/stats/html/p.adjust.html

Description: Given a set of p-values, returns p-values adjusted using one of several methods.

使用
p.adjust(p, method = p.adjust.methods, n = length(p))

p.adjust.methods
# c("holm", "hochberg", "hommel", "bonferroni", "BH", "BY", "fdr", "none")


参数：
p:	numeric vector of p-values (possibly with NAs). Any other R object is coerced by as.numeric.
method:	correction method. Can be abbreviated.
n:	number of comparisons, must be at least length(p); only set this (to non-default) when you know what you are doing!


细节：
The adjustment methods include the Bonferroni correction ("bonferroni") in which the p-values are multiplied by the number of comparisons. 

Less conservative corrections are also included by Holm (1979) ("holm"), Hochberg (1988) ("hochberg"), Hommel (1988) ("hommel"), Benjamini & Hochberg (1995) ("BH" or its alias "fdr"), and Benjamini & Yekutieli (2001) ("BY"), respectively. 

A pass-through option ("none") is also included. 

The set of methods are contained in the p.adjust.methods vector for the benefit of methods that need to have the method as an option and pass it on to p.adjust.



例子：
require(graphics)

set.seed(123)
x <- rnorm(50, mean = c(rep(0, 25), rep(3, 25)))
p <- 2*pnorm(sort(-abs(x)))

round(p, 3)
round(p.adjust(p), 3)
round(p.adjust(p, "BH"), 3)

## or all of them at once (dropping the "fdr" alias):
p.adjust.M <- p.adjust.methods[p.adjust.methods != "fdr"]
p.adj    <- sapply(p.adjust.M, function(meth) p.adjust(p, meth))
p.adj.60 <- sapply(p.adjust.M, function(meth) p.adjust(p, meth, n = 60))
stopifnot(identical(p.adj[,"none"], p), p.adj <= p.adj.60)
round(p.adj, 3)
## or a bit nicer:
noquote(apply(p.adj, 2, format.pval, digits = 3))


## and a graphic:
matplot(p, p.adj, ylab="p.adjust(p, meth)", type = "l", asp = 1, lty = 1:6,
        main = "P-value adjustments")
legend(0.7, 0.6, p.adjust.M, col = 1:6, lty = 1:6)

## Can work with NA's:
pN <- p; iN <- c(46, 47); pN[iN] <- NA
pN.a <- sapply(p.adjust.M, function(meth) p.adjust(pN, meth))
## The smallest 20 P-values all affected by the NA's :
round((pN.a / p.adj)[1:20, ] , 4)






ref:
Benjamini, Y., and Hochberg, Y. (1995). Controlling the false discovery rate: a practical and powerful approach to multiple testing. Journal of the Royal Statistical Society Series B, 57, 289-300.
Benjamini, Y., and Yekutieli, D. (2001). The control of the false discovery rate in multiple testing under dependency. Annals of Statistics 29, 1165-1188.
Holm, S. (1979). A simple sequentially rejective multiple test procedure. Scandinavian Journal of Statistics, 6, 65-70.
Hommel, G. (1988). A stagewise rejective multiple test procedure based on a modified Bonferroni test. Biometrika, 75, 383-386.
Hochberg, Y. (1988). A sharper Bonferroni procedure for multiple tests of significance. Biometrika, 75, 800-803.
Shaffer, J. P. (1995). Multiple hypothesis testing. Annual Review of Psychology, 46, 561-576.
Sarkar, S. (1998). Some probability inequalities for ordered MTP2 random variables: a proof of Simes conjecture. Annals of Statistics, 26, 494-504.
Sarkar, S., and Chang, C. K. (1997). Simes' method for multiple hypothesis testing with positively dependent test statistics. Journal of the American Statistical Association, 92, 1601-1608.
Wright, S. P. (1992). Adjusted P-values for simultaneous inference. Biometrics, 48, 1005-1013.




========================================
|-- 多重假设检验：Bonferroni 和 FDR (R语言实现)
----------------------------------------
1.概念
FDR，Q value，adjust p value
p-value：衡量一次检验假阳性率的指标（False positive rate） ；
q value：衡量错误发现率的指标（False discovery rate，简称FDR，所有检验中假阳性的概率）。即使用Q value的这个参 数预估FDR。Q value 需要利用公式从p value 校正计算后得到，所以Q value 通常又被称为adjusted p value。所以一般情况下：我们可以认为Q value = FDR = adjusted p value，即三者是一个东西，虽然有些定义上的细微区别，但是问题也不大。


2.矫正
如要使用的校正办法有两种：Bonferroni 校正；FDR（FalseDiscovery Rate） 校正
(1).Bonferroni 校正
Bonferroni 校正法可以称作是“最简单粗暴有效”的校正方法，它拒绝了所有的假阳性结果发生的可能性，通过对p值的阈值进行校正来实现消除假阳性结果。

Bonferroni 校正的公式为p*(1/n)，其中p为原始阈值，n为总检验次数。

如果像我们举的例子一样，原始的P值为0.05，检验次数为10000次，那么在Bonferroni 校正中，校正的阈值就等于5%/ 10000 = 0.000005，所有P值超过0.00005的结果都被认为是不可靠的。这样的话假阳性结果在10000次检验中出现的次数为 10000 * 0.000005 =0.5，还不到1次。

但是这也存在问题：Bonferroni 委实太过严格，被校正后的阈值拒绝的不只有假阳性结果，很多阳性结果也会被它拒绝。



(2).FDR（FalseDiscovery Rate） 校正
相对Bonferroni 来说，FDR温和得多，这种校正方法不追求完全没有假阳性结果，而是将假阳性结果和真阳性的比例控制在一定范围内。

举个例子，我们最开始设定的情况中进行了10000次检验，这次我们设定FDR<0.05，如果我们的检验对象为差异表达的基因，那么在10000次检验中假如得到了500个基因，那么这500个基因中的假阳性结果小于 500*5% = 25 个。

FDR的计算方法有很多种，这里介绍一个比较常用的：

1)BH（Benjaminiand Hochberg）法：
BH 法需要将总计m次检验的结果按由小到大进行排序，k为其中一次检验结果的P值所对应的排名。
找到符合原始阈值α的最大的k值，满足P(k)<=α*k/m，认为排名从1到k的所有检验存在显著差异，并计算对应的q值公式为q = p*(m/k)。
举个例子，如果我们有总共六个结果进行FDR校正：

Gene	p-value 
G1	P1=0.053
G2	P2=0.001
G3	P3=0.045
G4	P4=0.03
G5	P5=0.02
G6	P6=0.01

Order:
G2	P2=0.001
G6	P6=0.01
G5	P5=0.02
G4	P4=0.03
G3	P3=0.045
G1	P1=0.053

按α=0.05进行计算：
排名第四的 P (4) = 0.03 < 0.05*4/6 = 0.033，符合要求
排名第五的 P (5)= 0.045 > 0.05*5/6 = 0.041，不满足P(k)<=α*k/m. 
因此在这个列表里排名前四的G2,G6,G5,G4 为具有显著差异的基因。


我们也可以用q值进行FDR校正：
G2	P2=0.001	q2=0.001*6/1=0.006
G6	P6=0.01	q6=0.01*6/2=0.03
G5	P5=0.02	q5=0.02*6/3=0.04
G4	P4=0.03	q4=0.03*6/4=0.045
G3	P3=0.045	q3=0.045*6/5=0.054
G1	P1=0.053	q1=0.053*6/6=0.053
其中，G3的q值大于0.05，故G2,G6,G5,G4 为具有显著差异的基因。





3. R语言实例：adj p value
############ 循环实现矫正
compareL=data.frame(
  p.value=c(1.423900e-06, 2.187725e-06, 3.555254e-06, 5.761348e-06, 6.274032e-06, 1.046657e-05, 2.897417e-05, 3.537313e-05, 4.001844e-05,
            6.336900e-05, 6.385193e-05, 6.845141e-05, 8.500831e-05, 8.849766e-05, 9.792548e-05, 1.050767e-04, 1.421291e-04, 1.724226e-04,
            1.850125e-04, 1.944649e-04)
)
head( compareL )
n=nrow(compareL);n #20
qvalues=c()
for(i in seq(1,n)){
  if(i%%5==0) print(i) #进度条
  q=compareL$p.value[i]*n/i
  qvalues=c(qvalues, q)
}
length(qvalues) #
qvalues[1:5] 
# 2.847800e-05 2.187725e-05 2.370169e-05 2.880674e-05 2.509613e-05
#
############ R函数矫正 test for adj.p value function
qvalues2=p.adjust(p=compareL$p.value, method = "fdr")
qvalues2[1:5]
# 2.187725e-05 2.187725e-05 2.370169e-05 2.509613e-05 2.509613e-05
#这个函数和上述for循环结果完全一样。



(2) p.adjust.methods
# c("holm", "hochberg", "hommel", "bonferroni", "BH", "BY",
#   "fdr", "none")


1) 默认的矫正方法是 holm 
table(
  p.adjust( p=compareL$p.value ) ==
  p.adjust( p=compareL$p.value, method = "holm" ) 
)
#TRUE 
#  20



2) fdr 就是 BH 法: 
table(
  p.adjust(p=compareL$p.value, method = "BH") ==
  #Benjamini & Hochberg (1995) ("BH" or its alias "fdr"),
  p.adjust(p=compareL$p.value, method = "fdr")
)
#TRUE 
#  20




3) 文章的描述: 
(2014 NC, DaPar, Wei Li) Fig 3c:
https://www.researchgate.net/publication/268796985_Dynamic_analyses_of_alternative_polyadenylation_from_RNA-seq_reveal_a_3'-UTR_landscape_across_seven_tumour_types

(c) For genes with shorter 3'UTRs in tumours, their fold-change expression between tumours and normal tissues are plotted against their delta PDUI values. All isoforms of the same gene were combined for the expression measurement. The genes signiﬁcantly up- or downregulated in tumours are shown in red and blue, respectively, which were identiﬁed by paired t-test with Benjamini–Hochberg (BH) false-discovery rate at 5%. Accordingly, the red and blue bar plots indicate the number of up- and downregulated genes, respectively.




refer: https://www.jianshu.com/p/949626b18e69



========================================
|-- Benjamini correction == FDR == adjusted p-value
----------------------------------------
https://www.biostars.org/p/293613/

Benjamini correction is your false discovery rate and it is your adjusted p-value. So you should forget about your p-value after correction. So your test is significant if your adjusted p-value is smaller than criteria (such as 0.05 or 0.01). If you want to more about multiple testing, you can check here




========================================
数据的离散程度: sd, MAD, IQR
----------------------------------------
1. sd 



2. MAD 最大离差

MAD 定义为，一元序列 Xi 同其中位数偏差的绝对值的中位数（deviation，偏差本身有正有负）；
MAD=median(|Xi−median(X)|)

MAD 的方法相对于分位数方法的一大优势即在于 MAD 方法对样本大小是不敏感也即是稳定的鲁棒的一种评价指标。



3. IQR 

四分位距（interquartile range, IQR），又称四分差。是描述统计学中的一种方法，以确定第三四分位数和第一四分位数的区别。与方差、标准差一样，表示统计资料中各变量分散情形，但四分差更多为一种稳健统计（robust statistic）。

(1) 文献描述：各分组中，变异较大的(IRQ>=0.8) 的分别占 xx%
https://www.thno.org/v10p10531.htm#B23 P38右下:

The percentage of tandem 3′UTRs that showed relatively large variances (interquartile range [IQR] ≥ 0.8) was 15.9%, 13.6%, 17.5% and 21.1% for LAR, MLIA, BL and S subtypes according to the FUSCC APA classification, respectively, 

and was 19.6%, 17.5%, 14.6%, 20.0%, 10.9%, 17.5% and 18.3% for BL1, BL2, IM, M, MSL, LAR and UNS subtypes based on Lehmann subtypes, respectively (Figure 3B and C).






(2) R 自带函数
> IQR(iris$Sepal.Length)
[1] 1.3
> IQR(iris[,2])
[1] 0.5

和对应的sd比较
> sapply(iris[,1:4], IQR)
Sepal.Length  Sepal.Width Petal.Length  Petal.Width 
         1.3          0.5          3.5          1.5 
> sapply(iris[,1:4], sd)
Sepal.Length  Sepal.Width Petal.Length  Petal.Width 
   0.8280661    0.4358663    1.7652982    0.7622377 

> sapply(iris[,1:4], mad)
Sepal.Length  Sepal.Width Petal.Length  Petal.Width 
     1.03782      0.44478      1.85325      1.03782 




========================================
****** 参数检验 ******
----------------------------------------



========================================
方差分析的原理, 方差分析表
----------------------------------------
https://www.bilibili.com/video/BV1X441187gE?p=1
https://mp.weixin.qq.com/s?__biz=MzIyNzIyNTczNA==&mid=2247487460&idx=1&sn=6548ac48ddb16378f459b60a232e6a90


1. 单因素方差分析 
https://mp.weixin.qq.com/s?__biz=MzIzNzgyNjAxMQ==&mid=2247483981&idx=1&sn=0cb38a4e9c55bb61ed8afbe73d00a42c

一共N个数据，分为1,2,...,k组。

(1)组间差异
SSB=累加nj*(xjbar-xbar)^2; 自由度为k-1;
组间均方 MSB^2表示(between)=累加ni*(xibar-xbar)^2/(k-1);

(2)组内差异，也叫误差
SSW=累加(x-xjbar)^2; 自由度为N-k;
MSW^2=累加(x-xibar)^2/(N-k); 也记做 MSE。

(3) 总方差 
SST=累加(x-xbar)^2, 自由度为N-1;

(4)单因素方差分析表:
###############
来源  SS   df  MS  F 
组间  SSB; k-1;  F=MSB/MSE;
误差  SSW; N-k;  作分母
总共  SST; N-1;
###############
检验: 
- 自由度k-1 + N-k=N-1, 能对应上;
- SST=SSB+SSW;

(5)H0: 组间没有显著差异。
F=MSB^2/MSW^2, F在临界值为a=0.05 自由度为(k-1, N-k) 的F值为Fa, 如果F>Fa,则拒绝H0, 认为组间有显著差异。

然后还要逐步检验，看哪些组之间有差异。




例: 三组学生，每组5个人，A组都是90分，B组都是80分，C组都是50分。
求分组之间是否有显著差异。
解: H0: 组间没有显著差异。
组内均方 
MSb=累加nj*(xjbar-xbar)^2/(k-1)=[ 5*(90-73.3)^2+ 5*(80-73.3)^2+ 5*(50-73.3)^2]/(3-1)

组内均方，也叫误差
MSw=MSe=累加(x-xjbar)^2 /(N-k)=[ (90-90)^2+..共5个90分减去该组平均分.+(90-90)^2+...+(50-50)^2] /(15-3)=0
这个例子比较极端，分母为0了
F=MSb/MSw=无穷大，超过了F在a=0.05 自由度为(2,12)的阈值，
所以p值太小，认为小概率事件在一次事件中不可能发生，否定H0，认为组间差异显著。









2. 多因素方差分析(以两因素为例，考虑交叉因素)
http://www.biye5u.com/article/R/2019/6403.html

(1)示例数据是两分组(比如男女)，三水平的(group1,group2,group3)
		condition1, condition2,... condition2 s
group1   x11  x12  x1s
group2   x21  x22  x2s
...
group r   xr1  xr2 xrs

总行数R=r行, 总列数C=s列; 总分组K=r*s; 为了防止标记混乱，后面尽量使用R和C；
该实验重复L次，总数据个数N=r*s*l; 


SST=SSM+SSE; 总方差=模型+误差
其中 SSM=A+B+AxB，所以 
SST=SSA + SSB + SSAxB +SSE;


0) 为求AxB的交叉效应，需要先求模型方差=把数据按照行和列分组，每组均值-总方差，求平方和;
SSM=累加( nj*(xj_bar-x_bar)^2 )，自由度为 K-1=R*C-1;
该值不写到方差分析表中。


1) 行间方差 = 数据分行，每行求平均值，行平均值和总均值的差，再求平方和。
SSR=累加( nR*(xR_bar-x_bar)^2 )，自由度为 R-1;

2) 列间方差 = 每列均值-总均值，再求平方和；
SSC=累加( nC*(xC_bar-x_bar)^2 )，自由度为 C-1;

3) 行列交叉效应 
SSAxB=SSM-SSA-SSB; 自由度为 (R-1)(C-1);

4) 误差，也就是组内均方差的和=按照行列交叉分组，每组内元素和该组均值的差，求平方和;
SSE=累加( (x-x_bar)^2 ), 自由度为 N-RC;

5) 总方差和=每个元素和总均值的差，求平方和;
SST=累加( (x-x_bar)^2 ), 自由度为 N-1;

验算
1) SSM=SSA+SSB+SSAB;
2) 自由度 T=A+B+AB+E; R-1+C-1+(R-1)(C-1)+N-RC=R+C-2+RC-R-C+1+N-RC=N-1;


两因素方差分析表:
###############
来源  SS  df  MS  F 
A行间 SSR R-1  Fa
B列间 SSC C-1  Fb
AxB交叉 SSAB (R-1)(C-1)  Baxb
E误差 SSE (N-RC)  做分母
T总共 SST N-1
###############
求F值，求该自由度下的p值，看是否足够小而拒绝H0.
MS=SS/df; 

FR=SSR/SSE; F~(r-1, (r-1)(s-1))
FC=SSC/SSE; F~(s-1, (r-1)(s-1))
FRC=(SSM-SSA-SSB)/SSE; F~(N-rs, (r-1)(s-1))



例: 把横竖表 “宽变长” 得到如下表:
groupA是3行分组；
sexB是2列分组: 男女;
x是观测指标；问A和B哪个分组是显著的。
实验重复5次。一共3*2*5=30个观测值;

groupA	sexB	x
1	1	12
1	1	15
1	1	16
1	1	17
1	1	14
2	1	14
2	1	17
2	1	19
2	1	20
2	1	17
3	1	25
3	1	27
3	1	29
3	1	24
3	1	22
1	2	21
1	2	19
1	2	18
1	2	24
1	2	25
2	2	21
2	2	20
2	2	23
2	2	27
2	2	25
3	2	37
3	2	34
3	2	36
3	2	26
3	2	29

1) 先求总平均数 x_bar	22.43333333
2) A
groupA	mean	n	xRowbar-xbar方	SSR	df	ms
1	18.1	10	18.77777778	651.4666667	2	325.7333333
2	20.3	10	4.551111111			
3	28.9	10	41.81777778			

3) B
groupB	mean	n	xColbar-xbar方	SSC	df	ms
1	19.2	15	10.45444444	313.6333333	1	313.6333333
2	25.66666667	15	10.45444444			

4) 模型
groupM	mean	n	xjbar-xbar方	SSM	df	ms
11	14.8	5	58.26777778	966.9666667	5	193.3933333
21	17.4	5	25.33444444			
31	25.4	5	8.801111111			
12	21.4	5	1.067777778			
22	23.2	5	0.587777778			
32	32.4	5	99.33444444			

5) 交叉AxB=M-A-B;
SSCross	df	ms
1.866666667	2	0.933333333

6) 总差异=(每个值-总xbar)^2求和
excel中使用原数据表每行-总xbar，平方后再sum；
SST	df	ms
1191.366667	29	41.0816092

7) 误差=(x-每行列分组xbar)^2求和
excel中先计算每个行列分组内的均值xjbar AVERAGEIFS(C:C,A:A,A2,B:B,B2)
每行-xjbar,平方后再sum;
SSE	df	ms
224.4	24	9.35

8)方差分析表
model	966.9666667	5	193.3933333	20.68377897	2.620654147	Yes	5.43052E-08 这一行不写

来源	SS	df	ms	F	F(a=0.05)	sig	Pvalue
rowA	651.4666667	2	325.7333333	34.83778966	3.402826105	Yes	7.99868E-08
columnB	313.6333333	1	313.6333333	33.54367201	4.259677214	Yes	5.69894E-06
crossAxB	1.866666667	2	0.933333333	0.099821747	3.402826105	no	0.905372469
Error	224.4	24	9.35				
total	1191.366667	29	41.0816092				






========================================
|-- R语言进行方差分析(1-way) 单因素方差分析
----------------------------------------
ggpubr, ggsci, ggsignif, car, userfriendlyscience

data(ToothGrouth)
ToothGrouth$dosef=factor(ToothGrouth$dose,ordered=T);


1. 单因素方差分析 https://www.jianshu.com/p/cf0f637d5db7
group value
1 95
1 90
1 99
2 80
2 82
2 89
3 50
3 52
3 56

data1=read.table('clipboard', header=T); data1
data1$group=as.factor(data1$group) #分组变量必须是因子！！！


(1) 正态性检验 
shapiro.test(data1$group)
shapiro.test(data1$value)

shapiro.test( rnorm(200) ) #p-value = 0.4489 p太大接受H0: 来自正态分布样本;

(2) 方差齐性检验
# leveneTest(value~group, data1) #安装不上包
bartlett.test(value~group, data1) #p-value = 0.8449 无法拒绝H0:方差相等的群体

#方差齐性 summary(aov())
#方差不齐性，使用Welch's anova: oneway.test();




(3) 单因素 anova
aov1=aov(value~group, data1)
summary(aov1)
## 结果
            Df Sum Sq Mean Sq F value   Pr(>F)    
group        2   2846  1423.0    82.1 4.38e-05 ***
Residuals    6    104    17.3                     
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

group之间差异显著；


(4)也有人认为对残差进行正态性、方差齐性检验
# 提取残差
res1=residuals(aov1); res1
res1_2=aov1$residuals; res1_2
#检验残差的正态性
shapiro.test(res1)  #期望这个p>0.05
qqplot(names(res1), names(res1)) #画QQ图可视化

#
leveneTest(res1~group, data1) #期望这个p>0.05



(5) 多重检验，看哪个分组之间显著，方法有很多，常见的有:

1)多重比较 https://bbs.pinggu.org/thread-2744833-1-1.html
summary(fm1 <- aov(breaks ~ wool + tension, data = warpbreaks))
TukeyHSD(fm1, "tension", ordered = TRUE)

> TukeyHSD(aov1)
#  Tukey multiple comparisons of means
#     95% family-wise confidence level
# 
# Fit: aov(formula = value ~ group, data = data1)
# 
# $group
#     diff       lwr         upr     p adj
# 2-1  -11 -21.43013  -0.5698725 0.0407381
# 3-1  -42 -52.43013 -31.5698725 0.0000423
# 3-2  -31 -41.43013 -20.5698725 0.0002403


2) 两两比较
pairwise.t.test(data1$value, data1$group)
# Pairwise comparisons using t tests with pooled SD 
# data:  data1$value and data1$group 
#  1       2      
#2 0.0178  -     
#3 5.1e-05 0.0002
#
#P value adjustment method: holm 
结论: 可见两两检测(1-2,1-3,2-3)，都是有显著差异的。

#也可以指定其他的矫正方法，组数比较多还是推荐fdr
p.adjust.methods 
#[1] "holm" "hochberg" "hommel" "bonferroni" "BH" "BY" "fdr" "none" 
pairwise.t.test(data1$value, data1$group, p.adjust.method = "BH")





(6) # 画图
library(ggplot2)
data1$group=as.factor(data1$group);
ggplot(data1, aes(x=group, y=value, fill=group ))+
  stat_boxplot(geom="errorbar")+
  geom_boxplot()+
  geom_jitter()+
  theme_classic(base_size=16) #基准字号变大


(7) welch anova 对于不满足方差齐性的数据
oneway.test(value~group, data1, var.equal=F)
不返回残差，不能检验。
#One-way analysis of means (not assuming equal variances)
#
#data:  value and group
#F = 90.029, num df = 2.000, denom df = 3.828, p-value = 0.0006046


oneway.test(value~group, data1, var.equal=T) #var.equal=T则是经典方法，结果同上
#One-way analysis of means
#data:  value and group
#F = 82.096, num df = 2, denom df = 6, p-value = 4.382e-05

(8) 事后检验 #函数不存在
with(data1, 
	posthocTGH(value,group, method="games-howell")
)



(9) 如果不符合正态性，就要使用非参数检验了
kruskal.test(value~group, data1)
#Kruskal-Wallis rank sum test
#data:  value by group
#Kruskal-Wallis chi-squared = 7.2, df = 2, p-value = 0.02732

虽然p<0.05，拒绝H0，认为有group间差异，
但是p值比刚才要大，检验效力没有参数检验强。不容易纳伪，但是更容易弃真；


非参数的两两检验
with(data1, 
	pairwise.wilcox.test(value, group, exact=F)
)

#Pairwise comparisons using Wilcoxon rank sum test 
#
#data:  value and group 
#  1    2   
#2 0.24 -   
#3 0.24 0.24
#P value adjustment method: holm 
非参数的两两检验的结论是，两两之间差异不显著。



========================================
|-- R语言进行方差分析(2-way)
----------------------------------------
数据见上文。

1. 数据 
data2=read.table('clipboard', header=T)
data2

groupA	sexB	x
1	1	12
1	1	15
1	1	16
1	1	17
1	1	14
2	1	14
2	1	17
2	1	19
2	1	20
2	1	17
3	1	25
3	1	27
3	1	29
3	1	24
3	1	22
1	2	21
1	2	19
1	2	18
1	2	24
1	2	25
2	2	21
2	2	20
2	2	23
2	2	27
2	2	25
3	2	37
3	2	34
3	2	36
3	2	26
3	2	29


2 两因素，有交叉效应和没有交叉效应两种情况。
data2$groupA=as.factor(data2$groupA) #必须转为因子！
data2$sexB=as.factor(data2$sexB)

# aov2=aov(x~groupA+sexB, data2) #没交叉效应

aov2=aov(x~groupA*sexB, data2)  #交叉效应
#aov2=aov(x~groupA+sexB+groupA:sexB, data2)  #交叉效应
summary(aov2)
## 结果
#            Df Sum Sq Mean Sq F value  Pr(>F)    
#groupA       2  651.5   325.7   34.84 8.0e-08 ***
#sexB         1  313.6   313.6   33.54 5.7e-06 ***
#groupA:sexB  2    1.9     0.9    0.10   0.905    
#Residuals   24  224.4     9.4                    
#---
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

和之前excel手算的结果一致。
交互作用不显著。


(2) 诊断模型
res2=residuals(aov2);
shapiro.test(res2) #p>0.05
ggqqplot(res2) #没有这个函数
leveneTest(res2~groupA*sexB, dat2) #没有这个函数


(3) 两两比较，及可视化
> TK=TukeyHSD(aov2, 'groupA:sexB'); TK
# Tukey multiple comparisons of means
#    95% family-wise confidence level
#
# Fit: aov(formula = x ~ groupA * sexB, data = data2)
#
# $`groupA:sexB`
#         diff        lwr      upr     p adj
# 2:1-1:1  2.6 -3.3795101  8.57951 0.7580309
# 3:1-1:1 10.6  4.6204899 16.57951 0.0001624 **
# 1:2-1:1  6.6  0.6204899 12.57951 0.0245686 *
# 2:2-1:1  8.4  2.4204899 14.37951 0.0026899 **
# 3:2-1:1 17.6 11.6204899 23.57951 0.0000000 **
# 3:1-2:1  8.0  2.0204899 13.97951 0.0044533 **
# 1:2-2:1  4.0 -1.9795101  9.97951 0.3360790
# 2:2-2:1  5.8 -0.1795101 11.77951 0.0609450
# 3:2-2:1 15.0  9.0204899 20.97951 0.0000008 **
# 1:2-3:1 -4.0 -9.9795101  1.97951 0.3360790
# 2:2-3:1 -2.2 -8.1795101  3.77951 0.8608062
# 3:2-3:1  7.0  1.0204899 12.97951 0.0152655 *
# 2:2-1:2  1.8 -4.1795101  7.77951 0.9345076
# 3:2-1:2 11.0  5.0204899 16.97951 0.0000978 **
# 3:2-2:2  9.2  3.2204899 15.17951 0.0009715 **
## 需要手动挑选出显著的行; 后面的星号是我手工添加的;
TK2=as.data.frame( TK$`groupA:sexB`)
TK2[which(TK2$`p adj`<0.05),]


1) 或者boxplot可视化看一下
ggplot(data2, aes(x=groupA, y=x, fill=sexB))+
  stat_boxplot(geom='errorbar')+
  geom_boxplot()
# aes中x是一个分组，fill是第二个分组;
可见: 性别2普遍比1高; 分组123呈递增趋势;



2) 可视化方法2: 画出两两比较的置信区间;
> TK=TukeyHSD(aov2, 'groupA:sexB')
> plot(TK) #置信区间跨过0的就是没有差异的。
# 为什么有15条线? 3*2=6组，两两比较 C(6,2)=6!/(2!4!)=5*6/2=15;

# 缺点: y坐标组名字有遗漏，使用ggplot2重绘

3) 使用ggplot2重绘置信区间图
TK2=as.data.frame( TK$`groupA:sexB`)
TK2$pair=rownames(TK2); #画图的坐标
TK2$sig=cut(TK2$`p adj`, breaks=c(0,0.01, 0.05,1), labels=c('P<0.01', 'P<0.05', 'NS'), right=F)
# right=F 表示右为开区间,则[0,0.05), [0.05,1)

#版本1,
ggplot(TK2, aes(x=`p adj`, y=pair, color=sig))+
  geom_errorbarh(aes(xmin=lwr, xmax=upr))+
  geom_point(aes(x=diff))
#

#版本2: 更精细;
ggplot(TK2, aes(x=`p adj`, y=pair, color=sig))+
  geom_errorbarh(aes(xmin=lwr, xmax=upr), height=0.2)+ #bar的长度。height设置bar的高度
  geom_point(aes(x=diff))+ #点
  geom_vline(xintercept = 0, lty=2)+ #竖线，line type 线形 2为虚线
  labs(x=NULL, y=NULL, title="95% family-wise confidence level", color="Significance")+
  theme_classic()
#








3. gl()函数和两因素方差分析实例

(1) 介绍一个产生因子的函数 gl
gl(4,1,12) #n个level, k个重复，总共length个
#[1] 1 2 3 4 1 2 3 4 1 2 3 4
#Levels: 1 2 3 4

gl(4,3,12) #n个level, 
#[1] 1 1 1 2 2 2 3 3 3 4 4 4
#Levels: 1 2 3 4



(2)实例
行:销售地区（A）	列:包装方法（B）
    B1	B2	B3	B4
A1	45	75	30	40
A2	50	50	40	48
A3	35	65	50	53

X<-c(45,75,30,40,50,50,40,48,35,65,50,53)
A<-c(1,1,1,1,2,2,2,2,3,3,3,3)
#或者A<-gl(3,4)

B<-rep(c(1:4),3)
#或者B<-gl(4,1,12)

dat<-data.frame(X,A,B)

re<-aov(X~A+B,data=dat)
summary(re)
## 方差分析表
           Df Sum Sq Mean Sq F value Pr(>F)
A            2   33.2    16.6   0.145  0.868
B            3  963.6   321.2   2.809  0.130
Residuals    6  686.2   114.4  
因为P>0.05，所以A因素和B因素对食品销量没有显著影响。







========================================
方差分析(analysis of variance, 简写为ANOVA)
----------------------------------------
方差分析(analysis of variance, 简写为ANOVA)是工农业生产和科学研究中分析试验数据的一种有效的统计方法. 引起观测值不同(波动)的原因主要有两类: 一类是试验过程中随机因素的干扰或观测误差所引起不可控制的的波动, 另一类则是由于试验中处理方式不同或试验条件不同引起的可以控制的波动.

方差分析的主要工作就是将观测数据的总变异(波动)按照变异的原因的不同分解为因子效应与试验误差，并对其作出数量分析，发现多组数据之间的差异显著性，比较各种原因在总变异中所占的重要程度，以此作为进一步统计推断的依据.

在进行方差分析之前先对几条假设进行检验，由于随机抽取，假设总体满足独立、正态，考察方差齐次性（用bartlett检验）.





1.正态性检验
在进行方差分析前先对输入数据做正态性检验。
对数据的正态性，利用Shapiro-Wilk正态检验方法(W检验)，它通常用于样本容量n≤50时，检验样本是否符合正态分布。

R中，函数shapiro.test()提供了W统计量和相应P值，所以可以直接使用P值作为判断标准(P值大于0.05说明数据正态)，其调用格式为shapiro.test(x)，参数x即所要检验的数据集，它是长度在3到5000之间的向量。

(1)
nx <- c(rnorm(10));nx
#[1] -0.83241783 -0.29609562 -0.06736888 -0.02366562 0.23652392 0.97570959
#[7] -0.85301145 1.51769488 -0.84866517 0.20691119
shapiro.test(nx)
#Shapiro-Wilk normality test
#data: nx
#W = 0.9084, p-value = 0.2699

检验结果，因为p 值小于W 值，所以数据为正态分布.

(2)更多正态性检验见：R语言做正态分布检验 https://www.cnblogs.com/blueicely/archive/2013/01/08/2850929.html
其中，D检验(Kolmogorov - Smirnov)是比较精确的正态检验法。

SPSS 规定:当样本含量3 ≤n ≤5000 时,结果以Shapiro - Wilk (W 检验) 为准,当样本含量n > 5000 结果以Kolmogorov - Smirnov 为准。
SAS 规定:当样本含量n ≤2000 时,结果以Shapiro - Wilk (W 检验) 为准,当样本含量n >2000 时,结果以Kolmogorov - Smirnov (D 检验) 为准。








2. 方差齐性检验
方差分析的另一个假设：方差齐性，需要检验不同水平下的数据方差是否相等。R中最常用的是Bartlett检验,bartlett.test()调用格式为
bartlett.test(x，g…)
其中，参数X是数据向量或列表(list) ; g是因子向量，如果X是列表则忽略g.当使用数据集时，也通过formula调用函数:
bartlett.test(formala, data, subset，na.action…)
formula是形如lhs一rhs的方差分析公式;data指明数据集:subset是可选项，可以用来指定观测值的一个子集用于分析:na.action表示遇到缺失值时应当采取的行为。

> x=c(x1,x2,x3)
> account=data.frame(x,A=factor(rep(1:3,each=7)))
> bartlett.test(x~A,data=account)
# Bartlett test of homogeneity of variances
# data: x by A
# Bartlett's K-squared = 0.13625, df = 2, p-value = 0.9341
由于P值远远大于显著性水平a=0.05，因此不能拒绝原假设，我们认为不同水平下的数据是等方差的。








3. 方差分析：F-Test
In R the function var.test allows for the comparison of two variances using an F-test.Although it is possible to compare values of s2 for two samples, there is no capability within R for comparing the variance of a sample,s2,to the variance of a population, σ2. The syntax for the testing variances is :

var.test(X, Y, ratio = 1, alternative = "two.sided", conf.level = 0.95)


> std.method<-c( 21.62, 22.20, 24.27, 23.54, 24.25, 23.09, 21.01 )
> new.method<-c(21.54 ,20.51 ,22.31, 21.30, 24.62, 25.72, 21.54 ) 
> var(std.method); var(new.method) 
[1] 1.638495
[1] 3.690329
> var.test(std.method, new.method)    

	F test to compare two variances

data:  std.method and new.method
F = 0.444, num df = 6, denom df = 6, p-value = 0.3462
alternative hypothesis: true ratio of variances is not equal to 1
95 percent confidence interval:
 0.07629135 2.58395513
sample estimates:
ratio of variances 
         0.4439971

#


1）判断组间是否有差别
R中的函数aov()用于方差分析的计算，其调用格式为:
aov(formula, data = NULL, projections =FALSE, qr = TRUE,contrasts = NULL, ...)

其中的参数formula表示方差分析的公式，在单因素方差分析中即为x~A ;
data表示做方差分析的数据框:projections为逻辑值，表示是否返回预测结果;
qr同样是逻辑值，表示是否返回QR分解结果，默认为TRUE;
contrasts是公式中的一些因子的对比列表;
通过函数summary()可列出方差分析表的详细结果。


以淀粉为原料生产葡萄的过程中, 残留许多糖蜜, 可作为生产酱色的原料. 在生产酱色的过程之前应尽可能彻彻底底除杂, 以保证酱色质量.为此对除杂方法进行选择. 在实验中选用5种不同的除杂方法, 每种方法做4次试验, 即重复4次, 结果见表.
除杂方法 / 除杂量X
A1/ 25.6 22.2 28 29.8
A2/ 24.4 30.0 29.0 27.5
...


> X<-c(25.6, 22.2, 28.0, 29.8, 24.4, 30.0, 29.0, 27.5, 25.0, 27.7,
       23.0, 32.2, 28.8, 28.0, 31.5, 25.9, 20.6, 21.2, 22.0, 21.2)
> A<-factor(rep(1:5, each=4))
> miscellany<-data.frame(X, A)
> miscellany
     X A
1  25.6 1
2  22.2 1
3  28.0 1
4  29.8 1
5  24.4 2
6  30.0 2
...
> aov.mis<-aov(X~A, data=miscellany)
> aov.mis
# Call:
#    aov(formula = X ~ A, data = miscellany)
# 
# Terms:
#                       A Residuals
# Sum of Squares  131.957   114.915
# Deg. of Freedom       4        15
# 
# Residual standard error: 2.767851
# Estimated effects may be unbalanced

> summary(aov.mis)
            Df Sum Sq Mean Sq F value Pr(>F)  
A            4  132.0   32.99   4.306 0.0162 *
Residuals   15  114.9    7.66                 
---
Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

代码解释
上述结果中, Df表示自由度; sum Sq表示平方和; Mean Sq表示均方和;
F value表示F检验统计量的值, 即F比; Pr(>F)表示检验的p值; A就是因素A;
Residuals为残差.
可以看出, F = 4.3061 > F0.05(5-1, 20-5) = 3.06, 或者p=0.01618<0.05,
说明有理由拒绝原假设, 即认为五种除杂方法有显著差异.



2）如果有差别，判断是哪两组间有差别
其中，上述所得结果为5个除杂方法之间的差异显著性分析，如果假设上述5中处理中A1为对照组，其余A2,A3,A4,A5均为处理组，现在若想分析一个对照和多个处理间的差异显著性，可以通过以下代码实现：

> A1A2<-miscellany[1:8,]
> A1A2
     X A
1 25.6 1
2 22.2 1
...
> an.aov.mis<-aov(X~A, data=A1A2)
> summary(an.aov.mis)
            Df Sum Sq Mean Sq F value Pr(>F)
A            1   3.51   3.511   0.419  0.542
Residuals    6  50.31   8.385


即选取对照为一组数据，处理为另一组，缺点是对于多个处理一个对照需要重复此操作，现在还没找到好的处理办法，希望以后能学到或者有谁知道望相告。
最近总结出的另一个比较有效的办法：
接上aov()的F检验通过summary(aov.mis)看出五种除杂方法有显著差异.接下来考察具体的差异（多重比较）通过 TukeyHSD()函数：

> TukeyHSD(aov.mis)
##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = X ~ A, data = miscellany)
## 
## $A
##       diff        lwr        upr     p adj
## 2-1  1.325  -4.718582  7.3685818 0.9584566
## 3-1  0.575  -5.468582  6.6185818 0.9981815
## 4-1  2.150  -3.893582  8.1935818 0.8046644
## 5-1 -5.150 -11.193582  0.8935818 0.1140537
## 3-2 -0.750  -6.793582  5.2935818 0.9949181
## 4-2  0.825  -5.218582  6.8685818 0.9926905
## 5-2 -6.475 -12.518582 -0.4314182 0.0330240
## 4-3  1.575  -4.468582  7.6185818 0.9251337
## 5-3 -5.725 -11.768582  0.3185818 0.0675152
## 5-4 -7.300 -13.343582 -1.2564182 0.0146983
#TukeyHSD图
> plot(TukeyHSD(aov.mis))

注意：可以看出上述结果是所有分组间的两两比较，但经常我们所需要的仅仅是一个对照组和其他几个处理组间的比较，这时multcomp包是不错的选择；


a = c(56,60,44,53)
b = c(29,38,18,35)
c = c(11,25,7,18)
d = c(26,44,20,32)
strains.frame = data.frame(a, b, c, d)
strains = stack(strains.frame)  #stack是reshape2包中的一个函数，用于将宽格式数据转化为长格式；
colnames(strains) = c("weight", "group")
##常规的两两相互比较计算
TukeyHSD( aov(weight ~ group, data=strains) )
library(multcomp)
summary(glht(aov(weight ~ group, data=strains), linfct=mcp(group="Dunnett")))
## The first group ("a" in this example) is used as the reference group. 
## If this is not the case, use the relevel() command to set the reference.
strains$group = relevel(strains$group, "b")
str(strains)
head(strains)
summary(glht(aov(weight ~ group, data=strains), linfct=mcp(group="Dunnett")))
plot(glht(aov(weight ~ group, data=strains), linfct=mcp(group="Dunnett")))


More: http://barcwiki.wi.mit.edu/wiki/SOPs/anova

multcomp包部分参数解释：
glht：General Linear Hypotheses，General linear hypotheses and multiple comparisons for parametric models, including generalized linear models, linear mixed effects models, and survival models.
linfct：a specification of the linear hypotheses to be tested，即指定之前的线性model将用于何种检验。
mcp (Multiple comparisons)：多重比较的意思，For each factor, which is included in model as independent variable, a contrast matrix or a symbolic description of the contrasts can be specified as arguments to mcp，其参数意思为Tukey’s all-pair comparisons or Dunnett’s comparison with a control.


> person <- rep(c(1:10),2)
> treat <- c("A","B","A","A","B","B","A","B","A","B","B","A","B","B","A","A","B","A","B","A")
> phase <- rep(c(1,2),each=10)
> x <- c(760,860,568,780,960,940,635,440,528,800,770,855,602,800,958,952,650,450,530,803)
> data46 <- data.frame(person,treat,phase,x)
> data46$person<-factor(data46$person)
> data46
   person treat phase   x
1       1     A     1 760
2       2     B     1 860
...
> result<-aov(x~phase+person+treat,data=data46)
> summary(result)
            Df Sum Sq Mean Sq  F value   Pr(>F)    
phase        1    490     490    9.925   0.0136 *  
person       9 551111   61235 1240.195 1.32e-11 ***
treat        1    198     198    4.019   0.0799 .  
Residuals    8    395      49                      
---
Signif. codes:  0 ?**?0.001 ?*?0.01 ??0.05 ??0.1 ??1

观察p adj值发现两两二者间的方差显著性.

据上述结果可以填写下面的方差分析表:
方差来源  |自由度 /平方和 /均方和 /F比 /p值
因素A     |4  /131.95 /32.989 /4.3061 /0.01618
误差      |15 /114.915 /7.661
总和      |19 /246.872

再通过函数plot( )绘图可直观描述5种不同除杂方法之间的差异, R中运行命令
> plot(miscellany$X~miscellany$A)

从图形上也可以看出, 5种除杂方法产生的除杂量有显著差异, 特别第5种与前面的4种, 而方法1与3, 方法2与4的差异不明显。



ref:
http://www.360doc.com/content/18/0731/12/46931810_774642090.shtml








========================================
Performing a binomial test in R 二项分布检验：binom.test(nsuccesses, ntrials, p)
----------------------------------------
paper说："one-tailed binomial test"?
The global tendency for 3′ UTR shortening or lengthening in one cell cluster relative to another was tested using a one-tailed binomial test.




1. Binomial test
A binomial test compares the number of successes observed in a given number of trials with a hypothesised probability of success. The test has the null hypothesis that the real probability of success is equal to some value denoted p, and the alternative hypothesis that it is not equal to p. The test can also be performed with a one-sided alternative hypothesis that the real probability of success is either greater than p or that it is less than p.

二项检验将在给定数量的试验中观察到的成功数量与假设的成功概率进行比较。
零假设是：观察值的真实概率等于一个给定的p，备择假设是不等于p。
该检验也可以进行单边备择检验，看p是大于或者小于p。

(1)
> binom.test(nsuccesses, ntrials, p) # 成功的观察数, 实验次数, 假设的p值
where nsuccesses is the number of successes observed, 
ntrials is the total number of trials 
and p is the hypothesised probability of success.

(2)
Alternatively you can give the number of successes and the number of failures observed, as shown below.
> binom.test(c(nsuccesses, nfailures), p) #(c(成功数, 失败数), 概率)

(3)To perform a one-sided test, set the alternative argument to "less" or "greater" as required.
> binom.test(nsuccesses, ntrials, p, alternative="greater") #单边检验


(4)The output includes a 95% confidence interval for the true probability. To adjust the size of this interval, use the conf.level argument as shown.

> binom.test(nsuccesses, ntrials, p, conf.level=0.99) #指定阈值






2. 实例 
(1)Example1: Binomial test for die(色子) rolls
In a game, you suspect your opponent is using a die which is biased to roll a six greater than 1/6 of the time. Suppose you want to prove this by rolling the die 300 times and using a binomial test to determine whether the probability of rolling a six is equal to 1/6. A one-tailed test with a significance level of 0.05 will be used.

你怀疑对手用的色子投出6的概率超过1/6。
你做了一个实验，投300次，看出现6的概率是否等于1/6。
在0.05水平，单尾检验。

You roll the die 300 times and throw a total of 60 sixes. To perform the test, use the command:

> binom.test(60, 300, 1/6, alternative="greater")

## Exact binomial test
## 
## data:  60 and 300
## number of successes = 60, number of trials = 300, p-value = 0.07299
## alternative hypothesis: true probability of success is greater than 0.1666667
## 95 percent confidence interval:
##  0.1626847 1.0000000
## sample estimates:
## probability of success 
##                    0.2

From the output you can see that the p-value is 0.07299. As this is not less that the significance level of 0.05, we cannot reject the null hypothesis that the probability of rolling a six is 1/6. This means that there is no evidence to prove that the die is not fair.
p>0.05，无法拒绝原假设。也就是没有证据表明色子不公平。



(2) 文献判断是否倾向于缩短？
https://www.sciencedirect.com/science/article/pii/S1097276519309529?via%3Dihub
(Seung WookYang, Molecular Cell, 2020) Fig.4A, 213 55

> binom.test(55, 213+55, 0.5, conf.level=0.99) 
p-value < 2.2e-16






http://www.instantr.com/2012/11/06/performing-a-binomial-test/





========================================
卡方检验 chi-squared tests: 列联表也称为 contingency table, 拟合优度检验
----------------------------------------
x2检验（chi-square test） http://www.cnblogs.com/emanlee/archive/2008/10/25/1319569.html


1.有两类：
There are two types of chi-square tests. Both use the chi-square statistic and distribution for different purposes:

(1)卡方拟合优度检验 chi-square goodness of fit test determines if a sample data matches a population. For more details on this type, see: Goodness of Fit Test.

(2)卡方独立性检验 A chi-square test for independence compares two variables in a contingency table to see if they are related. In a more general sense, it tests to see whether distributions of categorical variables differ from each another.

- A very small chi square test statistic means that your observed data fits your expected data extremely well. In other words, there is a relationship.
- A very large chi square test statistic means that the data does not fit very well. In other words, there isn’t a relationship.

The formula for the chi-square statistic used in the chi square test is:
卡方和 = 求和(i=1 to n) (O-E)**2 /E
- “O” is your observed value and 
- E is your expected value. 

检查自由度df=(row-1)*(col-1),p=0.05的临界值。

https://blog.csdn.net/flowingflying/article/details/8076296
实际观察次数O与某理论次数(E又称期望次数)之差的平方再除以理论次数乃是一个与抽样分布之一的χ2分布非常近似的次数分布。

如同n足够大是，二项分布和正态分布非常吻合一样，这里也不做理解证明，由法国数学家Pearson给出，就当给了个工具，我们相信工具有效，来使用工具，常用于检查出现频率。





2. 实例: 独立性检验
数据: 夫妻家务劳动分工
	Wife	Alternating	Husband	Jointly
Laundry	156	14	2	4
Main_meal	124	20	5	4
Dinner	77	11	7	13
Breakfeast	82	36	15	7
Tidying	53	11	1	57
Dishes	32	24	4	53
Shopping	33	23	9	55
Official	12	46	23	15
Driving	10	51	75	3
Finances	13	13	21	66
Insurance	8	1	53	77
Repairs	0	3	160	2
Holidays	0	1	6	153

# Import the data
file_path <- "http://www.sthda.com/sthda/RDoc/data/housetasks.txt"
housetasks <- read.delim(file_path, row.names = 1)
# head(housetasks)

#1画图
#install.packages("gplots")
library("gplots")
# 1. convert the data as a table
dt <- as.table(as.matrix(housetasks))
# 2. Graph
balloonplot(t(dt), main ="housetasks", xlab ="", ylab="",
            label = FALSE, show.margins = FALSE)
#2马赛克图
library("graphics")
mosaicplot(dt, shade = TRUE, las=2, main = "housetasks")
#3又一个可视化
# install.packages("vcd")
library("vcd")
# plot just a subset of the table
assoc(head(dt, 5), shade = TRUE, las=3)


#做卡方检验，只需要一句
chisq <- chisq.test(housetasks)
chisq
## 	Pearson's Chi-squared test
## 
## data:  housetasks
## X-squared = 1944.5, df = 36, p-value < 2.2e-16
结论： p<0.05，拒绝零假设，也就是行和列相关，夫妻和做的家务有明确对应关系。





探究哪些因素对卡方的贡献：
str(chisq)
chisq$observed #观察值
round(chisq$expected,2) #期望值

#
# Pearson residuals (r): r=(o-e)/sqrt(e)
round(chisq$residuals, 3)

#
# 残差图: 正相关blue，表示行和列有正关联。负相关red
library(corrplot)
corrplot(chisq$residuals, is.cor = FALSE)
## For a given cell, the size of the circle is proportional to the amount of the cell contribution.


#每个cell对卡方值的贡献 contrib=r**2/卡方
# Contibution in percentage (%)
contrib <- 100*chisq$residuals^2/chisq$statistic
round(contrib, 3)
# Visualize the contribution
corrplot(contrib, is.cor = FALSE)





3. 实例： 拟合优度检验
http://www.sthda.com/english/wiki/chi-square-goodness-of-fit-test-in-r

The chi-square goodness of fit test is used to compare the observed distribution to an expected distribution, in a situation where we have two or more categories in a discrete data. In other words, it compares multiple observed proportions to expected probabilities.
比较每一份的比例，是否和期望的概率一致。


Suppose that, in the region where you collected the data, the ratio of red, yellow and white tulip is 3:2:1 (3+2+1 = 6). This means that the expected proportion is:
3/6 (= 1/2) for red
2/6 ( = 1/3) for yellow
1/6 for white


R语言：
tulip <- c(81, 50, 27) #实际抽样的结果
res <- chisq.test(tulip, p = c(1/2, 1/3, 1/6))
res

## 	Chi-squared test for given probabilities
## 
## data:  tulip
## X-squared = 0.20253, df = 2, p-value = 0.9037
p>0.05，无法拒绝零假设。也就是认为采样符合期望的比例。


#拿到p值
res$p.value #[1] 0.9036928




描述： https://www.statisticshowto.datasciencecentral.com/probability-and-statistics/chi-square/
R语言： http://www.sthda.com/english/wiki/chi-square-test-of-independence-in-r



========================================
|-- Fisher’s Exact Test in R (代替卡方检验，2x2列联表 计数比较少的时候)
----------------------------------------
1.Fisher’s Exact Test is a test of significance that is used in place of a Chi Square Test in 2×2 tables when the sample sizes are small.

This tutorial explains how to conduct Fisher’s Exact Test in R.
https://www.statology.org/how-to-conduct-fishers-exact-test-in-r/


#step1 create 2x2 dataset
data = matrix(c(2,5,9,4), nrow = 2)
#view dataset
data
# 2 9
# 5 4
#step2 To conduct Fisher’s Exact Test, we simply use the following code:
fisher.test(data)
#
#	Fisher's Exact Test for Count Data
#
#data:  data
#p-value = 0.1597
#alternative hypothesis: true odds ratio is not equal to 1
#95 percent confidence interval:
# 0.0130943 1.8397543
#sample estimates:
#odds ratio 
# 0.1957871 



In Fisher’s Exact Test, the null hypothesis is that the two columns are independent (or equivalently, that the odds ratio is equal to 1). To determine if the two columns are independent, we can look at the p-value of the test. In this case the p-value is 0.1597, which tells us we do not have sufficient evidence to reject the null hypothesis. Thus, we cannot say that there is any statistically significant difference between the two columns.
原假设是两列是独立的，或者说 odds ratio 是1。
为了检验两列是否独立，可以看p值。本例中p=0.1597，并不能拒绝原假设。
我们不能说两列有显著差异。

Note that the odds ratio is 0.1957871. Since the p-value of the test is 0.1597, this tells us that the odds ratio is not significantly different than 1.
因为p不显著，odds ratio 是 0.1957871，和1没有显著差异。

The output of the test also gives us a 95% confidence interval for the odds ratio, which is:
(0.0130943, 1.8397543)

Since the number “1” is within this ratio, it confirms that the odds ratio is not significantly different than 1 (assuming we use alpha level 0.05).







2.Fisher’s Exact Test of Independence
https://rcompanion.org/rcompanion/b_07.html


### Chipmunk example, Fisher’s exact test, p. 80
Input =("
        Distance    Trill  No.trill
        10m        16     8
        100m        3    18
        ")
Matriz = as.matrix(read.table(textConnection(Input),
                              header=TRUE,
                              row.names=1))
Matriz
#     Trill No.trill
#10m     16        8
#100m     3       18
fisher.test(Matriz, alternative="two.sided")

#	Fisher's Exact Test for Count Data
#
#data:  Matriz
#p-value = 0.0006862
#alternative hypothesis: true odds ratio is not equal to 1
#95 percent confidence interval:
#  2.32073 77.46500
#sample estimates:
#odds ratio 
#  11.23249







3. 使用情况
(1).  All cells are having >=5, then you can use Chi-Square test. 
(2).  If any cell having <5, then you have to use the Fisher's Exact Test.
(3).  If any one cell having =0, then you can use the Yates' Chi-Square test.








http://www.utstat.toronto.edu/~brunner/oldclass/312f12/lectures/312f12FisherWithR.pdf








========================================
****** 非参数检验: Wilcoxon 检验之 rank-sum(秩和检验，独立样本) test( 也叫 Mann-whitney U test)， 及R/Python代码/手工计算
----------------------------------------

https://www.sciencedirect.com/topics/medicine-and-dentistry/rank-sum-test



1. 定义和区别
Wilcoxon rank-sum test（秩和检验）和 Wilcoxon signed-rank test（符号秩检验）。

Frank Wilcoxon (1892—1965) 是美国的统计学家，发表了 70 篇左右论文，但其最大的贡献就是这 2 个以他名字命名的非参假设检验方法：秩和检验 和 符号秩检验。
他在 1945 年发表的论文 1 中将二者分别称为 非成对检验 （unpaired experiment）和 成对检验（paired comparison）。 正是因为其巨大影响力使得这两个检验方法都以他的名字命名，并流传下来。


假设检验有点类似于我们高中数学中常见的“反证法”，即提出一个错误的假设，然后证明它是错的。那么我们提出的假设叫做 原假设 (Null Hypothesis)，简写为 H0，应为一般假设没有区别，也叫零假设，承认没有区别。
我们备选的假设叫做 备选假设 (Alternative Hypothesis)，简写为 Hα或H1。是零假设的否定，也就是有差别。
注意，在假设检验中只有 2 个假设，即原假设和备选假设，我们的目的就是要拒绝原假设。



(1). Nonparametric Comparison of Two Groups:
Mann–Whitney Test
If the measurement values from two groups are not normally distributed we have to resort to a nonparametric test. 
The most common nonparametric test for the comparison of two independent groups is the Mann–Whitney(–Wilcoxon) test.

Watch out, because this test is sometimes also referred to as Wilcoxon rank-sum test. 
This is different from the Wilcoxon signed rank sum test! 
注意和Wilcoxon signed rank sum test不同！

The test-statistic for this test is commonly indicated with u:
u_statistic, pVal = stats.mannwhitneyu(group1, group2)



(2).Wilcoxon rank-sum test 定义如下，

In statistics, the Mann–Whitney U test (also called the Mann–Whitney–Wilcoxon (MWW), Wilcoxon rank-sum test, or Wilcoxon–Mann–Whitney test) is a nonparametric test.
This test can be used to determine whether two independent samples were selected from populations having the same distribution. 2

概念： 在统计学中，Wilcoxon rank-sum test（威尔科克森秩和检验）也叫 Mann-Whitney U test（曼-惠特尼 U 检验），或者 Wilcoxon-Mann-Whitney test。

秩和检验是一个非参的假设检验方法，一般用来检测 2 个数据集是否来自于相同分布的总体。特别地，秩和检验不要求 2 个数据集大小相同，也就是说进行秩和检验并不是两两成对比较，这一点区别于下面描述的符号秩检验。




(3) 使用场景
秩和检验 和 符号秩检验。作者将二者分别称为 非成对检验 （unpaired experiment）和 成对检验（paired comparison）。

Mann–Whitney U test也叫回Wilcoxon rank-sum test，应用于两个independent samples的情况。
Wilcoxon signed-rank test(符号秩检验)应用于两个related samples(成对检验)。


samples size小的时候，是有列表的，sample size大到20左右时，就可以使用正态分布来近似，不查表了

一般来说，成组数据的t检验和方差分析比秩和检验更准确，这是由于秩和检验只利用了排序的位置信息，没有利用差值的大小。
但是秩和检验可以用于更广泛，比如总体非正态、定性数据等。




(4).对分组变量的差异显著性检验是微生物生态数据分析中常见的内容。

T-test是最为常用的检验方法，但t-test要求数据符合正态分布，在不符合正态分布的时候检验准确性要大打折扣。检验数据是否符合正态分布的方法可见往期推文“看SPSS如何检验数据是否服从正态分布”。如果被检数据不符合正态分布怎么办呢？

Wilcoxon test无需数据服从正态分布，适合在数据总体方差未知或知道甚少的情况下使用。
相应的缺点是，在数据符合正态分布的情况下，检验的准确性要比t-test低。下面介绍如何在R中实现Wilcoxon test。


曼-惠特尼U检验又称“曼-惠特尼秩和检验”，是由H.B.Mann和D.R.Whitney于1947年提出的。
它假设两个样本分别来自除了总体均值以外完全相同的两个总体，目的是检验这两个总体的均值是否有显著的差别。

Mann-Whitney U 检验是用得最广泛的两独立样本秩和检验方法。简单的说，该检验是与独立样本t检验相对应的方法，当正态分布、方差齐性等不能达到t检验的要求时，可以使用该检验。
其假设基础是：若两个样本有差异，则他们的中心位置将不同。

wilcoxon秩和及wilcoxon符号秩检验是对原假设的非参数检验，在不需要假设两个样本空间都为正态分布的情况下，测试它们的分布是否完全相同。












2.利用R进行Mann-Whitney U test检验(wilcox.test)：

Wilcoxon test使用方法和t-test类似，在R中输入‘?wilcox.test()’即可查看使用方法。如下：
Description: Performs one- and two-sample Wilcoxon tests on vectors of data; the latter is also known as ‘Mann-Whitney’ test.

Usage:wilcox.test(x, ...)


(1)## Default S3 method:
wilcox.test(x, y = NULL,
            alternative = c("two.sided", "less", "greater"),
            mu = 0, paired = FALSE, exact = NULL, correct = TRUE,
            conf.int = FALSE, conf.level = 0.95, ...)
#
非配对数据，样本个数不一定一样，比较均值大小。在R中执行wilcox.test(x, y, alternative ='two.sided')。
这里两处理的样品数目可以不等。我们不知道x和y谁大谁小，所以我们选择双尾检验（‘two.sided’）。如果要验证x是否显著大于y，可以选择‘greater’；验证x是否显著小于y，可以选择‘less’。
#
处理前后的配对数据，比较均值大小。则在R中执行wilcox.test(x, y, alternative ='two.sided',paired=T)。
这里各样品处理前后数据要一一对应，数目相等。同样地，用‘greater’或‘less’可以验证x是否显著大于或小于y。

(2)## S3 method for class 'formula'
wilcox.test(formula, data, subset, na.action, ...)



因为有公式，还是看原文好。
有书了尽量看书。
refer:
1.https://blog.csdn.net/qq_34734303/article/details/80296316
2.https://www.jianshu.com/p/8c0e7ce7a290








3.实例
########
# 考虑秩排列的2种极端情况
#1) 绝对分离
R1=sum(1:5)  #15
R2=sum(6:10) #40
#
U1=5*5+5*6/2-R1=25
U1=5*5+5*6/2-R2=0
U=min(U1,U2)=0

#2) 绝对均匀
R1=sum(c(1,3,5,7,9)) #25
R2=sum(c(2,4,6,8,10)) #30
#
U1=5*5+5*6/2-R1=15
U1=5*5+5*6/2-R2=10
U=min(U1,U2)=10
# 结论: U越小越差异，U越大越接收H0认为无差异。

这个也要看分布曲线确定方向。
如果在左侧尾，则 P-value = 2 pr(WA ≤ wA),
如果在右侧尾，则 P-value = 2 pr(WA ≥ wA),


#3) 画密度曲线，看U分布在哪一侧
(function(){
  x=1:60
  y=dwilcox(x, 7,9) #后2个参数是2个组数据量n1,n2
  plot(x,y, type='o', ylab='Density')
})()






##### (1). 在R中利用wilcox.test函数进行曼-惠特尼U检验Mann–Whitney U Test。
用来检验两组独立样品是否来自两组不同的样品。不要求样本数量必须相等。
t检验假设两个样本的数据集之间的差别符合正态分布（当两个样本集都符合正态分布时，t检验效果最佳）


例1: 一般形式
boxplot(mtcars$mpg~mtcars$am, ylab='mpg', names = c('automatic','manual'))
## 手动、自动挡mpg每英里耗油量。

#执行wilcoxon秩和检验验证自动档手动档数据分布是否一致
## wilcox.test(mtcars$mpg[mtcars$am==0],mtcars$mpg[mtcars$am==1])（与下面等价）
> wilcox.test(mpg ~ am, data=mtcars)
## 	Wilcoxon rank sum test with continuity correction
## data:  mpg by am
## W = 42, p-value = 0.001871
## alternative hypothesis: true location shift is not equal to 0

原假设为两种变速器的油耗完全相同，p-value小于0.05，拒绝原假设，意味着两种变速器的油耗有显著差异。




例2: Formula interface.
boxplot(Ozone ~ Month, data = airquality)
wilcox.test(Ozone ~ Month, data = airquality, subset = Month %in% c(5, 8)) ## 看5月和8月是否有显著区别？
##
	Wilcoxon rank sum test with continuity correction
data:  Ozone by Month
W = 127.5, p-value = 0.0001208
alternative hypothesis: true location shift is not equal to 0
## p<0.05，拒绝零假设，也就是两组有显著差别。



例3: 表达式形式
s1<-c(6,1,1,1,1,1)
s2<-c(5,5,5,5,5,0)
s<-c(s1,s2)
type<-c(rep(1,6),rep(2,6))
wd<-as.data.frame(cbind(s,as.factor(type)))
wilcox.test(s~type,data=wd)
#Wilcoxon rank sum test with continuity correction
#
#data:  s by type
#W = 11, p-value = 0.2617
#alternative hypothesis: true location shift is not equal to 0

根据结果显示，p-value值大于0.05，无法否定零假设，认为两个样品无显著差异。











4. 手工计算

例1: ( https://www.stat.auckland.ac.nz/~wild/ChanceEnc/Ch10.wilcoxon.pdf )

Native_American=c(8.50, 9.48, 8.65, 8.16, 8.83, 7.76, 8.63)
Caucasian=c( 8.27, 8.20, 8.25, 8.14, 9.00, 8.10, 7.20, 8.32, 7.70 )
#

# 整理数据
a1=Native_American
a2=Caucasian
#
df=data.frame(
  value=c(a1, a2),
  group=c(rep('a1', length(a1)), rep('a2', length(a2)))
)
df$rank=rank(df$value, ties.method ="average" )
head(df)
df

#step1: 计算两组的秩和(R1, R2)和数量(n1,n2)
rs=sapply(split(df,df$group), function(x){
  c( nrow(x), sum(x[3]) )
});rs
#     a1 a2
#[1,]  7  9
#[2,] 75 61


# step2: 计算U1和U2
u1=n1*n2+n1(n1+1)/2-R1=7*9+7*8/2-75=16
u2=n1*n2+n2(n2+1)/2-R2=7*9+9*10/2-61=47


或者: 令T表示样本小的秩和，T=R1=75，根据公式计算：
U1=n1*n2 + n1*(n1+1)/2 -T=7*9+7*8/2-75=16
U2=n1*n2 -U1=7*9-16=47
#
## 有一个性质： U1+U2=n1*n1;
#

# 较小的记为U
U=min(u1, u2)=16


# 画密度曲线，看U分布在哪一侧
(function(){
  x=1:60
  y=dwilcox(x, 7,9)
  plot(x,y, type='o', ylab='Density')
})()


#step3: 查wilcox双尾分布表，alpha=0.05,n1=7,n2=9时
qwilcox(0.05, 7, 9, lower.tail =F) #[1] 47
qwilcox(0.05, 7, 9, lower.tail =T) #[1] 16
# 16在峰左侧，正好压着临界点，怎么办？


pwilcox(16, 7, 9, lower.tail =T)
pwilcox(16, 7, 9) #0.05708042
p_value=2*P(U<=u)=2*pwilcox(16, 7, 9) #0.1141608
# 无法拒绝原假设。也即是没有显著差异。


#########使用R函数直接计算p值
wilcox.test(df$value ~ df$group)
# Wilcoxon rank sum test
# data:  df$value by df$group
# W = 16, p-value = 0.1142
# alternative hypothesis: true location shift is not equal to 0









例2：
x1=c(9,5,8,7,10,6,7) #n1=7个元素
x2=c(7,4,5,6,3,6,4,4) #n2=8个元素

step1: 排序，记下每个数的顺序
遇到相同的数字，则他们的rank取平均rank。
计算rank之和
R1=sum( c(14,5.5,13,11,15,8,11) )=77.5
R2=sum( c(11,3,5.5,8,1,8,3,3) )=42.5

step2:令T表示样本小的秩和，T=R1=77.5，根据公式计算：
U1=n1*n2 + n1*(n1+1)/2 -T=6.5
U2=n1*n2 -U1=49.5
U=min(U1,U2)=6.5

step3: 查Wilcoxon双尾临界表，当alpha=0.05，n1=7,n2=8的临界值是10.
由于U=6.5<10，所以拒绝原假设。

或者直接计算p值: 2*pwilcox(6.5, 7, 8) #0.009324009 ##?? 这个p值还是和函数直接算出来的不一致，why?

结论：x1和x2存在显著性差异，他们来自不同的总体。


1)Python中使用scipy包的stats.mannwhitneyu() 函数来实现秩和检验
from scipy import stats
def wilcoxon_rank_sum_test(x, y):
    res = stats.mannwhitneyu(x ,y)
    print(res)

x=[9,5,8,7,10,6,7]
y=[7,4,5,6,3,6,4,4]
wilcoxon_rank_sum_test(x,y)
## MannwhitneyuResult(statistic=6.5, pvalue=0.006966479792405637)
得到的统计量，就是我们的U1值。 
结论：p<0.05,拒绝零假设，有显著差异。



2) R语言版本:
x=c(9,5,8,7,10,6,7)
y=c(7,4,5,6,3,6,4,4)
wilcox.test(x,y)
## 
# Wilcoxon rank sum test with continuity correction
# data:  x and y
# W = 49.5, p-value = 0.01393
#alternative hypothesis: true location shift is not equal to 0
#
## 怎么做连续性矫正？ //todo
#
wilcox.test(x,y, correct=F)
## Wilcoxon rank sum test
## data:  x and y
## W = 49.5, p-value = 0.01182
## alternative hypothesis: true location shift is not equal to 0





ref:
The Wilcoxon Rank Sum Test: https://data.library.virginia.edu/the-wilcoxon-rank-sum-test/
https://github.com/thomas-haslwanter/statsintro_python/tree/master/ISP/Code_Quantlets/08_TestsMeanValues/twoGroups

Mann Whitney U Test (Wilcoxon Rank Sum Test): https://sphweb.bumc.bu.edu/otlt/MPH-Modules/BS/BS704_Nonparametric/BS704_Nonparametric4.html




========================================
|-- Wilcoxon 检验之 signed-rank(符号秩检验，配对样本) test
----------------------------------------
##############
# 配对数据
##############

1. Wilcoxon 符号秩检验, 配对数据。最好20组数据以上。
根据 wikipedia 解释， Wilcoxon signed-rank test 定义如下，

A Wilcoxon signed-rank test is a nonparametric test that can be used to determine whether two dependent samples were selected from populations having the same distribution. 

概念： Wilcoxon signed-rank test（威尔科克森符号秩检验）也是一种非参的假设检验方法，它成对的检查 2 个数据集中的数据（即 paired difference test）来判断 2 个数据集是否来自相同分布的总体。



### 例题(1) 威尔科克森符号秩检验实现(处理前后、配对数据)
配对样本，均匀分布，非正太分布: Wilcoxon signed-rank test, 用来进行配对样品的非参数检验。

# 一个样本：使用药物前后病情指数，配对样本。
x <- c(1.83,  0.50,  1.62,  2.48, 1.68, 1.88, 1.55, 3.06, 1.30)
y <- c(0.878, 0.647, 0.598, 2.05, 1.06, 1.29, 1.06, 3.14, 1.29)
wilcox.test(x, y, paired = TRUE, alternative = "greater") #要指定单尾测试，我们将替代参数设置为greater。
wilcox.test(y - x, alternative = "less")    # The same.
wilcox.test(y - x, alternative = "less",
            exact = FALSE, correct = FALSE) # H&W large sample
# approximation
## Wilcoxon signed rank test
## data:  x and y
## V = 40, p-value = 0.01953
## alternative hypothesis: true location shift is greater than 0
p<0.05，拒绝零假设，因此治疗前后是有显著差异的。





### 例题(2) 
ID	y1  y2 sign abs rank
0	125	110	+1	15	7
1	115	122	-1	7	3
2	130	125	+1	5	1.5
3	140	120	+1	20	9
4	140	140	-	0	-
5	115	124	-1	9	4
6	140	123	+1	17	8
7	125	137	-1	12	6
8	140	135	+1	5	1.5
9	135	145	-1	10	5


step1: 配对数据求差，求绝对值abs，按照abs排序得到rank列。
对于abs=0的，舍弃，如ID=4的行。因为零假设的差异是0为中心的，观察值恰好是0不能提供决绝零假设的信息。过多，则降低统计功效。
对于abs相同的，取rank的平均值，如ID=2和8的行，(1+2)/2


step2: 根据sign列和rank列，分别计算大于0的秩和Wplus，和小于0的秩和Wminus。
Wplus=7+1.5+9+8+1.5=27
Wminus=3+4+6+5=18
## 感觉这个不准： 最终的秩 W=abs(Wplus - Wminus)=9
## 这个靠谱：在零假设下，W+和W-应差不多。因而，当其中之一很小时，应怀疑零假设。在此，取检验统计量W=min(W+,W-)=18


step3: 根据W，查表，alpha=0.05, n=9时的临界值是5，而我们计算出的W=9>5，因此不能拒绝原假设。//why?需要看概率分布图
结论：y1和 y2无显著性差异，他们来自于分布相同的总体。








2. 代码实现

(1)在 python 中我们调用 scipy 包来里的 stats.wilcoxon() 函数来实现秩和检验
from scipy import stats
def wilcoxon_signed_rank_test(y1, y2):
    res = stats.wilcoxon(y1, y2)
    print(res)
#
y1=[125, 115, 130, 140, 140, 115, 140, 125, 140, 135]
y2=[110, 122, 125, 120, 140, 124, 123, 137, 135, 145]
wilcoxon_signed_rank_test(y1,y2)
###
#  UserWarning: Warning: sample size too small for normal approximation.
#   warnings.warn("Warning: sample size too small for normal approximation.")
WilcoxonResult(statistic=18.0, pvalue=0.5936305914425295)

给出的统计量18就是min(Wplus, Wminus).
p=0.59>0.05, 无法拒绝原假设，也就是可能无差异。


如果p值较小(比如小于或等于给定的显著性水平，譬如0.05)则可以拒绝零假设。
如果p值较大则没有充分的证据来拒绝零假设，但不意味着接受零假设。


之所以出现 Warning 信息是因为我们的数据量太少，一般来讲大于 20 是比较合适做假设检验的。





(2)R 语言版本：
y1=c(125, 115, 130, 140, 140, 115, 140, 125, 140, 135)
y2=c(110, 122, 125, 120, 140, 124, 123, 137, 135, 145)
wilcox.test(y1, y2, paired = TRUE, alternative = "greater")
###
# Wilcoxon signed rank test with continuity correction
# data:  y1 and y2
# V = 27, p-value = 0.3176
# alternative hypothesis: true location shift is greater than 0
#
wilcox.test(y1 - y2, alternative = "greater", exact = F, correct = F) #不矫正



为什么R和手算、Python版本的P值都不一样呢？




refer
https://blog.csdn.net/chikily_yongfeng/article/details/82255575
Wikipedia. Wilcoxon rank-sum test. link: https://en.wikipedia.org/wiki/Mann-Whitney_U_test
Wikipedia. Wilcoxon signed-rank test. link: https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test
https://blog.csdn.net/weixin_34067980/article/details/85890225






========================================
|-- Kruskal-Wallis Test 单因素方差分析的非参版/ 两样本Wilcoxon检验的多样本版
----------------------------------------
Kruskal-Wallis Test in R
http://www.sthda.com/english/wiki/kruskal-wallis-test-in-r

Kruskal-Wallis test by rank is a non-parametric alternative to one-way ANOVA test, which extends the two-samples Wilcoxon test in the situation where there are more than two groups. It’s recommended when the assumptions of one-way ANOVA test are not met. This tutorial describes how to compute Kruskal-Wallis test in R software.

## Kruskal-Wallis rank sum test?



1. Kruskal-Wallis Test
http://www.r-tutor.com/elementary-statistics/non-parametric-methods/kruskal-wallis-test

A collection of data samples are independent if they come from unrelated populations and the samples do not affect each other. Using the Kruskal-Wallis Test, we can decide whether the population distributions are identical without assuming them to follow the normal distribution.

例子:
在名为 airquality 的内置数据集中，记录了纽约1973年5月至9月的每日空气质量测量数据。臭氧密度在数据框中 Ozone 列。
> head(airquality) 
  Ozone Solar.R Wind Temp Month Day 
1    41     190  7.4   67     5   1 
2    36     118  8.0   72     5   2 
    .....

Problem问题
Without assuming the data to have normal distribution, test at .05 significance level if the monthly ozone density in New York has identical data distributions from May to September 1973.
不用假设数据符合正态分布，检验每月抽样浓度分布是否在0.05显著性水平上一致？

Solution解答
The null hypothesis is that the monthly ozone density are identical populations. To test the hypothesis, we apply the kruskal.test function to compare the independent monthly data. The p-value turns out to be nearly zero (6.901e-06). Hence we reject the null hypothesis.
零假设：每月抽样浓度是相同的总体。
为了检验，使用 kruskal.test 函数，检验每月数据的独立性，p值很小接近于零。所以拒绝零假设。

> kruskal.test(Ozone ~ Month, data = airquality) 
#
#        Kruskal-Wallis rank sum test 
# 
#data:  Ozone by Month 
#Kruskal-Wallis chi-squared = 29.267, df = 4, p-value = 6.901e-06

Answer答案
At .05 significance level, we conclude that the monthly ozone density in New York from May to September 1973 are nonidentical populations.
每月的分布不是相同的。






2.Kruskal-Wallis Test
https://www.statisticssolutions.com/kruskal-wallis-test/

The Kruskal-Wallis test is a nonparametric (distribution free) test, and is used when the assumptions of one-way ANOVA are not met.  
非参数检验，适用于 one-way ANOVA 条件达不到的情形。

Both the Kruskal-Wallis test and one-way ANOVA assess for significant differences on a continuous dependent variable by a categorical independent variable (with two or more groups).  
Kruskal-Wallis test and 单因素方差分析用来评估在一个分类独立变量(2组或更多组)时，一个连续的因变量的显著差异，

In the ANOVA, we assume that the dependent variable is normally distributed and there is approximately equal variance on the scores across groups. However, when using the Kruskal-Wallis Test, we do not have to make any of these assumptions.  
ANOVA 假设因变量是正态分布的，组间变异程度近似。而Kruskal-Wallis检验不需要这些假设。

Therefore, the Kruskal-Wallis test can be used for both continuous and ordinal-level dependent variables.  However, like most non-parametric tests, the Kruskal-Wallis Test is not as powerful as the ANOVA.
所以，Kruskal-Wallis test 可以用于连续性或者排序型因变量。然而，和大多数非参数检验一样，效力比不上ANOVA。


Null hypothesis: Null hypothesis assumes that the samples (groups) are from identical populations.
零假设：每组样品都来自同一个总体。

Alternative hypothesis: Alternative hypothesis assumes that at least one of the samples (groups) comes from a different population than the others.


Example questions answered:
i)How do test scores differ between the different grade levels in elementary school?
ii)Do job satisfaction scores differ by race?

The distribution of the Kruskal-Wallis test statistic approximates a chi-square distribution, with k-1 degrees of freedom, if the number of observations in each group is 5 or more.  If the calculated value of the Kruskal-Wallis test is less than the critical chi-square value, then the null hypothesis cannot be rejected.  If the calculated value of Kruskal-Wallis test is greater than the critical chi-square value, then we can reject the null hypothesis and say that at least one of the samples comes from a different population.
和自由度为1的卡方检验近似，如果每组观测值>=5。
如果p很小，否定原假设，就是至少一个组来自另一个总体。

Assumptions
1. We assume that the samples drawn from the population are random.
2. We also assume that the observations are independent of each other.
3. The measurement scale for the dependent variable should be at least ordinal.







3.Kruskal-Wallis test (H-test) 是 Wilcoxon test 的延伸，用于检验一系列非配对数据是否来自于同一个总体。
The Kruskal-Wallis test (H-test) is an extension of the Wilcoxon test and can be used to test the hypothesis that a number of unpaired samples originate from the same population. 

In MedCalc, Factor codes are used to break-up the (ordinal) data in one variable into different sample subgroups. If the null-hypothesis, being the hypothesis that the samples originate from the same population, is rejected (P<0.05), then the conclusion is that there is a statistically significant difference between at least two of the subgroups.

https://www.medcalc.org/manual/kruskal-wallis_test.php






========================================
|-- Kolmogorov-Smirnov (K-S) test: 检验2个分布是否有差异 (非参)
----------------------------------------
KS 检验一般配合画 累计曲线 cumulative fraction curve: 
https://tool.biomooc.com/R_scripts/index.html#t17



1. K-S 检验简介

Kolmogorov-Smirnov是比较一个频率分布f(x)与理论分布g(x)或者两个观测值分布的检验方法。
其原假设H0:两个数据分布一致或者数据符合理论分布。
D=max| f(x)- g(x)|，当实际观测值D>D(n,α)则拒绝H0，否则则接受H0假设。

KS检验与t-检验之类的其他方法不同是KS检验不需要知道数据的分布情况，可以算是一种非参数检验方法。当然这样方便的代价就是当检验的数据分布符合特定的分布事，KS检验的灵敏度没有相应的检验来的高。在样本量比较小的时候，KS检验作为非参数检验在分析两组数据之间是否不同时相当常用。

PS：t-检验的假设是检验的数据满足正态分布，否则对于小样本不满足正态分布的数据用t-检验就会造成较大的偏差，虽然对于大样本不满足正态分布的数据而言t-检验还是相当精确有效的手段。



K-S test 是检验单一样本是否来自某一特定分布的方法。比如检验一组数据是否为正态分布。它的检验方法是以样本数据的累计频数分布与特定理论分布比较，若两者间的差距很小，则推论该样本取自某特定分布族。即对于假设检验问题：

H0:样本所来自的总体分布服从某特定分布
H1:样本所来自的总体分布不服从某特定分布


KS检验使用的是两条累计分布曲线之间的最大垂直差作为D值（statistic D）作为描述两组数据之间的差异。




(1) Kolmogorov-Smirnov正态性检验
这里我们仅以Kolmogorov-Smirnov正态性检验为例介绍它的统计原理。

F0(x)表示分布的分布函数，Fn(x)表示一组随机样本的累计概率函数。设D为F0(x)与Fn(x)差距的最大值，定义如下式：
D=max|Fn(x)-F0(x)|
结论：当实际观测D>Dα（查表），则接受H1,反之则不拒绝H0假设。

例如：35位健康男性在未进食前的血糖浓度如表所示，试测验这组数据是否来自均值μ=80，标准差σ=6的正态分布
87 77 92 68 80 78 84 77 81 80 80 77 92 86 76 80 81 75 77 72 81 90 84 86 80 68 77 87 76 77 78 92 75 80 78  n=35

检验过程如下：
假设
H0: 健康成人男性血糖浓度服从正态分布
H1: 健康成人男性血糖浓度不服从正态分布

计算过程如表：
1|血糖浓度(x) 
2|次数（f）
3|累计次数(F) 
4|Fn(x)=F/n 
5|标准化值z=(x-μ)/σ  
6|理论分布F0（x）
7|D

1	2	3	4.0000	5	6.0000	7  ##列号

68	2	2	0.0571	-2	0.0228	0.0291
72	2	4	0.1143	-1.33	0.0934	0.0209
75	2	6	0.1714	-0.83	0.2033	0.0319
76	2	8	0.2286	-0.67	0.2514	0.0228
77	6	14	0.4	-0.5	0.3085	0.0915
78	3	17	0.4857	-0.33	0.3707	0.115
80	6	23	0.6571	0	0.5	0.1571
81	3	26	0.7429	0.17	0.5675	0.1754
84	2	28	0.8	0.67	0.7486	0.0514
86	2	30	0.8571	1	0.8413	0.0158
87	2	32	0.9143	1.17	0.879	0.0353
92	3	35	1	2	0.9772	0.0228

结论：上表中的理论值F0(x)是根据标准化值z查表得到，实际上
D=max |Fn(x)-F0(x)|=0.1754 < D0.55, 35=0.23查D值表，故不能拒绝H0即健康成年男人血糖浓度服从正态分布。

当样本容量n大时可以用Dα，n=1.36/ 求得结果，
如上述D0.55, 35=1.36/ =0.2299=0.23


χ2检验与Kolmogorov-Smirnov正态性检验都采用实际频数和期望频数进行检验。它们之间最大的区别在于前者主要用于类别数据，而后者主要用于有单位的数量数据，有时前者也可以用于数量数据但必须将数据分组得到实际观测频数，并要求多变量之间独立，而后者可以不分组直接把原始数据进行检验。因此k-s检验对数据的应用较完整。



(2)
在R中可以使用 ks.test() 函数。

1) 单样本K-S检验
单样本K-S检验即是检验样本数据点是否满足某种理论分布。
注意！若该理论分布的参数是由样本点估计的，该方法无效！
我们从零假设出发。（即假设样本点不满足理论分布）



2) 双样本集K-S检验
双样本K-S检验即是检验两个样本集是否满足同样的潜在分布。











2. 与类似的分布检验方式比较

(1)
经常使用的拟合优度检验和Kolmogorov-Smirnov检验的检验功效较低，在许多计算机软件的Kolmogorov-Smirnov检验无论是大小样本都用大样本近似的公式，很不精准，一般使用Shapiro-Wilk检验和Lilliefor检验。

Kolmogorov-Smirnov检验只能检验是否一个样本来自于一个已知样本，而Lilliefor检验可以检验是否来自未知总体。

Shapiro-Wilk检验和Lilliefor检验都是进行大小排序后得到的，所以易受异常值的影响。

Shapiro-Wilk检验只适用于小样本场合（3≤n≤50）,其他方法的检验功效一般随样本容量的增大而增大。

拟合优度检验和Kolmogorov-Smirnov检验都采用实际频数和期望频数进行检验，前者既可用于连续总体，又可用于离散总体，而Kolmogorov-Smirnov检验只适用于连续和定量数据。

拟合优度检验的检验结果依赖于分组，而其他方法的检验结果与区间划分无关。


(2)
Kolmogorov-Smirnov检验（K-S检验）基于累积分布函数，用以检验一个经验分布是否符合某种理论分布或比较两个经验分布是否有显著性差异。

两样本K-S检验由于对两样本的经验分布函数的位置和形状参数的差异都敏感而成为比较两样本的最有用且常规的非参数方法之一。

优点：该检验不依赖于要测试的累积分布函数，相比于卡方拟合检验（卡方检验需要50个以上的样本），不需要大量的样本。

缺点：只适用于连续分布；在分布中间敏感，在两端不够敏感；最大的局限在于整个分布需要完全确定，如果位置，形状等参数都是从数据中估计的，判定区间不再有效，因此这些参数一般只能通过模拟得到。

因此很多人推荐使用以下两种检验方法，这两种方法也是ks检验的改进版本。

Anderson-Darling test in R package of robCompositions

Shapiro-Wilk test in R package of mvShapiroTest










ref:
1. 例子 http://jchoo1986.blog.sohu.com/147211956.html
2. 图文例子 https://www.cnblogs.com/arkenstone/p/5496761.html
3. 文献 https://www.cnblogs.com/bnuvincent/p/5783896.html

https://www.itl.nist.gov/div898/handbook/eda/section3/eda35g.htm
http://www.physics.csbsju.edu/stats/KS-test.html



等待: https://cosx.org/tags/kolmogorov-smirnov






========================================
置换检验 permutation test (非参)
----------------------------------------

当样本不符合或不确定符合正态分布这一前提时，我们就要用非参数检验，而置换检验Permutation test就属于非参数检验的一种。

Permutation test is useful when we do not know how to compute the distribution of a test statistic.





1.什么是Permutation test

Permutation test又称randomization test，是Fisher[1]和 Pitman[2]等人于20世纪30年代提出的一种统计推断的方法，其属于一种非参数检验，对样本总体分布情况无要求，特别适用于总体分布未知的小样本数据，即使样本数据小到无法使用比如说t检验（这一点是说Permutation test可以用于样本量非常小的数据，笔者会在下面的“实例1”中进行详细的说明）；当然，Permutation test也可以用于分布未知的大样本量的数据，因此，其应用非常广泛。

Permutation test一般通过对两组样本进行顺序上的随机置换，并重新计算统计检验量，把上述过程重复多遍（比如说1000遍），就可以构造出统计检验量的经验分布，然后对比两组样本的统计检验量和构造出的统计检验量经验分布，就可以计算求出P值。

由于早期受到计算机技术的限制（因为Permutation test要产生大量的随机样本组合），Permutation test只能用于小样本数据的检验，现在随着目前计算机技术的发展，可以在短时间内产生大量的随机样本组合，因此目前Permutation test可以用于样本量较大的数据。


(2)
A permutation test gives a simple way to compute the sampling distribution for any test statistic, under the strong null hypothesis that a set of genetic variants has absolutely no effect on the outcome.

If the null hypothesis is true, changing the exposure would have no effect on the outcome. By randomly shuffling the exposures we can make up as many data sets as we like.









2. Permutation test的原理
接下来，通过两个实例，形象地认识下Permutation test的原理。

例子1:欲研究某新的教学方法能否显著提高学生的数学成绩。两组被试，每组10个人，A组采用传统教学方法，而B组采用这种新的教学方法，经过一个学期的教学后进行测试，并统计两组被试的成绩，如下所示：

A组成绩：65,75,43,80,67,68,54,78,80,62
B组成绩：91,69,73,87,75,71,89,64,70,95

针对这个例子，采用Permutationtest的步骤如下：
第一步：建立H0假设，即新不会提高学生的成绩，或者说新、旧方法并无差别；
第二步：计算统计检验量，这里同样计算两组被试的均值之差，Ms=-13.2；

第三步：把A组和B组成绩进性混合，
AB：65,75,43,80,67,68,54,78,80,62,91,69,73,87,75,71,89,64,70,95
从AB中随机抽取10作为新的A组（计为A1组）成绩，剩下的作为B组成绩（计为B1组），并重新计算统计检验量（均值差），计为Mn；
上述随机置换步骤重复若干次（如1000次）可以得到Mn的经验分布；

第四步：计算Mn中大于Ms的个数（计为n），那么P=n/随即置换次数。
得到的P值为：0.0090，说明新的教学方法可以显著提高学生的成绩。


## R 代码实现：
a=c(65,75,43,80,67,68,54,78,80,62)
b=c(91,69,73,87,75,71,89,64,70,95)
Ms=mean(b)-mean(a);Ms # 11.2

c=c(a,b)
n=length(c)

set.seed(202108)
rs=c();
Num=10000
for(i in 1:Num){
  s1=sample(1:20, size=10)
  s2=setdiff( seq(1,20), s1)
  rs=c(rs, mean(c[s2])-mean( c[s1]) )
}
hist(rs, n=100)
abline(v=Ms, col="red", lty=2)
len=as.numeric( table(rs>Ms)[2] )
P=len/Num; P
## [1] 0.0192 < 0.05 说明是小概率事件，原假设不可能发生。那就是有显著变化。







3. 一个SNP的例子 (没理解)
https://faculty.washington.edu/kenrice/sisg/SISG-08-06.pdf


## make up some ‘true’ data
set.seed(2021)
carrier<-rep(c(0,1), c(100,200)) #携带者
null.y<-rnorm(300) #随机分布的可能性？
alt.y<-rnorm(300, mean=carrier/2) #携带者可能性高


(1) t-test
In this case we know from theory the distribution of a difference in means and we could just do a t-test.

We can compare the t-test results to the results of a permutation test on the mean difference.

> t.test(null.y~carrier, var.equal=TRUE)
	Two Sample t-test
data:  null.y by carrier
t = -1.3836, df = 298, p-value = 0.1675
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -0.42528091  0.07414797
sample estimates:
mean in group 0 mean in group 1 
   -0.174484405     0.001082068  


> t.test(alt.y~carrier, var.equal=TRUE)
	Two Sample t-test

data:  alt.y by carrier
t = -5.4254, df = 298, p-value = 1.198e-07
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -0.9234767 -0.4318582
sample estimates:
mean in group 0 mean in group 1 
     -0.1040844       0.5735830 



(2) Means: permutation test

null.diff<-mean(null.y[carrier==1])-mean(null.y[carrier==0])
alt.diff<-mean(alt.y[carrier==1])-mean(alt.y[carrier==0])
one.test <- function(x,y) {
	xstar<-sample(x)
	mean(y[xstar==1])-mean(y[xstar==0])
}
many.truenull <- replicate(1000, one.test(carrier, null.y))
many.falsenull <- replicate(1000, one.test(carrier, alt.y))


hist(many.truenull)
abline(v=null.diff, lwd=2, col="purple")
mean(abs(many.truenull) > abs(null.diff))

hist(many.falsenull)
abline(v=alt.diff, lwd=2, col="purple")
mean(abs(many.falsenull) > abs(alt.diff))


2) How many permutations?

With 1000 permutations the smallest possible p-value is 0.001, and the uncertainty near p = 0.05 is about ±1%

If we have multiple testing we may need much more precision.

Using 100,000 permutations reduces the uncertainty near p =0.05 to ±0.1% and allows p-values as small as 0.00001.

A useful strategy is to start with 1000 permutations and continue to larger numbers only if p is small enough to be interesting, eg p < 0.1.

Parallel computing of permutations is easy: just run R on multiple computers.



3) Minimum p-value

Little point in permutation test for the mean: same result as t-test

Permutation test is useful when we do not know how to compute the distribution of a test statistic.

Suppose we test additive effects of 8 SNPs, one at a time, and we want to know if the most significant association is real.

For any one SNP the z-statistic from a logistic regression model has a Normal distribution.

We need to know the distribution of the most extreme of eight zstatistics. This is not a standard distribution, but a permutation test is still straightforward.


set.seed(2021)
dat <- data.frame(y=rep(0:1,each=100), SNP1=rbinom(200,2,.1),
                  SNP2=rbinom(200,2,.2),SNP3=rbinom(200,2,.2),
                  SNP4=rbinom(200,2,.4),SNP5=rbinom(200,2,.1),
                  SNP6=rbinom(200,2,.2),SNP7=rbinom(200,2,.2),
                  SNP8=rbinom(200,2,.4))
> head(dat)
  y SNP1 SNP2 SNP3 SNP4 SNP5 SNP6 SNP7 SNP8
1 0    0    0    0    2    0    0    0    1
2 0    0    0    1    2    0    0    0    1
3 0    0    1    0    1    0    0    0    1
4 0    0    1    0    1    0    1    0    0
5 0    0    0    0    2    0    0    0    2
6 0    0    0    0    0    0    0    1    2


oneZ<-function(outcome, snp){
  model <- glm(outcome~snp, family=binomial())
  coef(summary(model))["snp","z value"]
}
maxZ<-function(outcome, snps){
  allZs <- sapply(snps,
                  function(snp) oneZ(outcome, snp))
  max(abs(allZs))
}
true.maxZ<-maxZ(dat$y, dat[,-1])
manypermZ<-replicate(10000, maxZ(sample(dat$y), dat[,-1])) #这一步巨慢
## The histogram shows the permutation distribution for the maximum Z-statistic.
> hist(manypermZ, n=25, freq = F, ylim=c(0,1))

## The blue curve is the theoretical distribution for one Z-statistic 
> lines(density( rnorm(100000), n=250), col='blue', ann=F)

## The yellow curve is the theoretical distribution for the maximum of eight independent Z-statistics.
> lines(density(manypermZ, n=25), col='orange', lty=2, lwd=2 )


Clearly the multiple testing is important: a Z of 2.5 gives p = 0.012 for a single test but p = 0.075 for the permutation test.

The theoretical distribution for the maximum has the right range but the permutation distribution is quite discrete. 
The discreteness is more serious with small sample size and rare SNPs.

[The theoretical distribution is not easy to compute except when the tests are independent.]
理论分布不好计算，除非检验都是独立的。












ref:
[1] Fisher, R. A., 1935. The Design of Experiments. Oliver & Boyd, Edinburgh.
[2]Pitman, E., 1937. Significance tests which may be applied to samples from any populations: I. Journal of the Royal Statistical Society, B, 4, 119-130

https://zhuanlan.zhihu.com/p/328940140
https://blog.csdn.net/wangjunliang/article/details/120670128






========================================
|-- bootstrap method 可重复抽样：有限样本估算总体参数
----------------------------------------

Bootstrap方法是非常有用的一种统计学上的估计方法，是斯坦福统计系的教授Bradley Efron（我曾有幸去教授办公室约谈了一次）在总结、归纳前人研究成果的基础上提出一种新的非参数统计方法。Bootstrap是一类非参数Monte Carlo方法,其实质是对观测信息进行再抽样，进而对总体的分布特性进行统计推断。

因为该方法充分利用了给定的观测信息，不需要模型其他的假设和增加新的观测，并且具有稳健性和效率高的特点。1980年代以来，随着计算机技术被引入到统计实践中来，此方法越来越受欢迎，在机器学习领域应用也很广泛。

首先，Bootstrap通过重抽样，可以避免了Cross-Validation造成的样本减少问题，其次，Bootstrap也可以用于创造数据的随机性。比如，我们所熟知的随机森林算法第一步就是从原始训练数据集中，应用bootstrap方法有放回地随机抽取k个新的自助样本集，并由此构建k棵分类回归树。







1. 非参数bootstrap方法

进行参数估计时，总体的分布F我们不知道，但是现有一个容量为n的来自F的数据样本，之后我们对这n个数据进行放回抽样，抽取n个作为一个数据样本，这个数据样本称为bootstrap样本或者自助样本，同样的独立的抽取B个bootstrap样本，然后利用这B个bootstrap样本对总体F进行推断，这种方法就是非参数bootstrap方法又称自助法。


在 Fn 中抽取bootstrap样本，也就是在原始样本 x1,x2,...,xn 中采用放回抽样抽取容量为n的bootstrap样本 x1*,x2*,...,xn*.
用 bootstrap 样本估算参数。
... 估计量的标准误差的bootstrap估计。

公式不好写，直接看例子。


(1) 某种基金的年回报率是具有分布函数F的连续型随机变量，F未知，F的中位数 theta 是未知参数。现有一下数据(%率):
18.2 9.5 12.0 21.1 10.2
以样本中位数作为总体中位数 theta 的估计。试求中位数估计的标准误差的bootstrap估计

解答:有放回的抽样10000次，计算每个bootstrap样本的中位数
rates=c(18.2, 9.5, 12.0, 21.1, 10.2)
#样本中位数为
m0=median(rates); m0

oneSampling=function(){
  dt2=sample(rates, replace = T)
  median(dt2)
}
set.seed(2021)
N=10000
results=replicate(N, oneSampling()) 

hist(results, n=100)

m.sd=sqrt( sum(( results-mean(results) )**2) / (length(results) -1) )
m.sd #3.710834
sd(results) #[1] 3.710834 这两个值一模一样。
这就是估计量的标准误差的bootstrap估计。





##############
## 原作者的代码，很值得学习
x=c(18.2,9.5,12.0,21.1,10.2)
theta<-median(x)
bootstrap<-function(x,B=10000){
  set.seed(2021)
  G<-matrix(0,B,length(x))
  for(i in 1:B){
    G[i,]<-t(matrix(sample(x,length(x),replace = T)))
  }
  return(G)
}

#运行时间
tic<-proc.time()
b<-matrix(apply(bootstrap(x),1,median),1)
toc<-proc.time()
print(toc-tic)
#误差计算
(sd<-sqrt(((b)-mean(b))%*%(t(b)-mean(b))/(length(b)-1)))
# 3.710834






(2) 估计量的均方误差及偏差的bootstrap估计
例题2: 均方误差：设金属元素铂的升华热是具有分布函数F的连续型随机变量，F的中位数 theta 是未知参数，现测得以下的数据(以kcal/mol计）(千卡/摩尔):

136.3,136.3,135.8,135.4,134.7,135.0,134.1,143.3,147.8,
148.8,134.8,135.2,134.9,149.5,141.2,135.4,134.8,135.8,
135.0,133.7,134.4,134.9,134.8,134.5,134.3,135.2

以样本中位数 M=M(X) 作为总体中位数 theta 的估计，试求均方误差 MSE=E[(M-theta)^2] 的bootstrap估计。

解答：
取样本中位数 theta;
step1 可重复的取样B=10000个bootstrap样本；
step2 计算每个bootstrap样本的 Ri=(Mi-theta)^2, i=1,2,...,10000;
step3 用 E(R)=1/B*sum(Ri) 来估计E(R)。

#例题2
p<-c(136.3,136.3,135.8,135.4,134.7,135.0,134.1,143.3,147.8,
     148.8,134.8,135.2,134.9,149.5,141.2,135.4,134.8,135.8,
     135.0,133.7,134.4,134.9,134.8,134.5,134.3,135.2)
m<-median(p)
g<-matrix(apply(bootstrap(p),1,median),1)
(Rx<-(g-m)%*%t(g-m)/10000)
#样本中位数
135.1
#MSE值
0.06305875

# 计算偏差 bias=E(M-theta) ,很简单的取 R=R(X)=M-theta ,对应着上三个步骤进行替换就可以了。
(Biase<-mean(g-m))
#偏差
0.040825


(3) bootstrap置信区间
利用分位数法求未知参数 theta 的bootstrap置信区间。

#bootstrap置信区间
alpha<-0.05
g<-sort(g)
list("bootstrap置信区间"=c(g[length(g)*alpha/2],g[length(g)*(1-alpha/2)]))
$bootstrap置信区间
[1] 134.8 135.8











ref: https://www.sciencedirect.com/topics/mathematics/bootstrap-method
https://zhuanlan.zhihu.com/p/24851814




========================================
转录组差异表达筛选的真相
----------------------------------------
可惜，TPM、FPKM等方法已经对测序深度进行了均一化，所以生来就是用来比较样品内不同基因表达差异的，用于不同样品间同一基因的差异表达分析并不合适，很多信息已经被抹去了。


其实统计学家也很无奈啊，看看我们转录组实验得到的这些数据吧：我们的实验只进行少得可怜的生物学重复（n<10），而且，任何基因的表达量都不能是负数，这些数据并不符合正态分布，用于表征表达量的counts是非连续的（芯片信号是连续的），RNA-seq数据的离散通常是高度扭曲的，方差往往会大于均值……，就这些奇怪的特征，使得准确估计方差并没有想象的那么容易。


我们面临两个核心问题：
基因表达数据适合用什么统计学分布进行差异显著性检验？
如何利用少量生物学重复数据估算基因表达的标准差？



我们不去抖旧包袱，反正经过各种较量，大家普遍接受生物学重复这么少的情况下，RNA-seq数据用负二项分布（Negative binomialdistribution，通常写作NB）进行显著性检验是较合适的。

但，在生物学重复很少时，我们是很难准确计算每个基因表达的标准差的（相当于这个数据集的离散程度）。我们很可能会低估数据的离散程度。

被逼无奈的科学家提出了一个假设：表达丰度相似的基因，在总体上标准差应该也是相似的。我们把不同生物学重复中表达丰度相同的基因的总标准差取个平均值，低于这个值的都用这个值，高于这个值的就用算出来的值。







refer:
生信百科 2017-06-02 https://mp.weixin.qq.com/s/VcjnvI5FqwOFEC9wSUfdSw



========================================
MA plot 
----------------------------------------
MA plot即M-versus-A plot，在芯片数据处理出现之前也称为Bland-Altman plot，是由发明者名字命名的，而MA plot是对M与A作图而得名，M是minus的缩写，代表两个值之差，A是add的缩写，代表两个值之和。有研究者也把MA plot称为Ratio-Intensity (RI) plots，同时MA也正好是micro-array的简写。


MA plot的作用是为了展示两个值几乎相等的变量（x和y）之间的关系，为了展示两个变量之间的变化关系，大多数人的思维都是把x与y分别作为横轴和纵轴进行绘图，如果y=x，则该图呈45度角的直线（如下图中左边图的蓝色直线），可以通过查看点形成的直线偏离预期直线的多少来衡量系统偏差，然而该图存在以下几个缺点：

1. 人的视觉对水平线比更敏感
2. 不同坐标轴的刻度可能会使预期参考直线偏离45度
3. 很难从直观上衡量偏离一条线性的大小


MA plot的处理方法是把该直线顺时针旋转45度，把参考对角线变为直线，具体做法是把(x+y)/2作为横轴，(y-x)作为纵轴，则参考直线变为一条水平线，如下方右图，这样可以很清楚的在视觉上展示两个相等的变量之间偏离参考值的大小，即存在的系统误差的大小


图：MA plot与传统的y-x plot


对于芯片数据中信号值x和y的比较，一般先对它们进行log2处理，再进行Minus（log2{Y}-log2{x}=log2(y/x））和Add（(log2{x}+log2{y})/2）做MA plot，为什么使用log2处理的原因如下：

1. 取对数后的两组数据的值差异比不取对数时更独立于其值大小
2. 对于取对数后的值标准化只需简单的加法即可
3. 取对数后使分布不太过度偏斜
4. 取对数后使变异大小跨度更真实
5. 取log2而不取ln或log10是因为芯片的信号值大小范围为0~2^16-1的整数值（一般都是用计算机的16位来存储信号强度值）

参考：
http://bmbolstad.com/Dissertation/Bolstad_2004_Dissertation.pdf
http://bioinformatics.mdanderson.org/MicroarrayCourse/Lectures10/r3_bw.pdf
http://www.jstor.org/stable/24307038?seq=1#page_scan_tab_contents

ref:
https://www.jianshu.com/p/cdfac0bfb733



========================================
如何轻松绘制基因表达聚类趋势图
----------------------------------------

http://tool.biomooc.com/R_scripts/





========================================
相关系数: pearson correlation, spearman correlation, kendall correlation coefficient (定义、适用范围、意义、代码实现)
----------------------------------------
cor(x, y = NULL, use = "everything",
    method = c("pearson", "kendall", "spearman"))
#


1. 区别
(1)答案1
pearson相关系数和spearman相关系数的区别？

(1).连续数据，正态分布，线性关系，用pearson相关系数是最恰当，当然用spearman相关系数也可以，效率没有pearson相关系数高。
(2).上述任一条件不满足，就用spearman相关系数，不能用pearson相关系数。
(3).两个定序测量数据之间也用spearman相关系数，不能用pearson相关系数。

通常情况下默认用复pearson相关系数，数据分布呈现出不正态时制用Spearman相关系数。

在SPSS软件相关分析中,pearson(皮尔逊),kendall（肯德尔）和spearman（斯伯曼/斯皮尔曼）三种相关分析方法有什么异同？ 


(2)答案2

两个连续变量间呈线性相关时，使用Pearson积差相关系数，
不满足积差相关分析的适用条件时，使用Spearman秩相关系数来描述。

Spearman相关系数又称秩相关系数，是利用两变量的秩次大小作线性相关分析，对原始变量的分布不作要求，属于非参数统计方法，适用范围要广些。

对于服从Pearson相关系数的数据亦可计算Spearman相关系数，但统计效能要低一些。

Pearson相关系数的计算公式可以完全套用Spearman相关系数计算公式，但公式中的x和y用相应的秩次代替即可。


Kendall'stau-b等级相关系数：用于反映分类变量相关性的指标，适用于两个分类变量均为有序分类的情况。



对相关的有序变量进行非参数相关检验；取值范围在[-1, 1]之间，此检验适合于正方形表格；
	计算积距pearson相关系数，连续性变量才可采用;
	计算Spearman秩相关系数，适合于定序变量或不满足正态分布假设的等间隔数据;
	计算Kendall秩相关系数，适合于定序变量或不满足正态分布假设的等间隔数据。



(3) 实例区分

当比较的两个变量是单调相关的，比如tanh函数，即使它们的关系不是线性的，Spearman相关性为1。这意味着x值大于给定数据点的所有数据点也将具有更大的y值。相比之下，这并没有给出完美的Pearson相关性。


#正相关的例子
x=seq(-15,15, by=0.2)
y=(exp(x) - exp(-x) )/(exp(x) + exp(-x) )
RSp=cor.test(x,y, method = 'pearson');RSp #0.89
RSs=cor.test(x,y, method = 'spearman');RSs #1

plot(x,y, type='o', main=paste0("rho_p=",round(RSp$estimate,2), "(p=",RSp$p.value, ')\n',
                                "rho_s=",round(RSs$estimate,2), "(p=",RSs$p.value, ')')  )


## 负相关的例子
x=seq(-15,15, by=0.2)
y=exp(-x)
RSp=cor.test(x,y, method = 'pearson');RSp #-0.43
RSs=cor.test(x,y, method = 'spearman');RSs #-1





2. 定义和代码实现

(1). person correlation coefficient（皮尔森相关性系数）
两个变量(X, Y)的皮尔森相关性系数(ρX,Y)等于它们之间的协方差cov(X,Y)除以它们各自标准差的乘积(σX, σY)。

cor(X,Y)=cov(X,Y)/ sqrt( var(X) * var(Y) )


公式的分母是变量的标准差，这就意味着计算皮尔森相关性系数时，变量的标准差不能为0（分母不能为0），也就是说你的两个变量中任何一个的值不能都是相同的。如果没有变化，用皮尔森相关系数是没办法算出这个变量与另一个变量之间是不是有相关性的。

就好比我们想研究人跑步的速度与心脏跳动的相关性，如果你无论跑多快，心跳都不变（即心跳这个变量的标准差为0），或者你心跳忽快忽慢的，却一直保持一个速度在跑（即跑步速度这个变量的标准差为0），那我们都无法通过皮尔森相关性系数的计算来判断心跳与跑步速度到底相不相关。


假设你现在做了个生物学实验，喜得以下两个变量：
X1=c(1, 2, 3, 4, 5, 6)
Y1=c(0.3, 0.9, 2.7, 2, 3.5, 5)

mean(X1)  #平均值 3.5
mean(Y1)  #2.4

var(X1)    #方差 3.5
var(Y1) #3.976

sd(X1)     #标准差 sd(X1)     #标准差
sd(Y1) #1.725109

cov(X1,Y1)  #协方差 3.06

cor(X1,Y1,method="pearson")  #皮尔森相关性系数 0.9481367

cov(X1,Y1)/(sd(X1)*sd(Y1)) #0.9481367

此外，从上面的公式我们知道，皮尔森相关性系数是协方差与标准差的比值，所以它对数据是有比较高的要求的：
第一， 实验数据通常假设是成对的来自于正态分布的总体。
为啥通常会假设为正态分布呢？
因为我们在求皮尔森相关性系数以后，通常还会用t检验之类的方法来进行皮尔森相关性系数检验，而 t检验是基于数据呈正态分布的假设的。

## 获取p值：
rs=cor.test(X1,Y1);rs
str(rs)
rs$p.value #0.003964957 p值
#rs$estimate
#str(rs$estimate)
#attr(rs$estimate, which="names") #"cor"
as.numeric(rs$estimate) #0.9481367 相关系数

第二， 实验数据之间的差距不能太大，或者说皮尔森相关性系数受异常值的影响比较大。比如刚才心跳与跑步的例子，万一这个人的心脏不太好，跑到一定速度后承受不了，突发心脏病，那这时候我们会测到一个偏离正常值的心跳（过快或者过慢，甚至为0），如果我们把这个值也放进去进行相关性分析，它的存在会大大干扰计算的结果的。




(2) spearman correlation coefficient（斯皮尔曼相关性系数）
斯皮尔曼相关性系数，通常也叫斯皮尔曼秩相关系数。“秩”，可以理解成就是一种顺序或者排序，那么它就是根据原始数据的排序位置进行求解，这种表征形式就没有了求皮尔森相关性系数时那些限制。下面来看一下它的计算公式：

表示通常的Pearson相关系数，但应用于秩变量：秩变量的协方差 / 秩变量的标准偏差乘积。

简化后：
ro = 1 -  6*累加(di ** 2 ) / [n(n**2-1)]


计算过程就是：首先对两个变量（X, Y）的数据进行排序，然后记下排序以后的位置（X’, Y’），（X’, Y’）的值就称为秩次，秩次的差值就是上面公式中的di，n就是变量中数据的个数，最后带入公式就可求解结果。举个例子吧，假设我们实验的数据如下：


X     Y   X1  Y1 di
11    2   2   1  1
490  75   6   6  0
14    3   3   2  1
43   44   5   5  0
30    7   4   3  1
3    42   1   4  3


把秩序X1,Y1带入person相关系数公式中，cor(X,Y)=cov(X,Y)/ sqrt( var(X) * var(Y) )
就得到spearman相关系数：
X1=rank(X) #注意！不能用order()!
Y1=rank(Y)
cov(X1,Y1)=2.3
cov(X1,Y1)/sqrt(var(X1)*var(Y1)) #[1] 0.6571429


带入快捷公式，求得斯皮尔曼相关性系数：ρs= 1-6*(1+1+1+9)/6/35=0.657


也就是说，我们不用管X和Y这两个变量具体的值到底差了多少，只需要算一下它们每个值所处的排列位置的差值，就可以求出相关性系数了。这下理解起来是不是容易多了！还是用上面的数据，下面写下代码实现：

> X=c(11,490,14,43,30,3)
> Y=c(2,75,3,44,7,42)
> cor(X,Y,method="spearman") 
[1] 0.6571429

# 检验显著性
> rs=cor.test(X,Y,method="spearman") 
> rs$estimate  #0.6571429 
> rs$p.value #0.175




(3). kendall correlation coefficient（肯德尔相关性系数）
肯德尔相关性系数，又称肯德尔秩相关系数，它也是一种秩相关系数，不过它所计算的对象是分类变量。
分类变量可以理解成有类别的变量，可以分为
无序的，比如性别（男、女）、血型（A、B、O、AB）；
有序的，比如肥胖等级（重度肥胖，中度肥胖、轻度肥胖、不肥胖）。
通常需要求相关性系数的都是有序分类变量。

举个例子。比如评委对选手的评分（优、中、差等），我们想看两个（或者多个）评委对几位选手的评价标准是否一致；或者医院的尿糖化验报告，想检验各个医院对尿糖的化验结果是否一致，这时候就可以使用肯德尔相关性系数进行衡量。


由于数据情况不同，求得肯德尔相关性系数的计算公式不一样，一般有3种计算公式，在这里就不繁琐地列出计算公式了，直接给出R语言的计算函数：

还是用cor函数求，这时候把method这个参数设成“kendall”，这时我们假设老师对选手的评价等级---3表示优，2表示中，1表示差：

> X=c(3,1,2,2,1,3)
> Y=c(1,2,3,2,1,1)
> cor(X,Y,method="kendall") 
[1] -0.2611165

> cor.test(X,Y,method="kendall")  #p-value = 0.5173

这时候就可以理解为两位老师对选手们的看法是呈相反趋势的，不过这种相反的程度不很大。






ref:
https://blog.csdn.net/ZJZJ0320/article/details/82350177
https://blog.csdn.net/ChenVast/article/details/83022649



========================================
|-- R相关系数计算函数 use 的取值的意义
----------------------------------------
cor(x, y = NULL, use = "everything",
    method = c("pearson", "kendall", "spearman"))
#
na.rm: logical. Should missing values be removed?

use: an optional character string giving a method for computing covariances in the presence of missing values. This must be (an abbreviation of) one of the strings "everything", "all.obs", "complete.obs", "na.or.complete", or "pairwise.complete.obs".



示例: 输入数据框，计算列之间的相关系数
dt=data.frame(
  x=c(1,2,3,4,5,NA,6,7),
  y=c(3,4,NA,7,8,NA,NA,6),
  z=c(4,5,6,NA,9,10,11,12)
);dt
#    x  y  z
# 1  1  3  4
# 2  2  4  5
# 3  3 NA  6
# 4  4  7 NA
# 5  5  8  9
# 6 NA NA 10
# 7  6 NA 11
# 8  7  6 12



1. 默认 everything 只要有一个NA则结果也是NA
> cor(dt)
   x  y  z
x  1 NA NA
y NA  1 NA
z NA NA  1





2.complete.obs 就是所有行一起看，去掉出现NA的行。
也就是一行中只要出现na，整行就会被去除掉。

> cor(dt, use="complete.obs")
          x         y         z
x 1.0000000 0.7779078 0.9986590
y 0.7779078 1.0000000 0.7522874
z 0.9986590 0.7522874 1.0000000

> cor(dt[c(1,2,5,8),]$x, dt[c(1,2,5,8),]$y)
[1] 0.7779078

> cor(dt[c(1,2,5,8),]$x, dt[c(1,2,5,8),]$z)
[1] 0.9986590

> cor(dt[c(1,2,5,8),]$z, dt[c(1,2,5,8),]$y)
[1] 0.7522874






3. 如果是 pairwise.complete.obs，就是直接计算相关系数的2列中，去掉出现NA的行。
去na稍微温和点，只局限在正在比较的两列之间，出现na的行去掉。

> cor(dt, use="pairwise.complete.obs")
          x         y         z
x 1.0000000 0.7372609 0.9953212
y 0.7372609 1.0000000 0.7522874
z 0.9953212 0.7522874 1.0000000


> cor(dt[-c(3,6,7),]$x, dt[-c(3,6,7),]$y)
[1] 0.7372609
> cor(dt[-c(4,6),]$x, dt[-c(4,6),]$z)
[1] 0.9953212
> cor(dt[-c(3,4,6,7),]$y, dt[-c(3,4,6,7),]$z)
[1] 0.7522874






4. na.or.complete，结果和 complete.obs 一样，不知道啥区别？ //todo
> cor(dt, use="na.or.complete")
          x         y         z
x 1.0000000 0.7779078 0.9986590
y 0.7779078 1.0000000 0.7522874
z 0.9986590 0.7522874 1.0000000

> cor(dt, use="complete.obs")
          x         y         z
x 1.0000000 0.7779078 0.9986590
y 0.7779078 1.0000000 0.7522874
z 0.9986590 0.7522874 1.0000000






ref:
1. "complete.obs" https://bbs.pinggu.org/thread-3992878-1-1.html



========================================
|-- 相关系数的 p 值什么意思？需要矫正吗？
----------------------------------------

1. cor.test {stats} from R Documentation

Test for Association/Correlation Between Paired Samples

Description: Test for association between paired samples, using one of Pearson's product moment correlation coefficient, Kendall's tau or Spearman's rho.


检验方式：
If method is "pearson", the test statistic is based on Pearson's product moment correlation coefficient cor(x, y) and follows a t distribution with length(x)-2 degrees of freedom if the samples follow independent normal distributions. If there are at least 4 complete pairs of observation, an asymptotic confidence interval is given based on Fisher's Z transform.


If method is "kendall" or "spearman", Kendall's tau or Spearman's rho statistic is used to estimate a rank-based measure of association. These tests may be used if the data do not necessarily come from a bivariate normal distribution.
二元正态分布；
双变量常态分配



2. 文献资料 

(1) Fig2: 图中坐标 
https://www.researchgate.net/figure/Scatter-plot-of-the-p-value-of-the-log-rank-test-against-the-Pearson-correlation_fig1_338078373
Scatter plot of the p-value of the log-rank test against the Pearson correlation coefficient (PCC) of gene pairs in breast cancer. Only the gene pairs with an adjusted p-value of the log-rank test <0.05 and p-value of PCC <0.05 were selected as potential prognostic gene pairs (red dots)

x=Pearson correlation coefficient (PCC), 
y=-log10(p value of log-rank test)，
红点表示选择进入后续步骤的: adjusted p-value of the log-rank test <0.05 且 p-value of PCC <0.05 。


(2) Fig1: 图中坐标
https://www.researchgate.net/figure/Volcano-plot-for-Pearson-correlations-between-whole-blood-and-plasma-miRNA-PCR-cycle_fig2_301696991
Volcano plot for Pearson correlations between whole blood and plasma miRNA PCR cycle values. Y-axes represent logarithm (base-10) of P value of each correlation coefficient. X-axes represent correlation coefficient. Dotted line is Bonferroni adjusted P value for 153 miRNA comparisons. Selected miRNAs are labeled on plots.

x=correlation coefficient.
y=logarithm (base-10) of P value of each correlation coefficient. 

Dotted line is Bonferroni adjusted P value for 153 miRNA comparisons.


结论： 看文献，是需要矫正的。




ref:
https://courses.lumenlearning.com/introstats1/chapter/testing-the-significance-of-the-correlation-coefficient/





========================================
Barplot with error bars: mean±SEM, mean±SD, mean±SE有何区别，都是可使用的吗？
----------------------------------------
问题:
看了很多外文文献，有的统计结果中以mean±SEM表示, 有的以mean±SD表示, 也有以mean±SE表示，国内多半以x±s表示，请问哪一种是最恰当的。
SEM、SE应该是标准误，SD和s应该是标准差，所以简单的说要以标准误表示，还是标准差表示呢?
柱状图上的T，即标准差（误）应该是标准误还是标准差呢？


我的理解:
(1)假设一个实验，一周测量一次某植物的高度，一次实验至少3盆花，然后测量4周，每周就有3个数字，可以求该时间点的mean+-sd; 可以画图了height~week plot。
注: 每个点背后有3个植物。

(2)然后可能导师怕该实验是偶然发生的，又让其他学生重复进行了2次。
然后每个时间点就有3个mean了，然后计算这3个mean的mean和sd，记作mean+-se，又可以画图了height~week plot。
注: 每个点背后有3*3=9个植物。

简言之：你做了一次实验，就用mean+-sd; 重复该实验多次，就用mean+-se; 
明显后者更好，但是很多时候，受到时间和经费限制，实验不能重复。



1. 分析1
(1) 定义
mean表示都是平均数。

mean±SD表示的是均数加减标准差。
mean±SEM与mean±SE表示的意义相同，即均数加减标准误。

SD全称standard deviation标准差，又常称均方差，是离均差平方的算术平均数的平方根，用σ表示。
SEM是standard error of mean是平均数的抽样误差，反应平均数的抽样准确性。


(2) 用法
前者表示定量资料抽样分布的均数的分布情况，而后者表示定量资料（满足或近似满足正态分布）的个体测量值的分布情况，意义完全不同。一般情况下是以均数加减标准差来表示。


SEM计估计值的准确性无法度量，但可以用统计方法来测量。

测试的误差来源包括系统误差和采样误差，这些误差都不容易克服。采样误差是由许多无法控制的内部和外部因素引起的，这些因素都是偶然的，即使在测试中非常小心也很难消除，但可以通过增加重复次数来减少。

小样本（n≤30）取平均值±标准差，大样本（n>30）取平均值±标准误差。


(3) 类型不同
标准差是方差的算术平方根。标准差可以反映数据集的离专散程度。如果平均值相同，则标准差可能不相同。

标准误差是用样品的标准偏差除以样品容量的平方根来计算的，标准误差受样本量影响较大，样本量越大，标准误差越小，抽样误差越小，说明样本能够更好地代表种群。







2.区分2
你写错了，均数±标准数。

假设天空有1000000万颗星星。每颗星星的直径都不同。    
你第一次观察了300个星星的直径，然后顺便求了一下他们的 平均直径 把这个平均直径记作A  （或许你会顺便计算一下这300颗星星的标准差记作A1）。

第二次，你又心血来潮，去观察了另外300颗星星得到了这些星星的 平均直径 记作 B，其标准差记作B1。

等有一天你观察了26次时候，你得到了26个平均数(A-----Z)和26个标准差（A1--------Z1）。。。
然后你看星星都烦死了，懒得再去观察很多了。。。。。

这个时候你想用现在获得的数据去 估计 这1000000万 个星星的平均直径，可若是要对你之上研究过的 26×300=7800  颗星星做平均直径， 那么你得到的是什么？？？？

我相信你知道结果你会哭晕在厕所，因为那样做得到的  平均直径  是7800颗星星的平均直径，跟1000000万颗星星的平均直径   恐怕就是一毛钱的关系。
那么应该怎么做呢？
神一般的人物研究早就研究过了，将你之前得到的那26个 平均直径（A----Z，这里要非常清醒的知道A,B…都是之前计算出来的平均数）将这些平均数先相加再求平均值    这样就得到了一个【平均数的平均数】，称之为 平均数 ，对！就是平均数。

之前观察了的300颗星星我们除了求其平均数，标准差。那么现在我们想求一下这 26个平均数的 标准差，很简单公式大家都会，那么求出来的数叫标准差吗？
no。。。它有了新名字叫 标准误，标准误≠标准差(它们的来头不一张)。。。

个人感觉对于300颗星星  每个星星的直径 你都一清二楚，所以均数就是均数，标准差就是标准差，你敢拍着胸脯说。     而1000000万颗星星，不是每个星星的直径我们都知道，所以均数还叫均数，而标准差变成了标准误。这是为了区分，还是为了没把握。我觉得的是没把握所以才区分。





3. 实验数据的表述——SD和SE的区别
很多刚进入实验室的同学对实验数据的标准差（SD）与标准误（SE）的含义搞不清，不知道自己的数据报告到底该用SD还是SE。这里对这两个概念进行一些介绍。

标准差（SD）强调raw data的Variation，而标准误（SE）强调平均数的可信程度。例如在毒理学实验中，可能少数个体出现不良反应也很重要，需要给予关注，因此这时SD比SE更重要。而在一般的生物实验中，如果我们主要关心的不是少数样本的特殊反应(即个别情况)，我们主要关心的是整个群体对的平均状况，需要了解整体数据的可信度时，SE比SD更重要。SD强调raw data的Variation，不随n变化，而SE强调的是平均数的可信程度。SE反比于n的平方根。n越大，SE越小，对应的平均数越可信。

标准误=标准差/sqrt(n)      # n是样本量。公式意思是：标准误等于标准差除以样本量的平方根。

简单的说，SD描述的是sample的离散程度的。SE描述的是精确度，也就是说从sample里你所得到的这个参数（一般是平均值）和真正的population的差别大小。

ref http://blog.sciencenet.cn/blog-41454-844564.html




4.
(1) 标准差（SD）更能反应离散程度。
paper里需要Mean±SD这个信息，就是便于读者进行判断数据的离散性，e.g.，一般我们把偏离平均值2或3个SD的值作为outlier（i.e., 异常值）。

(2) 标准误则比较适合用于评估精确性或准确性的问题。
paper里根据需要也可以提供Mean±SE这个信息，就是便于读者进行判断数据的不确定性，e.g.，95%置信区间是用的Mean ± 2*SE。（不是1.96*se吗）

无论用哪种表达方式，一定要注意标明，特别是error bar，好的paper都会说明这是什么的。

ref https://blog.csdn.net/lglfa/article/details/80575124




5. SD vs SEM
The standard deviation (SD) represents variation in the values of a variable, whereas the standard error of the mean (SEM) represents the spread that the mean of a sample of the values would have if you kept taking samples. So the SEM gives you an idea of the accuracy of the mean, and the SD gives you an idea of the variability of single observations. The two are related: 

SEM = SD/(square root of sample size).

ref https://blog.csdn.net/seagal890/article/details/105671689


6. R 计算方法, 画图方法
https://www.r-graph-gallery.com/4-barplot-with-error-bar.html

(1) Standard Deviation (SD). 
It represents the amount of dispersion of the variable. Calculated as the root square of the variance:

sd <- sd(vec)
sd <- sqrt(var(vec))


(2) Standard Error (SE).
It is the standard deviation of the vector sampling distribution. Calculated as the SD divided by the square root of the sample size. By construction, SE is smaller than SD. With a very big sample size, SE tends toward 0.
 
se = sd(vec) / sqrt(length(vec))


(3) Confidence Interval (CI).
This interval is defined so that there is a specified probability that a value lies within it. It is calculated as t * SE. Where t is the value of the Student???s t-distribution for a specific alpha. Its value is often rounded to 1.96 (its value with a big sample size). If the sample size is huge or the distribution not normal, it is better to calculate the CI using the bootstrap method, however.

alpha=0.05
t=qt((1-alpha)/2 + .5, length(vec)-1)   # tend to 1.96 if sample size is big enough
CI=t*se






ref:
https://www.dxy.cn/bbs/newweb/pc/post/17685297

这个barplot 的 error bar用 mean+1.96*se 对吗？https://bstaton1.github.io/au-r-workshop/ch2.html




========================================
两个群体百分数的比较: How to Compare Two Population Proportions
----------------------------------------

1. 构建统计量 z = (p1-p2) / sqrt( p*(1-p)* (1/n1 + 1/n2) )
其中:
p1是第一个样本的百分比(男士抽烟率)
p2是第二个样本的百分比(女士抽烟率)
p是总样本百分比(男女总抽烟率)
n1,n2分别是两个群体的人数

底下的分母 sqrt( p*(1-p)* (1/n1 + 1/n2) ) 表示sd。
然后使用z分布求出p值 
pnorm(0) # 0.5
pnorm(1.96) # 0.9750021


例子:
药物1上瘾率 26 of the 374 subjects (7%)
烟草上瘾率 8 of the 210 subjects (4%)
比较是否有差异？

(1) 计算百分比
p1=26/374=0.06951872
p2=8/210 =0.03809524

n1=374; n2=210;


(2) 总体百分比
p=(26+8)/(374+210)=0.05821918

(3) 求standard error:
sd=sqrt( p*(1-p)* (1/n1 + 1/n2) )=0.02019152

(4) 求统计量z
z=(p1-p2)/sd=1.556271

(5) 求p值
1-pnorm(z) # 0.05982179

0.032 is not significantly greater than 0.





2. 如果两次调研，想比较年龄的差异，可以用t-test吗？
25 to 34 - Survey 1: 64 (8.3%) Survey 2: 117 (8.5%)
35 to 44 - Survey 1: 233 (30.3%) Survey 2: 398 (29.0%)
45 to 54 - Survey 1: 253 (32.9%) Survey 2: 533 (38.8%)
55 to 64 - Survey 1: 204 (26.6%) Survey 2: 313 (22.8%)
65+ - Survey 1: 14 (1.8%) Survey 2: 13 (0.9%)

观点:
(1)t-test is used to test the significant differences between two means.

(2)应该用 chi-square test with the frequency table，但是只能知道是否有差异，无法确定谁多谁少。
如果要比较谁高谁低，使用 Wilcoxon-Mann-Whitney。
If you want to ask if one group is older than the other, you would want to treat the age categories as ordinal. A natural way to test this is with the Cochran-Armitage test. Ordinal regression or Wilcoxon-Mann-Whitney will likely give similar results.


(3)Percentages usually do not fit the assumptions of the ANOVA, unless the sample size is huge even under the popular conversions. This is because the ANOVA is rather sensitive to skew,  But if the sample is above, say 400 per comparison, then Pearson's chi square will possibly  be hyper sensitive.


(4)I would do this as logistic regression. Generally speaking, it is not a good idea to convert categorical data into percentages; percentages look like a continuous variable but they generally violate the assumption of most continuous-variable tests (like ANOVA and t-tests).


(5)I think ANOVA is not good option data is based on count outcome so it can be checked through compare the two group proportionally using Z test








ref:
1. https://www.dummies.com/education/math/statistics/how-to-compare-two-population-proportions/
2. https://www.researchgate.net/post/Comparing_two_groups_of_percentages-is_a_t-test_ok



========================================
----------------------------------------


========================================
----------------------------------------


========================================
----------------------------------------



========================================
----------------------------------------




========================================
----------------------------------------


========================================
----------------------------------------



========================================
----------------------------------------




========================================
----------------------------------------


========================================
----------------------------------------


========================================
----------------------------------------



========================================
----------------------------------------




========================================
----------------------------------------


========================================
----------------------------------------



========================================
----------------------------------------




========================================
----------------------------------------



========================================
----------------------------------------


========================================
----------------------------------------


========================================
----------------------------------------


========================================
----------------------------------------

