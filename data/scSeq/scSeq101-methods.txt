scSeq methods
分离单细胞的方法
单细胞数据分析流程(通用的流程和方法)


单细胞可视化技术、思路、代码, 最常用的包汇聚到主题文件。







========================================
文献跟踪：单细胞测序新方法、新包
----------------------------------------
单细胞转录组分析综述
https://mp.weixin.qq.com/s?__biz=MzI1Njk4ODE0MQ==&mid=2247484039&idx=1&sn=1e799a06dbea57ed74596812d1e6c6df







========================================
[经典]Question: Single Cell RNAseq data analysis protocol
----------------------------------------
(1) Tophat - Cufflink - Cuffdiff; 
(2) Subread - featureCounts - DESeq2; 
(3) STAR - RSEM - EBSeq; 
(4) Bowtie - eXpress - edgeR; 
(5) kallisto - sleuth; 
(6) HISAT - StringTie - Ballgown.



单细胞转录组数据挖掘推荐: https://www.jianshu.com/p/5e7212109648





Orchestrating Single-Cell Analysis with Bioconductor: https://osca.bioconductor.org/




1.https://www.biostars.org/p/199310/
This tutorial was recently posted here: Analysis of single-cell RNA-seq data


2. I started a list of single-cell analysis software, tutorials and workshops here:
https://github.com/seandavi/awesome-single-cell




3. current issue of Genome Biology: Single-Cell Omics ( special issue)
Genome Biology highlights the emergence of this field with a special issue focused on single-cell methods and their applications.
http://www.biomedcentral.com/collections/singlecellomics



4. [经典]Tutorial: Analysis of single-cell RNA-seq data
github:https://github.com/hemberg-lab/scRNA.seq.course
web: http://hemberg-lab.github.io/scRNA.seq.course/index.html
pdf: http://hemberg-lab.github.io/scRNA.seq.course/scRNA-seq-course.pdf


http://hemberg-lab.github.io/scRNA.seq.course/construction-of-expression-matrix.html#mapping-qc

A survey of best practices for RNA-seq data analysis
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4728800/

sam文件格式：https://github.com/DawnEve/NGS_training/blob/master/day3.markdown

c1测序分析(P5)：http://www.pnas.org/content/113/12/3293.full.pdf




5. RNAseq的39个工具
文献：Sahraeian S M E, Mohiyuddin M, Sebra R, et al. Gaining comprehensive biological insight into the transcriptome by performing a broad-spectrum RNA-seq analysis[J]. Nature Communications, 2017, 8(1):59.

这是一篇在NC上发表的使用RNAseq工具对比的一篇文献，解读这篇文献对我们使用RNAseq发文提供了思路。

http://www.a-site.cn/article/1567422.html
http://www.360doc.com/content/17/1002/18/45962007_691819499.shtml



6.sanger研究所： Single Cell Bioinformatics Tools and Software
At the Wellcome Genome Campus, both the EBI and Sanger Institute are continually developing tools and software to help in the processing and analysing Single Cell data.

https://www.singlecellbioinformatics.org/tools/



7.单细胞splicing的研究
BRIE: transcriptome-wide splicing quantification in single cells
https://genomebiology.biomedcentral.com/articles/10.1186/s13059-017-1248-5




8.scSeq工具列表
For differential expression:
–   SCDE: http://pklab.med.harvard.edu/scde/index.html
–   SCA: https://github.com/RGLab/SingleCellAssay
–   MAST: https://github.com/RGLab/MAST
–   SAMseq: http://cran.r-project.org/web/packages/samr

For clustering etc.:
–   Monocle: https://github.com/cole-trapnell-lab/monocle-release
–   Rtsne: http://cran.r-project.org/web/packages/Rtsne
–   Sincell: http://master.bioconductor.org/packages/devel/bioc/html/sincell.html
–   scLVM: https://github.com/PMBio/scLVM
–   BASiCS: https://github.com/catavallejos/BASiCS
–   Pagoda: http://pklab.med.harvard.edu/scde
–   Seurat toolkit: http://www.satijalab.org/seurat.html
–   Sincera pipeline: https://research.cchmc.org/pbge/sincera.html 


9.SINGLE-CELL RNA SEQUENCING DATA ANALYSIS SOFTWARE TOOLS
https://omictools.com/single-cell-rna-seq-category

## normalization: Linnorm,NODES, SAMstrt, SCnorm, scran, DESeq and TMM

## feature Selection
Detecting highly variable genes
correlated gene pairs
cell cycle phase
tissue specific gene signatures

## Dimension Reduction: MDS,PCA,t-SNE

## clustering
K-means clustering
Mixture models
Hierarchical clustering


## DEG analysis methods: monocle,MAST,SCDE, BASiCS, NODES, SAMstrt, Seurat and DESeq2


## Pseudotime
Monocle / Monocle 2 / Census
Wanderlust / Cycler / Wishbone
SCUBA
Slingshot


## scRNAseq R包中的数据集
这个包内置的是 Pollen et al. 2014 数据集，人类单细胞细胞，分成4类，分别是 pluripotent stem cells 分化而成的 neural progenitor cells (“NPC”) ，还有 “GW16” and “GW21” ，“GW21+3” 这3种孕期细胞。
一个探索这个数据集的教程 http://bio-info-trainee.com/tmp/scRNA/study_scRNAseq.html














========================================
R 语言分析 单细胞的流程包 //todo
----------------------------------------
https://www.jianshu.com/p/e90f5d4d0ab6









========================================
scSeq 建库方法列表
----------------------------------------
单细胞更加精准，最终得到的是每个细胞型的表达量，从而可以帮助理解组织异质性，鉴定罕见的细胞类型，检测细胞组分的变化，例如在癌症异质性、胚胎发育、细胞对药物的反应、神经细胞分型、差异表达通路等方面都发挥重要作用



1.Overview of experimental methods for generating scRNA-seq data

CEL-seq
CEL-seq2
Drop-seq （原理介绍使用的方法）
InDrop-seq
MARS-seq
SCRB-seq
Seq-well
Smart-seq
Smart-seq2
SMARTer
STRT-seq

但是即使测序办法繁多丰富，但根底里是需要面对两个问题:  quantification（定量）和 capture（捕捉）


2.Quantification（定量）

关于quantification（定量），目前存有着两种处理方式：full-length（全长） and tag-based（标签依赖）

full-length的处理方法旨在对每个转录本获取统一的测序覆盖度，相反tag-based处理方法只捕捉mRNA的5'或3'端，定量处理方法的选择取决于你后期想要分析的目的。

理论上，full-length的处理可以提供一个相对平均的测序覆盖度，但是就目前的结果来说还是存在着很多bias。

而tag-based的优势在于它可以结合UMI（前面介绍过）来提高定量的水平，缺点在于未捕捉完全的转录本序列，在比对的时候无法区分iosform (Archer et al. 2016)



3.Capture（捕捉）

捕捉RNA的策略决定了你的产出，细胞如何被选择包括是否携带额外信息都值得大做文章。三个被广泛运用的方法包括：

microwell-based
microfluidic-based
droplet-based

(1)microwell-based
简单来说，这种方法就是把单个细胞利用laser capture或者example pipette的技术分离到微流体孔里面。这种技术的既有优势在于可以结合FACS分选技术，根据细胞表面marker挑选出的合适的细胞亚群，并且可以对细胞形态进行记录，找出并丢弃损伤细胞或粘连的非单个细胞。这个技术的缺陷在于由于分选的局限性导致的低通量，和相匹配的较大的工作量。


(2)microfluidic-based
以Fluidigm’s C1举例，其提供了一个整合的细胞捕获系统，并可以执行建库前的反应，所以相对于microwell-based方法有更高的通量。

但其弊端在于其只能捕获10%左右的细胞，所以不太适合应用于有较少样品量或者样品较为珍惜的情况。


(3)droplet-based

这种技术就是我以上介绍的原理的例子，通过纳升级别的携带beads的小液滴，捕获单个细胞，并在液滴内完成建库，其优势在于可以定量的鉴别每个cell内的转录本数量，劣势在于测序深度低，往往一个细胞只有小几千个转录本被检测到。


(4)What platform to use for my experiment?
老生常谈, 适合的即是最好的。

你所选用的决定于你想要研究什么样的生物学问题。
	假如想要定义一个组织内细胞的组成成分，那么droplet-based方法是较为有效的，因为它可以捕捉到相对大数量级的细胞。
	换一个方面来说，加入想要去研究一群数量有限而又知道细胞表面分子marker的细胞，那么FACS分选接测序才是较好的方案。
	
	想要研究可变剪切转录本，自然需要全长测序的实验方案，这个时候tag标签和UMI就成了异常鸡肋的存在（当然在定量中还是举足轻重的，要看如何取舍了）。
-


refer:
https://www.plob.org/article/12022.html?wpzmaction=add&postid=12022




========================================
|-- Drop-seq / MARS-Seq / Smart-Seq2
----------------------------------------
1. Drop-seq
http://mccarrolllab.org/dropseq/
McCarroll Lab > Computational resources > CookBook





2. MARS-Seq
使用 MARS-Seq 的文献：NB 
Paired-cell sequencing enables spatial gene expression mapping of liver endothelial cells
https://www.plob.org/article/12130.html






3. Smart-Seq2
https://www.illumina.com/science/sequencing-method-explorer/kits-and-arrays/smart-seq2.html

Smart-Seq2 includes several improvements over the original Smart-Seq protocol. 
比着一代有很多改进。

The new protocol includes a locked nucleic acid (LNA), an increased MgCl2 concentration, betaine, and elimination of the purification step to significantly improve the yield. 
提高产出。

In this protocol, single cells are lysed in a buffer that contains free dNTPs and oligo(dT)-tailed oligonucleotides with a universal 5′-anchor sequence. Reverse transcription is performed, which adds 2–5 untemplated nucleotides to the cDNA 3′ end. A template-switching oligo (TSO) is added, carrying two riboguanosines and a modified guanosine to produce a LNA as the last base at the 3′ end.  After the first-strand reaction, the cDNA is amplified using a limited number of cycles. Tagmentation is then used to quickly and efficiently construct sequencing libraries from the amplified cDNA.


Pros:
The sequence of the mRNA does not have to be known
As little as 50 pg of starting material can be used
Improves coverage across transcripts
High level of mappable reads


Cons:
Not strand-specific
No early multiplexing
Applicable only to poly(A)+ RNA

refer:
Smart-Seq2: Picelli S., Bjorklund A. K., Faridani O. R., Sagasser S., Winberg G., et al. (2013) Smart-seq2 for sensitive full-length transcriptome profiling in single cells. Nat Methods 10: 1096-1098

Smart-Seq2: Picelli S., Faridani O. R., Björklund Å. K., Winberg G., Sagasser S., et al. (2014) Full-length RNA-Seq from single cells using Smart-seq2. Nat. Protocols 9: 171-181





========================================
|-- Fluidigm/Smart-Seq data sets: 使用C1分离细胞，使用Smart-Seq建库
----------------------------------------

using the Fluidigm C1 system to isolate cells and 
generate single-cell transcriptomes using Smart-Seq-based methods

https://genome.cshlp.org/content/28/9/1353.long






========================================
分析流程和方法
----------------------------------------


========================================
|-- 单细胞测序怎么标准化？
----------------------------------------
http://www.360doc.com/content/18/0120/23/19913717_723747538.shtml


1.使用CPM去除文库大小影响

之所以需要normalization，就是因为测序的各个细胞样品的总量不一样，所以测序数据量不一样，就是文库大小不同，这个因素是肯定需要去除。最简单的就是counts per million (CPM)，所有样本的所有基因的表达量都乘以各自的文库reads总数再除以一百万即可。(一般miRNA-seq数据结果喜欢用这个) 代码如下：

calc_cpm <>
function (expr_mat, spikes = NULL) 
{
   norm_factor <- colsums(expr_mat[-spikes,="">
   return(t(t(expr_mat)/norm_factor)) * 10^6
}
但是CPM方法有一个很严重的缺陷，那些高表达并且在细胞群体表达差异很大的基因会严重影响那些低表达基因。




2.RPKM, FPKM and TPM去除基因或者转录本长度影响
这些normalization方法并不适合单细胞转录组测序数据，因为有一些scRNA-seq建库方法具有3端偏好性，一般是没办法测全长转录本的，所以转录本的长度跟表达量不是完全的成比例。

对于这样的数据，需要重新转换成 reads counts 才能做下游分析。


适用于bulk RNA-seq的normalization方法
比较流行的有：
DESeq的size factor (SF)
relative log expression(RLE)
upperquartile (UQ)
weighted trimmed mean of M-values(TMM)
这些适用于 bulk RNA-seq data 的normalization方法可能并不适合 single-cell RNA-seq data ，因为它们的基本假设是有问题的。


特意为single-cell RNA-seq data 开发的normalization方法
LSF (Lun Sum Factors)
scran package implements a variant on CPM specialized for single-cell data
而scater包把这些normalization方法都包装到了normaliseExprs函数里面，可以直接调用。



3.Raw
先看看原始的表达值的分布情况，这里本来应该是对每一个样本画boxplot的，但是这里的样本数量太多了，这样的可视化效果很差， 就用PCA的方式，看看这表达矩阵是否可以把样本区分开，只有那些区分度非常好的normalization方法才是最优的。

不过scater包提供了一个plotRLE函数，可以画出类似于样本boxplot的效果。





========================================
|-- 如何处理带 UMI（Unique Molecular Identifiers） 的测序数据？ UMI-tools
----------------------------------------

1. 使用 UMI-tools
ref: https://www.ncbi.nlm.nih.gov/labs/pmc/articles/PMC7655794/
Reads from bc-Smart-seq2 single cells were demultiplexed with UMI-tools (version 0.5.3; Smith et al., 2017). A cell barcode whitelist was used to filter barcodes for downstream processing. Cell barcodes and the UMI from each read were extracted to the read name of the sequence using the UM-tools extract function. 

CellRanger 之外，
DropEst、Kallisto-BUStools、UMI-Tools、STARSolo和Alevin都是可选的reads处理方法，它们对运行时长和内存进行了改进，使用户能够处理其scRNA-seq运行时不必在计算基础设施上投入太多。

此外，与CellRanger相比，DropEst、UMI­Tools和Kallisto-BUS Tools提供的对UMI和cell barcode错误的增强校正可改善基因表达估计。



Demultiplexing：这一步是根据细胞barcode和 mRNA UMI来识别转录分子来源并分配reads；常用的工具有zUMIs，UMI-tools等。


(2) 对该工具的评价

可发现Cell Ranger 3.1在识别细胞条形码上最为灵敏；

UMI-tools和zUMIs可在每个细胞中过滤掉大多数低表达基因的同时检测到更多的基因，其检测到的基因表达水平也与每个细胞的共识基因高度相关，即UMI-tools和zUMIs拥有最高的一致性

UMI-­Tools  是另一种纠正细胞barcode和UMIs中测序错误的流程，以提供更准确的基因表达定量。


DropEst、Kallisto-BUStools、UMI-Tools、STARSolo和Alevin都是可选的read处理方法，它们对运行时长和内存进行了实质的改进，允许用户处理他们的scRNA-seq数据而不必在计算基础设施上投入太多。
此外，与CellRanger相比，DropEst、UMI­Tools和Kallisto-BUS Tools提供的对UMI和cell barcode错误的增强校正可以改善基因表达估计。


(3) 其他工具 
方法比较综述： https://www.nature.com/articles/s41581-020-0262-0
Review Article | Published: 27 March 2020 | Nature Reviews Nephrology
Tools for the analysis of high-dimensional single-cell RNA sequencing data


STARSolo 和Alevin分别是两种比对和伪比对方法的扩展，也可以用来处理scRNA-seq数据。
STARSolo和Alevin的运行时间都明显快于CellRanger，但STARSolo的最大内存使用量更高。


https://github.com/alexdobin/STAR/blob/master/docs/STARsolo.md
https://cumulus.readthedocs.io/en/latest/starsolo.html





2. UMI tools 怎么使用

Smith T, Heger A, Sudbery I. UMI-tools: modeling sequencing errors in Unique Molecular Identifiers to improve quantification accuracy. Genome Res. 2017;27(3):491–499.

Saiful Islam, et al. Quantitative single-cell RNA-seq with unique molecular identifiers. Nature Methods. 2014, 11:163-166.

Kivioja T, et al. Counting absolute numbers of molecules using unique molecular identifiers. Nat Methods. 2011, 9(1):72-4.


(1) 安装下载
https://umi-tools.readthedocs.io/en/latest/Single_cell_tutorial.html

$ pip3 -V
pip 19.1.1 from /home/wangjl/software/anaconda3/lib/python3.7/site-packages/pip (python 3.7)

$ pip3 install umi_tools
# Successfully installed pybktree-1.1 regex-2022.1.18 umi-tools-1.1.2


(2) 检查版本号
$ pip3 list | grep umi
umi-tools                          1.1.2



(3) 子命令

$ umi_tools
For full UMI-tools documentation, see: https://umi-tools.readthedocs.io/en/latest/
umi_tools.py - Tools for UMI analyses
:Author: Tom Smith & Ian Sudbury, CGAT
:Release: $Id$
:Date: |today|
:Tags: Genomics UMI

There are 6 tools:
  - whitelist
  - extract
  - group
  - dedup
  - count
  - count_tab

To get help on a specific tool, type:
    umi_tools <tool> --help

To use a specific tool, type::
    umi_tools <tool> [tool options] [tool arguments]



(4) 使用UMI-tools之前需要准备的软件：
https://umi-tools.readthedocs.io/en/latest/Single_cell_tutorial.html

1)、UNI-tools
2)、STAR
3)、参考基因组的STAR index文件
4)、基因组注释文件 gtf
5)、Subread（版本1.5.3或以上）
	http://subread.sourceforge.net/
	$ subread-align -v
	Subread-align v1.6.0

	$ featureCounts -v #可能是用这个，统计bam中的表达量的
	featureCounts v1.6.0
#







3. 使用UMI-tools定量单细胞数据的几个流程

Step:	Inputs	/Output
Find Cell barcode whitelist:	Read 1 fastq	/whitelist.txt
Extract CB/UMIs and filter CBs: 	R1 + R2 fastqs + whitelist.txt	/extracted fastqs
Map reads:	extracted fastqs	/BAM
Assign reads to genes:	BAM + transcriptome GTF	/BAM
Count unique reads per genes per cell:	BAM	/Counts.txt

第一步，获得细胞barcode的白名单文件（也就是分细胞）；
第二步，根据白名单文件提取对应的reads（也就是根据分好的细胞提取每个细胞对应的reads）；
第三步，将reads比对到参考基因组；
第四步，利用基因组注释文件将比对的reads对应到相应的基因上；
第五步，计算每个细胞中每个基因的表达值。


(1) step1: 合并成2个fastq.gz文件，R1，R2各一个。
cat fastqs/hgmm_100_S1_L00?_R1_001.fastq.gz > hgmm_100_R1.fastq.gz;
cat fastqs/hgmm_100_S1_L00?_R2_001.fastq.gz > hgmm_100_R2.fastq.gz;




(2) step2:  Identify correct cell barcodes 根据R1获取细胞cell barcode
$ umi_tools whitelist --stdin hgmm_100_R1.fastq.gz \
                    --bc-pattern=CCCCCCCCCCCCCCCCNNNNNNNNNN \
                    --set-cell-number=100 \
                    --log2stderr > whitelist.txt;

其中--bc-pattern 表示的是细胞的barcode和UMI的格式。“CCCCCCCCCCCCCCCCNNNNNNNNNN”代表16bp的barcode和10bp的UMI序列。

# 对于 10x 的试剂:
	V2试剂盒的R1端长度为26bp，包含16bp的barcode和10bp的UMI序列，
	V3试剂盒的R1端长度为28bp，包含16bp的barcode和12bp的UMI序列；
	V2试剂盒的R2端为98bp, V3试剂盒的R2端为91bp。




(3) 根据分好的细胞提取每个细胞对应的reads。
输入是 R1 + R2 fastqs + whitelist.txt

# Step 3: Extract barcdoes and UMIs and add to read names 提取cb和UMI到 Read 2的 read name上。
$ umi_tools extract --bc-pattern=CCCCCCCCCCCCCCCCNNNNNNNNNN \
                  --stdin hgmm_100_R1.fastq.gz \
                  --stdout hgmm_100_R1_extracted.fastq.gz \
                  --read2-in hgmm_100_R2.fastq.gz \
                  --read2-out=hgmm_100_R2_extracted.fastq.gz \
                  --whitelist=whitelist.txt; 


(4) Step 4: Map reads 比对

可以
	比对到 transcriptome，每个contig代表一个转录本；
	或者 genome 上，然后把reads归给某个基因。

比对到 transcriptome 做下游分析更方便，但是推荐比对到  genome 上，因为当其他地方有更好的匹配位置的时候，该方法不强制read比对到某个转录本。
While transcriptome mapping allows for easier downstream analysis, we recommend mapping to the genome because it doesn’t force reads to map to transcripts when a better match outside an annotated gene exists. 

但是，做 Variations 选择的时候还是比对到 transcriptome 更好。
However, there are cases when transcriptome mapping should be favoured, and we discuss this in the Variations section.

$ STAR --runThreadN 4 \
     --genomeDir hg38_noalt_junc85_99.dir \
     --readFilesIn hgmm_100_R2_extracted.fastq.gz \
     --readFilesCommand zcat \
     --outFilterMultimapNmax 1 \ #We do not allow multimapping reads.
	 --outFileNamePrefix fastq/extracted_ \ #添加output文件名前缀
     --outSAMtype BAM SortedByCoordinate;



(5) 将比对上的reads对应到注释基因上。
# Step 5: Assign reads to genes (subread 1.5.3 and above)

This means that two reads from the same gene might have different mapping locations and still represent duplicates, as long as they come from the same gene.

确实没有去重：We can do this with the featureCounts tool from the subread package. As well as outputting a table of (undeduplicated) counts, we can also instruct featureCounts to output a BAM with a new tag containing the identity of any gene the read maps to.



$ featureCounts -a geneset.gtf \
              -o gene_assigned \
              -R BAM Aligned.sortedByCoord.out.bam \
              -T 4;            
samtools sort Aligned.sortedByCoord.out.bam.featureCounts.bam -o assigned_sorted.bam;
samtools index assigned_sorted.bam;


(6) 计算每个细胞中每个基因的表达值。
we can now count the number of distinct UMIs mapping to each gene in each cell.

# Step 6: Count UMIs per gene per cell
umi_tools count --per-gene --gene-tag=XT --assigned-status-tag=XS --per-cell -I assigned_sorted.bam -S counts.tsv.gz




========================================
|-- 如何处理带 UMI（Unique Molecular Identifiers） 的测序数据？ STAR solo 更简约
----------------------------------------
https://github.com/alexdobin/STAR/blob/master/docs/STARsolo.md
https://www.biorxiv.org/content/10.1101/2021.05.05.442755v1.full.pdf



1. 版本号
$ STAR --version
STAR_2.5.2b #这个版本没 solo 选项


(1) 暂时先使用其他人安装的版本

$ /home/yangwl/anaconda2/bin/STAR --version
2.7.4a


$ vim ~/.bashrc #添加一行
alias STAR27=/home/yangwl/anaconda2/bin/STAR

$ STAR27 --version
2.7.4a

(2) 用到 snakemake 中找不到该命令
最后在 ~/bin/ 下建立了软链接。

$ whereis STAR27
STAR27: /home/wangjl/bin/STAR27

$ ls -lth /home/wangjl/bin/STAR27
lrwxrwxrwx. 1 wangjl jinwf 31 Feb 22 12:55 /home/wangjl/bin/STAR27 -> /home/yangwl/anaconda2/bin/STAR








2. 构建索引
测试了一下，版本 2.5和2.7确实不是一个索引。

The genome index is the same as for normal STAR runs.

(1) for human
$ mkdir /home/wangjl/data/ref/hg38/gencode/index/STAR27/
$ STAR27 --runMode genomeGenerate \
	--runThreadN 150 \
	--genomeDir /home/wangjl/data/ref/hg38/gencode/index/STAR27/ \
	--genomeFastaFiles /home/wangjl/data/ref/hg38/gencode/GRCh38.p13.genome.fa \
	--sjdbGTFfile /home/wangjl/data/ref/hg38/gencode/GRCh38.p13.gtf \
	--sjdbOverhang 100


(2) for mouse
$ mkdir /home/wangjl/data/ref/GRCm39/gencode/index/STAR27/
$ STAR27 --runMode genomeGenerate \
	--runThreadN 200 \
	--genomeDir /home/wangjl/data/ref/GRCm39/gencode/index/STAR27/ \
	--genomeFastaFiles /home/wangjl/data/ref/GRCm39/gencode/GRCm39.genome.fa \
	--sjdbGTFfile /home/wangjl/data/ref/GRCm39/gencode/gencode.vM28.annotation.gtf \
	--sjdbOverhang 100
# 22:25 -->  #200个核有点多了。不能超过2/3的总核数。









3. 开始比对

(1) --soloType Droplet 参数
$ mkdir star27
$ STAR27 --runThreadN 100 \ #这个用法错误，请看test3。要设置好 cb 和 UMI 的起始位置。
	--genomeDir /home/wangjl/data/ref/GRCm39/gencode/index/STAR27/ \
	--readFilesIn /home/wangjl/data/chenxi/batch0/raw/SS3-RNASeq-3_L4_1001279.R2.fastq.gz /home/wangjl/data/chenxi/batch0/raw/SS3-RNASeq-3_L4_1001279.R1.fastq.gz \
	--soloType Droplet \
	--soloCBlen 8 \
	--soloUMIlen 10 \
	--soloBarcodeReadLength 150 \
	--readFilesCommand zcat \
	--soloCBwhitelist /home/wangjl/data/chenxi/batch0/raw/cell_barcode.txt \
	--outFileNamePrefix star27/t1/Droplet_
# 13:22 - 13:37, 15min




# test1: --soloBarcodeReadLength 0
$ STAR27 --runThreadN 100 \
	--genomeDir /home/wangjl/data/ref/GRCm39/gencode/index/STAR27/ \
	--readFilesIn /home/wangjl/data/chenxi/batch0/raw/SS3-RNASeq-3_L4_1001279.R2.fastq.gz /home/wangjl/data/chenxi/batch0/raw/SS3-RNASeq-3_L4_1001279.R1.fastq.gz \
	--soloType CB_UMI_Simple \
	--soloCBlen 8 \
	--soloUMIlen 10 \
	--soloBarcodeReadLength 0 \
	--readFilesCommand zcat \
	--soloCBwhitelist /home/wangjl/data/chenxi/batch0/raw/cell_barcode.txt \
	--outFileNamePrefix star27/t1/Droplet_
# 20:06-->20:27, 21min;
$ awk 'NR>3{print $0}' /home/wangjl/data/chenxi/batch0/star27/t1/Droplet_Solo.out/Gene/filtered/matrix.mtx | awk '{a += $3};END{print a}' #3,576,755=3.5 Million Reads


# test2: --soloUMIdedup=Exact
$ STAR27 --runThreadN 100 \
	--genomeDir /home/wangjl/data/ref/GRCm39/gencode/index/STAR27/ \
	--readFilesIn /home/wangjl/data/chenxi/batch0/raw/SS3-RNASeq-3_L4_1001279.R2.fastq.gz /home/wangjl/data/chenxi/batch0/raw/SS3-RNASeq-3_L4_1001279.R1.fastq.gz \
	--soloType CB_UMI_Simple \
	--soloCBlen 8 \
	--soloUMIlen 10 \
	--soloBarcodeReadLength 0 \
	--readFilesCommand zcat \
	--soloCBwhitelist /home/wangjl/data/chenxi/batch0/raw/cell_barcode.txt \
	--soloUMIdedup=Exact \
	--outFileNamePrefix star27/t2/Droplet_
# 20:10 --> 20:31; 20min;
$ awk 'NR>3{print $0}' /home/wangjl/data/chenxi/batch0/star27/t2/Droplet_Solo.out/Gene/filtered/matrix.mtx | awk '{a += $3};END{print a}' #14753223=14,753,223=14 Million Reads



# test3: --soloCBstart 1  --soloUMIstart 9 --soloUMIdedup=Exact
$ STAR27 --runThreadN 100 \
	--genomeDir /home/wangjl/data/ref/GRCm39/gencode/index/STAR27/ \
	--readFilesIn /home/wangjl/data/chenxi/batch0/raw/SS3-RNASeq-3_L4_1001279.R2.fastq.gz /home/wangjl/data/chenxi/batch0/raw/SS3-RNASeq-3_L4_1001279.R1.fastq.gz \
	--soloType CB_UMI_Simple \
	--soloCBstart 1 --soloCBlen 8 \
	--soloUMIstart 9 --soloUMIlen 10 \
	--soloBarcodeReadLength 0 \
	--readFilesCommand zcat \
	--soloCBwhitelist /home/wangjl/data/chenxi/batch0/raw/cell_barcode.txt \
	--soloUMIdedup=Exact \
	--outFileNamePrefix star27/t3/Droplet_
# 20:23 --> 20:46, 23min;
$ awk 'NR>3{print $0}' /home/wangjl/data/chenxi/batch0/star27/t3/Droplet_Solo.out/Gene/filtered/matrix.mtx | awk '{a += $3};END{print a}' #49030399=49,030,399=49 Million Reads
# 这个数字最接近 UMI tools 的 50M reads;





# test4: --soloCBstart 1  --soloUMIstart 9
$ STAR27 --runThreadN 100 \
	--genomeDir /home/wangjl/data/ref/GRCm39/gencode/index/STAR27/ \
	--readFilesIn /home/wangjl/data/chenxi/batch0/raw/SS3-RNASeq-3_L4_1001279.R2.fastq.gz /home/wangjl/data/chenxi/batch0/raw/SS3-RNASeq-3_L4_1001279.R1.fastq.gz \
	--soloType CB_UMI_Simple \
	--soloCBstart 1 --soloCBlen 8 \
	--soloUMIstart 9 --soloUMIlen 10 \
	--soloBarcodeReadLength 0 \
	--readFilesCommand zcat \
	--soloCBwhitelist /home/wangjl/data/chenxi/batch0/raw/cell_barcode.txt \
	--outFileNamePrefix star27/t4/Droplet_
# 20:51 --> 21:06, 15min;
$ awk 'NR>3{print $0}' /home/wangjl/data/chenxi/batch0/star27/t4/Droplet_Solo.out/Gene/filtered/matrix.mtx | awk '{a += $3};END{print a}' # 48356229=48,356,229=48 Million Reads



# test5: 和 cellranger 一样的输出?
$ STAR27 --runThreadN 100 \
	--genomeDir /home/wangjl/data/ref/GRCm39/gencode/index/STAR27/ \
	--readFilesIn /home/wangjl/data/chenxi/batch0/raw/SS3-RNASeq-3_L4_1001279.R2.fastq.gz /home/wangjl/data/chenxi/batch0/raw/SS3-RNASeq-3_L4_1001279.R1.fastq.gz \
	--soloType CB_UMI_Simple \
	--soloCBstart 1 --soloCBlen 8 \
	--soloUMIstart 9 --soloUMIlen 10 \
	--soloBarcodeReadLength 0 \
	--readFilesCommand zcat \
	--soloCBwhitelist /home/wangjl/data/chenxi/batch0/raw/cell_barcode.txt \
	--outSAMattributes CB UB \
	--outSAMtype BAM SortedByCoordinate \
	--outFileNamePrefix star27/t5/Droplet_
# 16:40 --> 17:09, 29min;

$ head /home/wangjl/data/chenxi/batch0/star27/t5/Droplet_Solo.out/Gene/filtered/matrix.mtx
%%MatrixMarket matrix coordinate integer general
%
55357 371 2600458
32 1 68
34 1 11

计算第三列总和:
$ awk 'NR>3' star27/t5/Droplet_Solo.out/Gene/filtered/matrix.mtx| awk '{a+=$3}END{print a}'
# 48356229=48,356,229=48 M reads;



输出的文件，确实有 CB 和 UB 标签了。
$ samtools view star27/t5/Droplet_Aligned.sortedByCoord.out.bam | head -n 3
A00679:526:HYVNJDSXY:4:1450:21305:34350 256     chr1    3109499 0       108M42S *       0       0       GTTATACAGACACTAAGAGAACACAAATTCCAGCCCAGGCTACTATACCCAGCCAAACTCTCAATTACCATAGATGGAGAAACCAAAGTATTCCATGACAAAACCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGGAAAACAAAGATGAA  FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF:,:,FF,,:F,,,FF,F,  CB:Z:GTCATCTC   UB:Z:TGCGTTCCAG
A00679:526:HYVNJDSXY:4:2419:17011:3709  256     chr1    3109499 0       108M42S *       0       0       GTTATACAGACACTAAGAGAACACAAATTCCAGCCCAGGCTACTATACCCAGCCAAACTCTCAATTACCATAGATGGAGAAACCAAAGTATTCCATGACAAAACCAAAAAAAAAAAAAAAAAAAAAAAAAAAAATGGAACGCAGAGATGA  FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF::FFFFFFFFFFFFFFFFFFFFFFFFFFFFFF,,,,,F:,,FF,:,F,::  CB:Z:GTCATCTC   UB:Z:TGCGTTCCAG
A00679:526:HYVNJDSXY:4:2450:21414:26866 256     chr1    3109499 0       108M42S *       0       0       GTTATACAGACACTAAGAGAACACAAATTCCAGCCCAGGCTACTATACCCAGCCAAACTCTCAATTACCATAGATGGAGAAACCAAAGTATTCCATGACAAAACCAAAAAAAAAAAAAAAAAAAAAAAAAAATGAAAACACAAGATTAAA  FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF,,,,:F,,,,,:,,,,F,F  CB:Z:GTCATCTC   UB:Z:TGCGTTCCAG



# 取1e6行做测试，节省时间。

# test6: 仅保留 uniq mapping，输出 CB 和 UB。
$ STAR27 --runThreadN 100 \
	--genomeDir /home/wangjl/data/ref/GRCm39/gencode/index/STAR27/ \
	--readFilesIn raw/S3.R2.fastq.gz raw/S3.R1.fastq.gz \
	--soloType CB_UMI_Simple \
	--soloCBstart 1 --soloCBlen 8 \
	--soloUMIstart 9 --soloUMIlen 10 \
	--soloBarcodeReadLength 0 \
	--readFilesCommand zcat \
	--outSAMtype BAM SortedByCoordinate \
	--soloCBwhitelist /home/wangjl/data/chenxi/batch0/raw/cell_barcode.txt \
	--outFilterMultimapNmax 1 \
	--outSAMattributes CB UB \
	--outFileNamePrefix tmp/S3_

加入2条：只要uniq map，要输出 CB，UB。能输出 NH 吗？
# 23:33 -> 23:39

$ samtools view  tmp/S3_Aligned.sortedByCoord.out.bam  | awk '{print $5}' | sort | uniq -c | sort -k1nr
 143480 255

$ samtools view  tmp/S3_Aligned.sortedByCoord.out.bam | head
A00679:526:HYVNJDSXY:4:1101:21847:10927	16	chr1	3700996	255	31S119M	*	0	0	TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTGGAGTTTAAAACCAAGTATTTAATGTTTTCATTAAATTGTTTCAATACAATTTCAAACAAATGCCAACTGGAAGACAATGTCCAAAAACTCTGAAGC	FF:FFFFFFFFFFFFFFFFFFFF:FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF:FFFFFFFFFFF	CB:Z:CGGTGCTC	UB:Z:CACGTGCTCT
A00679:526:HYVNJDSXY:4:1101:6343:28385	16	chr1	3700996	255	23S127M	*	0	0	TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTGGAGTTTAAAACCAAGTATTTAATGTTTTCATTAAATTGTTTCAATACAATTTCAAACAAATGCCAACTGGAAGA



# test7: 输出其他标签呢？
去掉 	--outFilterMultimapNmax 1 \，添加更多标签
$ STAR27 --runThreadN 100 \
	--genomeDir /home/wangjl/data/ref/GRCm39/gencode/index/STAR27/ \
	--readFilesIn raw/S3.R2.fastq.gz raw/S3.R1.fastq.gz \
	--soloType CB_UMI_Simple \
	--soloCBstart 1 --soloCBlen 8 \
	--soloUMIstart 9 --soloUMIlen 10 \
	--soloBarcodeReadLength 0 \
	--readFilesCommand zcat \
	--outSAMtype BAM SortedByCoordinate \
	--soloCBwhitelist /home/wangjl/data/chenxi/batch0/raw/cell_barcode.txt \
	--outSAMattributes CB UB NH HI AS nM \
	--outFileNamePrefix tmp/S3_t2_
# 09:25 -> 09:27

$ samtools view tmp/S3_t2_Aligned.sortedByCoord.out.bam | head
A00679:526:HYVNJDSXY:4:1101:21847:10927	16	chr1	3700996	255	31S119M	*	0	0	TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTGGAGTTTAAAACCAAGTATTTAATGTTTTCATTAAATTGTTTCAATACAATTTCAAACAAATGCCAACTGGAAGACAATGTCCAAAAACTCTGAAGC	FF:FFFFFFFFFFFFFFFFFFFF:FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF:FFFFFFFFFFF	NH:i:1	HI:i:1	AS:i:101	nM:i:8 CB:Z:CGGTGCTC	UB:Z:CACGTGCTCT

$ samtools view tmp/S3_t2_Aligned.sortedByCoord.out.bam | wc
 208948 3550250 90996710

$ samtools view tmp/S3_t2_Aligned.sortedByCoord.out.bam |awk '{print $5}' | sort | uniq -c | sort -k1nr
 143480 255
  35928 3
  17027 1
  12513 0

$ samtools view tmp/S3_t2_Aligned.sortedByCoord.out.bam | awk '{print $12}' | sort | uniq -c | sort -k1nr
 143480 NH:i:1
  35928 NH:i:2
  12183 NH:i:3
   4844 NH:i:4
   3505 NH:i:5
   2994 NH:i:6
   2219 NH:i:7
   1710 NH:i:10
   1053 NH:i:9
   1032 NH:i:8
也就是说，uniq mapping 的 MAPQ=255，且 NH=1，这2个是等价条件。













2)目测t1的输出，前几行的数据

$ head /home/wangjl/data/chenxi/batch0/star27/t1/Droplet_Solo.out/Gene/filtered/matrix.mtx
%%MatrixMarket matrix coordinate integer general
%
55357 382 2596436
32 1 1
34 1 1
36 1 1
44 1 1
54 1 1
68 1 1
75 1 2



经过反复核查，发现需要设置 CB和 UMI 的第一个碱基位置，上文 t3, t4 已经添加。
	soloCBstart
	soloUMIstart
采用 t3，删掉t1,t2,t4的结果。





参数简介：

The STAR solo algorithm is turned on with:
	--soloType Droplet
or, since 2.7.3a, with more descriptive:
	--soloType CB_UMI_Simple #这两个是一样的，但是这个读起来比 Droplet 更直观。

The CellBarcode whitelist has to be provided with:
	--soloCBwhitelist /path/to/cell/barcode/whitelist


白名单的格式：
https://github.com/10XGenomics/cellranger/raw/master/lib/python/cellranger/barcodes/737K-august-2016.txt
好吧，看了一下，就是一列，每行是一个cb: https://raw.githubusercontent.com/10XGenomics/cellranger/master/lib/python/cellranger/barcodes/737K-august-2016.txt
AAACCTGAGAAACCAT
AAACCTGAGAAACCGC
AAACCTGAGAAACCTA
AAACCTGAGAAACGAG
AAACCTGAGAAACGCC
...




(2) 怎么设置 CB 碱基个数
https://cumulus.readthedocs.io/en/stable/starsolo.html
The default barcode lengths (CB=16b, UMI=10b) work for 10X Chromium V2. For V3, specify:
	--soloUMIlen 12

--CBstart 1 --CBlen 8 \
--UMIstart 9 --UMIlen 10 \




(3) 设置cDNA和 cb+UMI的顺序是固定的：第一个是cDNA，第二个是 cb+UMI
Importantly, in the --readFilesIn option, the 1st file has to be cDNA read, and the 2nd file has to be the barcode (cell+UMI) read, i.e.
	--readFilesIn cDNAfragmentSequence.fastq.gz CellBarcodeUMIsequence.fastq.gz



(4) How to make STARsolo raw gene counts (almost) identical to CellRanger's















========================================
|-- 由很多2列表达数据文件，使用shell获得表达矩阵 getMatrix.sh
----------------------------------------

$ cat getMatrix.sh
#必须有2个参数 idListFile outputFile [dir], 第三个参数htseq文件的路径 默认是当前文件夹(不过不是也要修改)
#目的: 根据idListFile中的id，合并dir目录中的两列数据文件中的第二列，得到matrix矩阵。输出到outputFile中。
# 注意：用户需要保证两列数据的rowname是相同的。本脚本只是抽取第二列，简单合并，没有排序。
# v3.0

## settings
idListFile=$1; #第一个参数是id list file
idListFile=${idListFile:?"必须设置id list file路径"}

outputFile=$2; #输出的文件名文件
outputFile=${outputFile:?"必须设置要输出的文件名"}

dir=$3;#数据文件夹，默认是当前目录下
dir=${dir:='.'}


##产生随机乱码，作为临时文件名
tmp="tmp_"`date |sha256sum|base64|head -c 20`
tmp_test2="test2_"`date |sha256sum|base64|head -c 20`

##step1 add 1st column to target
id=`head -n 1 ${idListFile}`
awk '{print $1}' ${dir}/${id}.freq > $outputFile;

##step2 combine all 2nd columns to target
i=0;
cat ${idListFile} | while read id; do ((i++)); echo ${i} $id;
awk '{print $2}' ${dir}/${id}.freq > $tmp;
paste $outputFile $tmp >$tmp_test2;
mv $tmp_test2 $outputFile;
done;

##step3 add the first row to target
line1=`cat ${idListFile} | xargs`;
line1="pas "${line1}
## echo ${line1};
sed -i "1i ${line1}" $outputFile

#step4 clean
rm $tmp

echo "done~ result file: "${outputFile}




#运行合并脚本，如果2必须参数没有指定，则报错并退出。
$ bash getMatrix.sh /home/wangjl/data/apa/190705PAS/225.cellID test4.txt


##接着使用R语言读取矩阵，检测效果
## 接着使用R语言去掉后5行，和全是0的行，然后重新保存。


========================================
|-- 由很多2列表达数据文件，使用R（太慢）获得表达矩阵 getMatrix.R
----------------------------------------
#目的：合并为apa matrix
# v0.1 可以运行
# v0.2 correct: id=id_list[1]
# v0.3 for cell line

setwd('/home/wangjl/data/apa/190705PAS/bed/freq/')
getwd()


#读取cell id list
id_list=readLines('/home/wangjl/data/apa/190705PAS/225.cellID')
#id_list=id_list[1:10] #debug

head(id_list) # "c01_ROW07" "c01_ROW12"
length(id_list) #225


#获取第一个bed文件，作为文件整体框架，其余文件只需要提取第2列即可
main_matrix=read.table(paste0(id_list[1],".freq"),header=F)
main_matrix[1:4,]
cb=id_list[1]
colnames(main_matrix)=c('PAS',cb)
head(main_matrix)


#function: 从细胞文件中获取第2列信息
getInter=function(id){
  info=read.table(paste0(id,".freq"),header=F)
  info[,2]
}

#添加其余列
for( i in 2:length(id_list) ){
  if(i %% 2==0) print(i)
  #if(i>100) break;
  cb=id_list[i];
  cbdata=getInter(cb);
  main_matrix[,cb]=cbdata
}

dim(main_matrix) #[1] 1559047      11

#写入文件，用tab分割
write.table(main_matrix,"all225_matrix_APACounts.txt",row.names=F,sep="\t")

#end
print("====End===")

在命令行执行:
$ Rscript script/e07_getMatrix.R


========================================
数据降维: 常用的Feature selection的方法
----------------------------------------

1. 选基因的方法

1）基于先验信息的方法（如已知细胞的亚型）。比如通过SCDE软件鉴定已知不同细胞亚型间的差异表达基因，然后再基于差异表达基因来聚类分析等。

2）非监督方法。又可细分为：
(i) 基于highly variable genes (HVG) ；
(ii) 基于spike-in，如scLVM (Buettner et al., 2015)和BASiCS (Vallejos et al., 2015)等；
(iii)基于 dropout，如M3Drop (Andrews and Hemberg, 2018)。


(2)Highly variable genes (HVG)
它基于这种假设：基因相当于平均表达值而言，出现的较大的差异是由于生物学影响，而不仅仅是技术噪音。这种方法试图通过权衡方差与平均表达量之间的关系来找到比预期差异性更高的基因。这种关系很难拟合，实际中基因是按照与移动中位数（moving median）的距离进行排序的(Kolodziejczyk et al., 2015)，或者使用另一种源自方差的统计量，比如：方差的平方系数(Brennecke et al. 2013)

先进行spike-in based feature selection，再PCA（Liu et al., 2016; Tasic et al., 2016）；
先HVG，后tSNE（Segerstolpe et al., 2016）；
先HVG，后PCA+tSNE(Campbell et al., 2017)






2. 陷阱和建议：
- 我们建议根据数据集的复杂程度选择1,000至5,000个高可变基因 (HVG)。

- 当将基因表达值归一化为均值为0和单位方差时，或者将模型拟合的残差用作标准化表达值时，不能使用基于基因表达均-方差的特征选择方法。因此，在选择HVG之前，必须考虑要执行哪些预处理。

- 信息汇总 (summarization，类比于挑选重要的主成分)和可视化应使用不同的降维方法。

- 我们建议使用UMAP进行探索性分析可视化；使用PCA做为通用数据降维方法；diffusion maps可以在轨迹推断时替代PCA。

- UMAP+PAGA是可视化特别复杂的数据集的合适替代方法。






ref:
1.单细胞RNA测序分析的最佳实践教程 （原理、代码和评述）
http://blog.sciencenet.cn/home.php?mod=space&uid=118204&do=blog&id=1220240
Luecken MD, Theis FJ. Current best practices in single-cell RNA-seq analysis:
a tutorial. Mol Syst Biol. 2019 Jun 19;15(6):e8746. doi: 10.15252


2. 手写单细胞降维代码，比掉包能做更细致的分析
https://www.cnblogs.com/leezx/p/8648390.html






========================================
|-- t-SNE算法，及其优缺点
----------------------------------------
t-SNE http://lvdmaaten.github.io/tsne/
R包 https://cran.r-project.org/web/packages/tsne/

t-SNE(t-distributed stochastic neighbor embedding)是用于降维的一种机器学习算法，是由 Laurens van der Maaten 和 Geoffrey Hinton在08年提出来。此外，t-SNE 是一种非线性降维算法，非常适用于高维数据降维到2维或者3维，进行可视化。

tSNE描述
http://bindog.github.io/blog/2016/06/04/from-sne-to-tsne-to-largevis/

比PCA高级的t-SNE也存在缺点 https://www.jianshu.com/p/a67fb39a213a

更多见 R/机器学习: t-SNE;










========================================
|-- umap 包
----------------------------------------

更多见 R/机器学习: UMAP






========================================
|-- 构建发育谱系: diffusioMap 扩散映射 理论部分
----------------------------------------
常见的方法有基于线性分析来聚类区分，如
    主成分分析（PCA），
    独立成分分析（ICA）和
    线性判别分析 (LDA)等，
还有根据特征信息来进行分群，例如 
    t分布-随机邻近嵌入（t-SNE），
    统一流形逼近和投影 (UMAP）等。

这些方法大多是区分离散亚群或者检测胞间临近关系，通常都没有保留细胞间的连续分化轨迹，当我们的研究对象为连续分化的细胞群，反而不希望出现明显区分的细胞簇。


那如何在区分细胞间差异的同时，又能最大限度保留其连续性呢？基于此研究目的，Laleh Haghverdi 团队提出基于内在扩散样动力学识别细胞分化轨迹的方法，并在Bioinformatics上发布了DiffusionMap软件。


ref: 
    https://github.com/jmzeng1314/mouse-xx-xy-C1/blob/master/step5-Slingshot/step2-Slingshot.R diffusionmap和slingshot





1. diffusion map是一种非线性数据降维技术。由于diffusion component强调数据的转换，因此主要用于诸如细胞分化之类的连续过程。通常，每个diffusion component（即diffusion map 维度）突出显示不同细胞群体的异质性。

# Here we explore more refined distances and diffusion maps that can show cell development trajectories as in Figure 9.35.

Diffusion Map是基于非线性的降维模式。对于单细胞表达谱而言，该降维方法有利于降维出“枝干形状”的效果。


(1) 原始论文: Diffusion maps, Ronald R.Coifman, StéphaneLafon1, 2006
https://www.sciencedirect.com/science/article/pii/S1063520306000546

In this paper, we provide a framework based upon diffusion processes for finding meaningful geometric descriptions of data sets. 

We show that eigenfunctions of Markov matrices can be used to construct coordinates called diffusion maps that generate efficient representations of complex geometric structures. 

The associated family of diffusion distances, obtained by iterating the Markov matrix, defines multiscale geometries that prove to be useful in the context of data parametrization and dimensionality reduction. 

The proposed framework relates the spectral properties of Markov processes to their geometric counterparts and it unifies ideas arising in a variety of contexts such as machine learning, spectral graph theory and eigenmap methods.


(2) 另一个论文 An Introduction to Diffusion Maps, By J. de la Porte.
https://inside.mines.edu/~whereman/talks/delaPorte-Herbst-Hereman-vanderWalt-DiffusionMaps-PRASA2008.pdf
    PCA 
    MDS
    Isomap 

(3) DiffusionMap算法简介
https://baijiahao.baidu.com/s?id=1754509263575159606&wfr=spider&for=pc
DiffusionMap （扩散映射）是一款R软件，通过高斯模型和马尔科夫模型，把单细胞（scRNA）表达矩阵的非线性结构映射为连续性结构，并关联至对应细胞分组。数据计算主要包括以下几步：

A.由四种不同细胞类型组成的 n × G 单细胞表达矩阵。矩阵右侧的最后一列代表每个细胞的类型;

B.在G维基因空间中，由高斯函数表示每个细胞。由于高斯波干扰，具有相对高概率密度的连续路径在数据流形上形成扩散路径;

C.计算 n × n 的细胞间马尔可夫转移概率矩阵;

D.马尔可夫转移矩阵的前两个特征向量（DC1和DC2）数据嵌入，它们对应了数据流形的最大扩散系数。DiffusionMap显示了四种细胞类型中细胞的连续流动趋势。

此外，团队也针对单细胞数据常见的零值、缺失值和采样密度异质性情况，对软件的计算模型和高斯kenralwidth 筛选进行了优化，确保在数据的遍历扩散过程是连续型的同时细胞之间的扩散距离仍然有较高的灵敏度。


汉语图文描述：https://www.jianshu.com/p/a5d5addede97






2. 视频: https://www.bilibili.com/video/av38891467
(1) 大纲
- Definition of diffusion map;
- Procedure and pseudo code;
- The meaning of diffusion map;
	* First left eigenvector
	* Diffusion distance
- Extensions:
	* Result on stem cell dataset/beta cell dataset;
	* MAGIC;
# 
# 前置知识: PCA(principle component analysis)

1) Coifman and Lafon, 2005
2) 非线性降维
3) Shown in 3D: 环形螺线圈构成的圆(3D中)，每个螺线圈一个主颜色;
intrinsically 2D: 把3D的螺线圈拉直，就是一个标准的颜色渐变的圆(2D中);
如何把3D变2D，就是 diffusion map要做的。真实的可能更高维。

4) High dimension data:
 * Present in R^n, intrinsically 2D/3D;
 * 2D/3D for visuallyzation;
#

5) 怎么获取这个扭曲的高维结构的呢？
一个点向周围扩散，遇到的点的顺序会被记录。然后把距离转变为概率。

经典案例是瑞士卷 Swiss Roll Dataset: 把一个二维的矩形卷起来，放到三维中。
* Shown in 3D, intrinsically 2D;
* Aim: return to 2D space;
* sklearn.dataset.make_swiss_roll;

做PCA则仅仅是对数据进行旋转，获得的二维图就是原图的不同截面。
而 diffusion map 使用不同的kernal就能获得不同的展开，部分重现原始矩形。
* Swiss Roll Diffusion Map Gaussian Sigma=1.3,t=1;
* Swiss Roll Diffusion Map Adaptive k=5,t=1;




(2) 计算过程
step1: 计算高斯核矩阵; （若t>1，则计算该矩阵的t次方） 
6) Distance Matrix
* Data matrix X: n_cells x m_features;
* dist(x,y)=累加(i, (xi^2-yi^2)^2)
* Distance matrix -> n_cells x n_cells;
* Can use distance other than Euclidean;


7) Distance to Affinity via Kernel: 距离变概率，距离越大则P越小。相当于距离x映射到概率y上。
- Take distance Dij;
- Affinity matrix A:
	* Aij=k(Dij)
- Kernel function: 核函数要满足2个性质：对称性和非负。
	* k(x,y)=k(y,x)
	* k(x,y)>=0
	* Measure neighbor structure
- Gaussian Kernel
	k(x,y)=exp(-||x-y||^2*(2*sigma^2)); 
	* 分子就是距离; 分母sigma是带宽，越大则越扁平，纳入的点越多。sigma越小越专注于局部数据特征。
- Adaptive Gaussian Kernel
	k(x,y)=0.5*( exp(-||x-y||^2/(2*sigma k (x)^2)) + exp(-||x-y||^2/(2*sigma k (y)^2)) );
	sigma k(x): distance to kth-nearest neighbor of x.
#




step2: 计算扩散矩阵（将核矩阵的行归一化）
8) Affinity to Markov, Eigen decomposition 概率变马尔科夫模型。
- Markov matrix:
	* Normalize Affinity by row sum;
	Mij=Aij/sum(Ai) # 这样每一行的和都是1，相当于每一行跳到任何一行的随机行走的概率。
- Eigen decomposition 对马尔科夫矩阵进行奇异值分解
	M=L.A.R, #A是对角线为特征值的对角矩阵，L是左矩阵，R是右矩阵。
	M^t.I=L.A^t.R; #也可以进行t次随机行走, t越大，扩散的越大。
- Multiply Markov matrix by t:diffusion step
	* Eigenvalue will change 
	* Eigenvector will not;
	多步行走时特征值会变(A -> A^t)，特征向量不变。
#
# 实际计算时，要先计算一个 Degree matrix:
- Degree matrix D:
	* diagonal matrix of row sum; 每一行求和，排成一个对角矩阵。
- M=D^-1 * A; 马尔科夫矩阵=D的逆矩阵 * A矩阵。
- Symmetric: Ms=D^(-1/2).A.D^-(-1/2); 经常用的是 对称马尔科夫矩阵
#


step3: 计算扩散矩阵M的特征值和特征向量; 
9) Diffusion Mapping
因为马尔科夫矩阵每一行都是1，所以总有一个特征值是1。
1=Lambda1 >=L2>=L3>=...>=Ln>=0;
对应的特征向量为 xi=Ri/1n, 


step4, 映射到d维扩散空间 -- 在时刻t时，只取前d个特征值和特征向量。 
扩散距离 Yi' 如下：
Yi'=[Lambda1^t.fai1(i), Lambda2^t.fai2(i), ..., Lambda n^t.fai n(i)]^T;
其中，fai1(i)就是矩阵M的first-eigenvector 的第i个元素。

- New Coordinates of x: fai t(x)=(Lambda2^t.fai2(x), Lambda3^t.fai3(x),...,Lambdan^t.fain(x))
- Mapping=A^t.fai, take first k coordinates; 
	比如想画二维diffusion map，就取k=2，画前2个维度(Lambda2^t.fai2(x), Lambda3^t.fai3(x))	
#

10) 总结
- input: dataset(n x m)
1- calculate distance(n x n)
2- calculate affinity(n x n) via kernel
3- calculate Markov(n x n) via row sum 
4- calculate Eigenvector (n x n-1) via eigendecomposition
- output: diffusion map(n x k), k is the chosen dimension;
	要画二维图，就选前2个维度: 1st Eigenvector, 2nd Eigenvector;
	画3维，就选前3个维度。
#

11) 补充: Left most Eigenvector
- steady state of diffusion: lim(t->无穷大, p(t,y|x), fai 0(y) )
- Also indicator of density;
刚才那个 Left most Eigenvector矩阵，第一个列向量是fai0, 代表了扩散过程汇总的steadyness, 
markov^t, 当t接近无穷的时候，扩散的概率和其他点没有关系，值取决于这个点所处的环境，
	* 当它处于点密集区时，其他点很容易找到它；
	* 当它处于点稀疏区域时，其他点不容易找到它。
#

12) Diffusion Distance 
- Diffusion distance at time t for x,y:	
	欧氏距离并不代表随机行走的距离;
	随机行走的距离实际上被他们的 diffusion map 所度量: fai t(x); 
	D t(x,y)=累加(y, ( (p(t,y|xi))-(p(t,y|xj)) )^2/fai 0(y) )=||fai t(xi) - fai t(xj)||^2
- Thus the diffusion map is a new set of coordinates to present diffusion distance as Euclidean distance;
	Diffusion map 就是给数据一套新的坐标，让新坐标系统中的欧氏距离代表diffusion过程中的distance.
- Why take first few eigenvector should be enough?
	Do a PCA on diffusion mapping A^t.fai;
	实际上Diffusion map坐标做PCA后还是它自己，前几个eigenvector 已经解释了最大的变异。
#
# t值
Pt(x,y) -- 从 x 经 t 步走到y   
一般取第t轮迭代的kenel matrix。
理解: 联系markov链，矩阵 Pt 就是把 transition matrix 矩阵的 t 次方）
若增大t值，就进一步地扩散了每个点的近邻的影响；
若x，y之间有多条路径，其扩散距离就很小


13) 应用: Real dataset: 
- iPSC 诱导过程中, 浅色表示前面的时间，深色表示后面的时间，在 diffusion map adaptive k=5 t=1的3D图中，使用到前5个维度
	可见到2条分化路径，进一步看每一条路径的marker，可见一条路径是 apoposis凋亡，另一条是变成iPSC。
- 一个胰岛Beta细胞的scRNAseq数据集，有3个分化路径: stem-like, beta-like, alpha-like;


14) Other methods 
- 其他非线性降维方法
	* Isomap, LLE(local linear embedding)
	* tSNE: t-distributed stochastic neighbor embedding 
- MAGIC: Markov Affinity-based Graph Imputation of Cells
	* Data Matrix X[n_cell, m_features]
	* Magic interpolated: M^T.X;
		把马尔科夫矩阵乘到原矩阵左侧
		可以得到scRNAseq失去的部分，就是还原那些0.
	* https://magic.readthedocs.io/en/stable
#








========================================
|-- -- 构建发育谱系: diffusioMap 扩散映射 with destiny 包
----------------------------------------
3. 代码实例 destiny R包
https://www.jianshu.com/p/97ab7371312c
    使用基因：All the top 100 markers of each cluster were used for the cell ordering.

https://github.com/jmzeng1314/mouse-xx-xy-C1
    使用 diffusionMap 做 monocle 普系发育

(0) R 包 安装
调包 library(diffusionMap) 
https://cran.r-project.org/web/packages/diffusionMap/index.html


或: destiny 包(貌似用的比较多)
https://www.jianshu.com/p/16ebecb3b5fa
https://github.com/NBISweden/excelerate-scRNAseq/blob/master/session-trajectories/session-trajectories.md


# 安装包
# https://bioconductor.org/packages/release/bioc/html/destiny.html
# devtools::install_version("destiny", version="2.12.0") #失败



# https://mirrors.tuna.tsinghua.edu.cn/
options(repos=structure(c(CRAN="https://mirrors.tuna.tsinghua.edu.cn/CRAN/"))) # 推荐
BiocManager::install(pkgs="destiny")




# On Z server: $ cmake --version #cmake version 3.27.5
#error Error: ranger requires C++14. Possible fixes: 1) Update R, 2) Set "CXX = g++ -std=gnu++14" or similar in local Makevars, 3) update C++ compiler. See https://github.com/imbs-hl/ranger/wiki/FAQ.
$ which g++
~/software/gcc-12.1.0/bin/g++
我的gcc竟然还不够高级。懒得更新了。

使用老版本 ranger：
> devtools::install_version("ranger", version = "0.10.0") #2023.12.27 #默认是 "0.16.0"
> BiocManager::install(pkgs="destiny")




# On @X:20220: 缺少 cmake，也不知道是2还是3版本？
1: In .inet_warning(msg) :
  installation of package ‘nloptr’ had non-zero exit status
2: In .inet_warning(msg) :
  installation of package ‘lme4’ had non-zero exit status
3: In .inet_warning(msg) :
  installation of package ‘pbkrtest’ had non-zero exit status
4: In .inet_warning(msg) :
  installation of package ‘car’ had non-zero exit status
5: In .inet_warning(msg) :
  installation of package ‘VIM’ had non-zero exit status
6: In .inet_warning(msg) :
  installation of package ‘destiny’ had non-zero exit status

> install.packages("nloptr")
    #sudo apt install cmake          #(Debian/Ubuntu; inside a terminal).

[wangjl@biosrv ~]$ docker exec -it 950b bash
root@950b30fec8df:/# apt update #不执行找不到源
root@950b30fec8df:/# apt install cmake
root@950b30fec8df:/# cmake --version
cmake version 3.16.3

> install.packages("nloptr") #ok
> install.packages("lme4")  #ok
> install.packages("pbkrtest") #ok
> install.packages("car") #ok
> install.packages("VIM") #ok

> BiocManager::install(pkgs="destiny") #3.8.1




(1) 教程： from Seurat to destiny
if (!require("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install("destiny")

#Good: http://barcwiki.wi.mit.edu/wiki/SOP/scRNA-seq/diffusionMaps

# step1: Making a single cell object from a Seurat object
library(Seurat) 
library(SingleCellExperiment)
sce <- as.SingleCellExperiment(scObj)
# this has the cell classification
table(sce$ident)

# step2: Running diffusion map
# this step may take a long time (days) or not finish. It is recommend to send it to the cluster as a script that reads the Seurat or the single cell object, runs DiffusionMap, and saves the object. 
library(destiny)
dm <- DiffusionMap(sce, verbose = TRUE) #12:31->
# 输出信息:
    finding knns......done. Time: 550.03s
    Calculating transition probabilities......done. Time: 0.71s

    performing eigen decomposition......done. Time: 1.57s
    Warning messages:
    1: In DiffusionMap(sce, verbose = TRUE) :
      You have 15855 genes. Consider passing e.g. n_pcs = 50 to speed up computation.
    2: In (function (data, k, ..., query = NULL, distance = c("euclidean",  :
      find_knn does not yet support sparse matrices, converting data to a dense matrix.


# step3: Plotting the diffusion map
library(ggplot2)
# cellLabels <- sce$ident
tmp <- data.frame(DC1 = eigenvectors(dm)[, 1],
                  DC2 = eigenvectors(dm)[, 2],
                  DC3 = eigenvectors(dm)[, 3],
                  DC4 = eigenvectors(dm)[, 4],
                  Samples = sce$ident)
#pdf("./DC1_DC2.pdf", w=11, h=8.5)
ggplot(tmp, aes(x = DC1, y = DC2, colour = Samples)) +
  geom_point(size=0.2)  + 
  xlab("Diffusion component 1") + 
  ylab("Diffusion component 2") +
  theme_classic()+
  guides(color = guide_legend(override.aes = list(size = 3)))
#dev.off()


# 对照UMAP图
DimPlot(scObj, label=T)


# step4: Plotting cell progression along the diffusion map components
sce$pseud_dm1 <- rank(eigenvectors(dm)[,1])      # rank cells by their dpt dm1
sce$pseud_dm2 <- rank(eigenvectors(dm)[,2])      # rank cells by their dpt dm2
sce$pseud_dm1R <- rank(-eigenvectors(dm)[,1])    # rank cells by their dpt dm1 reverse order
sce$pseud_dm2R <- rank(-eigenvectors(dm)[,2])    # rank cells by their dpt dm2 reverse order

SortedDM1 <- data.frame(DM1Sort = as.data.frame(colData(sce))$pseud_dm1,
                        Samples = as.data.frame(colData(sce))$ident)
SortedDM2 <- data.frame(DM2Sort = as.data.frame(colData(sce))$pseud_dm2,
                        Samples = as.data.frame(colData(sce))$ident)
SortedDM1R <- data.frame(DM1SortR = as.data.frame(colData(sce))$pseud_dm1R,
                         Samples = as.data.frame(colData(sce))$ident)
SortedDM2R <- data.frame(DM2SortR = as.data.frame(colData(sce))$pseud_dm2R,
                         Samples = as.data.frame(colData(sce))$ident)

ggplot(SortedDM1, aes(x=SortedDM1[,1], y=Samples,color=Samples)) +
  geom_jitter() + xlab("Diffusion component 1 (DC1)") + ylab("Samples") +
  ggtitle("Cells ordered by DC1")
ggplot(SortedDM2, aes(x=SortedDM2[,1], y=Samples,color=Samples)) +
  geom_jitter() + xlab("Diffusion component 2 (DC2)") + ylab("Samples") +
  ggtitle("Cells ordered by DC2")
  
ggplot(SortedDM1R, aes(x=SortedDM1R[,1], y=Samples,color=Samples)) +
  geom_jitter() + xlab("Minus Diffusion component 1 (DC1)") + ylab("Samples") +
  ggtitle("Cells ordered by reversed DC1")
ggplot(SortedDM2R, aes(x=SortedDM2R[,1], y=Samples,color=Samples)) +
  geom_jitter() + xlab("Minus Diffusion component 2 (DC2)") + ylab("Samples") +
  ggtitle("Cells ordered by reversed DC2")


# step5: Make and interactive 2D and 3D diffusion map figure
library(plotly)

#interactive 2D
p2 = plot_ly(x=tmp$DC1, y=tmp$DC2, type="scatter", mode="markers", color=tmp$Samples, marker.size = 0.5)
htmlwidgets::saveWidget(as_widget(p2), "Interactive2D_DiffM.html", title = "Diffusion map")

#interactive 3D
p = plot_ly(x=tmp$DC1, y=tmp$DC2, z=tmp$DC3, type="scatter3d", mode="markers", color=tmp$Samples, marker = list(size = 2 ))
htmlwidgets::saveWidget(as_widget(p), "Interactive3D.html", title = "Diffusion map")






(2) 定义函数法: 效果不好

library(Biobase)
run_diffMap = function(data, condition, sigma){
    # 这个包装的函数其实做了下面几行代码的事情
    #data=females_data
    #condition=female_clustering
    #sigma=15
    destinyObj <- as.ExpressionSet(as.data.frame(t(data)))
    destinyObj$condition <- factor(condition)
    dm <- DiffusionMap(destinyObj, sigma, rotate = TRUE)
}

if(0){
    female_dm = run_diffMap(
      females_data, 
      female_clustering,
      sigma=15
    )
    # 保存结果
    save(female_dm, females_data, female_clustering, female_stages,
         file = 'diffusionMap_output.Rdata')
}

# 实例
scObj_dm = run_diffMap(
  data = scObj@assays$RNA@data, 
  condition = scObj$seurat_clusters,
  sigma=11
) #14:45 ->14:50
提示：
    Warning message:
    In DiffusionMap(destinyObj, sigma, rotate = TRUE) :
      You have 15855 genes. Consider passing e.g. n_pcs = 50 to speed up computation.


# 绘图
scObj_dm@eigenvectors |> 
    as.data.frame() |>
    cbind( cluster = factor(scObj$seurat_clusters) ) |> 
    ggplot( aes(x=DC1, y=DC2, color=cluster))+
    geom_point(size=0.2) + 
    theme_classic()+
    guides(color = guide_legend(override.aes = list(size = 3)))






(3) 另一个教程

1) 导入数据
library(destiny)
as.matrix(rnaM.logcpm)[1:5,1:5]
dim(as.matrix(rnaM.logcpm))
#
pDat=data.frame(
    'cell'=as.character(cellInfo$cid),
    'celltype'=as.character(cellInfo$cellType),
    stringsAsFactors=F
)
rownames(pDat)=pDat$cell
head(pDat)
str(pDat)


2) 构建eset
library(Biobase)
eset=Biobase::ExpressionSet(as.matrix(rnaM.logcpm), phenoData=Biobase::AnnotatedDataFrame(pDat))
eset
# ExpressionSet (storageMode: lockedEnvironment)
# assayData: 18662 features, 222 samples 
#   element names: exprs 
# protocolData: none
# phenoData
#   sampleNames: c12ROW03 c12ROW04 ... c9ROW15 (222 total)
#   varLabels: cell celltype
#   varMetadata: labelDescription
# featureData: none
# experimentData: use 'experimentData(object)'
# Annotation:  

saveRDS(eset, 'eset_rnaM.logcpm.rds')

3) 画图
dmap=DiffusionMap(eset) #耗时 5 min
提示:
    Warning message:
    In DiffusionMap(eset) :
      You have 15855 genes. Consider passing e.g. n_pcs = 50 to speed up computation

plot.DiffusionMap(dmap)

plot.DiffusionMap(dmap, dims=c(1,2))
plot.DiffusionMap(dmap, dims=c(2,3))
plot.DiffusionMap(dmap, dims=c(1,3))
# dmap@eigenvectors$DC1


# 4) 重绘
dat = dmap@eigenvectors |> 
    as.data.frame() |>
    cbind( cluster = factor(scObj$seurat_clusters) )

# 设定 cluster，并高亮大号点显示
cluster.highlight=0; ggplot(dat, aes(x=DC1, y=DC2, color=cluster))+
    geom_point(size=0.2) + 
    geom_point(data=dat[which(dat$cluster==cluster.highlight),], mapping=aes(DC1, DC2), size=0.8) + #高亮显示某一类
    theme_classic()+
    guides(color = guide_legend(override.aes = list(size = 3)))

# 对比 Seurat 结果
DimPlot(scObj, label=T, reduction = "pca")





(4) 轨迹图 destiny 2.0 brought the Diffusion Pseudo Time (DPT) class  //todo
data -> transition probabilities -> DiffusionMap
data -> transition probabilities -> DPT


https://www.bioconductor.org/packages/release/bioc/vignettes/destiny/inst/doc/DPT.html
dpt <- DPT(dm)

set.seed(4)
dpt_random <- DPT(dm, tips = sample(ncol(guo), 3L))

library(gridExtra)  # Also we need grid.arrange
# Plotting without parameters results in the DPT of the first root cell:
grid.arrange(plot(dpt), plot(dpt_random), ncol = 2)


# Other possibilities include the DPT from the other tips or everything supported by plot.DiffusionMap:
grid.arrange(
    plot(dpt, col_by = 'DPT3'),
    plot(dpt, col_by = 'Gata4', pal = viridis::magma),
    ncol = 2
)


# The DPT object also contains a clustering based on the tip cells and DPT, and you can specify where to draw paths from and to:
plot(dpt, root = 2, paths_to = c(1,3), col_by = 'branch')


# 3D 图
plot(dpt, col_by = 'branch', divide = 3, dcs = c(-1,-3,2), pch = 20)






(5) detecting relevant genes with destiny 3
https://www.bioconductor.org/packages/release/bioc/vignettes/destiny/inst/doc/Gene-Relevance.html

The chosen distance metric has big implications on your results, you should try at least cosine and rankcor.

library(purrr)
set.seed(1)
dms <- c('euclidean', 'cosine', 'rankcor') %>% #, 'l2'
    set_names() %>%
    map(~ DiffusionMap(eset, distance = ., knn_params = list(method = 'covertree')))
#

时间太长了，下次分别测试： //todo
    > c('euclidean', 'cosine', 'rankcor') %>% #, 'l2'
    +     set_names() 
      euclidean      cosine     rankcor 
    "euclidean"    "cosine"   "rankcor" 
















=> 测试数据 （忽视）
    data(guo)
    DiffusionMap(guo)
    报错：
        Error: (converted from warning) 'as(<dsCMatrix>, "dsTMatrix")' is deprecated.
        Use 'as(., "TsparseMatrix")' instead.
        See help("Deprecated") and help("Matrix-deprecated").

    单击该函数，查找 as.matrix ，共找到2行
        line45: imputed_data <- as.matrix(hotdeck(data, imp_var = FALSE))
            修改为: 
                imputed_data <- as(hotdeck(data, imp_var = FALSE), "TsparseMatrix")
        line97: eig_vec <- as.matrix(t(t(eig_vec) %*% d_rot))
    //todo

R 包和版本: https://github.com/NBISweden/excelerate-scRNAseq/blob/master/session-trajectories/session-trajectories.md
# R version 3.5.3 (2019-03-11)
# Platform: x86_64-pc-linux-gnu (64-bit)
# Running under: CentOS Linux 7 (Core)
#  [1] destiny_2.12.0      biomaRt_2.38.0      monocle_2.10.1     
#  [4] DDRTree_0.1.5       irlba_2.3.3         VGAM_1.1-1         
#  [7] ggplot2_3.1.1       Biobase_2.42.0      BiocGenerics_0.28.0
# [10] Matrix_1.2-17 











========================================
|-- 构建发育谱系: diffusioMap 扩散映射 with diffusionMap 包(效果一般)
----------------------------------------

4. 代码实例 diffusionMap R包

(1) 安装
https://cran.r-project.org/web/packages/diffusionMap/index.html

# on Y station
install.packages("diffusionMap")


(2) 实例 内置数据
library(diffusionMap) #1.2.0

> data(annulus)
> plot(annulus,main="Annulus Data",pch=20,cex=.7)
> head(annulus)
# A tibble: 6 × 2
        X      Y
    <dbl>  <dbl>
1  1.30   -1.09 
2 -1.31    1.99 


D = dist(annulus) # use Euclidean distance
dmap = diffuse(D,eps.val=.1) # compute diffusion map & plot
print(dmap)
plot(dmap)


(3) 单细胞实例
# https://www.jianshu.com/p/53b8df5aa96a

#    dis2 = dist(data)
#    library("diffusionMap")
#    d2 = diffuse(dis2, neigen = 11)
#    plot(d2)

# test1: use snn as distance
pbmc_dm = diffuse(
    D=1-pbmc@graphs$RNA_snn, 
    neigen = 3 #几个维度
)
plot(pbmc_dm)

> pbmc_dm$X |> dim()
[1] 2638    3
> pbmc_dm$X |> head()
              [,1]         [,2]          [,3]
[1,] -0.0012559742  0.001208330  0.0003961142
[2,] -0.0016465685  0.002221412 -0.0033531939

> library(ggplot2)
> data.frame(DF_1=pbmc_dm$X[,1], DF_2=pbmc_dm$X[,2], cluster=pbmc$celltype) |>
   ggplot( aes(x=DF_1, y=DF_2, color=cluster))+
   geom_point(size=0.2) + 
   theme_classic()+
   guides(color = guide_legend(override.aes = list(size = 3)))

> DimPlot(pbmc, label=T)





# test2: use dist(HVG) as input
# dist 按行计算，所以需要转置后 cid 放到行
pbmc_dm2 = diffuse(
    D=dist( t(pbmc@assays$RNA@scale.data[pbmc@assays$RNA@var.features,]) ), 
    neigen = 11 #几个维度
) #耗时 47s
plot(pbmc_dm2)

data.frame(DF_1=pbmc_dm2$X[,1], DF_2=pbmc_dm2$X[,2], cluster=pbmc$celltype) |>
   ggplot( aes(x=DF_1, y=DF_2, color=cluster))+
   geom_point(size=0.2) + 
   theme_classic()+
   guides(color = guide_legend(override.aes = list(size = 3)))

# 使用高变基因的 diffusionMap，结果类似 PCA?
> DimPlot(pbmc, label=T, reduction = 'pca')











10. 进一步 阅读一下这几篇文章
Diffusion Maps, Spectral Clustering and Eigenfunctions of Fokker-Planck Operators；2006;
Diffusion maps, spectral clustering and reaction coordinates of dynamical systems
Diffusion maps: A unified framework for dimension reduction, data partitioning and graph subsampling

作者都是S. Lafon。我也正在看这部分东西，尤其是他和拉普拉斯特征映射的关系以及diffusion map对于随机游走的解读。

毕竟近年来，以DW为代表的RW+W2V已经可以被解读为某种对Lsym为基础的矩阵分解。那么就有一些必要去看一下相关的知识。

? Spectral Clustering



ref: 
https://blog.csdn.net/zhouxinxin0202/article/details/79715352
https://baijiahao.baidu.com/s?id=1754509263575159606&wfr=spider&for=pc







========================================
|-- 构建发育谱系: Slingshot
----------------------------------------













ref:
https://cloud.tencent.com/developer/article/1606694














========================================
统计学参数 in single cell
----------------------------------------



========================================
|-- 平均绝对离差 average absolute deviation (AAD), or mean absolute deviation (MAD)
----------------------------------------
1.
the average of the absolute deviations.
It is a summary statistic of statistical dispersion or variability.

In the general form, the central point can be the mean, median, mode, or the result of any other measure of central tendency or any random data point related to the given data set.

The absolute values of the difference, between the data points and their central tendency, are totaled and divided by the number of data points.

The mean absolute deviation of a set {x1, x2, ..., xn} is
\frac{1}{n}\sum_{i=1}^n |x_i-m(X)|.

1/n * 求和( abs(xi - mean(X) ) )



2.
Several measures of statistical dispersion are defined in terms of the absolute deviation.
有好几个叫做 绝对离差 的统计量，用于衡量数据离散程度。
要说清是什么中心，算的绝对离差： mean/median/mode?
data set {2, 2, 3, 4, 14}, 
mean=5, MAD=3.6;
median=3, MAD=2.8;
Mode=2, MAD=3.0

The mean absolute deviation from the median is less than or equal to the mean absolute deviation from the mean. 
In fact, the mean absolute deviation from the median is always less than or equal to the mean absolute deviation from any other fixed number.
中位数为中心的 平均绝对离差 通常是任何中心计算中最小的。


# R 代码
a=c(2, 2, 3, 4, 14)
mean(abs(a-mean(a))) #3.6
mean(abs(a-median(a))) #2.8

# Create the function.
getmode <- function(v) {
  uniqv <- unique(v)
  uniqv[which.max(tabulate(match(v, uniqv)))]
}
mean(abs(a-getmode(a))) #3
#
###############
#获得众数的细节
uniqA=unique(a)
uniqA #2  3  4 14
#
rs1=match(a, uniqA) #match(x, table) 返回x元素在table的位置
rs1 #[1] 1 1 2 3 4

tabulate(rs1) #[1] 1 1 2 3 4
#tabulate(bin, nbins = max(1, bin, na.rm = TRUE))
#计算整数向量bin中每个整数出现的次数
#rs2=table(rs1);rs2
#unname(rs2) #2 1 1 1
which.max(tabulate(rs1)) #1

uniqA[which.max(tabulate(rs1))]
#



3.例子：https://sciencing.com/calculate-relative-standard-error-6899277.html

a=c(2, 2, 4, 5, 5, 5, 9, 10, 12)
a.mean=mean(a);a.mean #6
a1=abs(a-a.mean)
mean(a1) #2.88




ref:
https://en.wikipedia.org/wiki/Average_absolute_deviation






========================================
|-- 中位数绝对偏差 median absolute deviation(MAD), 阈值 median-3 x MAD 
----------------------------------------
1.
MAD 定义为，一元序列 Xi 同其中位数偏差的绝对值的中位数（deviation，偏差本身有正有负）；
MAD=median(|Xi−median(X)|)


MAD 的方法相对于分位数方法的一大优势即在于 MAD 方法对样本大小是不敏感也即是稳定的鲁棒的一种评价指标。



https://blog.csdn.net/lanchunhui/article/details/80381516




2.
threshold=median(df2$counts)-mad(df2$counts)*3;threshold

Low-quality cells were discarded if the cell library size or the number of expressed genes(counts larger than 0) was smaller than pre-defined thresholds, which were the medians of all cells minus 3x median absolute deviation.[zhang zemin,2018,NM]

在加生一个上限？
threshold2=median(df2$counts) + mad(df2$counts)*3;threshold2













========================================
[Python] scanpy对scRNA-seq数据的聚类分析 //todo
----------------------------------------
1.
Scanpy is a scalable toolkit for analyzing single-cell gene expression data built jointly with anndata. It includes preprocessing, visualization, clustering, trajectory inference and differential expression testing. The Python-based implementation efficiently deals with datasets of more than one million cells.

(1) 文章 SCANPY: large-scale single-cell gene expression data analysis
# https://genomebiology.biomedcentral.com/articles/10.1186/s13059-017-1382-0
Published: 06 February 2018


(2)
官网 https://scanpy.readthedocs.io/en/latest/
	 https://scanpy.readthedocs.io/en/stable/

代码 https://github.com/theislab/scanpy

教程 https://scanpy.readthedocs.io/en/stable/tutorials.html
	https://scanpy.readthedocs.io/en/stable/usage-principles.html

简书 https://www.jianshu.com/p/b190efae4d31
	https://www.jianshu.com/p/4ff1c74f0929



2. 安装 

(1) 在ubuntu上，初次安装报错 
$ sudo apt-get install llvm  #LLVM version... 6.0.0
$ pip3 install llvmlite -i https://pypi.douban.com/simple/
RuntimeError: Building llvmlite requires LLVM 10.0.x or 9.0.x, got '6.0.0'. Be sure to set LLVM_CONFIG to the right executable path.
  Read the documentation at http://llvmlite.pydata.org/ for more information about building llvmlite.
  
  error: command '/usr/bin/python3' failed with exit status 1
#


(2) 再次安装，主包安装成功
$ sudo apt-get install libllvm-10-ocaml-dev libllvm10 llvm-10 llvm-10-dev llvm-10-doc llvm-10-examples llvm-10-runtime

$ sudo dpkg -l | grep llvm  #查已经安装的包
# 包含 6.0.0 和 10.0.0


##参照 https://github.com/numba/llvmlite/issues/220
$ vim ~/.bashrc 添加一句
export LLVM_CONFIG="/usr/bin/llvm-config-10"
$ source ~/.bashrc


$ pip3 install scanpy -i https://pypi.douban.com/simple/


(3) 再次升级一个包，不报错了。
$ python3
Python 3.6.9 (default, Oct  8 2020, 12:12:24)

>>> import scanpy
/home/wangjl/.local/lib/python3.6/site-packages/numba/core/errors.py:154: UserWarning: Insufficiently recent colorama version found. Numba requires colorama >= 0.3.9
  warnings.warn(msg)
#

$ pip3 list | grep colorama
colorama (0.3.7)

$ pip3 install colorama==0.3.9

$ python3
>>> import scanpy #不报错了
>>> quit()





(4) 划分细胞时，提示要安装包
ImportError: Please install the leiden algorithm: `conda install -c conda-forge leidenalg` or `pip3 install leidenalg`.

1) $ pip3 install leidenalg -i https://pypi.douban.com/simple/
报错:  
../../../source/igraph/ylwrap: line 176: yacc: command not found
...
Could not compile the C core of igraph.
Failed building wheel for leidenalg

$ pip3 install python-igraph==0.7.1.post6


2)
$ sudo apt-get install -y libigraph0-dev
$ sudo apt-get install python3-igraph

$ sudo apt-get install python-igraph

$ apt-get install build-essential python3-dev libxml2 libxml2-dev zlib1g-dev



3) 参考 https://github.com/igraph/python-igraph/issues/162
$ sudo apt install bison
$ sudo apt install flex

$ pip3 install python-igraph -i https://pypi.douban.com/simple/
$ pip3 install leidenalg -i https://pypi.douban.com/simple/



(5) 伪时间分析

sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20)
sc.tl.draw_graph(adata)
WARNING: Package 'fa2' is not installed, falling back to layout 'fr'.To use the faster and better ForceAtlas2 layout, install package 'fa2' (`pip install fa2`).

$ pip3 install fa2










========================================
现有好用的单细胞分析脚本
----------------------------------------
注明文献，预期效果图；
输入数据和格式。


========================================
|-- 长和短isoform比例，及显著性
----------------------------------------

长和短isoform比例
2015Lars Velten,MSB paper fig7A, fisher's test
https://www.embopress.org/doi/full/10.15252/msb.20156198


#x long; y short
#cell1, 10 genes
n=1000
x1=as.integer( runif(n,0,100) );#x1
y1=as.integer(runif(n,0,100) );#y1

#cell2, 10 genes
x2=as.integer(runif(n,0,100) );#x2
y2=as.integer(runif(n,0,100) );#y2
#
#检查10 gene的显著性 Fisher's test
dfs=NULL
for(i in c(1:n)){
  if(i%%100==0){
    print(i)
  }
  #i=1
  mx=matrix(c(x1[i],y1[i],x2[i],y2[i]),nrow=2)
  #mx
  rs=fisher.test(mx, alternative = 'two.sided')
  p=rs$p.value
  #p
  ratioX=x1[i]/x2[i]
  ratioY=y1[i]/y2[i]
  df=data.frame(
    x=ratioX,
    y=ratioY,
    p=p
  )
  dfs=rbind(dfs,df)
}
#head(dfs)
dfs$sig=dfs$p<0.05
dfs$sig=factor(dfs$sig,levels=c(T,F))
head(dfs)
library(ggplot2)
ggplot(dfs,aes(log2(x),log2(y),color=sig))+geom_point()
#


========================================
找高变基因(HVG)的方法
----------------------------------------
高变异基因就是highly variable features（HVGs），就是在细胞与细胞间进行比较，选择表达量差别最大的。


1. Seurat
参考：https://satijalab.org/seurat/v3.0/pbmc3k_tutorial.html

利用FindVariableFeatures函数，会计算一个mean-variance结果，也就是给出表达量均值和方差的关系并且得到top variable features

计算方法主要有三种：

(1)vst（默认）：首先利用 local polynomial regression (loess) 对 log(variance) 和log(mean) 拟合一条直线，然后利用观测均值和期望方差（由拟合曲线给出）对基因表达量进行标准化，最后根据保留最大的标准化的表达量计算方差。

(2)mean.var.plot(mvp): 首先利用mean.function和 dispersion.function分别计算每个基因的平均表达量(mean.function)和离散情况(dispersion.function)，然后根据平均表达量将基因们分散到一定数量（默认是20个）的小区间（bin）中，并且按照bin计算其中的基因的z-score。这是为了识别变异基因，同时保持变异和平均表达量的强联系。

(3)dispersion（最直接, disp）：挑选最高离差值的基因。




例如：
## 使用Seurat 版本3
# V3 代码来自官方教程https://satijalab.org/seurat/v3.0/pbmc3k_tutorial.html
pbmc <- FindVariableFeatures(pbmc, selection.method = "vst", nfeatures = 2000)
top10 <- head(VariableFeatures(pbmc), 10)

# 分别绘制带基因名和不带基因名的
plot1 <- VariableFeaturePlot(pbmc)
plot2 <- LabelPoints(plot = plot1, points = top10, repel = TRUE)
CombinePlots(plots = list(plot1, plot2))


## 使用Seurat版本2
pbmc <- FindVariableGenes(object = pbmc, 
                         mean.function = ExpMean, 
                         dispersion.function = LogVMR )
length( pbmc@var.genes) 
# 默认值是：x.low.cutoff = 0.1, x.high.cutoff = 8, y.cutoff = 1，就是说取log后的平均表达量(x轴)介于0.1-8之间的；分散程度(y轴，即标准差)至少为1的


- V3计算mean.function和FastLogVMR均采用了加速的FastExpMean、FastLogVMR模式
- V3横坐标范围设定参数改成：mean.cutoff，整合了原来V2的x.low.cutoff + x.high.cutoff；纵坐标改成：dispersion.cutoff ，替代了原来V2的y.cutoff
- V3默认选择2000个差异基因，检查方法也不同（V3用VariableFeatures(sce)检查，V2用sce@var.genes检查）





2. Monocle
参考：https://cole-trapnell-lab.github.io/monocle-release/docs/#clustering-cells

# V2
cds <- estimateSizeFactors(cds)
cds <- estimateDispersions(cds)
disp_table <- dispersionTable(cds) 
> head(disp_table)
     gene_id mean_expression dispersion_fit dispersion_empirical
1 AL669831.5     0.011673004      42.669671             0.000000
2      NOC2L     0.140316168       5.221419             1.696712
3    PLEKHN1     0.016292004      31.089206             0.000000
4 AL645608.8     0.009537725      51.814220             0.000000
5       HES4     0.265523990       3.619078            28.119205
6      ISG15     0.793811626       2.424032            11.047583

unsup_clustering_genes <- subset(disp_table, mean_expression >= 0.1) 
cds <- setOrderingFilter(cds, unsup_clustering_genes$gene_id) 
plot_ordering_genes(cds) 






3. scran
参考：https://bioconductor.riken.jp/packages/3.7/workflows/vignettes/simpleSingleCell/inst/doc/work-5-mnn.html

利用函数trendVar()和decomposeVar() 根据表达量计算highly variable genes (HVGs)

fit <- trendVar(sce, parametric=TRUE) 
dec <- decomposeVar(sce, fit)
如果有不感兴趣的差异来源（例如plate、donor），为了确保后面鉴定HVGs过程不会扩大真实的数据偏差，可以设置block

block <- paste0(sce$Plate, "_", sce$Donor)
fit <- trendVar(sce,block=block, parametric=TRUE) 
dec <- decomposeVar(sce, fit)


最后作图
plot(dec$mean, dec$total, xlab="Mean log-expression", 
    ylab="Variance of log-expression", pch=16)
OBis.spike <- isSpike(sce)
points(dec$mean[is.spike], dec$total[is.spike], col="red", pch=16)
curve(fit$trend(x), col="dodgerblue", add=TRUE)




在decomposeVar函数帮助文档中有一句描述：Highly variable genes (HVGs) can be identified as those with large biological components. The biological component is determined by subtracting the technical component from the total variance.

HVGs能够代表大部分的生物学差异，而这种差异是由总体差异减去技术因素差异得到的

dec$Symbol <- rowData(dec)$Symbol
dec <- dec[order(dec$bio, decreasing=TRUE),]

> head(dec,2)
DataFrame with 2 rows and 7 columns
                            mean            total              bio
                       <numeric>        <numeric>        <numeric>
ENSG00000254647 2.83712754306791 6.30184692631371 5.85904290864641
ENSG00000129965 1.88188510741958 5.96360144483475  5.5152391307155
                             tech   p.value       FDR      Symbol
                        <numeric> <numeric> <numeric> <character>
ENSG00000254647 0.442804017667299         0         0         INS
ENSG00000129965 0.448362314119254         0         0    INS-IGF2






4. M3Drop
Brennecke et al. (2013) Accounting for technical noise in single-cell RNA-seq experiments. Nature Methods 10, 1093-1095. doi:10.1038/nmeth.2645

library(M3DExampleData)
# 需要提供表达矩阵(expr_mat)=》normalized or raw (not log-transformed) 
HVG <- BrenneckeGetVariableGenes(expr_mat=M3DExampleData, spikes=NA, suppress.plot=FALSE, fdr=0.1, minBiolDisp=0.5, fitMeanQuantile=0.8)
HVG_spike <- BrenneckeGetVariableGenes(Mmus_example_list$data, spikes=5550:5600)











5. 自定义函数
Extract genes with a squared coefficient of variation >2 times the fit regression (Brennecke et al 2013 method)

《Accounting for technical noise in single-cell RNA-seq experiments》
pdf: https://www.nature.com/articles/nmeth.2645
Supplement II https://media.nature.com/original/nature-assets/nmeth/journal/v10/n11/extref/nmeth.2645-S2.pdf



实现了：Select the highly variable genes based on the squared coefficient of variation and the mean gene expression and return the RPKM matrix the the HVG



# https://rdrr.io/cran/statmod/man/glmgam.html

getMostVarGenes <- function(
  data=data,                # RPKM matrix
  fitThr=1.5,           # Threshold above the fit to select the HGV
  minMeanForFit=1           # Minimum mean gene expression level
){
  # data=females;fitThr=2;minMeanForFit=1   
  # Remove genes expressed in no cells
  data_no0 <- as.matrix(
    data[rowSums(data)>0,]
  )
  # Compute the mean expression of each genes
  meanGeneExp <- rowMeans(data_no0)
  names(meanGeneExp)<- rownames(data_no0)
  
  # Compute the squared coefficient of variation
  varGenes <- rowVars(data_no0)
  cv2 <- varGenes / meanGeneExp^2
  
  # Select the genes which the mean expression is above the expression threshold minMeanForFit
  useForFit <- meanGeneExp >= minMeanForFit
  
  # Compute the model of the CV2 as a function of the mean expression using GLMGAM
  fit <- glmgam.fit( cbind( a0 = 1, 
                            a1tilde = 1/meanGeneExp[useForFit] ), 
                     cv2[useForFit] )
  a0 <- unname( fit$coefficients["a0"] )
  a1 <- unname( fit$coefficients["a1tilde"])
  
  # Get the highly variable gene counts and names
  fit_genes <- names(meanGeneExp[useForFit])
  cv2_fit_genes <- cv2[useForFit]
  fitModel <- fit$fitted.values
  names(fitModel) <- fit_genes
  HVGenes <- fitModel[cv2_fit_genes>fitModel*fitThr]
  print(length(HVGenes))
  
  # Plot the result
  plot_meanGeneExp <- log10(meanGeneExp)
  plot_cv2 <- log10(cv2)
  plotData <-  data.frame(
    x=plot_meanGeneExp[useForFit],
    y=plot_cv2[useForFit],
    fit=log10(fit$fitted.values),
    HVGenes=log10((fit$fitted.values*fitThr))
  )
  p <- ggplot(plotData, aes(x,y)) +
    geom_point(size=0.1) +
    geom_line(aes(y=fit), color="red") +
    geom_line(aes(y=HVGenes), color="blue") +
    theme_bw() +
    labs(x = "Mean expression (log10)", y="CV2 (log10)")+
    ggtitle(paste(length(HVGenes), " selected genes", sep="")) +
    theme(
      axis.text=element_text(size=16),
      axis.title=element_text(size=16),
      legend.text = element_text(size =16),
      legend.title = element_text(size =16 ,face="bold"),
      legend.position= "none",
      plot.title = element_text(size=18, face="bold", hjust = 0.5),
      aspect.ratio=1
    )+
    scale_color_manual(
      values=c("#595959","#5a9ca9")
    )
  print(p)
  
  # Return the RPKM matrix containing only the HVG
  HVG <- data_no0[rownames(data_no0) %in% names(HVGenes),]
  return(HVG)
}


P.S.
参考：https://bioconductor.org/packages/release/workflows/vignettes/simpleSingleCell/inst/doc/var.html
https://bioconductor.org/packages/devel/bioc/vignettes/scran/inst/doc/scran.html




还有其他的一些函数：

the coefficient of variation, using the technicalCV2() function (Brennecke et al. 2013) or the DM() function (Kim et al. 2015) in scran, which quantify expression variance based on the coefficient of variation of the (normalized) counts. 另外还有technicalCV2()的升级版improvedCV2()
the dispersion parameter in the negative binomial distribution, using the estimateDisp() function in edgeR (McCarthy, Chen, and Smyth 2012).
a proportion of total variability, using methods in the BASiCS package (Vallejos, Marioni, and Richardson 2015).












6.Detection of high variability in gene expression from single-cell RNA-seq profiling
BMC Genomics. 2016; 17(Suppl 7): 508.
PMID: 27556924
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5001205/
Fig. 4 a CV-mean plot of data set GSE60361 and b the CV difference histogram







refer:
几个scRNA找高变异基因（HVGs）的方法 https://www.jianshu.com/p/3d40c56e5fc8



========================================
|-- BASiCS 包：求高变基因 HVG (不靠谱)
----------------------------------------
首页： http://bioconductor.org/packages/release/bioc/html/BASiCS.html
文档： http://bioconductor.org/packages/release/bioc/vignettes/BASiCS/inst/doc/BASiCS.html

github: https://github.com/catavallejos/BASiCS


1.作用：
BASiCS (Bayesian Analysis of Single-Cell Sequencing data) is an integrated Bayesian hierarchical model that propagates statistical uncertainty by simultaneously performing data normalisation (global scaling), technical noise quantification and two types of supervised downstream analyses:

(1)For a single group of cells [1]: 
BASiCS provides a criterion to identify highly (and lowly) variable genes within the group.

(2)For two (or more) groups of cells [2]: 
BASiCS allows the identification of differentially expressed genes between the groups. As in traditional differential expression tools, BASiCS can uncover changes in mean expression between the groups. Besides this, BASiCS can also uncover changes in over-dispersion --- a measure for the excess cell-to-cell variation that is observed after accounting for technical noise. This feature has led, for example, to novel insights in the context of immune cells across aging [3]. More recently, the BASiCS model has been extended to address the confounding between mean and variability that is typically observed in scRNA-seq datasets. This is achieved by introducing a residual over-dispersion parameter that is not confounded by mean expression [4].


BASiCS - [R] - 单细胞RNA-seq数据的贝叶斯分析。估计特定于细胞的标准化常数。基于加标基因量化技术可变性。表达计数的总变异性被分解为技术和生物组分。BASiCS还可以鉴定在两组或更多组细胞之间具有差异表达/过度分散的基因。


需要spike-in，如果没有，则需要多批次的样本。
The original implementation of BASiCS relies on the use of spike-in genes --- that are artificially introduced to each cell's lysate --- to perform these analyses. 
However, our latest work has extended the BASiCS model to datasets in which spike-ins are not available (multiple batches are required) [4].




2. 安装
(1)
#library(devtools)
#if (!requireNamespace("BiocManager", quietly=TRUE))
    #install.packages("BiocManager")
#BiocManager::install("BiocGenerics")
#BiocManager::install("scran")
#install.packages("Rcpp")

# install.packages("devtools")
devtools::install_github("catavallejos/BASiCS", build_vignettes = TRUE) ## 总是失败！


(2)用一般命令安装的
BiocManager::install("BASiCS")
library(BASiCS)
## 又报错：namespace ‘htmltools’ 0.3.6 is already loaded, but >= 0.4.0 is required

remove.packages("htmltools")
install.packages("BASiCS",dependencies=T,source=T)
## 还是报错

(3)算了，换机器，使用Yi工作站
按照(1)安装。

反正最后装好了。


## Residual over-dispersion
To use this feature, please set Regression = TRUE as a function parameter in BASiCS_MCMC.

## More recently, Eling et al. (2018) extendeded BASiCS to also address datasets for which spikes-ins are not available 
To use this feature, please set WithSpikes = FALSE as a function parameter in BASiCS_MCMC.






3. 使用 
#得到的结果不满意，因为它HVG排名前10的基因基本都是只有2-5个细胞表达的。
#而Seurat3给出的排名靠前的HVG则都是至少上百个细胞表达的，感觉更靠谱。


#BiocManager::install("BASiCS")
library(BASiCS)


# step1 输入数据
#https://github.com/catavallejos/BASiCS/wiki/2.-Input-preparation
#整体batch
query<-dbSendQuery(con, 'select cid,cellType,batch from cell_c1;' );
batchR=fetch(query, n=-1);
rownames(batchR)=sub('_','',batchR$cid)
head(batchR)
#
br.data3=br.data2
rn=colnames(br.data2)
rn=sub('mix','',rn)
rn=sub('sync','',rn)
#rn
colnames(br.data3)=rn

batch=batchR[colnames(br.data3),]
head(batch)
#
# Create SingleCellExperiment object containing batch information
library(SingleCellExperiment)
DataExample <- SingleCellExperiment(assays = list(counts = as.matrix(br.data3) ),
                                    colData = data.frame(BatchInfo = batch$batch))
#
#step2: 耗时(N=1000,10min)
# LARGER NUMBER OF ITERATIONS ARE USUALLY REQUIRED TO ACHIEVE CONVERGENCE. 
# OUR RECOMMENDED SETTING IS N=20000, Thin=20 and Burn=10000.
Chain <- BASiCS_MCMC(Data = DataExample, N = 10000, Thin = 20, Burn = 5000, 
                     WithSpikes = FALSE,
                     PrintProgress = T, Regression = TRUE)#N=10000,14:35(2.5h)->17:05
str(Chain)
#acceptance rates 要接近0.44，否则要提高N and Burn(burn通常是N的一半)
# MCMC algorithm一定要收敛，才能进行下一步。
#Typically, setting N=20000, Thin=20 and Burn=10000 leads to stable results.
#https://github.com/catavallejos/TutorialBASiCS/blob/master/Material/TutorialMLPM2015_Convergence.pdf
#
#Minimum acceptance rate among mu[i]'s: 0.0468
#Average acceptance rate among mu[i]'s: 0.453859
#Maximum acceptance rate among mu[i]'s: 0.9398
#
#Minimum acceptance rate among delta[i]'s: 0.2422
#Average acceptance rate among delta[i]'s: 0.45048
#Maximum acceptance rate among delta[i]'s: 0.6214
#
#
#检查收敛性，使用coda R包
CairoPDF(file='BASiC_plot-chain.pdf',width=10,height=5)
plot(Chain, Param = "mu", Gene = 2, log = "y")
#plot(Chain, Param = "phi", Cell = 2)
dev.off()
#

displayChainBASiCS(Chain, Param = "mu")[1:5,1:5]
ChainSummary <- Summary(Chain)
ChainSummary
head(displaySummaryBASiCS(ChainSummary, Param = "mu"))
#First column: posterior medians
#Second column: lower limit of the 95% HPD interval
#Third column: upper limit of the 95% HPD interval
#            median     lower    upper
# A1BG-AS1 2.0906366 1.1428834 4.030563
# A2M      0.8055853 0.2817670 1.943634
# A2M-AS1  1.0188817 0.2314853 2.473844
save(Chain, file='HVG_BASiCS_Chain.rds')


#step3(3.1) Analysis for a single group of cells
par(mfrow = c(2,2))
HVG <- BASiCS_DetectHVG(Chain, VarThreshold = 0.6, Plot = TRUE)
LVG <- BASiCS_DetectLVG(Chain, VarThreshold = 0.2, Plot = TRUE)
save(HVG, file='HVG_BASiCS_HVG.rds')
save(LVG, file='HVG_BASiCS_LVG.rds')
#
head(HVG$Table)
#229        229      ADAM20 1.341123 2.852403    1 TRUE
#844        844 ARHGAP5-AS1 1.016198 2.613082    1 TRUE
#2702      2702       CHST4 1.262379 3.120179    1 TRUE
#4913      4913    FANCD2P2 1.716802 3.341589    1 TRUE
#5622      5622       GLIS1 1.596360 3.226006    1 TRUE
#5725      5725    GOLGA8EP 1.863771 4.254077    1 TRUE
for(g in head(HVG$Table$GeneName,20)){
  print( paste(g, sum(br.data2[g,]), sum(br.data2[g,]>0)  ) )
}
#gene /总counts数 /在几个细胞表达
# [1] "ADAM20 622 5"
#[1] "ARHGAP5-AS1 538 18"
#[1] "CHST4 3 3"
#[1] "FANCD2P2 4 2"
#[1] "GLIS1 80 2"
#[1] "GOLGA8EP 2 2"
#[1] "HNRNPA1P55 2 2"
#[1] "HOXD8 66 2"
#[1] "ICAM2 48 2"
#[1] "IDI2 2 2"
#[1] "ILF2P1 2 2"
#[1] "KDM5D 4 4"
#[1] "KLK3 2 2"
## 结论：这些高变基因，都是表达细胞比较少的基因？

#
head(LVG$Table)
#  GeneIndex GeneName        Mu   Epsilon Prob  LVG
#36         36    ABCA8 1.168386 -5.442292    1 TRUE
#55         55    ABCD1 1.012398 -1.994452    1 TRUE
#63         63    ABCG1 1.137015 -2.309389    1 TRUE
#74         74   ABHD15 1.132363 -2.340396    1 TRUE
#98         98 ABRAXAS1 2.380846 -1.957602    1 TRUE
#100       100     ABT1 1.545265 -2.531951    1 TRUE
for(g in head(LVG$Table$GeneName,20)){
  print( paste(g, sum(br.data2[g,]), sum(br.data2[g,]>0)  ) )
}
#gene /总counts数 /在几个细胞表达
# "ABCA8 1031 195"
# "ABCD1 966 46"
# "ABCG1 557 60"
# "ABHD15 783 78"
# "ABRAXAS1 2562 72"
# "ABT1 1129 74"
# "ADPGK 1435 86"
# "AHCYL2 1425 72"
# "AHDC1 1354 52"
# "AIDA 729 39"
# "AKT1 629 116"
# "AKT1S1 3141 111"
# "ALDH16A1 3344 102"
# "ALKBH6 2047 84"

#查看基因
getGeneInList=function(g){
  #g='MGP';
  df=HVG$Table[which(HVG$Table$GeneName==g),]
  df2=LVG$Table[which(LVG$Table$GeneName==g),]
  df$ProbL=df2$Prob
  df$LVG=df2$LVG
  #
  row.names(df)=g
  df$totalReads=sum(br.data2[g,])
  df$totalCell=sum(br.data2[g,]>0)
  print(df)
}
getGeneInList('MGP')
getGeneInList('NEAT1')
getGeneInList('S100A7')
getGeneInList("AZGP1")
getGeneInList("ATP8B4")
#     GeneIndex GeneName       Mu  Epsilon Prob  HVG ProbL   LVG totalReads totalCell
#MGP      8858      MGP 1071.73 2.23532    1 TRUE     0 FALSE    1098578       214
#NEAT1      9924    NEAT1 375.8503 2.175418    1 TRUE     0 FALSE     344963       222
#S100A7     14098   S100A7 274.8956 1.994682 0.992 TRUE     0 FALSE     278314       204
#AZGP1      1235    AZGP1 173.7354 1.180928    0 FALSE     0 FALSE     155031       200
#ATP8B4      1195   ATP8B4 3.098955 -0.08324083    0 FALSE     0 FALSE       3522        30
#
#
getGeneInList('ADGRE4P')
getGeneInList('ABCA8')
#         GeneIndex GeneName       Mu  Epsilon Prob  HVG ProbL   LVG totalReads totalCell
#ADGRE4P       285  ADGRE4P 0.9836823 1.447095 0.316 FALSE     0 FALSE          3         2
#ABCA8        36    ABCA8 1.168386 -5.442292    0 FALSE     1 TRUE       1031       195


#
#step3(3.2) Analysis for two groups of cells 
#暂时就一组，没用这个。难道要两group间？
Test <- BASiCS_TestDE(Chain1 = Chain, Chain2 = ChainRNA,
                      GroupLabel1 = "SC", GroupLabel2 = "PaS",
                      EpsilonM = log2(1.5), EpsilonD = log2(1.5),
                      EFDR_M = 0.10, EFDR_D = 0.10,
                      Offset = TRUE, PlotOffset = FALSE, Plot = TRUE)
#







========================================
单细胞转录组数据分析 | 隐藏在PC轴中的秘密：如何去除 batch effect //todo
----------------------------------------
https://www.jianshu.com/p/bcb0b520e056






========================================
轨迹推断中的细胞周期 //todo
----------------------------------------
https://www.jianshu.com/p/60b8fd91e131

轨迹推断，顾名思义是推断细胞分化状态的一种方法，然而现行的轨迹推断的方法都不能将周期纳入其中，但是总会有人这样想，然后实现了它。





========================================
如何GPU加速分析？
----------------------------------------
GPU版scanpy (rapids)实践 | 大型单细胞数据分析利器
https://mp.weixin.qq.com/s?__biz=MzU1MDMyNzUyNQ==&mid=2247484329&idx=1&sn=1cf0bf1f70f96e93c2ed18f23f13c982




========================================
----------------------------------------




========================================
----------------------------------------




========================================
----------------------------------------




========================================
----------------------------------------




========================================
----------------------------------------

