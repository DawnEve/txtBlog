深度学习与 TensorFlow


CS231n Convolutional Neural Networks for Visual Recognition
	https://cs231n.github.io/convolutional-networks/


https://tyang816.github.io/categories/stanford-cs329p/





========================================
简介: Keras 与 TensorFlow
----------------------------------------
1. Keras: 基于 Python 的深度学习库
Keras 的开发重点是支持快速的实验。能够以最小的时延把你的想法转换为实验结果，是做好研究的关键。

官网 
	https://keras.io/
	https://keras.io/zh/ 中文教程
	
	https://keras.io/getting_started/
	https://keras.io/api/
	https://keras.io/guides/
	https://keras.io/examples/

中文教程
	http://www.uml.org.cn/ai/202011042.asp

英文教程
	https://www.manning.com/books/deep-learning-with-python-second-edition 书。keras 首页推荐。




2. tensorflow
官网 
	https://www.tensorflow.org/ 打不开，被墙了

https://docs.microsoft.com/en-us/azure/databricks/applications/machine-learning/train-model/tensorflow






========================================
|-- 安装 TensorFlow
----------------------------------------
1. 官网
https://github.com/tensorflow/tensorflow

To install the current release, which includes support for CUDA-enabled GPU cards (Ubuntu and Windows):

$ pip3 install tensorflow -i https://pypi.douban.com/simple/

查看版本号
$ pip3 freeze | grep -i tensorflow
tensorflow==2.7.0
tensorflow-estimator==2.7.0
tensorflow-io-gcs-filesystem==0.22.0

升级
To update TensorFlow to the latest version, add --upgrade flag to the above commands.


测试 
$ python3 

>>> import tensorflow as tf
>>> tf.add(1, 2).numpy()
2021-11-14 13:04:57.201315: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2021-11-14 13:04:57.201445: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (sustc-HG): /proc/driver/nvidia/version does not exist
2021-11-14 13:04:57.202959: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.

3
>>> hello = tf.constant('Hello, TensorFlow!')
>>> hello.numpy()
b'Hello, TensorFlow!'
>>> quit()
$


(2) 看提示 no CUDA-capable device is detected
显卡支持
https://www.tensorflow.org/install/gpu


查看显卡
$ lspci | grep NVIDIA
65:00.0 VGA compatible controller: NVIDIA Corporation GP106GL [Quadro P2000] (rev a1)
65:00.1 Audio device: NVIDIA Corporation GP106 High Definition Audio Controller (rev a1)

该显卡需要的驱动
$ ubuntu-drivers devices
WARNING:root:_pkg_get_support nvidia-driver-390: package has invalid Support Legacyheader, cannot determine support level
== /sys/devices/pci0000:64/0000:64:00.0/0000:65:00.0 ==
modalias : pci:v000010DEd00001C30sv00001028sd000011B3bc03sc00i00
vendor   : NVIDIA Corporation
model    : GP106GL [Quadro P2000]
driver   : nvidia-driver-460-server - distro non-free
driver   : nvidia-driver-418-server - distro non-free
driver   : nvidia-driver-390 - distro non-free
driver   : nvidia-driver-470-server - distro non-free
driver   : nvidia-driver-450-server - distro non-free
driver   : nvidia-driver-470 - distro non-free recommended
driver   : nvidia-driver-495 - distro non-free
driver   : nvidia-driver-460 - distro non-free
driver   : xserver-xorg-video-nouveau - distro free builtin


（没做）去NVDIA driver search page搜索你的显卡需要的驱动型号并下载
https://www.nvidia.com/Download/Find.aspx
https://www.nvidia.com/download/driverResults.aspx/177149/en-us


禁用nouveau。
打开终端，输入：
$ sudo vim /etc/modprobe.d/blacklist.conf
在blacklist.conf文件末尾加上这两行，并保存：
blacklist nouveau
options nouveau modeset=0

然后执行命令：
$ sudo update-initramfs -u  //应用更改


直接安装显卡驱动
$ sudo apt-get install nvidia-driver-460 #很慢
最后一条输出 update-initramfs: Generating /boot/initrd.img-5.4.0-90-generic


$ sudo lspci -nn | grep NVIDIA
65:00.0 VGA compatible controller [0300]: NVIDIA Corporation GP106GL [Quadro P2000] [10de:1c30] (rev a1)
65:00.1 Audio device [0403]: NVIDIA Corporation GP106 High Definition Audio Controller [10de:10f1] (rev a1)


重启系统
$ sudo reboot

执行下面的命令，查看驱动的安装状态
$ sudo nvidia-smi
$ sudo nvidia-settings


查看NVIDIA版本检验是否安装完成

没重启时
$ nvidia-smi
NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.



ref:
https://blog.csdn.net/flowrush/article/details/80254301



========================================
手写体识别与Tensorflow
----------------------------------------
1.如同所有语言的hello world一样，手写体识别就相当于深度学习里的hello world。

TensorFlow是当前最流行的机器学习框架，有了它，开发人工智能程序就像Java编程一样简单。


(1)设法使用 GPU
使用GPU能让训练加速10-100倍，已经不是秘密，这意味着你可以把迭代自己想法(是好是坏)的速度提高100倍。
实验做得越快，学到的知识就越多。


查看linux机器是否有GPU的简单命令:
$ lspci |grep -i nvidia
65:00.0 VGA compatible controller: NVIDIA Corporation GP106GL (rev a1)
65:00.1 Audio device: NVIDIA Corporation GP106 High Definition Audio Controller (rev a1)

结论: Ubuntu工作站有GPU，其他2台server没有GPU。


(2) 安装 GPU支持 //todo
https://tensorflow.google.cn/install/gpu






2. 训练集和测试集

MNIST 数据集已经是一个被”嚼烂”了的数据集, 很多教程都会对它”下手”, 几乎成为一个 “典范”. 不过有些人可能对它还不是很了解, 下面来介绍一下.

MNIST 数据集可在 http://yann.lecun.com/exdb/mnist/ 获取, 它包含了四个部分:

       Training set images: train-images-idx3-ubyte.gz (9.9 MB, 解压后 47 MB, 包含 60,000 个样本)  
       Training set labels: train-labels-idx1-ubyte.gz (29 KB, 解压后 60 KB, 包含 60,000 个标签) 
       Test set images: t10k-images-idx3-ubyte.gz (1.6 MB, 解压后 7.8 MB, 包含 10,000 个样本) 
       Test set labels: t10k-labels-idx1-ubyte.gz (5KB, 解压后 10 KB, 包含 10,000 个标签)

MNIST 数据集来自美国国家标准与技术研究所, National Institute of Standards and Technology (NIST). 训练集 (training set) 由来自 250 个不同人手写的数字构成, 其中 50% 是高中学生, 50% 来自人口普查局 (the Census Bureau) 的工作人员. 测试集(test set) 也是同样比例的手写数字数据.

tensorflow提供一个input_data.py文件，专门用于下载mnist数据，我们直接调用就可以了，代码如下：

import tensorflow.examples.tutorials.mnist.input_data
mnist = input_data.read_data_sets("MNIST_data/", one_hot=True)
执行完成后，会在当前目录下新建一个文件夹MNIST_data

input_data文件会调用一个maybe_download函数，确保数据下载成功。这个函数还会判断数据是否已经下载，如果已经下载好了，就不再重复下载。


(1)### 报错：
ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory

### 环境：
Ubuntu 1804 64bit, 
$ python -V
Python 3.6.3 :: Anaconda, Inc.

$ pip list | grep flow
tensorflow-gpu                     1.10.1


2)重新安装包：
$ pip install --upgrade pip
$ pip -V
pip 19.2.1 from /home/wangjl/anaconda3/lib/python3.6/site-packages/pip (python 3.6)


#ERROR: Cannot uninstall 'wrapt'问题  https://www.cnblogs.com/xiaowei2092/p/11025155.html
$ pip install -U --ignore-installed wrapt enum34 simplejson netaddr

$ pip search tensorflow                                                                                                                           
tensorflow (1.14.0)     - TensorFlow is an open source machine learning framework for everyone.
$ pip install tensorflow  
安装成功 Successfully installed tensorflow-1.14.0

升级
$ pip install --upgrade tensorflow-gpu


3)
$ pip install --upgrade setuptools


(2) 再次尝试执行两行下载代码
还是那个报错 
ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory

1) 需要安装cuda？
CUDA（Compute Unified Device Architecture），是显卡厂商NVIDIA推出的运算平台。
放弃！！ 下次，换个环境继续： https://colab.research.google.com





(3)win10安装，数据加载成功
开始报错 module 'tensorflow.python.keras.backend' has no attribute 'get_graph'
重装
$ pip install keras==2.2.0 -i https://pypi.douban.com/simple/

import sys, numpy as np
from keras.datasets import mnist

(x_train, y_train), (x_test, y_test) = mnist.load_data()
print(len(x_train))
# 60000
ref:https://blog.csdn.net/qq_42823242/article/details/101717247


(4)CentOS上安装
https://www.cnblogs.com/conver/p/11141176.html
1).遇到了
ERROR: Cannot uninstall 'wrapt'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.
办法1：输入 pip install -U --ignore-installed wrapt enum34 simplejson netaddr -i https://pypi.douban.com/simple/

2).遇到了(我没遇到这个)
ERROR: tensorboard 1.14.0 has requirement setuptools>=41.0.0, but you'll have setuptools 39.1.0 which is incompatible.
原因： setuptools 版本太低
办法：更新setuptools版本 输入 pip install --upgrade setuptools





https://www.cnblogs.com/skyme/p/8595642.html



========================================
|-- 卷积神经网络 (CNN)
----------------------------------------
图解：https://www.cnblogs.com/skyfsm/p/6790245.html
推荐书: Grokking deep learning 深度学习图解。

我的笔记： https://github.com/DawnEve/ML_MachineLearning/blob/master/ANN/Grokking_Deep_Learning_6_10.ipynb



1. 如何制作自己的手写数字图片，并使用训练模型进行识别

#Tips: 手写时，使用picpick截屏白色背景67*67，然后用6px黑色画笔写数字，然后缩放 图像大小 到28*28像素，保存为png。
# 要写到图片正中间，偏离中心可能识别出错。
#
#1.白底黑字的手写数字图片png, 缩放为 28*28 像素图片
#2.读入py，处理：取出rgb一个维度，(255-位点) /255，再转为 一行 784列
#3.使用卷积核和权重矩阵，获得对10个数字的打分，哪个打分高就是哪个数字。

from PIL import Image

def getImage2Matrix(PATH):
    im = Image.open(PATH)
    plt.imshow(im)
    plt.show()

    data=im.getdata()
    data=np.array(data)
    #print(data.shape)

    data=np.reshape(data.T[0], (784, 1)) #只取rgb的一个维度
    print(data.shape)
    input2 = ((255 - np.array(data, dtype=np.uint8)) / 255.0).reshape(1,-1)
    print(input2.shape)
    return input2;
#

PATH ="my_num_pics/pic8.png"
img_mt=getImage2Matrix(PATH)
img_mt.shape


def sayNumberByMatrix(image_mt): #(1,784)
    plt.imshow(image_mt.T.reshape(28,28))
    plt.show()
    
    layer_0=image_mt
    layer_0=layer_0.reshape(layer_0.shape[0],28,28)
    #layer_0.shape

    sects=list()
    for row_start in range(layer_0.shape[1]-kernel_rows+1):
        for col_start in range(layer_0.shape[2]-kernel_cols+1):
            sect=get_image_section(layer_0, row_start, row_start+kernel_rows,  col_start, col_start+kernel_cols)
            sects.append(sect)

    expanded_input=np.concatenate(sects,axis=1)
    es=expanded_input.shape
    flattened_input=expanded_input.reshape(es[0]*es[1], -1)

    kernel_output=flattened_input.dot(kernels)
    layer_1=tanh(kernel_output.reshape(es[0], -1))

    layer_2=np.dot(layer_1, weights_1_2) #验证集输出不再使用softmax
    print(layer_2)
    return np.argmax(layer_2)
#
sayNumberByMatrix(img_mt)


# 一行调用
sayNumberByMatrix(getImage2Matrix("my_num_pics/pic6.png"))







========================================
深度学习 - Deep Learning
----------------------------------------




========================================
|-- CNN：人工卷积神经网络(吴恩达视频课) //todo
----------------------------------------
1. 文本资料
http://www.seeprettyface.com/research_notes.html










========================================
|-- RNN：循环神经网络 //todo
----------------------------------------






========================================
|-- GNN: 图神经网络 //todo
----------------------------------------






========================================
熵(Entropy)，交叉熵(cross Entropy)，损失函数(loss function)
----------------------------------------

小结：交叉熵的“交叉”指的是真实分布和估计的交叉，并且希望这个值越小越好，所以可以用来做损失函数。

1. 香农提出了熵的定义：无损编码事件信息的最小平均编码长度。

P=1/N;
log2(N)=-log2(1/N)=-log2(P)

那么熵的那些描述和解释(混乱程度，不确定性，惊奇程度，不可预测性，信息量等)代表了什么呢？

如果熵比较大(即平均编码长度较长)，意味着这一信息有较多的可能状态，相应的每个状态的可能性比较低；因此每当来了一个新的信息，我们很难对其作出准确预测，即有着比较大的混乱程度/不确定性/不可预测性。

并且当一个罕见的信息到达时，比一个常见的信息有着更多的信息量，因为它排除了别的很多的可能性，告诉了我们一个确切的信息。在天气的例子中，Rainy发生的概率为12.5%，当接收到该信息时，我们减少了87.5%的不确定性(Fine,Cloudy,Snow)；如果接收到Fine(50%)的消息，我们只减少了50%的不确定性。

E(x)=累加(i, -pi*log2(pi))

定义R函数：
entropy=function(arr){
  if(1!=sum(arr)){stop("sum not 1")}
  results=0
  for(p1 in arr){
    results = results -p1*log2(p1)
  }
  results
}

仅有一个分类时，熵最小，为0.
仅有2个分类时，熵最大为平分：
	> entropy(c(0.5, 0.5)) #[1] 1
	> entropy(c(0.1, 0.9)) #[1] 0.4689956

其中：
	> -0.1*log2(0.1) #	[1] 0.3321928  小概率时间对应的熵大
	> -0.9*log2(0.9) #	[1] 0.1368028

分组越多，最大熵越大，就是平分的时候：
	> entropy( rep(1/3, 3) ) #[1] 1.584963
	> entropy( rep(1/4, 4) )# [1] 2
	> entropy( rep(1/5, 5) )# [1] 2.321928
	> entropy( rep(1/10, 10) ) #[1] 3.321928





2. 交叉熵

(1) 另一种写法

E(x)=累加(i, -pi*log2(pi))

x~P代表我们使用概率分布P来计算期望，熵又可以简写为H：

H(P)=Entropy=Ex~p[-logP(x)]

重要的事情再说一遍：“熵是服从某一特定概率分布事件的理论最小平均编码长度”，只要我们知道了任何事件的概率分布，我们就可以计算它的熵；那如果我们不知道事件的概率分布，又想计算熵，该怎么做呢？那我们来对熵做一个估计吧，熵的估计的过程自然而然的引出了交叉熵。




(2) 熵的估计

假如我们现在需要预报东京天气，在真实天气发生之前，我们不可能知道天气的概率分布；但为了下文的讨论，我们需要假设：对东京天气做一段时间的观测后，可以得到真实的概率分布P。

在观测之前，我们只有预估的概率分布Q，使用估计得到的概率分布，可以计算估计的熵：

EstimatedEntropy = Ex~Q[-logQ(x)]

如果Q是真实的概率分布，根据上述公式，我们已经得到了编码东京天气信息的最小平均长度；然而估计的概率分布为我们的公式引入了两部分的不确定性：
* 计算期望的概率分布是Q，与真实的概率分布P不同。
* 计算最小编码长度的概率是 -logQ，与真实的最小编码长度 -logP 不同。

因为估计的概率分布Q影响了上述两个部分(期望和编码长度)，所以得到的结果很可能错得离谱，也因此该结果和真实熵的对比无意义。和香农的目标一样，我们希望编码长度尽可能的短，所以我们需要对比我们的编码长度和理论上的最小编码长度(熵)。假设经过观测后，我们得到了真实概率分布P，在天气预报时，就可以使用P计算平均编码长度，实际编码长度基于Q计算，这个计算结果就是P和Q的交叉熵。这样，实际编码长度和理论最小编码长度就有了对比的意义。

CrossEntropy = Ex~P[-logQ(x)]

Entropy=Ex~P[-logP(x)]




(3) 交叉熵 >= 熵

交叉熵使用H(P,Q)表示，意味着使用P计算期望，使用Q计算编码长度；
所以H(P,Q)并不一定等于H(Q,P)，除了在P=Q的情况下，H(P,Q) = H(Q,P) = H(P)。

H(P,Q)=Ex~P[-logQ(x)]

有一点很微妙但很重要：
* 对于期望，我们使用真实概率分布P来计算；
* 对于编码长度，我们使用假设的概率分布Q来计算，因为它是预估用于编码信息的。

因为熵是理论上的平均最小编码长度，所以交叉熵只可能大于等于熵。

换句话说，如果我们的估计是完美的，即Q=P，那么有H(P,Q) = H(P)，否则，H(P,Q) > H(P)。

至此，交叉熵和熵的关系应该比较明确了，下面让我们看看为什么要使用交叉熵作分类损失函数。




(4) 交叉熵作为损失函数
假设一个动物照片的数据集中有5种动物，且每张照片中只有一只动物，每张照片的标签都是one-hot编码。

Label Animal
10000 Dog
01000 Fox
00100 Horse
00010 Eagle
00001 Squirrel


第一张照片是狗的概率为100%，是其他的动物的概率是0；
第二张照片是狐狸的概率是100%，是其他动物的概率是0，
其余照片同理；
因此可以计算下，每张照片的熵都为0。
换句话说，以one-hot编码作为标签的每张照片都有100%的确定度，不像别的描述概率的方式：狗的概率为90%，猫的概率为10%。


假设有两个机器学习模型对第一张照片分别作出了预测：Q1和Q2,而第一张照片的真实标签为[1,0,0,0,0]。
Model Prediction
Q1    [0.4,0.3,0.05,0.05,0.2]
Q2    [0.98,0.01,0,0,0.01]


两个模型预测效果如何呢？可以分别计算交叉熵：

H(P1,Q1) = -累加(Pi*log2(Qi)) = -( 1*log2(0.4)+0*log2(0.3)+0*log2(0.05)+0*log2(0.05)+0*log2(0.2) )=1.3219
H(P1,Q2) = -累加(Pi*log2(Qi)) = -( 1*log2(0.98)+0*log2(0.01)+0*log2(0)+0*log2(0)+0*log2(0.01) )=0.029

交叉熵对比了模型的预测结果和数据的真实标签，随着预测越来越准确，交叉熵的值越来越小，如果预测完全正确，交叉熵的值就为0。
因此，训练分类模型时，可以使用交叉熵作为损失函数。




(5) 二分类交叉熵
在二分类模型中，标签只有是和否两种；这时，可以使用二分类交叉熵作为损失函数。假设数据集中只有猫和狗的照片，则交叉熵公式中只包含两种可能性：

H(P,Q)=-累加(i=(cat,dog), Pi*logQi) = -P(cat)logQ(cat) - P(dog)logQ(dog)

又因为 P(dog)=1-P(cat)
所以交叉熵可以表示为：

H(P,Q)= -P(cat)logQ(cat) - (1-P(cat))log(1-Q(cat))

使用如下定义
	P=P(cat)
	P_bar=Q(cat)

二分类的交叉熵可以写作如下形式，看起来就熟悉多了。

BinaryCrossEntropy=-Plog(P_bar) - (1-P)log(1-P_bar)





ref:
https://zhuanlan.zhihu.com/p/149186719


========================================
|-- KL 散度(Kullback-Leibler divergence)//todo
----------------------------------------
1. 定义 
KL divergence(Relative entropy/Information gain):

Dkl(p||q)=H(p,q)-H(p)=-累加(p(x)logq(x)) + 累加(p(x)logp(x))
	= -累加(p(x)*log[q(x)/p(x)])
	= 累加(p(x)*log[p(x)/q(x)])


2.性质
(1) 相对熵 = 交叉熵 - shannon熵
(2) 非对称 Dkl(p||q) != Dkl(q||p)，亦不满足三角不等式，故不是距离。
(3) Dkl(p||q)为p相对于q，值非负，取零若p=q。从公式上看，就是拿q替代p后熵的变化。
(4) KL = Kullback-Leibler






ref:
https://zhuanlan.zhihu.com/p/425693597



========================================
|-- 互信息熵（Mutual Information Entropy）//todo
----------------------------------------



ref:
https://zhuanlan.zhihu.com/p/128091167




========================================
《深度学习图解》概念扫盲：再学一遍
----------------------------------------
pdf: https://zhuanlan.zhihu.com/p/507883315
1. 评价：适合小白入门
https://book.douban.com/subject/34932968/
第 10 章直接对一个虚空数据集进行操作，。。。。。 对不起 rnn，对不起 lstm，对不起联邦学习 。
英文样张截图：https://mp.weixin.qq.com/s/UPZA4VXjR99tVoEmnA7TkQ
原书官网：https://livebook.manning.com/book/grokking-deep-learning/about-this-book/
	https://livebook.manning.com/book/grokking-deep-learning/brief-contents/v-12/1
作者：https://iamtrask.github.io/

《图解深度学习》最大的特点就是在调包类书籍泛滥的当下，这本书可以说是非常良心了，作者通过 10 多章的铺垫，最终完成了一个微型的深度学习库，这应该也是本书的最大价值。

本书所有的代码实现都是基于 Python，并没有简单地调用库。这样能够最大程度地帮助你理解深度学习中的概念和原理。



2. 重要参考资料
github Forked: https://github.com/dawnEve/Grokking-Deep-Learning

(1) 
** 实体书：
** 中文电子书：https://datawhalechina.github.io/easy-grokking-deep-learning/
** 我的笔记：https://github.com/DawnEve/ML_MachineLearning/tree/master/ANN
	本地：D:\xampp\htdocs\ML_MachineLearning


(2)
https://exacity.github.io/deeplearningbook-chinese/
https://github.com/exacity/deeplearningbook-chinese




========================================
|-- 名词解释: 卷积层、池化层和全连接层
----------------------------------------
1. two convolutional layers 和 one dense layer 

https://pubmed.ncbi.nlm.nih.gov/31530582/
Fig4: The input DNA sequence is one hot encoded and fed into a CNN composed of two convolutional layers and one dense layer with a final output of a single neuron with linear activation (Methods). 

(1) 卷积层 convolutional layer:

Convolutional layers, which apply a specified number of convolution filters to the image. For each subregion, the layer performs a set of mathematical operations to produce a single value in the output feature map. Convolutional layers then typically apply a ReLU activation function to the output to introduce nonlinearities into the model.

卷积层，就是使用一系列filter对图片做卷积计算，提取特征。并且典型的卷积层会使用ReLU激活函数来引入非线性因数。

卷积的计算过程方法如下图，也就是用filter扫描整个图片，并做wx+b计算：


一般要用激活函数，如 ReLu，引入非线性。
引入非线性的作用：
  a)减少计算 b)避免梯度消失 c)网络的稀疏性，避免过拟合
  引入非线性是为了提取特征的，线性变换的结果还是线性的，没有意义的。


(2) Pooling layers 池化层
池化这个概念相对简单，类似于压缩图片。
max pool即取设定矩形里最大的值作为输出数据。


(3) Dense(fully connected) Layer 稠密层(全连接层) 

通过卷积和池化，然后得到了众多特征，稠密层的每一个节点都与这些特征节点相连构成稠密层(全连接层)。

稠密层的作用就是分类。

简单的说就是每一个特征节点手里握着一定的权重来决定输入是属于那个分类，最终全部特征的权重共同决定了输入所属分类的权重或概率。

也有反对意见: dense 应该不是分类，它的作用是将所有的数据连接在一起，说白了就是把所有的分开的小的感受野组合成整体的感受野。
分类一般是用后面的softmax来实现的。



ref:
https://blog.csdn.net/fenjiehuang/article/details/79247215







========================================
----------------------------------------



========================================
----------------------------------------


========================================
----------------------------------------




========================================
----------------------------------------



========================================
----------------------------------------


========================================
----------------------------------------


