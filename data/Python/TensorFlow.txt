深度学习与 tensorflow / PyTorch


CS231n Convolutional Neural Networks for Visual Recognition
	https://cs231n.github.io/convolutional-networks/


https://tyang816.github.io/categories/stanford-cs329p/




========================================
《深度学习图解》概念扫盲：再学一遍
----------------------------------------
pdf: https://zhuanlan.zhihu.com/p/507883315
1. 评价：适合小白入门
https://book.douban.com/subject/34932968/
第 10 章直接对一个虚空数据集进行操作，。。。。。 对不起 rnn，对不起 lstm，对不起联邦学习 。
英文样张截图：https://mp.weixin.qq.com/s/UPZA4VXjR99tVoEmnA7TkQ
原书官网：https://livebook.manning.com/book/grokking-deep-learning/about-this-book/
	https://livebook.manning.com/book/grokking-deep-learning/brief-contents/v-12/1
作者：https://iamtrask.github.io/

《图解深度学习》最大的特点就是在调包类书籍泛滥的当下，这本书可以说是非常良心了，作者通过 10 多章的铺垫，最终完成了一个微型的深度学习库，这应该也是本书的最大价值。

本书所有的代码实现都是基于 Python，并没有简单地调用库。这样能够最大程度地帮助你理解深度学习中的概念和原理。



2. 重要参考资料
github Forked: https://github.com/dawnEve/Grokking-Deep-Learning

(1) 
** 实体书：
** 中文电子书：https://datawhalechina.github.io/easy-grokking-deep-learning/
** 我的笔记：https://github.com/DawnEve/ML_MachineLearning/tree/master/ANN
	本地：D:\xampp\htdocs\ML_MachineLearning


(2)
https://exacity.github.io/deeplearningbook-chinese/
https://github.com/exacity/deeplearningbook-chinese




========================================
|-- 名词解释: 卷积层、池化层和全连接层
----------------------------------------


1. two convolutional layers 和 one dense layer 

https://pubmed.ncbi.nlm.nih.gov/31530582/
Fig4: The input DNA sequence is one hot encoded and fed into a CNN composed of two convolutional layers and one dense layer with a final output of a single neuron with linear activation (Methods). 

(1) 卷积层 convolutional layer:

Convolutional layers, which apply a specified number of convolution filters to the image. For each subregion, the layer performs a set of mathematical operations to produce a single value in the output feature map. Convolutional layers then typically apply a ReLU activation function to the output to introduce nonlinearities into the model.

卷积层，就是使用一系列filter对图片做卷积计算，提取特征。并且典型的卷积层会使用ReLU激活函数来引入非线性因数。

卷积的计算过程方法如下图，也就是用filter扫描整个图片，并做wx+b计算：


一般要用激活函数，如 ReLu，引入非线性。
引入非线性的作用：
  a)减少计算 b)避免梯度消失 c)网络的稀疏性，避免过拟合
  引入非线性是为了提取特征的，线性变换的结果还是线性的，没有意义的。


(2) Pooling layers 池化层
池化这个概念相对简单，类似于压缩图片。
max pool即取设定矩形里最大的值作为输出数据。


(3) Dense(fully connected) Layer 稠密层(全连接层) 

通过卷积和池化，然后得到了众多特征，稠密层的每一个节点都与这些特征节点相连构成稠密层(全连接层)。

稠密层的作用就是分类。

简单的说就是每一个特征节点手里握着一定的权重来决定输入是属于那个分类，最终全部特征的权重共同决定了输入所属分类的权重或概率。

也有反对意见: dense 应该不是分类，它的作用是将所有的数据连接在一起，说白了就是把所有的分开的小的感受野组合成整体的感受野。
分类一般是用后面的softmax来实现的。









ref:
https://blog.csdn.net/fenjiehuang/article/details/79247215





========================================
简介: Keras 与 TensorFlow
----------------------------------------
1. Keras: 基于 Python 的深度学习库
Keras 的开发重点是支持快速的实验。能够以最小的时延把你的想法转换为实验结果，是做好研究的关键。

官网 
	https://keras.io/
	https://keras.io/zh/ 中文教程
	
	https://keras.io/getting_started/
	https://keras.io/api/
	https://keras.io/guides/
	https://keras.io/examples/

中文教程
	http://www.uml.org.cn/ai/202011042.asp

英文教程
	https://www.manning.com/books/deep-learning-with-python-second-edition 书。keras 首页推荐。




2. tensorflow
官网 
	https://www.tensorflow.org/ 打不开，被墙了

https://docs.microsoft.com/en-us/azure/databricks/applications/machine-learning/train-model/tensorflow






========================================
|-- 安装 TensorFlow
----------------------------------------
1. 官网
https://github.com/tensorflow/tensorflow

To install the current release, which includes support for CUDA-enabled GPU cards (Ubuntu and Windows):

$ pip3 install tensorflow -i https://pypi.douban.com/simple/

查看版本号
$ pip3 freeze | grep -i tensorflow
tensorflow==2.7.0
tensorflow-estimator==2.7.0
tensorflow-io-gcs-filesystem==0.22.0

升级
To update TensorFlow to the latest version, add --upgrade flag to the above commands.


测试 
$ python3 

>>> import tensorflow as tf
>>> tf.add(1, 2).numpy()
2021-11-14 13:04:57.201315: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2021-11-14 13:04:57.201445: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (sustc-HG): /proc/driver/nvidia/version does not exist
2021-11-14 13:04:57.202959: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.

3
>>> hello = tf.constant('Hello, TensorFlow!')
>>> hello.numpy()
b'Hello, TensorFlow!'
>>> quit()
$


(2) 看提示 no CUDA-capable device is detected
显卡支持
https://www.tensorflow.org/install/gpu


查看显卡
$ lspci | grep NVIDIA
65:00.0 VGA compatible controller: NVIDIA Corporation GP106GL [Quadro P2000] (rev a1)
65:00.1 Audio device: NVIDIA Corporation GP106 High Definition Audio Controller (rev a1)

该显卡需要的驱动
$ ubuntu-drivers devices
WARNING:root:_pkg_get_support nvidia-driver-390: package has invalid Support Legacyheader, cannot determine support level
== /sys/devices/pci0000:64/0000:64:00.0/0000:65:00.0 ==
modalias : pci:v000010DEd00001C30sv00001028sd000011B3bc03sc00i00
vendor   : NVIDIA Corporation
model    : GP106GL [Quadro P2000]
driver   : nvidia-driver-460-server - distro non-free
driver   : nvidia-driver-418-server - distro non-free
driver   : nvidia-driver-390 - distro non-free
driver   : nvidia-driver-470-server - distro non-free
driver   : nvidia-driver-450-server - distro non-free
driver   : nvidia-driver-470 - distro non-free recommended
driver   : nvidia-driver-495 - distro non-free
driver   : nvidia-driver-460 - distro non-free
driver   : xserver-xorg-video-nouveau - distro free builtin


（没做）去NVDIA driver search page搜索你的显卡需要的驱动型号并下载
https://www.nvidia.com/Download/Find.aspx
https://www.nvidia.com/download/driverResults.aspx/177149/en-us


禁用nouveau。
打开终端，输入：
$ sudo vim /etc/modprobe.d/blacklist.conf
在blacklist.conf文件末尾加上这两行，并保存：
blacklist nouveau
options nouveau modeset=0

然后执行命令：
$ sudo update-initramfs -u  //应用更改


直接安装显卡驱动
$ sudo apt-get install nvidia-driver-460 #很慢
最后一条输出 update-initramfs: Generating /boot/initrd.img-5.4.0-90-generic


$ sudo lspci -nn | grep NVIDIA
65:00.0 VGA compatible controller [0300]: NVIDIA Corporation GP106GL [Quadro P2000] [10de:1c30] (rev a1)
65:00.1 Audio device [0403]: NVIDIA Corporation GP106 High Definition Audio Controller [10de:10f1] (rev a1)


重启系统
$ sudo reboot

执行下面的命令，查看驱动的安装状态
$ sudo nvidia-smi
$ sudo nvidia-settings


查看NVIDIA版本检验是否安装完成

没重启时
$ nvidia-smi
NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.



ref:
https://blog.csdn.net/flowrush/article/details/80254301





========================================
怎么入门深度学习？至少必须会 pytorch
----------------------------------------
1.简单分成几步
基础：Python 、 Numpy、 Pandas 、 Pytorch
理论：简单了解 MLP，CNN 、 Transformer 为主，再考虑 RNN 的基础
模型：AlexNet、 VGG 、 ResNet、 Yolo 、 SSD 是里任选两个自己手写代码，标记数据、训练一下就好了。如果你真的有志于此，那我建议你手写完整的 Transformer 模型，这现在看是未来的所有。

完成上面几步，这样你就是一个不错的入门选手了。再看看书，就是一个只需要你部就班就能成为高手的路！

(2)在深度学习框架方面，PyTorch 和 TensorFlow 是两个主流选择。
* PyTorch：由于其易于理解的编程风格和动态计算图，PyTorch 在研究领域特别受欢迎。它的直观性使得开发新算法和实验新想法变得简单。

* TensorFlow：相比之下，TensorFlow 在工业界更为流行，尤其是在需要大规模部署的场景中。TensorFlow 提供了一个全面的生态系统，包括用于生产部署的工具和资源。

这其中 Pytorch 是必须的，这东西有无数人的无数论文都是基于它的，最新的东西如果你不会 Pytorch，那肯定是不成的。



2. 理论（完全以编码为假想条件）
简单了解 MLP，CNN 、 Transformer ，再考虑 RNN 的基础。至少你要懂下面的东西。

(1) 多层感知机（MLP）：
基础：MLP是神经网络的最基本形式，包含输入层、若干隐藏层和输出层。每一层都由一系列神经元组成，这些神经元与上一层的每个神经元相连接。

(2)卷积神经网络（CNN）：
核心：CNN在图像处理和计算机视觉领域非常成功。它的关键在于使用卷积层来自动和有效地提取图像的特征。
结构：一个典型的CNN包括卷积层、池化层和全连接层。卷积层通过卷积核提取局部特征；池化层则负责降低特征的空间维度；最后，全连接层用于分类或回归任务。
应用：CNN广泛应用于图像识别、视频分析和自然语言处理等领域。


(3)Transformer：
创新：Transformer模型在自然语言处理领域引起了革命。其核心是“自注意力”（Self-Attention）机制，允许模型在处理序列数据时关注序列中的任何部分。
优势：与RNN和LSTM相比，Transformer在处理长距离依赖方面更有效，且计算更可并行化。
应用：它是许多现代NLP模型的基础，如BERT、GPT、 LLaMa系列等。


(4)循环神经网络（RNN）：
特点：RNN是处理序列数据的一种经典方法。它通过在序列的每个步骤传递隐藏状态来保存过去信息。
局限：标准的RNN在处理长序列时遇到梯度消失或爆炸问题，这限制了其在长序列上的性能。
改进：LSTM（长短期记忆）和GRU（门控循环单元）是改进的RNN变体，设计用来解决这些问题。



3. 模型与实际操作
在深度学习和计算机视觉领域，AlexNet、VGG、ResNet、Yolo和SSD都是极为重要的模型，各自代表了图像识别和对象检测领域的重要进展。为了深入理解这些模型的工作原理和应用，手写代码并亲自进行数据标记和训练是一个非常有效的学习方法。

(1) AlexNet 和 VGG 是两个很好的起点：
AlexNet：作为深度学习历史上的里程碑，AlexNet 在2012年的ImageNet挑战赛中大放异彩。它的结构相对简单，包含5个卷积层和3个全连接层。手写AlexNet并在数据集上进行训练，可以帮助你理解卷积神经网络的基本构件和工作原理。

VGG：VGG网络以其简单和高效著称，特别是VGG-16和VGG-19。这些网络通过重复使用相同大小的小卷积核，展示了深层网络结构的强大能力。尝试手写VGG并训练它，将加深你对网络深度如何影响性能和特征学习的理解。


(2) 手写Transformer模型：
如果你对深入学习人工智能有长远的打算，那么手写完整的Transformer模型将是一个有意思的挑战。Transformer自2017年被提出以来，已经成为自然语言处理领域的核心模型，并且其影响力也扩展到其他领域如计算机视觉和音频处理。

Transformer模型的核心在于自注意力机制，这使得模型能够在处理序列数据时捕捉长距离依赖关系。此外，Transformer的层次结构和并行处理能力使其在处理大型数据集时更为高效。

手写Transformer模型不仅需要理解其复杂的架构和自注意力机制，还需要深入掌握如何有效地训练这样的大型模型。这个过程将极大地提升你在深度学习领域的理解和技能。

如果你懂了前三点，那你的 Transformer 的理解真是很到位了。

无论选择哪种模型，关键是通过实际操作来深入理解模型的工作原理。这包括了解模型的架构、学习如何处理和准备数据、了解训练过程以及如何调整参数以获得最佳性能。这种实践经验对于深入理解深度学习的原理和发展是非常宝贵的。

同时还有最重要的一点！如果你不看书，那还是对于这些是一个片面的认知，所以坚持 看书吧。李沐的《Dive into Deep Learning》、或者《understanding deep learning》从头看到尾就好了，但是不动手是真的不成啊。




========================================
pytorch 怎么学？环境 + 图书/视频资料
----------------------------------------
1. 学习哪个版本？
@J3 server
$ jupyter notebook list
Currently running servers:
http://10.10.117.158:8201/?token=f516dc29a0ef855f6b16d050fdbcc5c423e7b4dcfaf73fc7 :: /picb/jinlab/wangjl/web/docs/code/learnDL

$ python3 -V
Python 3.10.14

$ pip3 list | grep -in torch
184:torch                        2.2.2


PyTorch是一个流行的深度学习框架，由Facebook开发。它提供了动态计算图和强大的GPU加速，使得模型的定义和调试更加直观和便捷。

* 推荐直接看pytorch官网的tutorial即可，在github上面也有对应的example。一定要多动手，多总结，很快即可入门，然后再选择一个自己喜欢的方向深入学习即可。torch相对tf上手还是容易很多的。

* 撸n遍transformer源码，弄懂每一个点，入门的话暂时就够用了。有条件的再去跟一遍李沐的系列课及网站代码。





2.图书目录
(1) PyTorch 2.0 深度学习从零开始学，王晓华 著
https://www.zhihu.com/pub/book/120439544
PyTorch 概述、开发环境搭建
基于 PyTorch 的 MNIST 分类实战、深度学习理论基础、MNIST 分类实战、数据处理与模型可视化
基于 PyTorch 卷积层的分类实战、PyTorch 数据处理与模型可视化、实战 ResNet 卷积网络模型
有趣的 Word Embedding、基于循环神经网络的中文情感分类实战、自然语言处理的编码器
站在巨人肩膀上的预训练模型 BERT、自然语言处理的解码器
基于 PyTorch 的强化学习实战、基于 MFCC 的语音唤醒实战、基于 PyTorch 的人脸识别实战。


(2) PyTorch 深度学习实战，[美]伊莱·史蒂文斯 等著
https://www.zhihu.com/pub/book/120284551
由于像苹果、Facebook 和摩根大通这样的公司都使用 PyTorch，所以当你掌握了 PyTorth，就会拥有更多的职业选择。 本书是教你使用 PyTorch 创建神经网络和深度学习系统的实用指南。它帮助读者快速从零开始构建一个真实示例：肿瘤图像分类器。
本书主要内容： 
1）训练深层神经网络；
2）实现模块和损失函数；
3）使用 PyTorch Hub 预先训练的模型；
4）探索在 Jupyter Notebooks 中编写示例代码。
本书适用于对深度学习感兴趣的 Python 程序员。了解深度学习的基础知识对阅读本书有一定的帮助，但读者无须具有使用 PyTorch 或其他深度学习框架的经验。


(3) 细说 PyTorch 深度学习：理论、算法、模型与编程实现, 凌峰 等著
https://www.zhihu.com/pub/book/120430658
第一篇为基础知识，主要介绍 PyTorch 的基本知识、构建开发环境、卷积网络、经典网络、模型保存和调用、网络可视化、数据加载和预处理、数据增强等内容；
第二篇为高级应用，主要介绍数据分类、迁移学习、人脸检测和识别、生成对抗网络、目标检测、ViT 等内容。本书内容涵盖 PyTorch 从入门到深度学习的各个方面，是一本基础应用与案例实操相结合的参考书。


- 《PyTorch深度学习实战》：入门到进阶介绍了PyTorch的API，还从头到尾做了一个项目。
- 《动手学深度学习·PyTorch》：新版还引入了模型领域的一些最新成果，如Transformer架构。
- 《从零开始大模型开发与微调》：从最近点的卷积神经网络开始讲起，实现了一些经典的网络。再逐步过渡到最新的模型，transformer，bert，chatglm上。
- 如果想补充一些些数学基础，可以看看《机器学习的数学理论》和《深度学习》花书。




3. 入门教程

	1. 教程
	2. 练习
	3. pytorch 60题 （datawhale出品）
	4. 比赛中练习，在没有答案的打榜中学习。（强推）
	5. pytorch模型实现大全（作为练习强推）

概念介绍：https://mp.weixin.qq.com/s/cTVblMQ0EdrMF6Adn6mIHA

(1) 莫烦pytorch系列教程
https://mofanpy.com/tutorials/machine-learning/torch/

莫烦的这套视频一集最长也就15min，大多都是5分钟左右，莫烦哥哥风趣幽默，内容浅显易懂，直接上手，适合对pytorch有个基本了解。一天即可刷完并练习完。

pytorch简介
	- pytorch神经网络基础
	- 建立第一个神经网络
	- 高级神经网络结构
	- 高阶内容

(2) 新手如何入门pytorch？
第一步 github的 tutorials 尤其是那个60分钟的入门。只能说比tensorflow简单许多, 我在火车上看了一两个小时就感觉基本入门了. 另外jcjohnson 的Simple examples to introduce PyTorch 也不错
第二步 example 参考 pytorch/examples 实现一个最简单的例子(比如训练mnist )。
第三步 通读doc PyTorch doc 尤其是autograd的机制，和nn.module ,optim 等相关内容。文档现在已经很完善，而且绝大部分文档都是作者亲自写的，质量很高。
第四步 论坛讨论 PyTorch Forums 。论坛很活跃，而且质量很高，pytorch的维护者(作者)回帖很及时的。

Tutorials
	https://pytorch.org/tutorials/ 60分钟教程，2小时入门
	https://github.com/jcjohnson/pytorch-examples 入门示例
示例 https://pytorch.org/examples/
	https://github.com/pytorch/examples 官方示例
文档 documentation https://pytorch.org/docs/stable/index.html
	https://pytorch.org/docs/master/notes/autograd.html
	https://pytorch.org/docs/stable/nn.html
	https://pytorch.org/docs/stable/optim.html
论坛：https://discuss.pytorch.org/


(3)网友教程：
https://github.com/chenyuntc/pytorch-book


《Pytorch深度学习实践》完结合集：代码完全讲解，循序渐进。
	https://www.bilibili.com/video/BV1Y7411d7Ys/?vd_source=826befc4ac0d0fa3b98deaa3efc7f800

* pytorch官方的60分钟入门pytorch和pytroch官方doc。然后20天吃透Pytorch。
强推这个20天吃透pytorch，深入浅出，把pytorch常用的知识都讲了，看完直接手鲁各类网络
https://www.pytorchmaster.com/




========================================
pytorch 入门教程 Tutorial
----------------------------------------
1. 安装
CentOS7.9, python3.10.14

glibc>=2.17
$ ldd --version
ldd (GNU libc) 2.17
$ ls -lth /usr/share/doc/glibc-*
/usr/share/doc/glibc-2.17:

$ nvidia-smi #Driver Version: 535.154.05   CUDA Version: 12.2

##sudo apt install python3-pip
$ pip3 install torch torchvision torchaudio



2. 入门教程目录
https://pytorch.org/tutorials/beginner/basics/intro.html

0. Quickstart #如果熟悉其他DL框架，从这里看
1. Tensors #如果没有基础，从这里看
2. Datasets and DataLoaders
3. Transforms
4. Build Model
5. Automatic Differentiation
6. Optimization Loop
7. Save, Load and Use Model


下载数据：@J3:/home/wangjl/data/web/docs/dataset
http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz
http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz
http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz
http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz


========================================
|-- 1. Tensors 张量
----------------------------------------
张量是和向量、矩阵类似的数据类型。
深度学习中，使用张量来编码输入、输出、参数。

张量类似Numpy的 ndarrays，但是张量能用GPU等硬件加速。
	张量和Numpy的array常常共用内存，能省略复制数据。
	张量能自动微分：见后续 自动求导 章节

1. 初始化张量
import torch
import numpy as np

(1) 从数组初始化
data = [[1, 2],[3, 4]]
x_data = torch.tensor(data)
x_data
输出：
tensor([[1, 2],
        [3, 4]])

(2) From a NumPy array
np_array = np.array(data)
x_np = torch.from_numpy(np_array)
x_np
输出同上。

(3) From another tensor
新张量保留老张量参数的特性（shape, datatype），除非特别指定。
例1：
x_ones = torch.ones_like(x_data) # retains the properties of x_data
print(f"Ones Tensor: \n {x_ones} \n")
输出：
Ones Tensor: 
 tensor([[1, 1],
        [1, 1]]) 

例2：明确指定数据类型：
x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data
print(f"Random Tensor: \n {x_rand} \n")
输出：
Random Tensor: 
 tensor([[0.2446, 0.5477],
        [0.5175, 0.0887]]) 


(4) With random or constant values 随机值/常数值
shape = (2,3,)
rand_tensor = torch.rand(shape)
ones_tensor = torch.ones(shape)
zeros_tensor = torch.zeros(shape)

print(f"Random Tensor: \n {rand_tensor} \n")
print(f"Ones Tensor: \n {ones_tensor} \n")
print(f"Zeros Tensor: \n {zeros_tensor}")
输出：
Random Tensor: 
 tensor([[0.6509, 0.2554, 0.8626],
        [0.2287, 0.1412, 0.0070]]) 

Ones Tensor: 
 tensor([[1., 1., 1.],
        [1., 1., 1.]]) 

Zeros Tensor: 
 tensor([[0., 0., 0.],
        [0., 0., 0.]])



2. 张量的性质： shape, datatype, and the device on which they are stored

tensor = torch.rand(3,4)

print(f"Shape of tensor: {tensor.shape}")
print(f"Datatype of tensor: {tensor.dtype}")
print(f"Device tensor is stored on: {tensor.device}")
输出：
Shape of tensor: torch.Size([3, 4])
Datatype of tensor: torch.float32
Device tensor is stored on: cpu
为什么是保存到CPU?




3. 张量的操作
100多种张量操作方法：https://pytorch.org/docs/stable/torch.html
	算术、线性代数、矩阵（转置/索引/切片）、取样等

每种操作可以在GPU运行（通常比CPU快）。
	如果使用Colab，菜单 Runtime > Change runtime type > GPU 分配一个GPU。

默认张量创建在CPU，需要明确移动到GPU，使用.to方法。
	需要提前检查GPU是否可用
	注意：在设备之间移动大型张量很耗费时间和内存！

(0) 移动到GPU
# We move our tensor to the GPU if available
if torch.cuda.is_available():
    tensor = tensor.to("cuda")
print(f"Device tensor is stored on: {tensor.device}")
输出：Device tensor is stored on: cuda:0

和 NumPy API 十分像。

(1) 标准索引和切片
torch.manual_seed(2024) #随机数种子
tensor = torch.rand(4, 2)
print(tensor)

print(f"First row: {tensor[0]}")
print(f"First column: {tensor[:, 0]}")
print(f"Last column: {tensor[..., -1]}")
tensor[:,1] = 0
print(tensor)

输出：
tensor([[0.5317, 0.8313],
        [0.9718, 0.1193],
        [0.1669, 0.3495],
        [0.2150, 0.6201]])
First row: tensor([0.5317, 0.8313])
First column: tensor([0.5317, 0.9718, 0.1669, 0.2150])
Last column: tensor([0.8313, 0.1193, 0.3495, 0.6201])
tensor([[0.5317, 0.0000],
        [0.9718, 0.0000],
        [0.1669, 0.0000],
        [0.2150, 0.0000]])
#


(2)合并张量
例1：dim=0 扩充第1个(0-based)维度
t0=torch.cat([tensor, tensor], dim=0)
print(tensor.shape)
print(t0.shape)
print(t0)
输出：
torch.Size([4, 2])
torch.Size([8, 2])
tensor([[0.5317, 0.0000],
        [0.9718, 0.0000],
        [0.1669, 0.0000],
        [0.2150, 0.0000],
        [0.5317, 0.0000],
        [0.9718, 0.0000],
        [0.1669, 0.0000],
        [0.2150, 0.0000]])


例2：dim=1 扩充第二个(0-based)维度
t1 = torch.cat([tensor, tensor, tensor], dim=1)
print(tensor.shape)
print(t1.shape)
print(t1)
输出：
torch.Size([4, 2])
torch.Size([4, 6])
tensor([[0.5317, 0.0000, 0.5317, 0.0000, 0.5317, 0.0000],
        [0.9718, 0.0000, 0.9718, 0.0000, 0.9718, 0.0000],
        [0.1669, 0.0000, 0.1669, 0.0000, 0.1669, 0.0000],
        [0.2150, 0.0000, 0.2150, 0.0000, 0.2150, 0.0000]])


(3) 算术操作：矩阵乘法
# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value
# ``tensor.T`` returns the transpose of a tensor
tensor=torch.tensor([[0, 1, 2], [3, 4, 5]])
print(tensor)
print(tensor.T) #求转置
y1 = tensor @ tensor.T #@表示矩阵乘法
print(y1)
输出：
tensor([[0, 1, 2],
        [3, 4, 5]])
tensor([[0, 3],
        [1, 4],
        [2, 5]])
tensor([[ 5, 14],
        [14, 50]])

矩阵乘法2：
y2 = tensor.matmul(tensor.T)
y2
输出：
tensor([[ 5, 14],
        [14, 50]])

矩阵乘法3：
#y3 = torch.rand_like(y1) #RuntimeError: "check_uniform_bounds" not implemented for 'Long'
y3 = torch.ones(y1.shape, dtype=torch.int64)
print(y3, y3.dtype)
torch.matmul(tensor, tensor.T, out=y3)
y3
输出：
tensor([[1, 1],
        [1, 1]]) torch.int64
tensor([[ 5, 14],
        [14, 50]])
#


(4) 算术操作：逐个元素相乘
# This computes the element-wise product. z1, z2, z3 will have the same value
tensor=torch.tensor([[0,1,2], [3,4,5]])
print(tensor, tensor.dtype)

z1 = tensor * tensor
print(z1)
z2 = tensor.mul(tensor)
print(z2)

#z3 = torch.rand_like(tensor) #RuntimeError: "check_uniform_bounds" not implemented for 'Long'
#z3 = torch.randint_like(tensor, dtype=torch.int64) #TypeError: randint_like() missing 1 required positional arguments: "high"
z3 = torch.ones(tensor.shape, dtype=torch.int64)
torch.mul(tensor, tensor, out=z3)
print(z3)

输出：
tensor([[0, 1, 2],
        [3, 4, 5]]) torch.int64
tensor([[ 0,  1,  4],
        [ 9, 16, 25]])
tensor([[ 0,  1,  4],
        [ 9, 16, 25]])
tensor([[ 0,  1,  4],
        [ 9, 16, 25]])


(5) 单元素张量
可以使用item()方法转化为Python数字类型。

tensor=torch.tensor([[0,1,2], [3,4,5]])
agg = tensor.sum()
print(agg, type(agg), agg.dtype)

agg_item = agg.item()
print(agg_item, type(agg_item))
输出：
tensor(15) <class 'torch.Tensor'> torch.int64
15 <class 'int'>



(6) 原位操作：有_后缀，会改变输入x值
x.copy_(y), x.t_(), will change x.

tensor=torch.tensor([[0,1,2], [3,4,5]])
print(f"{tensor} \n")
tensor.add_(5)
print(tensor)
输出：
tensor([[0, 1, 2],
        [3, 4, 5]]) 

tensor([[ 5,  6,  7],
        [ 8,  9, 10]])

注意：原位操作可节省一些内存，但是计算导数时会因为立刻失去历史损失而出问题。所以，不推荐使用。
In-place operations save some memory, but can be problematic when computing derivatives because of an immediate loss of history. Hence, their use is discouraged.







4. 与NumPy桥接
(1) Tensor to NumPy array
t = torch.ones(5)
print(f"t: {t}")
n = t.numpy()
print(f"n: {n}")
输出：
t: tensor([1., 1., 1., 1., 1.])
n: [1. 1. 1. 1. 1.]

# 修改是联动的
t.add_(1)
print(f"t: {t}")
print(f"n: {n}")
输出：
t: tensor([2., 2., 2., 2., 2.])
n: [2. 2. 2. 2. 2.]


(2) NumPy array to Tensor
n = np.ones(5)
t = torch.from_numpy(n)
print(n)
print(t)
输出：
[1. 1. 1. 1. 1.]
tensor([1., 1., 1., 1., 1.], dtype=torch.float64)

# 修改是联动的
np.add(n, 1, out=n)
print(f"t: {t}")
print(f"n: {n}")
输出：
t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)
n: [2. 2. 2. 2. 2.]












========================================
|-- 2. Datasets & DataLoaders 数据集
----------------------------------------
1. 提供两个数据基元

- torch.utils.data.DataLoader 
- torch.utils.data.Dataset

可以使用已有数据集，或者自己的数据集。

- Dataset 保存样本和标签
- DataLoader  包装Dataset为可迭代的，方便获取样本

PyTorch  提供了一些预加载的数据集（如 FashionMNIST），
- torch.utils.data.Dataset 实现了数据特异的函数。
可作为测试你的模型的原型或基准。包括
	Image Datasets,
	Text Datasets,
	Audio Datasets.



(2) Loading a Dataset
从 TorchVision 加载 Fashion-MINIST 数据
* 包含60,000 training examples and 10,000 test examples. 
* 每张图28*28灰图及对应的10个标签中的一个。

参数包括：
	root: 保存的路径
	train: 指定是训练集或测试集
	download=True 如果root没有数据，则从互联网下载
	transform 和 target_transform 指定特点和标签转换

import torch
from torch.utils.data import Dataset
from torchvision import datasets
from torchvision.transforms import ToTensor
import matplotlib.pyplot as plt


training_data = datasets.FashionMNIST(
    root="/home/wangjl/data/web/docs/dataset/",
    train=True,
    download=True,
    transform=ToTensor()
)

test_data = datasets.FashionMNIST(
    root="/home/wangjl/data/web/docs/dataset/",
    train=False,
    download=True,
    transform=ToTensor()
)

这不厚道啊，在我的目录下又开始下载，并保存到：/home/wangjl/data/web/docs/dataset/FashionMNIST/raw/
我暂停，移动数据到这里：
$ cd /home/wangjl/data/web/docs/dataset/
$ mv *gz FashionMNIST/raw/
加载后自动解压：
	$ ls -lth FashionMNIST/raw/
	total 82M
	-rw-r--r--. 1 wangjl jinlab 9.8K Jul  5  2024 t10k-labels-idx1-ubyte
	-rw-r--r--. 1 wangjl jinlab 7.5M Jul  5  2024 t10k-images-idx3-ubyte
	-rw-r--r--. 1 wangjl jinlab  59K Jul  5  2024 train-labels-idx1-ubyte
	-rw-r--r--. 1 wangjl jinlab  45M Jul  5  2024 train-images-idx3-ubyte
	-rw-r--r--. 1 wangjl jinlab 5.1K Aug 31  2017 t10k-labels-idx1-ubyte.gz
	-rw-r--r--. 1 wangjl jinlab 4.3M Aug 31  2017 t10k-images-idx3-ubyte.gz
	-rw-r--r--. 1 wangjl jinlab  29K Aug 31  2017 train-labels-idx1-ubyte.gz
	-rw-r--r--. 1 wangjl jinlab  26M Aug 31  2017 train-images-idx3-ubyte.gz


(3) Iterating and Visualizing the Dataset
遍历和可视化数据

可以像list一样索引 Datasets: training_data[index]
使用 matplotlib 可视化训练集中的一些样本。

labels_map = {
    0: "T-Shirt",
    1: "Trouser",
    2: "Pullover",
    3: "Dress",
    4: "Coat",
    5: "Sandal",
    6: "Shirt",
    7: "Sneaker",
    8: "Bag",
    9: "Ankle Boot",
}
torch.manual_seed(2024) #随机数种子
figure = plt.figure(figsize=(8, 8))
cols, rows = 3, 3
for i in range(1, cols * rows + 1):
    sample_idx = torch.randint(len(training_data), size=(1,)).item()
    img, label = training_data[sample_idx]
    figure.add_subplot(rows, cols, i)
    plt.title(labels_map[label])
    plt.axis("off")
    plt.imshow(img.squeeze(), cmap="gray")
plt.show()



(4) Creating a Custom Dataset for your files | 创建自定义数据集
- 需要实现三个函数： __init__, __len__, and __getitem__. 查看怎么实现。
- FashionMNIST 图片保存在目录 img_dir 中，标签保存在独立的csv文件 annotations_file 中。

略，需要了再回来学习：https://pytorch.org/tutorials/beginner/basics/data_tutorial.html


(5) 使用 DataLoaders 准备训练数据
Dataset 一次获取一个样本。
但是训练时，我们通常需要一个“小批次”，每个循环中重排列数据来降低过拟合，使用python multiprocessing 并行加速。
* DataLoader 是一个可迭代的好用的API。

from torch.utils.data import DataLoader

train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)
test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)


(6) Iterate through the DataLoader | 通过DataLoader遍历
以下每次迭代返回一批 训练特征 和 训练标签(batch_size=64)
指定shuffle=True，表示遍历一次打乱一次。

# Display image and label.
train_features, train_labels = next(iter(train_dataloader))
print(f"Feature batch shape: {train_features.size()}")
print(f"Labels batch shape: {train_labels.size()}")
img = train_features[0].squeeze()
label = train_labels[0]
plt.imshow(img, cmap="gray")
plt.show()
print(f"Label: {label}")







========================================
|-- 3. Transforms | 变换
----------------------------------------
1. 为了方便训练

TorchVision 数据集接收2个参数
* transform 修改特征
* target_transform 修改标签
可调用的变换逻辑。
torchvision.transforms 模块提供几个常用转换。

FashionMNIST 特征是PIL图像格式，标签是整数。
训练时，我们需要特征是标准化的张量，标签是one-hot编码的张量。
可分别使用 ToTensor 和 Lambda 转换。


import torch
from torchvision import datasets
from torchvision.transforms import ToTensor, Lambda

ds = datasets.FashionMNIST(
    root="data",
    train=True,
    download=True,
    transform=ToTensor(),
    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))
)


(1) ToTensor()
PIL图像或者Numpy ndarray 转化为 FloatTensor。
并把图像的像素值scale到[0.,1.]之间。


(2) Lambda Transforms
自定义，把整数转为 one-hot 编码的张量。
- 先创建一个长度为10的张量，填充0
- 使用 scatter_ 函数，沿着第一个维度，在位置为 整数y 的地方赋值value=1

target_transform = Lambda(lambda y: torch.zeros(
    10, dtype=torch.float).scatter_(dim=0, index=torch.tensor(y), value=1))











========================================
|-- 4. Build the Neural Network | 构建神经网络
----------------------------------------
torch.nn 命名空间体提供了建立神经网络的所有模块。
每个模型都是 nn.Module 的子类。
一个网络本身也是其他网络（层）组成的。
他们嵌套的结构可以让我们很容易构建和管理复杂网络。

接下来，我们将构建神经网络，来对 FashionMNIST 数据集中的图像分类。

import os
import torch
from torch import nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

1. 显示用于训练的设备
device = (
    "cuda"
    if torch.cuda.is_available()
    else "mps"
    if torch.backends.mps.is_available()
    else "cpu"
)
print(f"Using {device} device")
输出：Using cuda device



2. 定义类
通过定义nn.Module的子类定义网络，使用 __init__ 初始化网络。
每个nn.Module子类实现 forward 方法，来对输入进行操作。


class NeuralNetwork(nn.Module):
    def __init__(self):
        super().__init__() #父类初始化
        self.flatten = nn.Flatten() #定义 flatten() 方法
        self.linear_relu_stack = nn.Sequential( #定义线性rela堆栈
            nn.Linear(28*28, 512), #线性层
            nn.ReLU(), #激活函数
            nn.Linear(512, 512), #线性层
            nn.ReLU(), #激活函数
            nn.Linear(512, 10), #线性层
        )

    def forward(self, x):
        x = self.flatten(x) #拉直成一维
        logits = self.linear_relu_stack(x) #线性层——激活函数，返回对每个分类的预测输出值
        return logits

创建NeuralNetwork 实例，转移给设备，并打印其结构：
model = NeuralNetwork().to(device)
print(model)

输出：
NeuralNetwork(
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (linear_relu_stack): Sequential(
    (0): Linear(in_features=784, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=10, bias=True)
  )
)

传入输入数据，使用该网络。这会执行模型的 forward 方法，及一些后台操作。
	不要直接调用 model.forward() !

对输入数据调用模型，返回一个2d张量，
	dim=0 对应于每个类的10个原始预测值的每个输出
	dim=1 对应于每个输出的单个值。
传入 nn.Softmax 模块获取预测概率。

X = torch.rand(1, 28, 28, device=device) #产生随机值
X.shape #torch.Size([1, 28, 28])

logits = model(X) #输入带入模型，产生的2d数组
logits.shape # torch.Size([1, 10])
logits       #只有一行（一个输入），10列，分别是10个分类的预测结果
#tensor([[ 0.0165,  0.0821,  0.0702, -0.0124, -0.0013, -0.1004, -0.0866,  0.0282,
#          0.0012, -0.0624]], device='cuda:0', grad_fn=<AddmmBackward0>)

pred_probab = nn.Softmax(dim=1)(logits)
pred_probab.shape #torch.Size([1, 10])
pred_probab      #一行的10个预测做softmax，转为正数[0,1]之间，类似概率
#tensor([[0.1022, 0.1091, 0.1078, 0.0992, 0.1004, 0.0909, 0.0921, 0.1034, 0.1006,
#         0.0944]], device='cuda:0', grad_fn=<SoftmaxBackward0>)

y_pred = pred_probab.argmax(1)
print(y_pred.shape) # torch.Size([1])
y_pred    #tensor([1], device='cuda:0')

print(f"Predicted class: {y_pred}") 
#Predicted class: tensor([1], device='cuda:0')






3. 模型层 Model Layers
逐步解析。取3个图像28*28，看怎么通过网络的。

input_image = torch.rand(3,28,28)
print(input_image.size())  #输出 torch.Size([3, 28, 28])


(1) nn.Flatten
二维图片28*28变一维784像素（dim=0是每批次图片个数，保持不变）

flatten = nn.Flatten()
flat_image = flatten(input_image)
print(flat_image.size()) #torch.Size([3, 784])
flat_image.shape


(2) nn.Linear 全连接层/线性层
使用保存好的权重和偏差，对输入做线性变换。

layer1 = nn.Linear(in_features=28*28, out_features=20)
hidden1 = layer1(flat_image)
print(hidden1.size()) #torch.Size([3, 20])


(3) nn.ReLU 激活函数
非线性激活函数，能在输入和输出之间创建复杂的映射关系。
线性转换后，引入非线性变换，帮助网络学习更广泛的现象。

本模型中，在线性层之间引入 nn.RuLU，还有其他可引入非线性的激活函数。


(4) nn.Sequential 序列容器
数据依次通过模块，按定义的顺序。
可以通过顺序容器快速构建网络：

seq_modules = nn.Sequential(
    flatten,
    layer1,
    nn.ReLU(),
    nn.Linear(20, 10)
)
input_image = torch.rand(3,28,28)
logits = seq_modules(input_image)



(5) nn.Softmax
网络的最后一个线性层返回 logits ，范围是(-无穷大，+无穷大)。
输入 nn.Softmax 模块返回[0,1]之间的数字，可以认为是预测概率。
dim参数规定了沿着哪个方向的和必须是1。






4. Model Parameters | 模型参数
网络内部的层必须是参数化的，比如相关权重，偏移量必须在训练中优化。
nn.Module 子类自动记录定义在模型中的所有域，并可以访问所有参数，通过函数
* parameters() 或 
* named_parameters()

本例子中，我们迭代每个参数，打印出它的大小并预览值：

print(f"Model structure: {model}\n\n")

for name, param in model.named_parameters():
    print(f"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \n")


输出如下：
Model structure: NeuralNetwork(
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (linear_relu_stack): Sequential(
    (0): Linear(in_features=784, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=10, bias=True)
  )
) #模型的结构：每一层

Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[ 0.0146,  0.0305, -0.0067,  ..., -0.0118,  0.0252, -0.0148],
        [ 0.0162,  0.0353, -0.0315,  ..., -0.0200, -0.0331, -0.0067]],
       device='cuda:0', grad_fn=<SliceBackward0>) #第0层的权重矩阵，W1*A=C

Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([-0.0233,  0.0199], device='cuda:0', grad_fn=<SliceBackward0>) #第0层的偏差，什么意思？W1*A + B = C，这个常量B。相当于线性拟合的截距。但为什么是2个数？

Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0057,  0.0159,  0.0064,  ...,  0.0063, -0.0018,  0.0304],
        [ 0.0387, -0.0214,  0.0170,  ...,  0.0045, -0.0051,  0.0139]],
       device='cuda:0', grad_fn=<SliceBackward0>)  #第2个线性层 权重矩阵

Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([-0.0232,  0.0441], device='cuda:0', grad_fn=<SliceBackward0>) #第2个线性层 偏差

Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[ 0.0370,  0.0175, -0.0114,  ...,  0.0269, -0.0377, -0.0422],
        [ 0.0113, -0.0166,  0.0265,  ...,  0.0039, -0.0038,  0.0031]],
       device='cuda:0', grad_fn=<SliceBackward0>)  #第3个线性层 权重矩阵

Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([0.0042, 0.0251], device='cuda:0', grad_fn=<SliceBackward0>) #第3个线性层 偏差


========================================
|-- --浅谈神经网络中的bias
----------------------------------------
1、什么是bias？

偏置单元（bias unit），在有些资料里也称为偏置项（bias term）或者截距项（intercept term），它其实就是函数的截距，与线性方程 y=wx+b 中的 b 的意义是一致的。在 y=wx+b中，b表示函数在y轴上的截距，控制着函数偏离原点的距离，其实在神经网络中的偏置单元也是类似的作用。 
因此，神经网络的参数也可以表示为：(W, b)，其中W表示参数矩阵，b表示偏置项或截距项。




2.bias的计算方式？
神经网络结构中对偏置单元的计算处理方式有两种， 
(1) 略 非主流

(2) 设置偏置单元，不在参数矩阵中设置对应偏置单元的参数，对应的神经网络如下： 
输入 [x1,x2,x3]T 添加常数项 [b1, x1,x2,x3]T

其中，b(1) 是 W(1) 对应的偏置单元向量，b(2) 是 W(2) 对应的偏置单元向量，b(1)1 是对应 a(2)1 的偏置单元。注意，此时神经网络的参数表示更改为：(W, b) 
* 在计算激活值时按照： 
激活值计算公式 a2=g(W1*x1 + w2*x2 + w3*x3 + b1)

相当于bias连接各个神经元的所有权重都为1，但bias本身不为1，即---有多个bias，但所有的bias对应的权重都为1（bias的个数等于hide层和out层神经元的个数）


综上， 
　两者的原理是一致的，只是具体的实现方式不同。 
　其实在大部分资料和论文中看到的神经网络的参数都是表示为：(W, b)，其中W代表weight，b代表bias。包括在UFLDL Tutorial中也是采用 (W, b) 表示，只是在Coursera上Andrew Ng老师的在线教程中看到将神经网络参数表示为 Θ，个人还是更喜欢 (W, b) 这种表示，很清晰。



3. 我的理解
[good] https://blog.csdn.net/zxyhhjs2017/article/details/94638904

(1) 猜测1：错
类比简单线性分类 y=ax+b，如果分别对(x,y)做偏置，得到 (y-y') = a(x-x') + b
矛盾：这三个常量了，x',y',b

(2) 猜测2：难道是 内外都有？错
激活函数 a2=g(W*A + b1) +b2
这样解释至少是2个常量了，和输出参数的  tensor([0.0042, 0.0251] 比较匹配。

Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([0.0042, 0.0251], device='cuda:0', grad_fn=<SliceBackward0>) #第3个线性层 偏差

(3) 其实就是一个输入对应一个偏置
该模型被应用到的数据X是2条数据，所以对应2个偏置。
	A.W+B=C 其中A/B/C都是行向量。A一行表示一个输入，2行表示2个输入。


Ref: 
https://www.cnblogs.com/shuaishuaidefeizhu/p/6832541.html




========================================
|-- 激活函数: relu, sigmoid 等
----------------------------------------
ReLU 性能快，效果好，现在常用。




Ref:
8.1 http://staff.ustc.edu.cn/~lgliu/Resources/DL/What_is_DeepLearning.html






========================================
|-- 5. Automatic Differentiation with torch.autograd | 自动微分/求导
----------------------------------------
训练网络，最常用的 反向传播。
本算法中，参数根据损失函数的梯度进行调整。

为了计算梯度，PyTorch 内建了求导数的引擎 torch.autograd，它支持根据计算图，自动计算梯度。

考虑到最简单的单层网络，输入x，参数是(w,b)，和一些损失函数。
可以在 PyTorch 中如下定义：

import torch

x = torch.ones(5)  # input tensor
y = torch.zeros(3)  # expected output
w = torch.randn(5, 3, requires_grad=True)
b = torch.randn(3, requires_grad=True)
z = torch.matmul(x, w)+b
loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)


(2) Tensors, Functions and Computational graph | 张量、方程、计算图
以上代码定义的计算图如下：

X->*->+->Z->CE->loss
   ↑  ↑      ↑
   w  b      y
其中参数是(W, b)，需要被优化。
需要根据变量计算损失函数的梯度。为此，设置这些张量的 requires_grad 性质。
- 可以创建张量时设置 requires_grad 
- 或之后使用 x.requires_grad_(True)方法

我们对张量使用的求导函数实际上是Function类的一个对象。
该对象知道怎么计算 forward 的方向，在后向传播步骤中怎么计算它的导数。
后向传播函数的一个指针保存在张量的grad_fn 属性中。
关于 Function 的更多文档：https://pytorch.org/docs/stable/autograd.html#function


print(f"Gradient function for z = {z.grad_fn}")
print(f"Gradient function for loss = {loss.grad_fn}")
输出：
Gradient function for z = <AddBackward0 object at 0x7fc6d169b520>
Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward0 object at 0x7fc6d169b370>



(3) Computing Gradients | 计算梯度
为了优化神经网络中的权重，需要计算对应参数下的损失函数的导数，
比如，我们需要在固定值x和y下，求偏导(loss)/偏导(w) 和 偏导(loss)/偏导(b)。
为计算这些导数，我们可以调用 loss.backward()，然后通过 w.grad 和 b.grad 求值。

loss.backward()
print(w.grad)
print(b.grad)

输出：
tensor([[0.1455, 0.1161, 0.2127],
        [0.1455, 0.1161, 0.2127],
        [0.1455, 0.1161, 0.2127],
        [0.1455, 0.1161, 0.2127],
        [0.1455, 0.1161, 0.2127]])
tensor([0.1455, 0.1161, 0.2127])

注意：
* 计算图的requires_grad =True，其子节点的 grad 才能访问。
	其他节点，梯度不可用。
* 性能角度，对于给定图，进行 微积分梯度的 backward 只能调用一次，
	对于同一个图需要调用多个backward 方法，我们需要 retain_graph=True 传递给 backward 调用。


(4) Disabling Gradient Tracking | 停止梯度追踪

默认，设置requires_grad=True的张量是记录它们的计算历史的，支持梯度计算。
然而，有些情况我们无需这样做，比如，已经训练过模型，仅仅是应用到一些输入数据上，比如，我们希望数据在网络上前向传播。
通过 torch.no_grad() 块包含代码，我们可以停止计算梯度。

z = torch.matmul(x, w)+b
print(z.requires_grad)

with torch.no_grad():
    z = torch.matmul(x, w)+b
print(z.requires_grad)
输出：
True
False


另一种方式，是在张量上使用 detach() 方法。
z = torch.matmul(x, w)+b
z_det = z.detach()
print(z_det.requires_grad) #False


停止梯度追踪的理由：
* 网络一些参数设为固定参数( frozen parameters)
* 仅前向传播，为了加速


(5) More on Computational Graphs | 计算图的更多知识
有向无环图 directed acyclic graph (DAG) 

概念上，自动求导记录数据（张量）和执行的操作（及产生的新张量）到一个DAG中。

在这个DAG中，叶子是输入的张量，根是输出张量。
从根追踪到叶子，可以使用链式规则求导。

在前向传递中，自动求导同时做了两件事：
- 按请求操作计算结果张量
- 在DAG中维护操作的梯度函数

反向传递开始时，DAG根节点调用.backward，然后是 autograd：
- 从每个 .grad_fn 计算梯度
- 在张量的.grad属性中累加这些
- 使用链式规则，一路传播到叶子张量

注意：
PyTorch中的DAG是动态的。图是从头生成的；每次调用 .backward() 方法，自动求导开始构建新的图。
这允许在模型中使用流程控制语句；如需要，可在每次迭代中改变shape, size 和操作符。



(6) Optional Reading: Tensor Gradients and Jacobian Products
可选：张量梯度和 雅可比乘积

很多时候，我们有一个常量损失函数，而且我们需要在一些参数下计算梯度。
然而，有些情况下，输出函数是一个任意张量。
这种情况下，PyTorch 允许计算 雅可比乘积，而不是真正的梯度。

略。https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html






========================================
|-- 6. Optimizing Model Parameters | 优化模型参数：损失函数/ 随机梯度下降
----------------------------------------
现在已有数据和模型，可以根据数据，通过优化参数，开始训练、验证和检验我们的模型了。

训练模型是一个迭代的过程，每次迭代，对结果做以此猜测，计算猜测的误差（损失），针对每个参数收集微分，使用梯度下降优化参数。
更细节的描述看视频：https://www.youtube.com/watch?v=tIeHLnjs5U8

1. 前置代码：载入数据，建立模型
import torch
from torch import nn
from torch.utils.data import DataLoader
from torchvision import datasets
from torchvision.transforms import ToTensor

training_data = datasets.FashionMNIST(
    root="data",
    train=True,
    download=True,
    transform=ToTensor()
)

test_data = datasets.FashionMNIST(
    root="data",
    train=False,
    download=True,
    transform=ToTensor()
)

train_dataloader = DataLoader(training_data, batch_size=64)
test_dataloader = DataLoader(test_data, batch_size=64)

class NeuralNetwork(nn.Module):
    def __init__(self):
        super().__init__()
        self.flatten = nn.Flatten()
        self.linear_relu_stack = nn.Sequential(
            nn.Linear(28*28, 512),
            nn.ReLU(),
            nn.Linear(512, 512),
            nn.ReLU(),
            nn.Linear(512, 10),
        )

    def forward(self, x):
        x = self.flatten(x)
        logits = self.linear_relu_stack(x)
        return logits

model = NeuralNetwork()



2. Hyperparameters | 超参数
超参数是可调节的控制模型处理的参数。
不同的超参数会影响模型的收敛性，超参数怎么调节：https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html

训练的超参数：
* Number of Epochs：数据集迭代次数
* Batch Size 批次：每次传播多少个样本，然后再进行参数更新
* Learning Rate：学习效率，每次更新模型多少，越小收敛越慢，越大容易出现振荡。

learning_rate = 1e-3
batch_size = 64
epochs = 5





3. Optimization Loop | 优化循环
一旦设置超参数，我们训练和优化模型，使用一个优化的循环。每个迭代循环叫一个 epoch.

每个 epoch 包含2个部分：
* 训练loop: 在训练集迭代，在最优参数上尝试收敛
* The Validation/Test Loop：在测试集上检查模型性能是否提升。

简要熟悉一下训练循环中的一些概念：https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html#full-impl-label

(1) 损失函数
衡量预测值和真实值差异的函数。训练中就是要优化到损失函数最小化。
为计算损失函数，根据输入样本计算预测值，并和真实值标签比较。

常用损失函数包含：
* nn.MSELoss(Mean Square Erro，均方误差)：https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss，用于回归任务

* nn.NLLLoss (Negative Log Likelihood，负对数似然)：用于分类任务
* nn.CrossEntropyLoss：交叉熵合并了 nn.LogSoftmax 和 nn.NLLLoss.

模型输出的 logits 值传给 nn.CrossEntropyLoss，会标准化 logits 值，计算预测误差：

# Initialize the loss function
loss_fn = nn.CrossEntropyLoss()



(2) Optimizer 优化器
每个训练步骤中通过调整参数，降低误差，就叫优化。
优化算法：定义该过程怎么实施（本例子使用 随机梯度下降 Stochastic Gradient Descent）。

所有的优化逻辑包裹在 optimizer 对象中。
这里使用 SGD 优化器。
另外，PyTorch可用的优化器包括 ADAM and RMSProp，对不同的数据和模型表现可能更好：https://pytorch.org/docs/stable/optim.html

通过注册模型参数、传入学习率超参数来初始化优化器。

optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)
optimizer
输出：
SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    momentum: 0
    nesterov: False
    weight_decay: 0
)

在训练循环中，优化分为三步骤：
1) 调用 optimizer.zero_grad() 重置模型参数的梯度。梯度默认是累加的；为防止重复技术，我们在每个循环中明确指定0。
2) 调用 loss.backward() 向后传播 预测损失。PyTorch将损失的梯度与每个参数关联起来(?)。
3) 有梯度后，调用 optimizer.step() 通过在后向传播中收集的梯度，来调整参数。





4. 完整实现
定义train_loop 函数来循环优化代码，test_loop 用测试数据检查模型性能。

def train_loop(dataloader, model, loss_fn, optimizer):
    size = len(dataloader.dataset)
    # Set the model to training mode - important for batch normalization and dropout layers
    # Unnecessary in this situation but added for best practices
    model.train()
    for batch, (X, y) in enumerate(dataloader):
        # Compute prediction and loss
        pred = model(X)
        loss = loss_fn(pred, y)

        # Backpropagation
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()

        if batch % 100 == 0:
            loss, current = loss.item(), batch * batch_size + len(X)
            print(f"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]")


def test_loop(dataloader, model, loss_fn):
    # Set the model to evaluation mode - important for batch normalization and dropout layers
    # Unnecessary in this situation but added for best practices
    model.eval()
    size = len(dataloader.dataset)
    num_batches = len(dataloader)
    test_loss, correct = 0, 0

    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode
    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True
    with torch.no_grad():
        for X, y in dataloader:
            pred = model(X)
            test_loss += loss_fn(pred, y).item()
            correct += (pred.argmax(1) == y).type(torch.float).sum().item()

    test_loss /= num_batches
    correct /= size
    print(f"Test Error: \n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \n")


初始化损失函数和优化器，传入到 train_loop 和 test_loop。
可自由增加 epoch 数量，记录模型提升的性能。

loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)

epochs = 10
for t in range(epochs):
    print(f"Epoch {t+1}\n-------------------------------")
    train_loop(train_dataloader, model, loss_fn, optimizer)
    test_loop(test_dataloader, model, loss_fn)
print("Done!")



========================================
|-- 7. Save and Load the Model | 保存和载入模型
----------------------------------------
怎么持久化模型呢？保存、载入、运行。

import torch
import torchvision.models as models

1. Saving and Loading Model Weights | 保存和载入模型的权重

(1) 保存权重
PyTorch模型把学习的参数保存在内部状态字典中，叫做 state_dict
可通过 torch.save 方法持久化。

model = models.vgg16(weights='IMAGENET1K_V1')
torch.save(model.state_dict(), 'model_weights.pth')
解释：第一行下载模型，并保存到变量中。第二行保存模型权重到本地文件。

# 实战：save model params
torch.save(model.state_dict(), '/home/wangjl/data/web/docs/dataset/model_weights.pth')

(2) 加载模型
需要创建一个同样的模型，然后使用 load_state_dict() 加载参数。

model3 = models.vgg16() # we do not specify ``weights``, i.e. create untrained model
model3.load_state_dict(torch.load('/home/wangjl/data/web/docs/dataset/model_weights.pth'))
model3.eval()

输出如下：
VGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (6): ReLU(inplace=True)
    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): ReLU(inplace=True)
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): ReLU(inplace=True)
    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): ReLU(inplace=True)
    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): ReLU(inplace=True)
    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (20): ReLU(inplace=True)
    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): ReLU(inplace=True)
    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (27): ReLU(inplace=True)
    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (29): ReLU(inplace=True)
    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): ReLU(inplace=True)
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): ReLU(inplace=True)
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=4096, out_features=1000, bias=True)
  )
)

注意：
一定要在推理之前调用model.eval()方法，将dropout层和批处理归一化层设置为求值模式。如果不这样做，将产生不一致的推理结果。





2. Saving and Loading Models with Shapes | 连带形状保存和加载模型

加载模型前，需要先实例化模型类，因为该模型类定义了网络的结构。
我们也可以保存网络参数+结构:

# 保存时使用 model，而不是 model.state_dict()
torch.save(model, 'model.pth')

# 加载：
model = torch.load('model.pth')

注意：
这种方法在序列化模型时使用Python pickle模块，因此它依赖于加载模型时可用的实际类定义。






========================================
|-- 8.PyTorch Custom Operators Landing Page | PyTorch 自定义操作符登录页
----------------------------------------
PyTorch 提供了很多对张量的操作符(torch.add, torch.sum 等)。
然而，也可以自定义操作符，且能和其他子系统(torch.compile, autograd, and torch.vmap)协同。
为此，注册自定义操作符需要使用 
* torch.library docs: https://pytorch.org/docs/stable/library.html
* 或者 C++ TORCH_LIBRARY APIs.

略




========================================
----------------------------------------




========================================
----------------------------------------



========================================
----------------------------------------


========================================
----------------------------------------




========================================
----------------------------------------



========================================
----------------------------------------


========================================
----------------------------------------


