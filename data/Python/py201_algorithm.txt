数据结构与算法

这里主要是python版本的
还有一个c版本的: C/数据结构与算法




推荐: 《数据结构与算法之美》的学习笔记和python代码实现
https://github.com/xiao-xiaoming/DataStructure-BeautyOfAlgorithm


算法图解(py2.7 -> 我改为了 py3.7): 
	www.manning.com/books/grokking-algorithms
	https://github.com/egonschiele/grokking_algorithms
	https://blog.51cto.com/u_15334850/3502082 可以考虑其他语言实现

  * 1 算法简介: 二分查找，大O表示法
  * 2 选择排序
  * 3 递归
  * 4 快速排序
  * 5 散列表
  * 6 广度优先搜索: 图简介，最短路径，队列
  * 7 迪克斯特拉算法
  * 8 贪婪算法
  * 9 动态规划 
  * 10 K最近邻算法
  * 11 接下来如何做: 10种算法
	树
	反向索引
	傅里叶变换
	并行算法
	MapReduce
	布隆过滤器和 HyperLogLog 
	SHA 算法 
	据不敏感的散列算法
	Diffie-Hellman 密钥交换
	线性规划



https://www.khanacademy.org/  更多算法。

数据结构 可视化 https://www.cs.usfca.edu/~galles/visualization/Algorithms.html





========================================
常用的算法
----------------------------------------

1. 数据结构
数组
链表
栈
跳表
图
Trie树



2. 排序
二分查找
搜索
哈希算法
贪心算法
分治算法
回溯算法
动态规划
字符串匹配算法

递归





========================================
二分查找，递归，大O表示法
----------------------------------------
1. 二分查找
必须是有序元素列表，如果要查找的元素存在，则返回其下标序号，如果不存在，则返回 null.

使用二分查找，每次排除一半数字。
所以1-100的数字，二分查找总能够在_步以内找到答案？ 答案是7步。

对于包含n个元素的列表，
	简单查找最多需要 n 步；大O表示就是 O(n) ，称作线性时间。
	而二分查找最多需要 log2(n) 步；大O表示就是 O(log n)，称作对数时间。

大O表示法的log是指的 log2.



(2) py算法
随机生成一个1-100的数字，用户猜测后给出大了、小了、对三种回复。正确则回复下标，错误则回复-1.

函数接收一列排序后的数字，和一个数字。

# 二分法查找
import math

def binary_search(sorted_arr, num, debug=False):
    low=0
    high=len(sorted_arr)-1
    mid= math.floor( (low+high)/2 )
    #
    while low<=high:
        mid= math.floor( (low+high)/2 )
        guess=sorted_arr[mid]
        if debug:
            print(low, mid, high)
        if guess==num:
            return mid;
        elif guess>num:
            high=mid-1
        else:
            low=mid+1
    return -1

arr1=[1,3,5,6,7]
print(binary_search(arr1, 50))
print(binary_search(arr1, 0))
print(binary_search(arr1, 7))
print(binary_search(arr1, 6, 0))
#print(binary_search(arr1, 6, True))






2. 大O表示法 算法的时间增速

(1)
大O表示法让你能够比较操作数，它指出了算法运行时间的增速。

大O 表示法指出了最糟情况下的运行时间

   算法的速度指的并非时间，而是操作数的增速。
   谈论算法的速度时，我们说的是随着输入的增加，其运行时间将以什么样的速度增加。
   算法的运行时间用大O表示法表示。
   O(log n)比O(n)快，当需要搜索的元素越多时，前者比后者快得越多。



(2) 一些常见的大O 运行时间
下面按从快到慢的顺序列出了你经常会遇到的5种大O运行时间。
  * O(log n)，也叫对数时间，这样的算法包括二分查找。
  * O(n)，也叫线性时间，这样的算法包括简单查找。
  * O(n * log n)，这样的算法包括第4章将介绍的快速排序——一种速度较快的排序算法。
  * O(n2)，这样的算法包括第2章将介绍的选择排序——一种速度较慢的排序算法。
  * O(n!)，这样的算法包括接下来将介绍的旅行商问题的解决方案——一种非常慢的算法。





3. 旅行商 问题 O(n!)

某人要去5个城市，同时要确保旅程最短。
需要穷举各种前往的顺序，计算每次的总路程，从而挑选最短路程的方案。
5个城市，需要穷举 5! =120 个方案。
6个城市，6!=720 个方案。
7个城市，7!=5040 个方案。






小结
  * 二分查找的速度比简单查找快得多。
  * O(log n)比O(n)快。需要搜索的元素越多，前者比后者就快得越多。
  * 算法运行时间并不以秒为单位。
  * 算法运行时间是从其增速的角度度量的。
  * 算法运行时间用大O表示法表示。



========================================
选择排序：数组和链表
----------------------------------------

排序后才能进行二分查找。
选择排序时下一节的 快速排序 的基石，而 快速排序 又是一种重要的算法。


1. 内存

内存可以看做很多抽屉，你有钥匙(地址)，就可以在对应的抽屉放东西。

fe0ffeeb是一个内存单元的地址。

存一个时，请求一个地址。
存多个时，可以使用 数组和链表。



2. 数组和链表

数组占用连续的空间。
	知道第一个元素的地址，可以算出来任何一个元素的地址。这就是说的数组支持随机访问。

链表占用空间不要求必须连续。
	链表必须同时保存数据和下一个元素的地址。就像一个寻宝游戏。
	链表不能直接读取最后一个元素，只能一个一个找到最后一个的地址，然后读取其中的元素。
	如果需要跳跃，链表的效率很低。

--     数组 | 链表
读取  O(1)  |  O(n)
插入  O(n)  |  O(1)
删除  O(n)  |  O(1)

其中 O(n) = 线性时间，O(1) = 常量时间。
我对链表删除时间 O(1) 持怀疑态度，他还需要查找地址的时间呢，既然是最坏的情况。 //todo


前面解释了读取。这里说一下插入新值。
插入一个元素时，数组需要把后面所有元素向后移动，而链表只需要修改前面一个元素指向的地址。
如果连续的空间不够，数组还需要把所有元素复制到其他地方。

删除元素时，链表同样比数组快。





3. 选择排序 
(1) 过程
有一些歌曲和其播放次数的数据，想按照播放次数对歌曲排序。
先挑选播放最多的，抽出来。 O(n)
然后再挑选最多的，抽出来。 O(n-1)
...
也就是需要执行 n次。
1+2+...+n=n(n+1)/2, 只记录幂次最高的，并忽略常数项系数，即O(n^2)，或者 O(n × n)。


选择排序是一种灵巧的算法，但其速度不是很快。
快速排序是一种更快的排序算法，其运行时间为O(n log n)，这将在下一章介绍。


数组的 pop 元素能按下标移除数组中的该元素，并返回该值。
arr=[20,1,6,100,5]
rs1=arr.pop(1)
print(rs1)
print(arr)
输出:
1
[20, 6, 100, 5]


参考实现
# 选择排序

arr=[20,1,6,100,5]

# 返回最小元素的下标
def findSmallest(arr):
    small=arr[0]
    index=0
    for i in range( len(arr)):
        if small> arr[i]:
            small=arr[i]
            index=i;
    return index

# use this function in sorting
def searchSort(arr):
    arr2=[]
    for i in range( len(arr) ):
        print(i, arr2)
        smallest=findSmallest(arr)
        arr2.append(arr.pop(smallest))
    return arr2;

print(arr)
arr2=searchSort(arr)
print(arr2)






小结
  * 计算机内存犹如一大堆抽屉。
  * 需要存储多个元素时，可使用数组或链表。
  * 数组的元素都在一起。
  * 链表的元素是分开的，其中每个元素都存储了下一个元素的地址。
  * 数组的读取速度很快。
  * 链表的插入和删除速度很快。
  * 在同一个数组中，所有元素的类型都必须相同（都为int、double等）。






排序算法: https://www.runoob.com/w3cnote_genre/algorithm









========================================
递归
----------------------------------------

1. 递归不能死循环
要有结束条件。



2. 调用栈 call stack

栈，只有两种操作: 压入(插入到顶端)和弹出(从顶端读取并删除)。

这个存储多个函数的变量，被称为 调用栈。


(1) 递归实现
def fact(x):
    if x<=1:
        return 1;
    else:
        if debug:
            print(x)
        return x*fact(x-1)

debug=True
x=fact(5)
print(x)

# 输出
5
4
3
2
120

注意，每个fact调用都有自己的x变量。在一个函数调用中不能访问另一个的x变量。


(2) 递归很长占用大量内存怎么办？
两种方案可以选择，改写为
	循环
	尾递归 //todo


小结
  * 递归指的是调用自己的函数。
  * 每个递归函数都有两个条件：基线条件和递归条件。
  * 栈有两种操作：压入和弹出。
  * 所有函数调用都进入调用栈。
  * 调用栈可能很长，这将占用大量的内存。




========================================
快速排序：使用 分而治之 (divide and conquer，D&C) 的策略
----------------------------------------

1. 分而治之 是 一种著名的递归式问题解决方法。

面对新问题时，你不再束手无策，而是自问：“使用分而治之能解决吗？”
D&C并非可用于解决问题的算法，而是一种解决问题的思路。


使用三个问题引入


(1) 问题: 把大小为 168*64 的地分成均匀的方块，且分出的方块尽可能的大。

- 分成 168*64 是方块，但是每个方块太小了。
- 一分为二，不是方块不行。
- 每块大小不同也不行。

使用D&C解决问题的过程包括两个步骤。
1) 找出基线条件，这种条件必须尽可能简单。
2) 不断将问题分解（或者说缩小规模），直到符合基线条件。

欧几里得算法：“适用于这小块地的最大方块，也是适用于整块地的最大方块”

伪算法
- 基线条件是分成 n*n 的方块，初步方案是先分成尽可能大的方块；
- 先分成 (64*2)*64 的两块，剩下 40*64
- 余下的再分成 40*40 的一块，还剩下 40*24
- 余下的再分成 24*24 的一块，还剩下 16*24
- 余下的再分成 16*16 的一块，还剩下 16*8
- 正好分成 (8*2)*8 的两块。

返回验证， n=8
2n * n
16*16 = 2n*2n;
24*24 = 3n*3n;
40*40 = 5n*5n;
(64*2)*64=(8n*2)*8n
都合适，那么这个就是最大的方块了: 8*8。
方块总数: 21n * 8n


实现：//todo





(2) 问题: 把几个数字相加，并求和。

# 分而治之: 数组求和，递归法;

def sumArr(arr):
    sum=0;
    for i in arr:
        sum+=i 
    return sum 

print(sumArr([2,4,6]))


# 方法二，使用递归，数组长度为1或0时返回，否则拿出一个值加上其余 求和数组
def sumArr2(arr):
    if len(arr)==0:
        return 0
    else:
        return arr[0] + sumArr2(arr[1:])

print(sumArr2([2,4,6]))


如果你喜欢递归或想学习一门新语言，可以研究一下Haskell。

二分查找也是一种分而治之的算法，请找出二分查找算法的基线条件和递归条件。



(3) 快速排序

快速排序是一种常用的排序算法，比选择排序快得多。
例如，C语言标准库中的函数qsort实现的就是快速排序。
快速排序也使用了D&C。

归纳证明: 像数学归纳法，证明一个，然后证明可以化简，然后就可以了。
	我能站到第一个梯子横板上，我能从一个横板爬到上一个横板，然后我就能爬到梯子最顶端。



算法实现：
# 快速排序，使用递归，是一种分而治之的策略。

def quickSort(arr):
    if len(arr)<2:
        return arr;
    else:
        pivot=arr[0]; #第一个数做参考，其余部分，分割成比它小的，比它大的
        less = [i for i in arr[1:] if i<=pivot]
        greater =[i for i in arr[1:] if i>pivot]
        
        # 然后分别排序，拍好后放出来
        return quickSort(less)+[pivot] + quickSort(greater)

print(quickSort([10,2,30,-100,5]))
# [-100, 2, 5, 10, 30]





(4) 合并排序（merge sort）

还有一种名为合并排序（merge sort）的排序算法，其运行时间为O(n log n)，比选择排序快得多！
快速排序的情况比较棘手，在最糟情况下，其运行时间为O(n^2)。

与选择排序一样慢！但这是最糟情况。在平均情况下，快速排序的运行时间为O(n log n)。你可能会有如下疑问。
- 这里说的最糟情况和平均情况是什么意思呢？
- 若快速排序在平均情况下的运行时间为O(n log n)，而合并排序的运行时间总是O(n log n)，为何不使用合并排序？它不是更快吗？



(5) 最佳情况/最糟情况/平均情况
二分查找，如果是从低到高的1-8。
每次使用第一个元素作为参考，则需要8次，每次第一个数组都是空数组。
如果每次都使用中间值，则只需要 log2(8)次。

但是两种情况，每次都需要和参考值比较n次。


在这个示例中，层数为O(log n)（用技术术语说，调用栈的高度为O(log n)），而每层需要的时间为O(n)。
因此整个算法需要的时间为O(n) * O(log n) = O(n log n)。这就是最佳情况。

在最糟情况下，有O(n)层，因此该算法的运行时间为O(n) * O(n) = O(n2)。

知道吗？这里要告诉你的是，最佳情况也是平均情况。
只要你每次都随机地选择一个数组元素作为基准值，快速排序的平均运行时间就将为O(n logn)。
快速排序是最快的排序算法之一，也是D&C典范。






小结
  * D&C将问题逐步分解。使用D&C处理列表时，基线条件很可能是空数组或只包含一个元素的数组。
  * 实现快速排序时，请随机地选择用作基准值的元素。快速排序的平均运行时间为O(n log n)。
  * 大O表示法中的常量有时候事关重大，这就是快速排序比合并排序快的原因所在。
  * 比较简单查找和二分查找时，常量几乎无关紧要，因为列表很长时，O(log n)的速度比O(n)快得多。









========================================
散列表(hash table)：实现、冲突、散列函数
----------------------------------------

学习散列表的内部机制：实现、冲突和散列函数。这将帮助你理解如何分析散列表的性能。

缓存是一种常用的加速方式，所有大型网站都使用缓存，而缓存的数据则存储在散列表中！

1.散列表适合用于：
  * 模拟映射关系；
  * 防止重复；
  * 缓存/记住数据，以免服务器再通过处理来生成它们。


2. 冲突

哈希函数冲突怎么办？比如 返回首字母，返回字符串长度等这些hash函数就有这些问题。
最简单的办法，如果两个键映射到了同一个位置，就在这个位置存储一个链表。

如果需要保存的数据都在某一个位置后面的链表中，则hash结构和链表一样慢。

经验教训：
	hash 函数很重要。
	冲突时同一位置的链表不能太长！



3. 性能

(1) 填装因子 

填装因子度量的是散列表中有多少位置是非空的 = 填充的条目/位置总数。

比如: _ 1 _ 的填装因子是 1/3.
如果只有 50个位置，但是塞了100个条目呢？填装因子是 100/50=2.


(2) 良好的散列函数

良好的散列函数让数组中的值呈均匀分布。
糟糕的散列函数让值扎堆，导致大量的冲突。

如果你好奇，可研究一下SHA函数。


散列函数的结果必须是均匀分布的，这很重要。它们的映射范围必须尽可能大。
最糟糕的散列函数莫过于将所有输入都映射到散列表的同一个位置。




4. 小结 
你几乎根本不用自己去实现散列表，因为你使用的编程语言提供了散列表实现。你可使用 Python提供的散列表，并假定能够获得平均情况下的性能：常量时间。

散列表是一种功能强大的数据结构，其操作速度快，还能让你以不同的方式建立数据模型。

你可能很快会发现自己经常在使用它。
  * 你可以结合散列函数和数组来创建散列表。
  * 冲突很糟糕，你应使用可以最大限度减少冲突的散列函数。
  * 散列表的查找、插入和删除速度都非常快。
  * 散列表适合用于模拟映射关系。
  * 一旦填装因子超过0.7，就该调整散列表的长度。
  * 散列表可用于缓存数据（例如，在Web服务器上）。
  * 散列表非常适合用于防止重复。










========================================
广度优先搜索 (breadth-first search, BFS)
----------------------------------------

1. 广度优先搜索让你能够找出两样东西之间的最短距离，不过最短距离的含义有很多！
使用广度优先搜索可以：
  * 编写国际跳棋AI，计算最少走多少步就可获胜；
  * 编写拼写检查器，计算最少编辑多少个地方就可将错拼的单词改成正确的单词，如将READED改为READER需要编辑一个地方；
  * 根据你的人际关系网络找到关系最近的医生


在我所知道的算法中，图算法应该是最有用的。




2. 查找A到B的最少换乘方案

- 先找一步能到的地方
- 如果无法到达B，则继续找2步能到的点；
- 如果还无法到B，则继续找3步能到的点；
...

这种问题被称为最短路径问题（shorterst-path problem）。


(1)  你经常要找出最短路径

这可能是前往朋友家的最短路径，也可能是国际象棋中把对方将死的最少步数。
解决最短路径问题的算法被称为广度优先搜索。

(2) 要确定如何从双子峰前往金门大桥，需要两个步骤。
- 使用图来建立问题模型。
- 使用广度优先搜索解决问题。



3. 什么是图
(1)图是节点和边组成。
边可以有方向 和 权重。

(2)
有方向：有向图 directed graph，有箭头。
无方向的：无向图 undirected graph，没有箭头。

(3)
有权重：权重图。
带权重的图称为加权图（weighted graph），不带权重的图称为非加权图（unweighted graph）。


(4)
一个节点可能与众多节点直接相连，这些节点被称为邻居。







4. 广度优先搜索

(1) 解决的问题
第一类问题：从节点A出发，有前往节点B的路径吗？
第二类问题：从节点A出发，前往节点B的哪条路径最短？


第一个问题：我是种芒果的，我的朋友有芒果经销商吗？
从社交网络开始，比如Facebook为例:
先从朋友查找，如果有结束。
再遍历朋友，逐个加朋友的朋友，是经销商吗？是则结束。
...


再说一次，广度优先搜索可回答两类问题。
- 第一类问题：从节点A出发，有前往节点B的路径吗？（在你的人际关系网中，有芒果销售商吗？）
- 第二类问题：从节点A出发，前往节点B的哪条路径最短？（哪个芒果销售商与你的关系最近？）


(2) 一度关系在二度关系之前加入查找名单。

你按顺序依次检查名单中的每个人，看看他是否是芒果销售商。这将先在一度关系中查找，再在二度关系中查找，因此找到的是关系最近的芒果销售商。

广度优先搜索不仅查找从A到B的路径，而且找到的是最短的路径。


你需要按添加顺序进行检查。有一个可实现这种目的的数据结构，那就是队列（queue）。




5. 队列
队列只支持两种操作：入队和出队。

队列是一种先进先出（First In First Out，FIFO）的数据结构，
而栈是一种后进先出（Last In First Out，LIFO）的数据结构。




6. 实现图
图就是点之间的对应关系。A->B 
正好，散列表可以实现键值对映射： key -> value.

(1)
比如，表示你和你的直接邻居：
graph = {}
graph["you"] = ["alice", "bob", "claire"]

注意，“你”被映射到了一个数组，因此graph["you"]是一个数组，其中包含了“你”的所有邻居。



(2) 更复杂的图的Python代码如下

graph = {}
graph["you"] = ["alice", "bob", "claire"]
graph["bob"] = ["anuj", "peggy"]
graph["alice"] = ["peggy"]
graph["claire"] = ["thom", "jonny"]
graph["anuj"] = []
graph["peggy"] = []
graph["thom"] = []
graph["jonny"] = []

散列表是无序的，因此添加键—值对的顺序无关紧要。





7. 实现广度优先算法

(1) 伪代码
创建队列，保存直接邻居
从对首遍历：
	是要找的，返回，结束查找。
	不是要找的
		弹出这个人
		并把这个人的邻居添加到队伍末尾。
如果队伍为空，则说明这个人的直接和间接邻居都没有要找的目标。


(2) py实现: 简陋实现
# 广度优先算法:
# 维护一个队列，先加入一度节点；
# 遍历，如果找到了就停止；没找到，就弹出，并把其好友添加到队列末尾。
# 直到返回，或者找不到。

# 创建图
graph = {}
graph["you"] = ["alice", "bob", "claire"]
graph["bob"] = ["anuj", "peggy"]
graph["alice"] = ["peggy"]
graph["claire"] = ["thom", "jonny"]
graph["anuj"] = []
graph["peggy"] = []
graph["thom"] = []
graph["jonny"] = []


# 在Python中，可使用函数deque来创建一个双端队列。
from collections import deque
search_queue = deque()
search_queue += graph["you"]

# 判断这个人是不是芒果经销商，最后一个字母是m 的停止
def person_is_seller(name):
    return name[-1] == 'm'

# 开始搜索
def bfs(search_queue):
    i=0
    while search_queue:
        person = search_queue.popleft() #左侧弹出一个元素
        
        i+=1
        print(f"[{i}] Cur:", person);
        
        if person_is_seller(person):
            print(person + " is a mango seller!")
            return True
        else:
            search_queue += graph[person]
    return False

bfs(search_queue);
print("==End==")


这个粗糙的实现有个问题，就是有人(peggy) 被查询了2次。
首先同一个元素检查2次是在浪费时间，其次这有可能陷入死循环，如果两个人互为好友。
应该使用一个表格，记录检查过的元素。



(3) 广度优先算法 标准实现
# 维护一个队列，先加入一度节点；
# 遍历，如果找到了就停止；没找到，就弹出，并把其好友添加到队列末尾。
# 直到返回，或者找不到。
from re import search

#
# v2: 为了避免死循环，要记录搜寻过的元素，并跳过它。
# 另一个更新，是把函数封装的更好：传入图和要查找的起始点。

# 创建图
graph = {}
graph["you"] = ["alice", "bob", "claire"]
graph["bob"] = ["anuj", "peggy"]
graph["alice"] = ["peggy"]
graph["claire"] = ["thom", "jonny"]
graph["anuj"] = []
graph["peggy"] = []
graph["thom"] = []
graph["jonny"] = []

# 在Python中，可使用函数deque来创建一个双端队列。
from collections import deque

# 判断这个人是不是芒果经销商，最后一个字母是m 的停止
def person_is_seller(name):
    return name[-1] == 'm'

# 开始搜索
def bfs2(graph, name="you", debug=True):
    search_queue = deque()
    search_queue += graph[name]

    searched=[]
    i=0
    while search_queue:
        i+=1
        person = search_queue.popleft() #左侧弹出一个元素
        if person in searched:
            print(f"[{i}]==>Jump:", person)
            continue;
        else:
            searched.append(person);
        
        if debug:
            print(f"[{i}] Cur:", person);
            print("\t>>>queue:", search_queue);
        
        if person_is_seller(person):
            print(person + " is a mango seller!")
            return True
        else:
            search_queue += graph[person]
    return False

bfs2(graph, "you");
print("==End==")





(4) 算法的时间复杂性

检查每条边 O(边数)
使用队列，检查每个人，将一个人添加到队尾的时间是固定的 O(1)，则总时间为 O(人数).
所以，广义优先搜索的运行时间为 O(人数 + 边数)，通常写作 O(V+E)
V 顶点 Vertice
E 边数 Edge



(5) 拓扑排序
从某种程度上说，这种列表是有序的。如果任务A依赖于任务B，在列表中任务A就必须在任
务B后面。这被称为拓扑排序，使用它可根据图创建一个有序列表


家谱结构的方向不能颠倒，这种图被称为树。树是一种特殊的图，其中没有往后指的边






8. 小结
  * 广度优先搜索指出是否有从A到B的路径。
  * 如果有，广度优先搜索将找出最短路径。
  * 面临类似于寻找最短路径的问题时，可尝试使用图来建立模型，再使用广度优先搜索来解决问题。
  * 有向图中的边为箭头，箭头的方向指定了关系的方向，例如，rama→adit表示rama欠adit钱。
  * 无向图中的边不带箭头，其中的关系是双向的，例如，ross - rachel表示“ross与rachel约会，而rachel也与ross约会”。
  * 队列是先进先出（FIFO）的。
  * 栈是后进先出（LIFO）的。
  * 你需要按加入顺序检查搜索列表中的人，否则找到的就不是最短路径，因此搜索列表必须是队列。
  * 对于检查过的人，务必不要再去检查，否则可能导致无限循环。









========================================
狄克斯特拉算法（Dijkstra’s algorithm）：加权图的最短距离
----------------------------------------

1. 狄克斯特拉算法包含4个步骤。
(1) 找出“最便宜”的节点，即可在最短时间内到达的节点。
(2) 更新该节点的邻居的开销，其含义将稍后介绍。
(3) 重复这个过程，直到对图中的每个节点都这样做了。
(4) 计算最终路径。



2.使用范围
狄克斯特拉算法只适用于有向无环图（directed acyclic graph，DAG）。

这就是狄克斯特拉算法背后的关键理念：找出图中最便宜的节点，并确保没有到该节点的更便宜的路径！



3. 负权边

如果有负权边，就不能使用狄克斯特拉算法。


为狄克斯特拉算法这样假设：对于处理过的海报节点，没有前往该节点的更短路径。
这种假设仅在没有负权边时才成立。


在包含负权边的图中，要找出最短路径，可使用另一种算法——贝尔曼-福德算法（Bellman-Ford algorithm）。



4. 实现

需要维护三个散列表： Graph, costs, parents.

随着算法的进行，不断更新 costs 和 parents 表。

(1) 图 
这里有权重，你需要保存邻居节点和权重。

graph={}
graph["start"] = {}
graph["start"]["a"] = 6
graph["start"]["b"] = 2

获取起点的邻居：
print( graph["start"].keys()  ) #["a", "b"]

获取起点到邻居的权重：
print( graph["start"]["a"] ) #6
print( graph["start"]["b"] ) #2

下面来添加其他节点及其邻居。
graph["a"] = {}
graph["a"]["fin"] = 1
graph["b"] = {}
graph["b"]["a"] = 3
graph["b"]["fin"] = 5
graph["fin"] = {}  #终点没有任何邻居



(2) 需要用一个散列表 (costs) 来存储每个节点的开销。
节点的开销指的是从起点出发前往该节点需要多长时间。

对于还不知道的开销，你将其设置为无穷大。
python 的无穷大: infinity = float("inf")


创建开销表的代码如下：
infinity = float("inf")
costs = {}
costs["a"] = 6
costs["b"] = 2
costs["fin"] = infinity


(3) 还需要一个存储父节点的散列表( parents )

parents = {}
parents["a"] = "start"
parents["b"] = "start"
parents["fin"] = None 


(4) 最后，你需要一个数组，用于记录处理过的节点，因为对于同一个节点，你不用处理多次。
processed = [] 


(5) 伪代码 

只要还有要处理的节点：
	获取离起点最近的节点
	更新其邻居的开销
	如果有邻居的开销被更新，同时更新其父节点
	该节点标记为处理过。


(6) python 实现

node = find_lowest_cost_node(costs) #从未处理的节点中找到开销最小的节点
while node is not None:  #在所有节点都被处理过后结束
	cost = costs[node]   #到该节点的权重
	neighbors = graph[node] #该节点的邻居
	for n in neighbors.keys():  #遍历该节点的邻居
		new_cost = cost + neighbors[n] #到给节点的邻居的权重=老权重，+连线权重
		if costs[n] > new_cost:  #如果经过当前节点前往邻居更近，则
			costs[n] = new_cost     #更新该邻居节点的开销
			parents[n] = node       # 修改该邻居节点的父节点为当前节点
	processed.append(node)   #将当前节点标记为处理过
	node = find_lowest_cost_node(costs) #找到下一个要处理的节点，并循环


目前还没有实现 函数find_lowest_cost_node()。
我们再次回顾过程。

在纸上画吧。
起点到终点，加上中间的AB共4个点。
start:{A:6, B:2}
A:{stop:1,}
B:{A:3, stop:5}

起始 costs 表，起点到各个点的距离
A:6
B:2
fin:无穷大
costs: {'a': 6, 'b': 2, 'fin': inf}

parents: {'a': 'start', 'b': 'start', 'fin': None}

开始costs最小的是B点。
到B的cost=2，邻居是 {A:3, final:5}
	n=A 时
		new_cost= B的开销 + 经过点B到A的权重=2+3=5
		起点到A的开销是 6 > 经过B再到A的距离 5: 
			进入if，更新A的开销和父节点
			parents: {'a': 'b', 'b': 'start', 'fin': None}
			costs: {'a': 5, 'b': 2, 'fin': inf}

	n=final 时
		new_cost = B的开销 + 经过B到final的权重=2+5=7
		起点到final的开销 初始为无穷大 > 经过B再到final的距离 7：
			进入if，更新 final 的开销和父节点
			parents: {'a': 'b', 'b': 'start', 'fin': "b"}
			costs: {'a': 5, 'b': 2, 'fin': 7}

从未处理节点中，找开销最小的点。这时是 A 
到A点的 cost=5，邻居是 {final:1}
	n=final时
		new_cost = A的开销 + 结果A到final的开销=5+1=6
		起点到final的开销 7 > 经过A到final的距离6:
			进入if，更新final的开销和父节点
			parents: {'a': 'b', 'b': 'start', 'fin': "a"}
			costs: {'a': 5, 'b': 2, 'fin': 6}


(7) 实现函数 find_lowest_cost_node()

def find_lowest_cost_node(costs):
	lowest_cost = float("inf")
	lowest_cost_node = None
	for node in costs: #遍历costs表的节点：遍历所有节点
		cost = costs[node] #该节点的开销
		if cost < lowest_cost and node not in processed: #选出未处理过的最小开销节点
			lowest_cost = cost
			lowest_cost_node = node
	return lowest_cost_node





5. 完整实现

#《算法图解》之狄克斯特拉算法
#https://blog.51cto.com/u_15334850/3502082

# the graph
graph = {}
graph["start"] = {}
graph["start"]["a"] = 6
graph["start"]["b"] = 2

graph["a"] = {}
graph["a"]["fin"] = 1

graph["b"] = {}
graph["b"]["a"] = 3
graph["b"]["fin"] = 5

graph["fin"] = {}
print(">>graph:", graph)


# the costs table
infinity = float("inf")
costs = {}
costs["a"] = 6
costs["b"] = 2
costs["fin"] = infinity
print(">>costs:", costs)


# the parents table
parents = {}
parents["a"] = "start"
parents["b"] = "start"
parents["fin"] = None
print(">>parents:", parents)

processed = []

def find_lowest_cost_node(costs):
    lowest_cost = float("inf")
    lowest_cost_node = None
    # Go through each node.
    for node in costs:
        cost = costs[node]
        # If it's the lowest cost so far and hasn't been processed yet...
        if cost < lowest_cost and node not in processed:
            # ... set it as the new lowest-cost node.
            lowest_cost = cost
            lowest_cost_node = node
    return lowest_cost_node


# Find the lowest-cost node that you haven't processed yet.
node = find_lowest_cost_node(costs)

# If you've processed all the nodes, this while loop is done.
while node is not None:
    print(">>node:", node)
    
    cost = costs[node]
    
    # Go through all the neighbors of this node.
    neighbors = graph[node]
    print(">>", node, " 's neighbors:", neighbors);
    
    for n in neighbors.keys():
        print("\t>>parents:", parents)
        print("\t>>costs:", costs)
        
        new_cost = cost + neighbors[n]
        print("\t>>n=", n, ", cost[n]:", costs[n], ", new_cost:", new_cost);
        # If it's cheaper to get to this neighbor by going through this node...
        if costs[n] > new_cost:
            print("\t>> update ...")
            # ... update the cost for this node.
            costs[n] = new_cost
            # This node becomes the new parent for this neighbor.
            parents[n] = node
    # Mark the node as processed.
    processed.append(node)
    # Find the next node to process, and loop.
    node = find_lowest_cost_node(costs)

print("\nCost from the start to each node:")
print(">costs: ", costs) #dynamic
print(">parents: ", parents) #dynamic
print(">graph: ", graph) #no change during process.


# find path from parents
# {'a': 'b', 'b': 'start', 'fin': 'a'}
x="fin"
chain=[x]
while parents.get(x) is not None:
    x=parents.get(x)
    chain.append(x);
print("->".join( chain[::-1] )) # start->b->a->fin




6.小结
  * 广度优先搜索用于在非加权图中查找最短路径。
  * 狄克斯特拉算法用于在加权图中查找最短路径。
  * 仅当权重为正时狄克斯特拉算法才管用。
  * 如果图中包含负权边，请使用贝尔曼-福德算法。



ref:
https://www.geeksforgeeks.org/dijkstras-shortest-path-algorithm-greedy-algo-7/






========================================
贪婪算法 - NP不完全问题的近似求解: (背包问题)、旅行商问题、集合覆盖问题
----------------------------------------

目标 
  * 学习如何处理不可能完成的任务：没有快速算法的问题（NP完全问题）。
  * 学习识别NP完全问题，以免浪费时间去寻找解决它们的快速算法。
  * 学习近似算法，使用它们可快速找到NP完全问题的近似解。
  * 学习贪婪策略——一种非常简单的问题解决策略。



1. 排课问题: 一个教室极可能多的排课

选最先结束的课；
然后上一节课结束后开始的课中，最先结束的课；
...

每一步都是最优的，通过局部最优获取全局最优，或近似最优。




2. 背包问题

有一个40磅的背包，有三件物品

物品   /价值    /重量(磅)
音响   $3000    30p
笔记本 $2000    20p
吉他   $1500    15p

使用贪婪策略：
先找到价值最大的商品，音响 3k，重量 30p，背包还剩10p，装不下其他的了。
如果它装另外连个物品，共 35p，价值 3.5k，比上一个更多。
说明这种情况下，贪婪算法失败了。
但也算接近最优解了。


从这个示例你得到了如下启示：在有些情况下，完美是优秀的敌人。
有时候，你只需找到一个能够大致解决问题的算法，此时贪婪算法正好可派上用场，因为它们实现起来很容易，得到的结果又与正确结果相当接近。









3. 集合覆盖问题

你办了一个节目，想让50个洲的听众都能收听。
每个电台覆盖的洲不同，两个电台覆盖的州可能重复。
每个电台播放都收取费用，怎么选用尽可能少的电台，覆盖全部州。


(1) 如果使用完整遍历，则需要遍历各种组合：
先看每个电台C(n, 1)，有没有能覆盖全部州的；
然后看2个电台的情况，各种两两组合C(n,2)，看是否覆盖全部州；
然后三个电台的情况，各种C(n, 3)，看有没有覆盖全部州的；
...
需要的总时间是：C(n,1)+C(n,2)+...+C(n,n)=2^n;
这个时间增速太快了，指数级的。
时间复杂度就是 O(2^n);



(2) 使用贪婪策略：
先找到覆盖最多州的电台；
然后在没覆盖的州中，选择覆盖最多的电台；
...
直到所有州都覆盖，或者电台用完。


这是一种近似算法（approximation algorithm）。在获得精确解需要的时间太长时，可使用近
似算法。判断近似算法优劣的标准如下：
	速度有多快；
	得到的近似解与最优解的接近程度


参考实现:

# 贪婪算法： 集合覆盖度问题
# 每个电台覆盖几个州，2个电台覆盖的州可能有重叠。求覆盖全部州需要至少哪几个电台？

# 传入所有的州，转为一个集合
states_needed=set(["mt", 'wa', 'or', 'id','nv','ut','ca','az'])

# 电台，及覆盖的州
stations={}
stations["kone"]=set(['id','nv','ut'])
stations['ktwo']=set(['wa','id','mt'])
stations['kthreee']=set(['or','nv','ca'])
stations['kfour']=set(['nv','ut'])
stations['kfive']=set(['ca','az'])

# 最终选用的电台
final_stations=set();

i=0;
while len(states_needed)>0:
    i+=1;
    if i>1000:
        break; #防止死循环
    
    # 一轮挑选一个覆盖(未覆盖区域)最广泛的电台
    best_station = None;
    # 覆盖的州
    states_covered=set();
    # 遍历电台
    for station, states_for_station in stations.items():
        # 求交集：未覆盖的州，该电台覆盖的州
        covered= states_needed & states_for_station;
        # 记录覆盖最多未覆盖州的电台
        if len(covered) > len(states_covered):
            best_station = station;
            states_covered = covered;
    # for 结束，就找到了覆盖最多的(未覆盖)州的电台
    # 则从未覆盖州中去掉这几个州
    states_needed -= states_covered;
    # 最终选用的电台增加一个
    final_stations.add(best_station)
    print(i, best_station)

# 集合无法保证顺序，添加顺序和打印集合的输出不一致。
print(final_stations)




(3) 下面各种算法是否是贪婪算法。
快速排序。
广度优先搜索。
狄克斯特拉算法。







4. 旅行商问题

(1) 遍历角度看
旅行商问题假设：
	A->B和B->A是不同的路线，因为有单行道，有绕行，路程可能不同。
	从哪里开始不确定，只要能不重复的走遍5个城市即可。

所以可以看做一个排列组合问题：
	先选中一个作为入口，5种情况
	再从其余的城市选一个，4种情况；
	...
	总共是 5! 种方案。

时间复杂度就是 O(n!);
阶乘级别的，增速也很快。



(2) 贪婪算法近似解答
随机选择一个城市作为入口，然后选择其余城市中距离最近的，
	然后选择其余城市中距离最近的，...。

//todo








5. NP 完全问题

旅行商问题和集合覆盖问题有一些共同之处：你需要计算所有的解，并从中选出最小/最短的那个。这两个问题都属于NP完全问题。

NP完全问题的简单定义是，以难解著称的问题，如旅行商问题和集合覆盖问题。
很多非常聪明的人都认为，根本不可能编写出可快速解决这些问题的算法。


很难判断出要解决的问题是否属于NP完全问题。比如，
	上一节说到的，从A到B的最短路径，就是可解的。
	找经过几个点的最短路径，就是旅行商问题，NP完全问题。


没办法判断问题是不是NP完全问题，但还是有一些蛛丝马迹可循的。
	元素较少时算法的运行速度非常快，但随着元素数量的增加，速度会变得非常慢。
	涉及“所有组合”的问题通常是NP完全问题。
	不能将问题分成小问题，必须考虑各种可能的情况。这可能是NP完全问题。
	如果问题涉及序列（如旅行商问题中的城市序列）且难以解决，它可能就是NP完全问题。
	如果问题涉及集合（如广播台集合）且难以解决，它可能就是NP完全问题。
	如果问题可转换为集合覆盖问题或旅行商问题，那它肯定是NP完全问题。







========================================
动态规划 Dynamic Programming (基础中最难的部分)
----------------------------------------
目标:
* 学习动态规划，这是一种解决棘手问题的方法，它将问题分成小问题，并先着手解决这些小问题。
* 学习如何设计问题的动态规划解决方案。


这是一类很难的算法，需要结合例子反复理解、实践: https://www.geeksforgeeks.org/dynamic-programming/




1. 背包问题 

数字细节和上文的略有调整。
有一个能装4磅的背包，另有三件物品，怎么才能装价值尽可能大的物品？

物品   /价值    /重量(磅)
音响   $3000    4p
笔记本 $2000    3p
吉他   $1500    1p


(1) 简单算法
遍历各种组合，判断能否装下，能装下的再计算总金额。

0
音响 3000   4p
笔记本 2000 3p
吉他 1500 1p
音响+笔记本 7p 装不下
音响+吉他  5p 装不下
笔记本+吉他 3500 4p   ### max
音响+笔记本+吉他 装不下

共 C(3,1)+C(3,2)+C(3,3)=2^3=8种组合。
如果n件物品，就需要 2^n 个组合，时间复杂度 O(2^n)，太慢。

商品多到一定程度该策略就不可行了，太慢。比如快递车需要运输哪些物品，保证高价值的商品先送到。
如何找到最优解呢？


(2) 动态规划
对于4磅的大背包，可以考虑2个小背包的情况: 1+3

动态规划是一个难以理解的概念，我们可以从示例开始。

填充一个 3行x4列的 表格。3行分别是三个物品，4列分别是1-4磅。

		1	2	3	4
吉他 
音响 
笔记本

1) 吉他行: 吉他 1500 1p
这时只有一个吉他可以填充，包的大小是变化的。

如果包只有1p，则可以填充吉他，最大价值是 1500.
如果包只有2p，则可以填充吉他，最大价值是 1500.
如果包只有3p，则可以填充吉他，最大价值是 1500.
如果包只有4p，则可以填充吉他，最大价值是 1500.

		1	2	  3	   4
吉他  1.5   1.5   1.5  1.5
音响 
笔记本

这行表示的是当前的最大价值。


2) 音响行: 音响 3000   4p
目前你可以塞 吉他和音响了。

如果包只有1p，它之前有一个1p的吉他，剩余空间塞不下了，最大价值还是 1500.
如果包只有2p 或 3p，它之前有一个1p的吉他，剩余空间塞不下了，最大价值还是 1500.
如果包只有4p，它之前有一个1p的吉他，剩余空间塞不下了，最大价值还是 1500，
	或者它还可以掏出来吉他，只装一个4p的音响，最大价值是 3000，这才是最大价值。

		1	2	  3	   4
吉他  1.5   1.5   1.5  1.5
音响  1.5   1.5   1.5  3
笔记本

我们看到，价值最大化，是考虑以下两种情况的最大者:
	只装当前物品的价值;
	之前的最大价值和剩余空间能装东西的最大价值;


3) 笔记本电脑行: 笔记本 $2000    3p
这时有三个物品可以塞进包里了。
音响   $3000    4p
笔记本 $2000    3p
吉他   $1500    1p

如果包只有1p，它之前有一个1p的吉他，剩余空间塞不下了，最大价值还是 1500.
如果包只有2p，它之前有一个1p的吉他，剩余空间1p塞不下了，最大价值还是 1500.
如果包只有3p，它之前有一个1p的吉他，剩余空间2p塞不下了，最大价值还是 1500.
	或者 只塞一个 笔记本电脑 3p，最大价值是 2000
如果包只有4p，它之前有一个4p的音响，剩余空间0p塞不下了，最大价值 3000.
	或者 只塞一个笔记本电脑 3p，还余下的1p(在装入笔记本电脑前的一行中，1p对应的格子是: 1500的吉他)，最大价值是 3500

		1	2	  3	   4
吉他  1.5   1.5   1.5  1.5
音响  1.5   1.5   1.5  3
笔记本 1.5  1.5   2    3.5



4) 公式
==> 总结一下我们计算每个单元格时使用的公式: i 表示行，j表示列。
cell[i][j] = max(
	上一个单元格的价值( cell[i-1][j] ),
	当前商品的价值 + 剩余空间的价值( cell[i-1][j-当前商品的重量] )
)
第一行上面都补充0，第一列前面都补充0.

像是黑魔法一样，我们得到了4磅包能装的最大价值是: 3500(笔记本电脑3p + 吉他1p)




5) 再增加一个商品: iPhone手机 $2000 1p
现在有4个物品了：
音响   $3000    4p
笔记本 $2000    3p
吉他   $1500    1p
手机   $2000    1p

我们重新计算表格:
如果包只有1p，它之前有一个1p的吉他，剩余空间塞不下了，最大价值 1500.
	或者 只装 1p的手机，2000
如果包只有2p，它之前有一个1p的吉他，剩余空间1p 能装下这个1p的手机，最大价值 1500+2000=3500.
	或者 只塞 1p 的手机，剩余空间1p在手机之前的最大价值是 1500的吉他，最大价值 2000+1500=3500.
如果包只有3p，它之前有一个3p的笔记本电脑，剩余空间0，最大价值 2000.
	或者 只塞 1p 的手机，剩余空间2p在手机之前的最大价值是 1p的吉他，最大价值是 2000+1500=3500
如果包只有4p，它之前有一个1p的吉他+3p的笔记本电脑，最大价值 1500+2000=3500.
	或者 只塞 1p 的手机，剩余的空间3p空间，在手机之前的最大价值是 3p的笔记本电脑，最大价值是 2000+2000=4000

		1	2	  3	   4
吉他  1.5   1.5   1.5  1.5
音响  1.5   1.5   1.5  3
笔记本1.5   1.5   2    3.5
手机   2    3.5   3.5  4    

从左上角开始往下走，最大值不可能降低。因为每次迭代，都是保留当前的最大值，最大价值要和过去比，不可能比过去低。



6) 假设你还可偷另外一件商品——MP3播放器，它重1磅，价值1000美元。你要偷吗？

// todo 



7) 如果填充的顺序发生变化，会影响最后的答案吗？
比如改为：音响、笔记本电脑、吉他。

音响   $3000    4p
笔记本 $2000    3p
吉他   $1500    1p

答案是没有变化。


8) 可以逐列填充吗？
本问题可以，但是其他问题不一定。


9) 增加一件更小的商品将如何呢
假设你还可以偷一条项链，它重0.5磅，价值1000美元。

由于项链的加入，你需要考虑的粒度更细，因此必须调整网格。
列变成 0.5, 1,1.5,2,2.5,3,3.5,4



10) 可以偷走商品的一部分吗？
比如大豆、玉米，偷走一部分。
动态规划无法处理这种情况。使用动态规划时，要么考虑拿走整件商品，要么考虑不拿，而没法判断该不该拿走商品的一部分。


但使用贪婪算法可轻松地处理这种情况！首先，尽可能多地拿价值最高的商品；如果拿光了，再尽可能多地拿价值次高的商品，以此类推。


11) 计算最终的解时会涉及两个以上的子背包吗

不会，因为算法就是2个小背包取最大值，大背包最多包含2个子背包。
但是，子背包可能再包含最多2个子背包。以此类推。



12) 最优解可能导致背包没装满吗
完全可能。假设你还可以偷一颗钻石。

比如有颗钻石非常大，重达3.5磅，价值100万美元，比其他商品都值钱得多。
剩余0.5磅装不下其他的东西了。







2. 旅游行程最优化

(1) 你要去度假，假期2天，你想去尽可能多的地方。你的清单如下:

景点	时间(天)	评分
A	    0.5		7
B	    0.5		6
C	    1		9
D	    2		9
E	    0.5		8

这也是一个背包问题:
打分表示想去看的程度: 对应背包的价值
约束条件是时间：对应背包的容量。

填表，记录每个景点对应的最大打分。
	0.5	1	1.5	2
A 
B 
C 
D 
E 



(2) 处理相互依赖的情况

如果取了E(巴黎)和F、G、H(巴黎的景点)在同一个方向，单独去F、G、H都需要1天，但是去了E再去F、G、H则总共只需要0.5天。
如何处理这种带有依赖的情况？

没办法建模。动态规划功能强大，它能够解决子问题并使用这些答案来解决大问题。
但仅当每个子问题都是离散的，即不依赖于其他子问题时，动态规划才管用。
这意味着使用动态规划算法解决不了去巴黎玩的问题。









3. 最长公共子串

(1) 启示
* 动态规划可帮助你在给定约束条件下找到最优解。在背包问题中，你必须在背包容量给定的情况下，偷到价值最高的商品。
* 在问题可分解为彼此独立且离散的子问题时，就可使用动态规划来解决。


(2) 要设计出动态规划解决方案可能很难
下面是一些tips

* 每种动态规划解决方案都涉及网格。
* 单元格中的值通常就是你要优化的值。在前面的背包问题中，单元格的值为商品的价值。
* 每个单元格都是一个子问题，因此你应考虑如何将问题分成子问题，这有助于你找出网格的坐标轴。


(3) 词典单词匹配问题
你是词典网站管理员，用户输入 fish 时错误的输入了 hish。
你的字典里没有这几个词，但是有类似的单词，他到底想查 hash 还是 vista 呢？
你怎么推测他最可能想查哪个单词呢？


先思考该问题怎么使用动态规划解决？
没思路也没关系，勤思考总是好的。



==> 绘制表格
单元格中的值是什么？
如何将这个问题划分为子问题？
网格的坐标轴是什么？

我们尝试找出 fish 和 hish 的最长公共子串。以及 hish 和 vista 的最长公共子串。 
单元格内通常是要优化的值，那就是最长公共子串的长度了。

如何划分为子问题？比较子串，而不是整个单词。那么坐标很可能是这2个单词了。

	H I S H 
F 
I 
S 
H 

这确实很难懂。耐心看，反复琢磨。
如果你一眼就理解了，你应该相信自己是天才。


==> 填充网格
我们目测知道 fish 和 hish 的最大子串是 ish，然后看怎么设计流程。
还是好难，找不到简单方法，给点提示，下面是表格的一部分:
	H I S H 
F   0 0
I 
S       2 0
H         3

每个单元格都是一个子问题的值。
为何 cell[3,3]=2, cell[3,4]=0 呢?
请尝试找出公式，然后接着读。
找不出来...也可以接着读。


完整表格
  H I S H 
F 0 0 0 0
I 0 1 0 0 
S 0 0 2 0
H 0 0 0 3

公式就是：
* 如果单元格x和y对应的字母不同，则cell[i,j]=0
* 如果单元格x和y对应的字母相同，则对应单元格的值为其左上角单元格的值+1

写成伪代码
if word_a[i] == word_b[j]:
	cell[i][j] = cell[i-1][j-1] + 1 #字母相同
else:
	cell[i][j] = 0 #字母不同



==> 单词hish和vista的最长公共子串时的表格
  V I S T A
H 0 0 0 0 0
I 0 1 0 0 0
S 0 0 2 0 0
H 0 0 0 0 0

最大值就是问题的答案，是2个，目测是 is

注意：最后一个单元格不是问题的答案！
对于背包问题，最终答案都在最后一个单元格中。
但是对于最大子串问题，答案为网格中的最大数字，可能不在最后一个格子内。


我们认为最长子串最长的是最佳答案， fish。





4. 最长公共子序列

用户不小心输入了 fosh，他原本想输入的是 fish 还是 fort 呢？
使用最长公共子串比较，都是2: sh 和 fo。
但是我们知道 fosh 与 fish 更像，这里比较的是公共 子序列，不是 子串。
子序列可以不连续 f*sh.

公共 子序列 规则:
* 如果2个字母不同，就选择上方和左方邻居中较大的那个。(与计算 子串时不同)
* 如果两个字母相同，就选择其左上角的值+1。 (与计算 子串时相同)

伪代码:
if word_a[i] == word_b[j]:
	cell[i][j] = cell[i-1][j-1] + 1 #字母相同
else:
	cell[i][j] = max(cell[i-1][j], cell[i][j-1]) #字母不同时


本章到这里就结束了！它绝对是本书最难理解的一章。





5. 动态规划都有哪些实际应用呢？

* 生物学家根据最长公共序列来确定DNA链的相似性，进而判断度两种动物或疾病有多相似。最长公共序列还被用来寻找多发性硬化症治疗方案。

* 你使用过诸如git diff等命令吗？它们指出两个文件的差异，也是使用动态规划实现的。

* 前面讨论了字符串的相似程度。编辑距离（levenshtein distance）指出了两个字符串的相似程度，也是使用动态规划计算得到的。编辑距离算法的用途很多，从拼写检查到判断用户上传的资料是否是盗版，都在其中。

* 你使用过诸如Microsoft Word等具有断字功能的应用程序吗？它们如何确定在什么地方断字以确保行长一致呢？使用动态规划！




6. 小结
	需要在给定约束条件下优化某种指标时，动态规划很有用。
	问题可分解为离散子问题时，可使用动态规划来解决。
	每种动态规划解决方案都涉及网格。
	单元格中的值通常就是你要优化的值。
	每个单元格都是一个子问题，因此你需要考虑如何将问题分解为子问题。
	没有放之四海皆准的计算动态规划解决方案的公式。




更多例子: https://www.geeksforgeeks.org/dynamic-programming/




========================================
K最近邻算法 //todo
----------------------------------------





















========================================
==> cur: (168/197)
----------------------------------------




















========================================
----------------------------------------

========================================
----------------------------------------

========================================
----------------------------------------


========================================
----------------------------------------

========================================
----------------------------------------

========================================
----------------------------------------


========================================
----------------------------------------

========================================
----------------------------------------

========================================
----------------------------------------
