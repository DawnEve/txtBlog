R03 - 统计学(经典统计学知识点，独立于R)

罗马数字、希腊字母 读音和写法

累加 大sigma
正态分布 X~N(mu, sigma^2)



本文记录数理统计学基础知识。
还有一个paper中遇到的统计学: scSeq/NGS_statistics.txt 
一个R与统计学: R/R03-statistics.txt



========================================
统计学资源汇总 及书单
----------------------------------------
1.StatQuest系列笔记汇总
https://mp.weixin.qq.com/s?__biz=MzAxMzkzNDUyOQ==&mid=2247484185&idx=1&sn=59944cbe7a078148287707e25be70467&scene=21


2.  概率论与数理统计学习笔记
https://blog.csdn.net/hpdlzu80100

G:\baiduDisk\考研数学2014基础班\概率统计


3.统计之都： http://cos.name/tag/%E5%8A%A8%E7%94%BB/



4.统计推断
统计推断作者: George Casella / Roger L. Berger
出版社: China Machine Press
https://book.douban.com/subject/1245344/

雷奥奇·卡塞拉、罗杰L.贝耶编著的《统计推断（英文版原书第2版）》从概率论的基础开始，通过例子与习题的旁征博引，引进了大量近代统计处理的新技术和一些国内同类教材中不能见而广为使用的分布。其内容包括工科概率论入门、经典统计和现代统计的基础，又加进了不少近代统计中数据处理的实用方法和思想，例如：Bootstrap再抽样法、刀切（Jackknife）估计、EM算法、Logistic回归、稳健（Robust）回归、Markov链、Monte Carlo方法等。它的统计内容与国内流行的教材相比，理论较深，模型较多，案例的涉及面要广，理论的应用面要丰富，统计思想的阐述与算法更为具体。《统计推断（英文版原书第2版）》可作为工科、管理类学科专业本科生、研究生的教材或参考书，也可供教师、工程技术人员自学之用。







###################
统计学书单

一、统计学基础部分
1、《统计学》 David Freedman等著，魏宗舒，施锡铨等译中国统计出版社
    据说是统计思想讲得最好的一本书，读了部分章节，受益很多。整本书几乎没有公式，但是讲到了统计思想的精髓。

2、《Mind on statistics(英文版）》机械工业出版社
    只需要高中的数学水平，统计的扫盲书。有一句话影响很深：Mathematics as to statistics is something like hammer, nails, wood as to a house, it's just the material and tools but not the house itself。

3、《Mathematical Statistics and Data Analysis（英文版.第二版）》 机械工业出版社
    看了就发现和国内的数理统计树有明显的不同。这本书理念很好，讲了很多新的东西，把很热门的Bootstrap方法和传统统计在一起讲了。Amazon上有书评。

4、《Business Statistics a decision making approach（影印版）》中国统计出版社
    在实务中很实用的东西，虽然往往为数理统计的老师所不屑

5、《Understanding Statistics in the behavioral science（影印版）》 中国统计出版社
    和上面那本是一个系列的。老外的书都挺有意思的

6、《探索性数据分析》中国统计出版社和第一本是一个系列的。
       大家好好看看陈希儒老先生做的序，可以说是对中国数理统计的一种反思。

二、回归部分
1、《应用线性回归》 中国统计出版社
    还是著名的蓝皮书系列，有一定的深度，道理讲得挺透的。看看里面对于偏回归系数的说明，绝对是大开眼界啊！非常精彩的书

2、《Regression Analysis by example (3rd Ed影印版)》
    这是偶第一本从头到底读完的原版统计书，太好看了。那张虚拟变量写得比小说都吸引人。没什么推导，甚至说“假定你有统计软件可以算出结果”，主要就是将分-析，怎么看图，怎么看结果。看完才觉得回归真得很好玩

3、《Logistics回归模型——方法与应用》王济川郭志刚高等教育出版社
    不多的国内的经典统计教材。两位都是社会学出身，不重推导重应用。每章都有详细的SAS和SPSS程序和输出的分析。两位估计洋墨水喝得比较多，中文写的书，但是明显老外写书的风格


三、多元

1、《应用多元分析（第二版）》王学民上海财经大学出版社
    现在好像就是用的这本书，但是请注意，这本书的亮点不是推导，而是后面和SAS结合的部分，以及其中的一些想法（比如P99 n对假设检验的影响，绝对是统计的感觉，不是推推公式就能感觉到的）。这是一本国内很好的多元统计教材。

2、《Analyzing Multivariate Data（英文版）》 Lattin等著机械工业出版社
    这本书有很多直观的感觉和解释，非常有意思。对数学要求不高，证明也不够好，但的确是“统计书”，不是数学书。

3、《Applied Multivariate Statistical Analysis (5th Ed影印版)》 Johnson & Wichem 著中国统计出版社
    个人认为是国内能买到的最好的多元统计书了。Amazon 上有人评论，评价很高的。不过据王学民老师说，这本书的证明还是有不太清楚，老外实务可以，证明实在不咋的，呵呵


四、时间序列

1、《商务和经济预测中的时间序列模型》弗朗西斯著
    Amazon 上五星推荐的书，讲了很多很新的东西也非常实用。我看完才知道，原来时间序列不知有AR(1) MA(1)啊，哈

2、《Forecasting and Time Series an applied approach(third edition)》 Bowerman & Connell 著
    本书的主讲Box-Jenkins(ARIMA)方法，附上了SAS和Minitab程序


五、抽样


1、《抽样技术》 科克伦著 张尧庭译
    绝对是该领域最权威，最经典的书了。王学民老师说：这本书不是那么好懂的，数学系的人，就算看得懂每个公式，未必能懂它的意思（不是数学系的人，还是别看了吧）。

2、《Sampling: Design and Analysis（影印版)》 Lohr著中国统计出版社
    讲了很多很新的方法，无应答，非抽样误差，再抽样，都有讨论。也很不好懂，当时偶是和《Advance Microeconomic Theory》一起看的，后者被许多人认为是梦魇，但是和前者一比，好懂多了。主要还是理念上的差距。我们的统计思想和数据感觉有待加强啊


六、软件及其他

1、《SAS软件与应用统计分析》王吉利张尧庭主编    好书啊！！！！

2、《SAS V8基础教程》汪嘉冈编中国统计出版社
    主要讲编程，没怎么讲统计。如果想加强SAS编程可以考虑。

3、《SPSS11统计分析教程（基础篇）（高级篇）》张文彤北京希望出版社
    当初第一次看这本书，发现怎么几乎都看不懂，尤其是高级篇，现在终于搞清楚了：）

4、《金融市场的统计分析》张尧庭著广西师范大学出版社
    张老师到底是大家，薄薄的一本书，言简意言简意赅，把主要的金融模型都讲清楚了。看完会发现，分析金融单单数学模型还是纸上谈兵，必须加上统计模型和统计方法才能真正应用。本书用的多元统计（代数知识）比较深
#


========================================
偏差信息准则 deviance information criterion (DIC),与 bayesian information criterion (BIC), AIC
----------------------------------------
The deviance information criterion (DIC) was introduced in 2002 by Spiegelhalter et al to compare the relative fit of a set of Bayesian hierarchical models.

It is similar to Akaike's information criterion (AIC) in combining a measure of goodness-of-fit and measure of complexity, both based on the deviance. 

While AIC uses the maximum likelihood estimate, DIC's plug-in estimate is based on the posterior mean. 

As the number of independent parameters in a Bayesian hierarchical model is not clearly defined, DIC estimates the effective number of parameters by the difference of the posterior mean of the deviance and the deviance at the posterior mean. 

This coincides with the number of independent parameters in fixed effect models with flat priors, thus the DIC is a generalization of AIC. 

It can be justified as an estimate of the posterior predictive model performance within a decision-theoretic framework and it is asymptotically equivalent to leave-one-out cross-validation. 

The DIC has been used extensively for practical model comparison in many disciplines and works well for exponential family models but due to its dependence on the parametrization and focus of a model, its application to mixture models is problematic. 

Keywords: Bayesian model comparison; posterior predictive accuracy; BIC; AIC; WAIC; scoring rule; cross-validation; decision theory; Kullback–Leibler information










========================================
1.事件与概率，及概率曲线
----------------------------------------
1. 概念的定义

(1)随机事件
 
条件相同可以重复进行
结果多样
实验前不知道结果

比如，丢色子；


(2)样本空间
所有事件的基本结果，用 欧米伽Ω 表示。

比如：丢6面色子有6个结果。
但是偶数面朝上，包含{2,4, 6}三个基本结果。







========================================
|-- 基本概率公式: 加法公式、乘法公式
----------------------------------------
加法规则 P(x)=累加( y, p(x,y) ); 也叫全概率公式

乘法规则 P(x, y)=P(x)P(y|x);
	可以推导 P(x,y)=P(y)P(x|y)=P(x)P(y|x) 得到贝叶斯公式 P(x|y)=P(y|x)P(x)/P(y);
#	






========================================
|-- f(x)=F'(x): 概率密度函数; F(x)=P(X<x)概率分布函数
----------------------------------------
对于密度函数f(x)，F(x)不可导的地方都取0；
对于F(x)，分界线等于值都给到大于，因为是右连续的。



1. f(x)=F'(x): 概率密度曲线(probability density curve) pdf曲线 /density
钟形曲线，根据情况带偏斜程度。


在数学中，连续型随机变量的概率密度函数（在不至于混淆时可以简称为密度函数）是一个描述这个随机变量的输出值，在某个确定的取值点附近的可能性的函数。

随机数据的概率密度函数：表示瞬时幅值落在某指定范围内的概率，因此是幅值的函数。它随所取范围的幅值而变化。


https://www.jianshu.com/p/70b188d512aa
图中曲线称为概率密度函数, 简称为pdf
pdf的曲线下面积(AUC)总和为1
曲线末端不会接触到x轴(换句话说, 我们不可能100%的确定某件事)

 







############
2. F(x)=P(X<=x): 概率分布函数; 概率累积曲线(probability cumulative curve) CDF曲线 /stat_ecdf

从0逐步上升到1的曲线。
对于每个观测值，一个经验累计分布函数（empirical cumulative distribution function，ECDF）显示小于该值的点的百分比。由于点的个数是有限的，经验累计分布函数是一个阶梯函数。

#概率累积曲线(probability cumulative curve)亦称粒度概率图，是一种在概率坐标纸上作出的累积曲线。
#概率纸上的纵座标是概率分度的百分数值，横座标是(等差的)算术分度的φ值，它通常是由若干直线段组成。


作用：累积分布函数是概率密度函数的积分，能完整描述一个实随机变量X的概率分布。
累积分布函数一般以大写CDF标记，与概率密度函数 probability density function（小写pdf）相对。
互补累积分布函数（complementary cumulative distribution function、CCDF），是对连续函数，所有大于a的值，其出现概率的和。


累计分布函数（The Cumulative Distribution Function, CDF）:在x点左侧事件发生的总和。
累积分布函数表示：
F(a)=P(x<=a)
对离散变量而言，所有小于等于a的值出现概率的和



实例
(1)准备数据
#https://bbs.pinggu.org/thread-3732035-1-1.html
data1=data.frame(
  id=seq(1,14),
  value=c(10,15,20,22,25,27,26,28,31,31.9,32,32.5,40,45),
  group=c(rep( c('A','B'),7))
)
data1


(2)
# https://blog.csdn.net/vv_eve/article/details/96457415
library("latticeExtra")
ecdfplot(~value|group, data=data1)
ecdfplot(~value, data=data1,group=group) #增得快，表示x轴这个位置数据多
#斜率最大的地方表示，概率密度曲线的峰值，也就是p值最大的点(看x坐标值)。

ref:
##原例
ecdfplot(~ gcsescore | factor(score), data = Chem97, 
         groups = gender, auto.key = list(columns = 2),
         subset = gcsescore > 0, xlab = "Average GCSE Score",
         main=" Figure 3.8 ")
#ecdfplot-->累积概率密度图; 
#subset函数,从某一个数据框中选择出符合某条件的数据或是相关的列



(3)#ggplot()+stat_ecdf()
library(ggplot2)
ggplot(data1,aes(x=value,color=group))+stat_ecdf()




ref:
https://baike.baidu.com/item/%E7%B4%AF%E7%A7%AF%E5%88%86%E5%B8%83%E5%87%BD%E6%95%B0/7763383?fr=aladdin
https://blog.csdn.net/wangyj705/article/details/81976455





========================================
2.一维随机变量及其分布
----------------------------------------

常见的一维随机变量的分布：
离散型：二项分布-负二项分布、泊松分布、几何分布；
连续型：均匀分布、正态分布、指数分布；






========================================
|-- 离散型 之 泊松分布 Poisson distribution
----------------------------------------
关于泊松分布，不算特别好理解。可以参考资料：
http://www.ruanyifeng.com/blog/2013/01/poisson_distribution.html
http://maider.blog.sohu.com/304621504.html

1. 泊松分布主要满足3个条件：
（一）A为小概率事件
（二）A发生概率是稳定的
（三）A与下一次A事件的发生，是相互独立的

#泊松分布适合于描述单位时间（或空间）内随机事件发生的次数（事件发生的次数只能是离散的整数）。
#如某一服务设施在一定时间内到达的人数，电话交换机接到呼叫的次数，汽车站台的候客人数，
#机器出现的故障数，自然灾害发生的次数，一块产品上的缺陷数，显微镜下单位分区内的细菌分布数等等。

#P(X=k)=lambda^k/k!*e^lamda, k=0,1,2
#对于泊松分布而言，其均值和方差是相等的。而我们的测序数据，通常方差比均值还大，怎么办？

#λ是波松分布所依赖的唯一参数。 λ值愈小分布愈偏倚， 随着λ的增大 ， 分布趋于对称。 
#当λ=20时分布接近于正态分布；当λ=50时， 可以认为波松分布呈正态分布。



(2)Density, distribution function, quantile function and random generation for the Poisson distribution with parameter lambda.
dpois(x, lambda, log = FALSE)
ppois(q, lambda, lower.tail = TRUE, log.p = FALSE)
qpois(p, lambda, lower.tail = TRUE, log.p = FALSE)
rpois(n, lambda)
lower.tail = FALSE允许在默认情况下获得更精确的结果，lower.tail = TRUE将返回1


#产生泊松分布的点
points=rpois(300, lambda=4) #points
plot(density(points))



(3)#泊松分布 (poisson)
library(RColorBrewer)
display.brewer.all()
#
par(mar=c(5, 4, 4, 5))
n=6
color2=brewer.pal(n,"Dark2") #11个
#
for(i in seq(1,n) ){
  print(i)
  if(i==1){
    plot(dpois(0:15, lambda = 1), col = color2[i], xlim = c(-1,15), type="o",
         pch=i,
         xlab = "n", ylab = "Probability", main = "Poisson Distribution")
  }else{
    lines(0:15, y=dpois(0:15, lambda = i),col =color2[i], type="o",pch=i)
  }
}
#
legend("topright", legend=seq(1,n), 
       #inset=-0.15,xpd=TRUE,
       box.col="white",
       lty=1, pch=seq(1,6), col=color2)
box()
###end





2.一家医院，统计下来平均每分钟接待2个客人，问假设某次一分钟接待4个客人的概率是：
dpois(4, lambda = 2) #[1] 0.09022352
其中，参数2为泊松分布公式中的λ * t

泊松分布概率分布律图：
plot(dpois(0:30, lambda = 2), col = "red", xlim = c(-1,30), xlab = "发生次数", ylab = "概率", main = "泊松分布图")





3. 假设检验
poisson.test(x, T = 1, r = 1, alternative = c(“two.sided”, “less”, “greater”), conf.level = 0.95)

例: 
poisson.test(137, 24.19893)

##
## 		Exact Poisson test
## 
## data:  137 time base: 24.19893
## number of events = 137, time base = 24.199, p-value < 2.2e-16
## alternative hypothesis: true event rate is not equal to 1
## 95 percent confidence interval:
##  4.753125 6.692709
## sample estimates:
## event rate 
##   5.661407 





4. 基因表达量的分布不符合泊松分布。

横坐标为基因在所有样本中的均值，纵坐标为基因在所有样本中的方差，直线的斜率为1，代表泊松分布的均值和方差的分布。
可以看到，真实数据的分布是偏离了泊松分布的，方差明显比均值要大。

如果假定总体分布为泊松分布， 根据我们的定量数据是无法估计出一个合理的参数，能够符合上图中所示分布的，这样的现象就称之为over dispersion。

由于真实数据与泊松分布之间的overdispersion，选择泊松分布分布作为总体的分布是不合理。

以上只证明了泊松分布是个不太恰当的分布估计，那怎么证明负二项分布就是合适的分布估计呢？



refer:
https://blog.csdn.net/qq_33335484/article/details/80389807



========================================
|-- 离散型 之 二项分布与负二项分布 (negative binomial)
----------------------------------------
1. 二项分布

dbinom(x, size, prob, log = FALSE)
pbinom(q, size, prob, lower.tail = TRUE, log.p = FALSE)
qbinom(p, size, prob, lower.tail = TRUE, log.p = FALSE)
rbinom(n, size, prob)

二项分布描述的是n重伯努利实验，在n重贝努利试验中，事件A恰好发生x(0≤x≤n)次的概率为：
Pn(x)=C(n,x)*p^x*(1-p)^(n-x)
参数n和p

#pic1
library(RColorBrewer)
display.brewer.all()
color2=brewer.pal(n,"Dark2")
i=2
plot(dbinom(0:100, size= i*20, prob=0.3), col = color2[i], xlim = c(0,25), type="o",
     pch=i,
     xlab = "n", ylab = "Probability", main = "Binomial Distribution")
text(20,0.12,"size=40,prob=0.3",col=color2[i])



#pic2
data=rbinom(n=10000,size=40,prob=0.3)
plot(density(data))









2.负二项分布
(Negative binomial distribution)。在实际生活中，我们可以使用负二项分布描述某种机器在坏掉前，能够工作的天数的分布；某运动员在获取r个奖牌前失败次数的分布等等。

负二项分布也基于伯努利试验，其定义有下面两种形式：

在一系列伯努利试验中，失败次数到达指定次数时，成功次数的离散概率分布
在一系列伯努利试验中，成功次数到达指定次数（记为r）时，失败次数（记为k）的离散概率分布

这两种定义只是将“成功”和“失败”对调，其本质上没差别。由于R中相关函数都采用第二种形式，因此下面将以第二种形式为例。



dnbinom(x, size, prob, mu, log = FALSE)
pnbinom(q, size, prob, mu, lower.tail = TRUE, log.p = FALSE)
qnbinom(p, size, prob, mu, lower.tail = TRUE, log.p = FALSE)
rnbinom(n, size, prob, mu)

负二项分布描述的也是伯努利实验，不过它的目标事件变成了：
对于Bernoulli过程，我们设定，当某个结果出现固定次数的时候，整个过程的数量，比如我们生产某个零件，假设每个零件的合格与否都是相互独立的，且分布相同，那么当我们生产出了r=5个不合格零件时，一共生产了多少合格的零件，这个数量就是一个负二项分布，公式如下：
f(k;r;p)=P(x=k)=C(r+k-1, k)*p^k*(1-p)^r

该公式描述的是，在合格率为p的一堆产品中，进行连续有放回的抽样，当抽到r个次品时，停止抽样，此时抽到的正品正好为k个的概率
它的概率分布如下：

#pic1
library(RColorBrewer)
display.brewer.all()
color2=brewer.pal(n,"Dark2")
i=2
plot(dnbinom(0:100, size= i*1, prob=0.1), col = color2[i], xlim = c(0,65), type="o",
     pch=i,
     xlab = "n", ylab = "Probability", main = "negative binomial distribution")
text(30,0.03,"size=2,prob=0.3",col=color2[i])

#pic2
data=rnbinom(n=10000,size=2,prob=0.1)
plot(density(data))



负二项回归。同泊松计数回归不同是，在负二项回归中假设方差大于均值，这种情形为通常称为过度离散(over dispersion)，相反，若方差小于均值，称之为低扩散(under dispersion)。负二项回归可以有效地对过离散数据建模，

负二项分布的均值和方差分别为:
mu=p*r/(1-p)
Sigma的平方  σ^2=p*r/(1-p)^2

将p用mu表示，得到：
p=mu/(mu+r)
1-p=r/(mu+r)

将上一步推出的p和1-p带入到方差的表达式中，得到
σ^2=p*r/(1-p)^2=mu^2/r + mu

记1/r=alpha，则
σ^2 = mu + alpha*mu^2 > mu

可见，方差是均值的二次函数，方差随着均值的增加而进行二次函数形式的递增，正好符合上文。
其中alpha和r称为dispersion parameter


负二项分布与泊松分布的关系，可以用α或r推出：
当 r -> ∞ 时，α -> 0，此时 σ2= μ，为泊松分布；
当 r -> 0 时，α -> ∞，此时 overdispersion



(2)
同泊松计数回归不同是，在负二项回归中假设方差大于均值，这种情形为通常称为过度离散(overdispersion)，相反，若方差小于均值，称之为低扩散(underdispersion)。

易见，这个负二项回归模型的方差为均值的二次函数，因此也被称为NB2模型。当时，NB2模型退化为泊松回归模型。负二项回归的系数可通过牛顿迭代法获得，在R中利用MASS包的glm.nb函数求取。最后一个问题，对于计数型数据集，如何判断它是否过度离散。因为在NB2中

σ^2=mu =alpha*mu^2

而在泊松回归中均值和方差相等，因此只需判断是否等于0，可通过R中的AER::dispersiontest函数实现。
具体的推导过程可参见Cameron和Trivedi在1990对这一问题的论述。


案例:
MASS包中的 quine 数据集描述了新南威尔士农村学校旷课情况，该数据集记录146个学生的宗教信仰(Eth), 性别(Sex),年龄(Age) ,学习状态(Lrn),旷课天数(Days)五个指标。我们想通过这一数据集合研究旷课天数与其他因素之间的关系。

library(MASS)
library(AER)
library(COUNT)

首先检查数据是否过度离散，先进行泊松回归，然后使用dispersiontest函数对泊松回归结果进行检测，看alpha是否大于0，注意需设置dispersiontest函数中的trafo=1，否则认为alpha大于1过离散。

po <- glm(Days ~ Sex+Age + Eth +Lrn, data = quine,family=poisson)
dispersiontest(po,trafo=1)
## 	Overdispersion test
## 
## data:  po
## z = 5.469, p-value = 2.263e-08
## alternative hypothesis: true alpha is greater than 0
## sample estimates:
##    alpha 
## 11.53013

过离散测试中alpha=11.53013,因此泊松回归不能有效反映这组数据真实特征，下面采用负二项回归研究这组数据

nb <- glm.nb(Days ~ Sex+Age + Eth +Lrn, data = quine)
#
list(nb=unlist(modelfit(nb)), po=unlist(modelfit(po)))
## $nb
##         AIC        AICn         BIC       BICqh 
## 1109.151018    7.596925 1130.036265    7.687628 
## 
## $po
##        AIC       AICn        BIC      BICqh 
## 2299.18363   15.74783 2320.06888   15.83854 

结果表明，对于quie数据集，在各项指标下，负二项回归都远比泊松回归好。

> nb
## 
## Call:  glm.nb(formula = Days ~ Sex + Age + Eth + Lrn, data = quine, 
##     init.theta = 1.274892646, link = log)
## 
## Coefficients:
## (Intercept)         SexM        AgeF1        AgeF2        AgeF3         EthN        LrnSL  
##     2.89458      0.08232     -0.44843      0.08808      0.35690     -0.56937      0.29211  
## 
## Degrees of Freedom: 145 Total (i.e. Null);  139 Residual
## Null Deviance:	    195.3 
## Residual Deviance: 168 	AIC: 1109






3. 方差估计
在生物学重复很少时，我们是很难准确计算每个基因表达的标准差的（相当于这个数据集的离散程度）。我们很可能会低估数据的离散程度。

被逼无奈的科学家提出了一个假设：表达丰度相似的基因，在总体上标准差应该也是相似的。我们把不同生物学重复中表达丰度相同的基因的总标准差取个平均值，低于这个值的都用这个值，高于这个值的就用算出来的值。

（图来自 H. J. Pimentel, et al. Differential analysis of RNA-Seq incorporating quantification uncertainty. bioRxiv, 2016）



(2)
然后为了建模，本来需要估计负二项分布的两个值，均值和方差，但是发现方差其实可以用均值和dispersion表示，于是就只要求均值和dispersion就行了。有了这两个值，就开以进行广义线性模型建模，就可以搞p值，找差异基因对吧。

另外，还有一个比较重要的值叫做Log Fold Change,这个受count数影响很大，原因是count数据是方差不齐性的，方差跟他的count均值有很大关系。

如果你的样本没有重复，那么你只要自己给每个基因都来一个dispersion就能算你最可爱的p值了，然后在低count，高LFC的基因留个心眼就行了。













refer: 
1.https://www.jianshu.com/p/ad24bb90b972
2.https://mp.weixin.qq.com/s/UTmSzCgDIFYbG2WByzaqQQ / http://www.jintiankansha.me/t/QicEQRzHra
3.转录组差异表达筛选的真相
https://mp.weixin.qq.com/s/VcjnvI5FqwOFEC9wSUfdSw

4.数萃大数据 2018-09-16 数据分析师应该知道的16种回归方法：负二项回归

5.负 字从何而来？ https://www.zhihu.com/question/24253978
6.R统计学(06): 负二项分布 https://www.jianshu.com/p/d60252dfb8ec
7.英文公开课:http://open.163.com/movie/2017/5/5/6/MCJQECVBF_MCL7VIT56.html 




========================================
|-- 离散型 之 几何分布 X~G(p)
----------------------------------------
几何分布：事件成功的概率为p，尝试第k次时才第一次成功，则k的分布符合几何分布。
P(X=k)=p*(1-p)^(k-1); (k=1,2,3,...)

1.产生几何分布随机变量(R中的几何分布k是成功前的实验次数，从0开始，要转换成一般定义的几何分布的k)
k=rgeom(1000,0.5)+1;k
hist(k)



2.




========================================
|-- 连续型 之 均匀分布 X~U(a,b)
----------------------------------------




========================================
|-- 连续型 之 指数分布 X~E(lambda)
----------------------------------------
1.
密度函数
f(x)={ lambda*e^(-lambda*x), x>=0; 0, x<0

分布函数:
F(x)={0, x<0;  1-e^(-lambda*x), x>=0;


##
2. 等价转换




========================================
|-- 连续型 之 正态分布( normal distribution /Gaussian又叫高斯分布 X~N(mu,sigma^2) ) 与 over dispersion(过度离散) 
----------------------------------------
1. 正态分布

dnorm(x, mean = 0, sd = 1, log = FALSE)
pnorm(q, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE)
qnorm(p, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE)
rnorm(n, mean = 0, sd = 1)


#pic0
x <- seq(-4, 4, length.out = 100)
p <- dnorm(x, mean = 0, sd = 1)
plot(x, p, type = 'l', lwd = 2, col = "red",
     xlab = "Residual", ylab = "Density")
#


#pic1
library(RColorBrewer)
display.brewer.all()
color2=brewer.pal(n,"Dark2")
i=2
plot(dnorm(0:100, mean= i*10, sd=4), col = color2[i], xlim = c(0,100), type="o",
     pch=i,
     xlab = "n", ylab = "Probability", main = "Normal Distribution")
text(40,0.095,"mean=20,sd=4",col=color2[i])
#


#pic1.2
x <- seq(0, 40, length.out = 100)
p=dnorm(x, mean= i*10, sd=4)
plot(x,p, col = color2[i], xlim = c(0,40), type="l", lwd=2,
     xlab = "n", ylab = "Probability", main = "Normal Distribution")
text(28,0.095,"mean=20,sd=4",col=color2[i])
#


#pic2
data=rnorm(n=10000,mean=20,sd=4)
plot(density(data))
#






2. What does under or over-dispersion look like?
https://www.r-bloggers.com/what-does-under-or-over-dispersion-look-like/

(1) 正态分布
x <- seq(-4, 4, length.out = 100)
p <- dnorm(x, mean = 0, sd = 1)
plot(x, p, type = 'l', lwd = 2, col = "red",
    xlab = "Residual", ylab = "Density")
#

(2)更离散的分布， add an over-dispersed curve using the Student t distribution
p_t <- dt(x, df = 1.4, ncp = 0)

plot(x, p, type = 'l', lwd = 2, col = "red",
    xlab = "Residual", ylab = "Density")
lines(x, p_t, col = "darkblue", lwd = 2)

(3)更不离散的分布draw an under-dispersed distribution, using the Laplace distribution
library(rmutil)
p_l <- dlaplace(x, m = 0, s = 0.4)


(4) 以上三个图合起来
plot(x, p_l, xlim = c(-4, 4), lwd = 2, xlab = "Residuals", main = "", type = "l")
lines(x, p, col = "red", lwd = 2, lty = 2)
lines(x, p_t, col = "darkblue", lwd = 2)
legend("topright", legend = c("normal", "under-dispersed", "over-dispersed"),
      lty = c(2,1,1), col = c("red", "black", "darkblue"), lwd = 2)
#

(5) 画QQ图是检查是否符合正态分布的重要标准(注意：怎么理解QQ图？)
plot them on a normal QQ plot, which you may be familiar with. It is
one of the standard checks of model residuals:

set.seed(1997)
par(mfrow = c(1,3))
qqnorm(rnorm(1000, mean = 0, sd = 1), main = "normal")
abline(0,1)
qqnorm(rt(1000, df = 1.4, ncp = 0), main = "over-dispersed")
abline(0,1)
qqnorm(rlaplace(1000, m = 0, s = 0.4), main = "under-dispersed")
abline(0,1)

# 我的理解：QQ图取的是样品和理论值的百分位数字。
第一个值1%位置就是最小的值，过度离散的样品由于扁平分布，很小的地方(-60)还有值，而正态分布在-3位置已经是最小值了。
在100%分位数是最大值，过度离散样本最大值很大(250)，而正态分布最大值在3左右。
中间的部分则比较接近，在0的位置是相等的。


#改变参数，能加深对结果的理解。

#####
# 增大Laplace分布的scale值，它会变成过离散的。因为两侧尾巴相对正态分布越来越胖(虽然中位数还有峰)。
scale for the Laplace distribution to a larger number it will become over-dispersed, 
because it gets fatter tails than the normal (despite being more peaked at its mode).


#####
# 低离散比你想象的更常见。只要有审核过程，就有可能发生。
Under-dispersion is more common than you might think. It can occur when you have a censoring process. 
比如你的机器只能测试某个精度的值，更小的值四舍五入为0了。
For instance, perhaps your machine can only measure length’s to a certain precision and any distance that is to small gets rounded down to zero.





3. Overdispersion
https://en.wikipedia.org/wiki/Overdispersion

When the observed variance is higher than the variance of a theoretical model, overdispersion has occurred. 
当观察到的变异高于理论模型时，过离散就出现了。

Conversely, underdispersion means that there was less variation in the data than predicted.
相反，低离散意味着观察到的变异比期望的更少。

在应用数据分析中，过度离散是一个非常常见的特征，因为在实践中，总体常常是异质性的(非均匀的)，这与广泛使用的简单参数模型中隐含的假设相反。








========================================
|-- z-标准化 / Z-normalization
----------------------------------------

https://jmotif.github.io/sax-vsm_site/morea/algorithm/znorm.html

公式
x′i=(xi−μ)/σ, where i∈N


R代码：
z-normalization can be coded as a simple R function:

znorm <- function(ts){
  ts.mean <- mean(ts)
  ts.dev <- sd(ts)
  (ts - ts.mean)/ts.dev
}

s1_znorm=znorm(series1)
s2_znorm=znorm(series2)








========================================
|-- qqplot和qqnorm有什么区别
----------------------------------------
1.QQ图的主要作用是判断样本是否近似于某种类型的分布，这里的“QQ”是两个Quantiles的大写字母，即两个分位数，一个是样本分位数（Sample Quantiles），一般画在纵轴，一个是理论分位数（Theoretical Quantiles），一般画在横轴。

n <-rnorm(1000, 0, 1) #生成1000个均值为0，方差为1的正态分布样本
qqnorm(n) #做变量n的QQ图
abline(0,1) #画一个截距是0，斜率是1的直线

这个（x,y）形式的二维的散点图的坐标是如何确定的?
要回答这个问题需要先从qqnorm()入手，把QQ图的结果保存到变量中，再对这个变量进行分析。

# q是一个列表变量
q<- qqnorm(n) # 将变量n的QQ图的结果保存到变量q中
str(q)
q$x[1:5]
q$y[1:5]

变量q$y是样本分位数，也是刚才随机产生的1000个样本的值，即和变量n是完全一样的，为了验证，如果运行下面的代码，会得到1000个“TRUE”

table(n == q$y)

接下来讨论这个q$x，q$x是理论分位数，之所以是“理论”，指的是如果按照正态分布的假设（qqnorm对应的是正态分布假设，qqpois对应的是泊松分布的假设），这个分位数的理论值应该是多少。

例如如果有5个样本，那么理论分位数应该给出的是20%，40%，60%，80%，100%的分位数，但是100%的分位数一般会无限大，因此在这里需要进行一下数据处理，找一个“近似”的理论样本，来替代“真正”的理论样本。在这里问题就在这个“近似”的理论样本的数据处理方法。举个例子，假设P()为正态分布函数，是正态分布函数的反函数，假设一共有N个样本，则第n个样本的“真正”的理论样本分位数应该是 


直线由四分之一分位点和四分之三分位点这两点确定的，四分之一分位点的坐标中横坐标为实际数据的四分之一分位点(quantile(data,0.25)),纵坐标为理论分布的四分之一分位点(qF(0.25)),四分之三分位点类似，这两点就刚好确定了QQ图中的直线。

##理论x1=qnorm(0.25,0,1)
##实际y1=quantile(n,0.25)
qqnorm(n)
# points(qnorm(0.25,0,1), quantile(n,0.25), col='red',type="p",lwd=5)
x2=c(qnorm(0.25,0,1),qnorm(0.75,0,1))
y2=c(quantile(n,0.25),quantile(n,0.75))
reg=lm(y2~x2)
reg
abline(reg,col='blue')


//todo?? 公式不清楚




## N=100#设定样本数量，可以将100改为别的数进行验证
d <- matrix(nrow= N ,ncol= 3)#生成一个N *3的矩阵
d[,1]<-1:N #给每一次N的值编上序号
for(i in 2:N){ #从i=2开始计算，一直计算到i=N
  x <- rnorm(i,0,1) #生成均值为0,、方差为1的i个数的样本，保存到x
  y <- qqnorm(x) #生成样本x的QQ图，保存到变量y
  yy <- sort(y$x) #将QQ图中的理论样本值保存到变量yy中
  yyy<- pnorm(yy,0,1) # 计算分位数yy的概率，保存到yyy中
  a <- 1:i
  ayyy<-lm(a~yyy) #计算公式“ayyy=a*系数+截距”中的参数
  b <-summary(ayyy)$coefficients
  d[i,2]<-b[1,1] #将截距保存到第二列
  d[i,3]<-b[2,1] #将系数保存到第三类
}
d






########

qqplot应该是两样本的正态性对比，而qqnorm应该是样本与样本期望的正态性对比。
在R里面如果单是qqplot(x)，其中x为一组样本，运行时会出错的，但qqnorm(x)就不会……

其实关于这个问题我也不是很确定，只是之前尝试得到的一些经验。具体你可以查R里面的help()，那里对于两者的参数设置会比较详细









========================================
|-- lognormal-like ditribution 及其平均数(几何平均值)的计算
----------------------------------------

1.画分布图
(1)
# 分布符合lognormal-like ditribution, 则要求几何平均数
hist(rlnorm(1000, meanlog = 0.1, sdlog = 0.500), n=300)
hist(rlnorm(1000, meanlog = 0.1, sdlog = 1.00), n=300)
hist(rlnorm(1000, meanlog = 0.1, sdlog = 2.00), n=300)

#
hist(rlnorm(1000, meanlog = 0.1305, sdlog = 0.018), n=300)



(2)
to create a lognormal distribution, you can use the property that if X follows a log-normal distribution and Y = ln(X), then Y follows a normal distribution.

(A positive random variable X is log-normally distributed if the logarithm of X is normally distributed.)
https://en.wikipedia.org/wiki/Log-normal_distribution

plot_lnormal=function(sd=0.5){
  set.seed(1234)
  dist <- rnorm(1000, 1, sd)
  ldist <- exp(dist)
  hist(ldist)
}
plot_lnormal(sd=0.1)
plot_lnormal(sd=0.5)
plot_lnormal(sd=1)
plot_lnormal(sd=1.5)
#





2.几何平均数的计算公式

(1) 几何平均数分为简单几何平均数和加权几何平均数两种。
1)简单几何平均数
G = (X1*X2*...*Xn)^(1/n);

2)加权几何平均数
G = (X1^f1 * X2^f2 * ... *Xn^fn)^(1/(f1+f2+...+fn));


(2) 使用R语言计算
G = (X1*X2*...*Xn)^(1/n);
取对数后
ln(G)=1/n * ln(X1*X2*...*Xn)= mean(ln(X))
相当于求原变量的对数的算术平均值。

也就是 G=e^ mean(ln(X))
这在R中很容易实现。


例子:
已知某市2010~2014年国内生产总值的增长率（以上1年为1）分别为12%、8%、14%、16%和13%，试计算该市5年的平均增长率

编写R程序：
x <- c(12,8,14,16,13)/100
tmp <- mean(log(1+x)) #防止遇到0吗？
re <- exp(tmp) - 1
print(re) #0.1256843

# 测试增加后来又减去的的这个值，对最终结果有啥影响
testG=function(x,plusN=1){
  tmp <- mean(log(plusN+x))
  exp(tmp) - plusN
}
testG(x,0) #0.1228266 这个才是什么都不加的真实值
testG(x) #0.1256843
testG(x,10) #0.1259652
testG(x,100) #0.1259965
testG(x,1000) #0.1259996
testG(x,1000000) #0.126 极限值

# 倾向于直接算，如果有0的，跳过去。


例2：
geometry.mean <- exp(mean(log(x)))

几何平均数实现算法，要考虑到NA或负值
geo_mean <- function(data) {
    log_data <- log(data)
    gm <- exp(mean(log_data[is.finite(log_data)]))
    return(gm)
}
# https://stackoverflow.com/questions/2602583/geometric-mean-is-there-a-built-in






ref:
https://stackoverflow.com/questions/54768902/lognormal-stock-price-distribution-in-r










========================================
3.二维随机变量及其分布
----------------------------------------



三、 常见的二维随机变量
(1) 均匀分布
(X,Y) ~ f(x,y)={ 1/A, (x,y)属于D;  0, (x,y)不属于D; }

(2) 二维正态分布
(X,Y) ~ N(mu1,mu2,sigma1^2, sigma2^2, rou)
则，
X ~ N(mu1, sigma1^2)
Y ~ N(mu2, sigma2^2)
反之不成立。



(3)推论:
如果
X ~ N(mu1, sigma1^2)
Y ~ N(mu2, sigma2^2)
且X和Y独立，
则线性组合 aX+bY ~ N(a*mu1+b*mu2, a^2*sigma1^2+b^2*sigma2^2)





四、
联合概率分布，边缘概率分布：边缘就是不管另一个变量(相当于另一个变量从-无穷大到+无穷大)。


求密度函数的方法：可以先求分布函数，再求导数(不可导的地方都取0)。


见微积分Gama函数性质
(2)gama 函数
Gama(alpha)=积分 0 到+无穷大 x^(alpha-1) * e^(-x) dx
性质:
Gama(alpha+1)=alpha*Gama(alpha);
Gama(n+1)=n!
Gama(1/2)=根号 Pi

常用：积分0到+无穷大 e^(-x) dx= 积分0到+无穷大 x^0 * e^(-x) dx= Gama(1)=0!=1




五、 等价转换
1. P{min(x,2)<=y}=1-P{min(x,2)>y}=1-P{x>y, 2>y}
因为按照2分界点进行讨论时，2>y不是必然事件，就是不可能事件。
又因为必然事件和不可能事件和任何事件都独立
	- 独立的判定标准就是P(AB)=P(A)P(B)
所以：
P{min(x,2)<y}=1-P(x>y)P(2>y)
(1) y<=2时，P(2>y)=1
P{min(x,2)<y}=1-P(x>y)*1=P(x<=y) ### 习惯上往F(x)和f(x)上靠近。
=Fx(y) #就是Fx(x)在x=y点的分布函数值
(2) y>2时， p(2>y)=0
P{min(x,2)<y}=1-0=1;




========================================
4.随机变量的数字特征(常见的4个): 数学期望、方差、协方差与相关系数
----------------------------------------
1. 数学期望 

(1)定义：
1)一维离散型 P(X=xi)=pi, E(X)=累加(Xi*pi)

2)一维连续型 X~f(x), E(X)=积分(-无穷大, +无穷大) x*f(x) dx;
如果 Y=T(X),则 E(Y)=E(T(x))=积分(-无穷大, +无穷大) T(x)*f(x) dx;

应用: E(X^2)=积分(-无穷大, +无穷大) x^2*f(x) dx;

3) 二维离散：
E(X+Y)=累加(i=1,m) 累加(j=1,n) (xi+yj)*pij;
E(X^2+Y^2)=累加(i=1,m) 累加(j=1,n) (xi^2+yj^2)*pij;

4) 二维连续：
(X,Y)~f(x,y),
如果 Z=T(X,Y)
则 E(Z)=积分(-无穷大,+无穷大) dx 积分(-无穷大,+无穷大) T(x,y)*f(x,y) dy




(2)数学期望的性质
1) E(C) = C。 
2) E(aX + bY) = aEX + bEY 。
   E(X +Y) = EX + EY
   E(kX ) = kEX 。 
3) 若随机变量X,Y 相互独立，则E(XY) = EX * EY 。反之不成立。





2. 方差：反应变异程度
为了反应波动，求出变量和期望的差，为了防止这些差值正负抵消，可以求绝对值或者平方，因为绝对值会产生分段函数，不可导，所以使用平方更好。


(1)方差的定义
方差的定义 DX = E(X − EX )^2
方差的计算公式 DX = E(X^2) − (EX)^2。

(2)方差的性质
1) D(C) = 0。 
2) D(k*X ) = k^2 * DX 。
3) 设随机变量X,Y 相互独立，则
D(aX + bY) = a^2*DX + b^2*DY;

D(X + Y) = DX + DY
D(X - Y) = DX + DY





3. 常见随机变量r.v. 的EX和DX
(1) X~B(n,p) 二项分布，n重伯努利实验，某结果出现的次数k=0,1,2,...,n;
P{X=k} = C(n,k) * p^k * (1-p)^(n-k)
EX=np;
DX=npq;

(2) X~Pi(lambda) (lambda>0) 泊松分布
P{X=k}=lambda^k * e^(-lambda) / k! (k=0,1,2,...)
EX=lambda;
DX=lambda;
## 好奇怪！泊松分布的数学期望和方差都是lambda!

推导过程：
高数 1+x+ x^2/2! + ... +x^n/n!+...=e^x
EX=累加(k=0, 无穷大) k*L^k*e^(-L) /k! 
  =累加(k=1, 无穷大) L^k*e^(-L) /(k-1)!
  =L*e^(-L) * 累加(k=1, 无穷大) L^(k-1)/(k-1)!
  =L*e^(-L) * e^L
  =L
#
EX^2 = 累加(k=0, 无穷大) k^2 * L^k*e^(-L) /k! #k=0时是0，去掉。
  = 累加(k=1, 无穷大) k^2 * L^k*e^(-L) /k!
  = e^L * 累加(k=1, 无穷大) k*L^k / (k-1)!
  = e^L * 累加(k=1, 无穷大) (k-1 +1)*L^k / (k-1)!
  = e^L * [累加(k=2, 无穷大) (k-1)*L^k / (k-1)! + 累加(k=1, 无穷大) L^k / (k-1)!] #因为第一个累加k=1时为0，所以从k=2开始累加不变。
  = e^L * [ L^2 *累加(k=2, 无穷大) L^(k-2) / (k-2)! + L*累加(k=1, 无穷大) L^(k-1) / (k-1)!]
  = e^(-L)*[ L^2*e^L + L*e^L]
  = L^2 + L
#
DX=EX^2-(EX)^2=L;


(3)均匀分布 X~U*(a,b)
密度函数 f(x)={ 1/(b-a), a<x<b;  0, 其他;
分布函数 F(x)=P{X<=x}=
	0, x<a
	(x-a)/(b-a), a<=x<b
	1, x>=b
#
EX=(a+b)/2;
DX=(b-a)^2 /12;

简单积分就能推导出来；



(4) 指数分布 X~E(lambda) (lambda>0)
密度函数 f(x)={ L*e(-L*x), x>0;  0, x<=0;
分布函数 F(x)={1-e^(-L*x),x>=0;  0,x<0;

EX=1/lambda;
DX=1/lambda^2;

推导过程： 
EX=积分(-无穷大,+无穷大) x*f(x) dx 
  =积分(0,+无穷大) x*lambda*e^(-lambda*x) dx 
  =1/L * 积分(0,+无穷大) x*L*e^(-L*x) d(L*x)
  = 1/L * 积分(0,+无穷大) t*e^(-t) dt 
  = 1/L * Gama(2)
  = 1/L * 1!
  = 1/L
EX^2=积分(0,+无穷大) x^2*lambda*e^(-lambda*x) dx 
  = 1/L^2 * 积分(0,+无穷大) (L*x)^2*e^(-L*x) d(L*x)
  = 1/L^2 * 积分(0,+无穷大) t^2*e^(-t) dt
  = 1/L^2 * Gama(3)
  = 1/L^2 * 2!
  = 2/L^2
DX=EX^2-(EX)^2=2/L^2 - (1/L)^2=1/L^2;

例题: X~E(lambda), P{X>根号DX}=?
= P{X>1/L}=1-P{X<=1/L}=1-F(1/L)
= 1- [ 1-e^(-L*x) ], x=1/L>=0
= e^(-L*1/L)=e^(-1)
=1/e



(5) 正态分布 X~N(mu, sigma^2)
密度函数 f(x)=1/sqrt(2*pi) *e^[ -(x-mu)^2/(2*sigma^2) ]
(X-mu)/sigma~N(0,1)

EX=mu;
DX=sigma^2;









========================================
|-- 协方差与相关系数
----------------------------------------
4. 协方差与相关系数

(1)cooperation variation 协方差 描述两者之间的变异关系。

DX=E(X-EX)^2 =E(X-EX)(X-EX) 就是每个变量和均值的差，求平方，再求期望。
把第二个改为Y，就是
协方差 Cov(X,Y)=E(X-EX)(Y-EY)

性质：
1) Cov(X,X)=DX;


(2) 相关系数 记为Row(X,Y) 或Cor(X,Y)
Cor(X,Y)=Cov(X,Y)/sqrt(DX*DY)

性质：
Row(X,Y)=0, 则称X和Y不相关;
Row(X,Y)=1, 则称X和Y正相关;
Row(X,Y)=-1, 则称X和Y负相关;


(3)协方差的性质

2) Cov(X,Y)=E(X-EX)(Y-EY)=E(XY-X*EY-Y*EX+EX*EY)
  =E(XY)-EY*EX-EX*EY+EX*EY 
  =E(XY)-EX*EY;
# 这个就是协方差计算公式：2个随机变量的协方差=乘积的数学期望-各自数学期望的乘积。
比定义还好用。

3)Cov(X, aY1+bY2)=a*Cov(X,Y1)+b*Cov(X,Y2)
协方差的结合律。

4)D(X+Y)= Cov(X+Y, X+Y)=Cov(X,X)+Cov(X,Y)+Cov(Y,X)+Cov(Y,Y)
=DX+DY+2*Cov(X,Y)
该公式不要求X和Y互相独立。


更一般的：
D(a*X+b*Y)=a^2*DX+b^2*DY+2abCov(X,Y)


(4) 相关系数的性质
1)abs(Row(X,Y))<=1;
2)Row(X,Y)=0 <=> Cov(X,Y)=0 <=> E(XY)=EX*EY
3)Row(X,Y)=1 <=> P{Y=a*X+b}=1 (a>0) 就是X和Y是线性相关的。
4)Row(X,Y)=-1 <=> P{Y=a*X+b}=1 (a<0) 就是X和Y是线性相关的。

例题：抛硬币n次，正反面分别为X和Y，则Row(X,Y)=?
X+Y=n, Y=-X+n 
所以 P{Y=-X+n}=1
所以 Row(X,Y)=-1;


例1: 射击命中率1/5，命中为止，射击次数x，求EX;
解: k=1,2,3,...
P{X=k}=0.8^(k-1)*0.2
EX=累加(1,无穷) k*0.8^(k-1)*0.2
  =1/5 * 累加(1,无穷) k*0.8^(k-1)
#
S(x)=Sigma(n=1,无穷) k*x^(k-1)
  =Sigma(n=1,无穷) (x^k)' #求导后求和，可以先求和再求导
  =( Sigma(n=1,无穷) x^k )' #几何幂级数
  =( x/(1-x) )'
  =1/(1-x)^2
#
EX=1/5 * S(4/5)=0.2*1/0.2^2=5;

更一般的，几何分布X~G(p)，则EX=p;



例2：从学校到火车站有3个红绿灯，信号灯之间互相独立，遇到红灯的概率是2/5，遇到红灯的次数是X，求EX？
X~B(3,2/5)
EX=np=1.2



例3: X~N(1,4), Y~N(1,9),X和Y独立，Z=|X-Y|，求EZ, DZ？
解: X-Y~N(0,13);
U=(X-Y)/sqrt(13)~N(0,1)

EZ=E(|X-Y|)
  =sqrt(13)*积分(-无穷大,+无穷大) |U|*1/sqrt(2*pi) *e^(-u^2/2) du 
  =2*sqrt(13)*积分(0,+无穷大) U*1/sqrt(2*pi) *e^(-u^2/2) du #偶函数积分的性质
  =2*2*sqrt(13/(2*pi))*积分(0,+无穷大) e^(-u^2/2) d(u^2/2) #积分变换
  =2*sqrt(13/(2*pi))*Gama(1) #Gama函数的性质
  =2*sqrt(13/(2*pi))
#
EZ^2=13*E( (X-Y)/sqrt(13) )^2=13*EU^2
因为U~N(0,1), EU=0,DU=1, 所以EU^2=(EU)^2+DU=1; 所以 EZ^2=13;
#
DZ=EZ^2-(EZ)^2=13- 4*13/(2*pi)=13*(1-2/pi)



问题: (X,Y)~f(x,y), X和Y独立，则X和Y不相关，反之不成立。(不相关推不出独立)
X和Y的独立性，一般强于其不相关性。
也有等价的情况： (X,Y)~N(mu1,mu2,sigma1^2,sigma2^2,Row)，则X和Y 独立<=>不相关。

证明：
1) =>
因为X和Y独立，所以EXY=EX*EY
所以Cov(X,Y)=EXY-EX*EY=0;
Row(X,Y)=Cov(X,Y)/sqrt(DX * DY)=0;

2) <= 推不出来，反例即可
X~U(-1,1), Y=X^2;
EX=积分(-无穷大,+无穷大) x*1/2 dx=0; #奇函数
EXY=EX3=0; #还是奇函数
Cov(X,Y)=EXY-EX*EY=0;
Row(X,Y)=0; 所以X和Y不相关。
#
再看独立性：若F(x,y)=Fx(x)*Fy(y)处处成立，则称X和Y独立。
F(1/2, 1/4)=P{X<=1/2, Y<=1/4}=P{X<=1/2, -1/2<=X<=1/2} #逗号表示且
  =P{-1/2 <=x<=1/2}
  =积分(-1/2, 1/2) 1/2 dx=1/2
#
Fx(1/2)=P{X<=1/2}=积分(1/2, -1) 1/2 dx=3/8
Fy(1/4)=P{Y<=1/4}=P{-1/2<=X<=1/2}=1/2
因为 F(1/2, 1/4)!=Fx(1/2)*Fy(1/4)
所以，不能保证 F(x,y)=Fx(x)*Fy(y)处处成立,
所以，X和Y不独立。



==> 并不是所有的随机变量都有数学期望和方差。
反例: X~f(x)=1/[Pi * (1+x^2)]
满足 f(x)>=0; 积分(-,+无穷大) f(x) dx=1;
但是 EX= 积分(-,+无穷大) x/[Pi * (1+x^2)] dx 不收敛。
也就是没有数学期望，更没有方差。




========================================
5.大数定律和中心极限定理
----------------------------------------

大数定律，就是发生很多次实验的时候，频率趋近于其概率。
抛硬币，10次，正面朝上不一定是0.5，但是实验1万次时，就很接近0.5了。


一、车比雪夫不等式
设随机变量 X 的方差存在，则对任意的ε > 0，有
P{|X-EX|>=ε} <= DX/ε^2 或者 P{|X-EX|<ε} >= 1-DX/ε^2

# 在数学期望周围t范围内，曲线下面积的概率占优势，比DX/t^2大或相等。

#例: X~N(1,4), Y~N(0,16),X和Y独立，用车比雪夫不等式估计P{|X-Y-1|<10}>=___
解: X+Y~N(1,20);
E(X+Y)=1, D(X+Y)=20;
P{|X-Y-1|<10}=P{|X+Y-E(X+Y)|<=10} >= 1- D(X+Y)/10^2=1-20/100=0.8;
#



二、大数定律(3个，注意它们的条件差异)

1、（车比雪夫大数定律）设随机变量X1,X2,...,Xn,... 相互独立，DXi 存在且 DXi≤M0 (i=1,2,...)，则对任意的 ε>0，有 lim(n->无穷大) P{|E(Xi) - E(EX)|<ε} =1。

通俗的说： 无数个随机变量，独立；都有方差，存在公共的方差上限；则均值概率收敛于期望的均值。
不太常用。

2、（独立同分布）设X1,X2,...,Xn,... 独立同分布，且EXi = mu, DXi = σ^2(i =1,2,...)，则对任意的 ε>0，有 lim(n->无穷大) P{|1/n*累加(i=1,n) Xi-mu|<ε}=1

通俗：一组随机变量，独立，同分布，有期望和方差(同分布，则相同)，则期望无限趋近于期望。


3、（辛钦大数定律）设X1,X2,...,Xn,... 独立同分布，且EXi= μ，则对任意的ε > 0，有 lim(n->无穷大) P{ |1/n*累加(i=1,n) Xi-mu|<ε}=1

通俗: 一组随机变量，独立，同分布，有共同期望mu，(不强调有方差)，则 均值概率收敛于期望mu。


4.（贝努利大数定律）设Xi,X2,...,Xn,... 独立同分布于参数为p 的0 −1分布，则对任意的ε > 0，有 lim(n->无穷大) P{ |1/n*累加(i=1,n) Xi-mu|<ε}=1




三、中心极限定理

1.（ Levy-Lindberg 中心极限定理） 设随机变量序列 Xi, X2,..., Xn,... 独立同分布， 且 EX =mu, DX = sigma^2 (i =1,2,...)，则对任意实数x，有
lim(n->无穷大) P{ (累加(i=1,n, Xi-n*mu) -n*mu )/sqrt(n)*sigma <= x}=1/sqrt(2*pi) * 积分(-无穷大,x) e^(-t^2/2) dt;



就是说不管n个随机变量原来什么分布，但是每个变量和，近似符合正态分布
累加(i=1,n) Xi ~ N(n*mu, n*sigma^2)



2.（拉普拉斯中心极限定理）设X ~ B(n, p)(0 < p <1)(n =1,2,...) ，则对任意实数x ，有Xn~N(np, npq)
(Xn-np)/[np(1-p)]~N(0,1)

例: X~B(100, 1/10), 用中心极限定理，估计P{X<=16} 约等于__?
解: X 近似 N(np,npq) 也即是N(10,9), 
所以 (X-10)/3~N(0,1);
P{X<=16}=P{(x-10)/3<=2}=Fai(2)


========================================
6.数理统计基础
----------------------------------------
一、 定义
1.总体 - 被研究对象的所有可能结果称为总体X。
2.样本 - 来自总体X的n个互相独立且与总体X同分布的随机变量X1,X2,...,Xn称为简单随机样本，样本X1,X2,...,Xn的观察值x1,x2,...,xn称为样本观察值。
抽样的几个原则:  
 1) X1,X2,...,Xi互相独立
 2) X1,X2,...,Xi与X同分布； 就是说抽样要有一般性：调查全国身高，要排除卫生年人、80岁以上老人、父子关系有一个抽过了(不独立了)

样本观察值: x1,x2,x3,...,xn


3.统计量 - 样本的无参函数称为统计量。

比如 (x1+x2+x2)/3, x1^2+x2*2+x3^2 都是统计量，
而 a*x1+b*x2+c*x3 不是统计量，因为包含未知参数a/b/c。

这样来看，样本有无数个统计量。


二、样本常用数字特征。

设X1,X2,...,Xn为来自总体X的简单样本，则 
1. 样本均值 X bar=1/n*累加(i=1,n, Xi)
2. 样本方差 S^2=1/(n-1) * 累加(i=1,n, Xi-X bar)^2
3. 样本的k阶原点矩 Ak=1/n * 累加(i=1,n, Xi^k), k=1,2,...
样本均值就是k=1阶原点矩。
4. 样本的k阶中心矩 Bk=1/n * 累加(i=1,n,Xi-X bar)^k, k=1,2,...
样本方差不是k=2的样本中心矩，注意1/n和1/(n+1)的区别。



========================================
|-- 常用的抽样分布(3个重要的): 卡方分布、t分布、F分布
----------------------------------------
三、常用的抽样分布(3个重要的)
1.卡方分布 χ^2
(1) 定义：随机变量X1,X2,...,Xn互相独立且都服从标准正态分布，
则称随机变量χ^2=X1^2 + X2^2+...+Xn^2 为服从自由度为n的χ^2分布，记为 χ^2~χ^2(n)。

例1: 总体Xi~N(mu, sigma^2), 1<=i<=n，取样本(X1,X2,...,Xn)

标准化 (Xi-mu)/sigma ~ N(0,1) (1<= x <=n)
则n个相互独立的标准正态分布的随机变量的和 ~N(n*mu, n^2*sigma^2) 
[(X1-mu)/sigma]^2 + [(X2-mu)/sigma]^2+...+[(Xn-mu)/sigma]^2
= 1/sigma^2 * 累加(i=1,n,(Xi-mu)^2 ) ~ χ^2(n)

例2: 总体 X~N(0,4)，则取样四个(X1,X2,X3,X4)，互相独立，
且 a*(X1-2*X2)^2 +b*(3*X3-4*X4)^2 ~χ^2(n)
求a、b、n的值。
解：正态分布标准化。
X1-2*X2~N(0,20), 则 (X1-2*X2)/sqrt(20)~N(0,1),
3*X3-4*X4~N(0, 100), 则 (3*X3-4*X4)/sqrt(100)~N(0,1),

## 如果随机事件A B C D E两两独立，则不重合的组合，如bar(A),B,E 和 C,D，也独立。

则X1-2*X2 和 3*X3-4*X4独立。
[(X1-2*X2)/sqrt(20)]^2 + [(3*X3-4*X4)/sqrt(100)]^2 ~X^2(2)

则 a=1/20,b=1/100,n=2

#
### 卡方分布的性质
1) X~N(0,1) => X^2 ~X^2(1)
2) X~X^2(n) => EX=n, DX=2*n;
3) X~X^2(m), Y~X^2(n),且X和Y独立 => X+Y ~X^2(m+n)


(2)卡方分布的概率密度函数：钟形曲线，从0开始升起，之后下降到无限接近0
a=rchisq(n=1000,df=10); hist(a,n=100)
df自由度越大，越对称。

1)下方积分面积是1。
2)如果右侧面积是a/2，则记x上该点为a/2分为点: X^2(下标 a/2)(n)

> qchisq(n=1000,df=10,p=0.05)
[1] 907.4394
> qchisq(n=1000,df=10,p=0.95)
[1] 1115.967

3) 某点左侧面积是a/2，则记该点为左分位数 X^2(下标 1-a/2)(n)

#卡方分布概率密度曲线
x=seq(0,30,1)
plot(x,dchisq(x,df=1), type="o", main="卡方分布")
points(x,dchisq(x,df=5), type="o", col="orange")
points(x,dchisq(x,df=10), type="o", col="red")
points(x,dchisq(x,df=20), type="o", col="green")

#c6=terrain.colors(10)[1:6]
c2=c('black','orange','red','green');
legend('topright', legend=c("df=1",'df=5',"df=10",'df=20'),col=c2, lty=c(2,2))

###画出0.05/2分位数
abline(v=qchisq(0.05/2, df=10), col='red')
abline(v=qchisq( 1-0.05/2, df=10), col='#FFaaaa')
#
abline(v=qchisq(0.2, df=10), col='lightgreen') #左侧曲线下面积为0.2, 曲线下面积总共为1




2. t分布
(1)定义：
总体X~N(0,1)，Y~X^2(n),X和Y独立， 
Z=X/sqrt[Y/n] #分子标准正态分布，分母是卡方分布除以自由度n(本质上也是正态分布的和再除以自由度)
则 Z~t(n)


例: 总体X~N(0,a^2), 总体取容量为15的简单样本(X1,X2,...,X15),两两独立，
记U=(X1-X2+X3-X4+...-X10)/sqrt(X11^2+...+X15^2) *(1/sqrt(2))，则U服从什么分布?

解:
正态分布的线性组合 X1-X2+X3-X4+...-X10 ~N(0,10a^2)
则标准化后 (X1-X2+X3-X4+...-X10)/sqrt(10a^2) ~N(0,1)

后几个Xi~N(0,a^2), i=11,12,13,14,15;
Xi/sigma~N(0,1), i=11,...15;
则 (X11/sigma)^2+...+(X15/sigma)^2~X^2(5);
也就是 1/sigma^2 * (X11^2+...+X15^2)~X^2(5);

分子分母没有重复变量，则独立。
(X1-X2+X3-X4+...-X10)/sqrt(10a^2) / sqrt[1/sigma^2 * (X11^2+...+X15^2) /5] ~t(5);
左边系数整理为 sqrt(sigma^2*5)/sqrt(10a^2)=1/sqrt(2)，左边就是U，所以 U~t(5).


例3: X和Y独立，X~N(0,9),Y~N(0,9),
从X抽样得到9个随机变量(X1,X2,...,X9),
从Y抽样得到9个随机变量(Y1,Y2,...,Y9).
则 U=(X1+...+X9)/sqrt(Y1^2+...+Y9^2)~?
解:
(1) X1+...+X9~N(0,81), 则(X1+...+X9)/9~N(0,1)
(2) Yi~N(0,9), 则 Yi/3~N(0,1), 1<=i<=9;
1/9(Y1^2+...+Y9^2)~X^2(9);
(3) (X1+...+X9)/9 / sqrt[1/9(Y1^2+...+Y9^2) /9] ~t(9);
左边就是 U=(X1+...+X9)/sqrt(Y1^2+...+Y9^2)


(2) 记号
t分布类似于标准正态分布。
右分位点 t(下标 a/2)(n) 表示该点右侧区线下面积为a/2.
左分位点 t(下标 -a/2)(n) 表示该点左侧区线下面积为a/2.


# t分布
x=seq(-5,5,0.1)
plot(x, dt(x,df=100), type="l",main='t分布')
points(x,dt(x,df=10), type="l", col="orange")
points(x,dt(x,df=3), type="l", col="red")
points(x,dt(x,df=1), type="l", col="green")
#
c2=c('black','orange','red','green');
legend('topright', legend=c("df=100",'df=10',"df=3",'df=1'),col=c2, lty=c(2,2))
#df越大越接近正态分布。

#t分布的0.05分位数
abline(v=qt(0.05/2, df=3),col='red',lty=2)
abline(v=qt( 1-0.05/2, df=3), col='#FFaaaa',lty=2)



3. F分布
X~X^2(m), Y~X^2(n), 且X和Y独立，记做F=(X/m)/(Y/n), 则F服从自由度为(m,n)的F分布，记做 F~F(m,n);
分别叫m和n为第一自由度，第二自由度。

(1)性质: 
如果F~F(m,n)，则 1/F~F(n,m);

(2)密度函数图形：钟形曲线，左侧从0开始，右侧无穷大。
右a/2分位数：F(下标 a/2)(m,n);
左a/2分位数: F(下标 1-a/2)(m,n);

例4: X~t(n), y=1/X^2 ~?
解: X~t(n) 则存在U~N(0,1), V~X^2(n),且U和V独立，使得X=U/sqrt(V/n)~t(n);
Y=1/X^2= V/n/(U^2/1)=F(n,1)
(V服从卡方分布，U服从正态分布，U^2/1~卡方(1))






========================================
|-- 正态总体的统计量
----------------------------------------
4. 正态总体的统计量
很多书会给出一个表格。

总体 X~N(mu, sigma^2)，取样本(X1,X2,...,Xn),

(1)样本均值 
bar(X)=(X1+...+Xn)/n ~ N(mu,sigma^2/n);

# 推导
E(X bar)=mu/n+...+mu/n=mu;
D(X bar)=1/n^2 *D(X1+...+Xn)=1/n^2 *n*DX=sigma^2/n
#
所以
(X-mu)/[sigma*sqrt(n)]~N(0,1)

(2) 样本均值的标准化，符合t分布
(X bar -mu) /[S/sqrt(n)]~t(n-1);

# 和(1)类似

(3) 
总体X~N(mu, sigma^2) =>(X1,..., Xn);
则 (Xi-mu)/sigma ~N(0,1) (1<=i<=n);
标准正态分布求和后符合卡方分布:
1/sigma^2 * 累加(i=1,n, [Xi-mu]^2)~X^2(n);

(4) 把上述中的总体均值mu替换为样本均值x bar后，也符合卡方分布，不过自由度少1:
1/sigma^2 * 累加(i=1,n, [Xi-X bar]^2)=(n-1)*S^2/sigma^2 ~X^2(n-1);

样本方差 S^2=1/(n-1) * 累加(i=1,n, [Xi-X bar]^2);

(5)ES^2=sigma^2;

S^2=1/(n-1) * 累加(i=1,n, [Xi-X bar]^2)样本方差(本质上是随机变量)的期望是总体方差。

只有样本方差的值，才是具体数字: S^2=1/(n-1) * 累加(i=1,n, [xi-X bar]^2)

# 若X~X^2(n)，则EX=n,
因为 (n-1)*S^2/sigma^2 ~X^2(n-1);
所以 E[(n-1)*S^2/sigma^2]=n-1;
左边提取常数项 (n-1)/sigma^2 * E(S^2)=n-1;
约去n-1得到 E(S^2)=sigma^2;
#

(6) X bar 与 S^2 独立。
独立就是检测 P(AB)=P(A)*P(B);



例: X~E(mu, sigma^2), 定义 T=累加(i=1,n, [Xi-X bar]^2), 求 E(X1*T)=?
解: T=(n-1)*1/(n-1)*累加(i=1,n, [Xi-X bar]^2)
  = (n-1)*S^2
#
E(X1*T)=(n-1)*E(X1*S^2)
#
因为 E(X1*S^2)=E(X2*S^2)=...=E(Xn*S^2) # 不懂??
所以 E(X1*S^2)=1/n*(EX1*S^2+...+EXn*S^2)=E[(X1+...+Xn)/n *S^2]
=E[X bar * S^2]

因为 X bar和S^2独立，
所以 E(X1*S^2)=E(X bar)*ES^2=mu*sigma^2;

所以 E(X1*T)=(n-1)*mu*sigma^2;



========================================
7.参数估计
----------------------------------------
统计学几大问题总结：
1.概念 
总体 X: r.v.
样本 (X1,X2,...,Xn), 独立且和总体同分布，又称简单样本；
  样本观察值(x1,...,xn): 抽样的个体的某个指标的具体值；
#
统计量: 没有参数的函数，无穷多个，比较有价值的有样本均值和样本方差等。

X bar:
Ak:
S^2:

2. 三个抽样分布
(1)卡方分布: n个相对独立的标准正态分布的平方和;
Xi~N(0,1), i属于[1,n]

(2) t分布 (最接近标准正态分布)
X~N(0,1), Y~X^2(n), X和Y独立，
则 X / sqrt(Y/n) ~t(n)

(3) F分布
X~X^2(m), Y~X^2(n), X和Y独立， 
(X/m) / (Y/n) ~F(m,n)


3.正态总体X~N(mu,sigma^2),则抽样(X1,X2,...,Xn) 有一些列统计量服从什么分布?
常见的6个，详见上文。


###
参数检验，假设检验(只需要20min即可入门到精通)。
傅里叶级数，也是一个模块。




1. 估计量的定义：
估计量: 用统计量 θˆ=ϕ( X1, X2, ..., Xn) 来估计未知参数θ，称该统计量为参数的估计量。

使用场景： 总体分布已知，但是含未知的参数，想根据样本的参数，来估计总体的该未知参数的值。
比如学生的英语成绩X~N(mu,sigma^2), 但是mu或者sigma未知。

(2).
点估计：估计一个具体值。theta=?
区间估计：要估计的是一个区间；P{X属于[?,?]}=1-alpha;

(3) 点估计的方法



========================================
|-- 方法1: 矩估计(使用大数定理)
----------------------------------------
辛钦大数定理: 1/n * 累加(n=1,n, Xi)概率收敛于mu;
更一般的 
EXi^k 存在，则 1/n * 累加(n=1,n, ri^k)概率收敛于 EX^k;

例1: X~G(theta), theta>0，有样本(X1,X2,...,Xn),估计 EX.
解:
EX=bar(X);
EX^2=A2=1/n * 累加(i=1,n, Xi^2);
#
p=theta;
几何分布 EX=累加(k=1,无穷大, k* (1-p)^(k-1)*p )
  = p* 累加(k=1, 无穷大, k*(1-p)^(k-1) )
#
令 S(x)=累加(n=1, 无穷大, n*x^(n-1) )=(累加[n=1,无穷大, x^n ])'
  = (x/1-x)'=1/(1-x)^2
则 EX=p*S(1-p)=p* (1/p^2)=1/p =1/theta= X bar;
theta^ =1/X bar;
这就是theta这个参数的矩估计量。




例2: 已知从总体X~N(mu, sigma^2)取样(X1,X2,...,Xn),求mu和sigma^2矩估计量。
解: EX=mu, DX=sigma^2;
则 EX^2=(EX)^2+DX=mu^2+sigma^2;

根据大数定理, 令 EX=X bar, EX^2=A2;
则 mu=X bar; mu^2+sigma^2=A1;

矩估计量 
mu^ =X bar;
sigma^2 ^=A2-X bar^2



小结: 求矩估计量的方法很简单，就是令 总体的原点矩= 样本的原点矩。
1/n * 累加(i=1, n, Xi^k) 概率P收敛于 EX^k;






========================================
|-- 方法2: 最大似然估计法
----------------------------------------
case1: 离散型
整个套路:
问题: 总体X-离散型(含参数theta)，取样本(X1,X2,...,Xn)，其观察值为(x1,x2,...,xn)
解: 
求似然函数 L(theta)=P{X1=x1}*...*P{Xn=xn}
两边取对数: ln(L(theta))=ln(P{X1=x1})+...+ln(P{Xn=xn})
求导数: 1/L(theta)=1/P{X1=x1}+...+1/P{Xn=xn}=0
导数等于0的点是极值点。
通过上式可求出theta的估计值theta^。

# 例1: 已知离散型总体X的分布如下(0<t<1/2),
X 0 1 2
P t t 1-2t
已知(X1,X2,...,X5)为其样本，0,0,1,2,2为观察值，
1)求t的最大似然估计值; 
2)求t的矩估计值;
3)如果有n个观察值，N1个0，N2个1，(n-N1-N2)个2，求t的最大似然估计量?
解:
1) L(t)=P{X1=0}*P{X2=0}*P{X3=1}*P{X4=2}*P{X5=2}
=P{X1=0}*P{X2=0}*P{X3=1}*P{X4=2}*P{X5=2} #简单随机样本，样本分布和总体一致
=t^3*(1-2*t)^2
两边同时取对数 ln(L(t))=3*ln(t)+2*ln(1-2*t)
两边求导数 d(ln(L(t))/dt=3/t-4/(1-2*t)=(3-10t)/[t*(1-2t)]=0
因为0<t<1/2，所以 t=3/10;
这既是t的最大似然估计值;
2)
EX=0*t+1*t+2*(1-2t)=2-3t
x bar=(0+0+1+1+2+2)/5=1;
根据大数定理，令EX=x bar, 
则 2-3*t=1, t=1/3;
这就是t的矩估计值。

两种方法估计的参数值不一致，哪种更好呢？后面会介绍怎么评价。

3)
估计值，是一个数字，记号 x bar, xi;
估计量，是一个随机变量，记号 X bar, Xi;

L(t)=t^(N1+N2) * (1-2*t)^(n-N1-N2)
取对数 ln(L(t))=(N1+N2)*ln(t) + (n-N1-N2)*ln(1-2*t)
求导 d(ln(L(t)))/dt=(N1+N2)/t-2*(n-N1-N2)/(1-2*t)=0
(可求出t的值；





case2: 连续型
总体X~f(x; theta)，其中theta未知，已知抽样(X1,X2,...,Xn)的观察值为(x1,x2,...,xn),求theta的估计值。

L(theta)=f(x1,t)*f(x2,t)*...*f(xn,t) #因为Xi的分布和X一样
取对数 ln(L(t))=
求导数 d(ln(L(t)))/dt=...=0;


例1:总体 X~f(x)={(t+1)*x^t, 0<t<; 0,其他; t>-1;
抽样(X1,X2,...,Xn)，求t的矩估计量和最大似然估计量；
解:
1) 矩估计量 
EX=积分(0,1, x*f(x)dx )=(t+1)*积分(0,1, x^(t+1)*dx )=


========================================
----------------------------------------

========================================
----------------------------------------

========================================
----------------------------------------


========================================
----------------------------------------

========================================
----------------------------------------

========================================
----------------------------------------


========================================
----------------------------------------

========================================
----------------------------------------

