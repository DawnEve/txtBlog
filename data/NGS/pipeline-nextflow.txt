NextFlow

Nextflow是西班牙巴塞罗那的生物医学和基因组学研究中心CRG开发的开源workflow引擎。是基于Groovy语言的一种工作流框架，能够大大简化复杂计算流程的编排工作，支持部署在本地计算机、集群、云端，同时也支持与Conda、Docker、Singularity等结合使用将流程在不同的平台之间进行迁移。


========================================
NextFlow 生物信息流程 简介
----------------------------------------
1. 简介
==> 官网
https://www.nextflow.io/
https://github.com/nextflow-io/nextflow
https://github.com/nextflow-io/nextflow/releases

https://blog.csdn.net/u011262253/category_10285121.html
纽约大学 https://learn.gencore.bio.nyu.edu/intro-to-nextflow/


(1) Nextflow: Data-driven computational pipelines
Nextflow enables scalable and reproducible scientific workflows using software containers. 
	支持容器。
It allows the adaptation of pipelines written in the most common scripting languages.
	支持几乎任意脚本语言。
Its fluent DSL simplifies the implementation and the deployment of complex parallel and reactive workflows on clouds and clusters.
	在云和集群上，很容易并行。

Nextflow 支持几乎所有的批处理调度程序（集群管理系统），包括：
	Sun Grid Engine (SGE)
	Open grid engine
	Univa grid engine
	Platform LSF
	Linux SLURM
	PBS Works
	Torque
	HTCondor

==> 相关视频
aws 的 nextflow 使用教程(没有讲语法)：
https://www.bilibili.com/video/BV1Bv411K7dB/?spm_id_from=333.337.search-card.all.click&vd_source=826befc4ac0d0fa3b98deaa3efc7f800

生信自动化分析流程 nf-core 的离线运行（图文详解）
https://blog.csdn.net/u011262253/article/details/107370353

生信自动化流程搭建 06 | 指令
https://blog.csdn.net/u011262253/article/details/107919614


(2) nextflow 管线主要内容
支持的脚本: R, Python, bash 等
依赖与环境：conda, docker, singlarity
版本控制: git, github, gitlab, bitbucket
运行时: aws, 
	grid engine; slurm;
	platform computing; kubernetes;


(3) 简单例子
$ bwa mem reference.fa sample.fq \
	| samtools sort -o sample.bam

改写后:

process align_samples{
	input:
		file 'reference.fa' from genome_ch
		file 'sample.fq' from reads_ch
	
	output:
		file 'sample.bam' into bam_ch
	
	script:
		"""
		bwa mem reference.fa sample.fq \
			| samtools sort -o sample.bam
		"""	
}

process index_sample{
	input:
		file 'sample.bam' from bam_ch 
	
	output:
		file 'sample.bam.bai' into bai_ch 
	
	script:
		"""
		samtools index sample.bam
		"""
}

(4) dataflow 
等待多个输入文件
通信通过FIFO队列：channels 频道
并行和任务依赖：隐式定义在 process 的输入和输出中。


(5) nextflow tower
管理很多任务。



(6) nextflow有专门的组学流程工具包，nfcore









2. 有一个（付费）在线会议：学习一下广告用语。

http://seqanswers.com/forums/showthread.php?t=101984
Online Workshop - Bioinformatics Pipeline Development with Nextflow (Nov 22-25, 2021)

How to manage your own data analysis pipelines using workflow management systems

When? November 22-25, 2021 9 am - 5 pm (CET)
Where? Online
Link? https://www.ecseq.com/workshops/work...ne-Course.html

Streamline your research through the development of reproducible analysis pipelines

In a nutshell
- Learn the fundamental best-practices of bioinformatic pipeline development
- Understand how workflow management systems can accelerate your research
- Use state-of-the-art, open source software to make complex analyses routine
- Perform your own custom analysis pipelines using Nextflow!


第一天：简介工作流
- Introduction to pipeline development and workflow management systems
- Introduction and overview:. Why build bioinformatic analysis pipelines at all?
- Workflow Management Systems:. What’s out there and how should I decide what to use? How do I think like an end-user?
- Where to find example pipelines, how to run them, and get a feel for what output to expect. Get familiar with the Linux command line.
- Considerations for different types of underlying computational infrastructure.
- Should my pipeline run locally, on a HPC or in the cloud? How do I make my work scalable?
- Setting up environmental dependencies and software containers. How do I make my work reproducible?
- Industry best-practices and optimising your work environment for software development.


第2-3天：使用Nextflow写工作流
- Nextflow for biological data analysis
- Understanding the concepts of dataflow: processes and channels, input and output
- Running a pipeline with Nextflow: work directory layout and process execution
- Language basics: Nextflow scripting and syntax
- Configuration options: parameters, scopes and profiles
- Execution abstraction: integrating with resource management software
- Workflow introspection: runtime metadata and handling errors
- Sharing your pipeline with online code repositories


第4天：建立自己的工作流
- Build your own analysis pipeline
- How to outline and approach a new project in pipeline development
- Getting started: building your pipeline from the ground up
- Write processes, define the workflow, add dependencies, run and test your pipeline!






ref: https://www.cnblogs.com/leezx/p/14768059.html



========================================
|-- nf-core: https://nf-co.re/
----------------------------------------
1. 项目简介
A community effort to collect a curated set of analysis pipelines built using Nextflow.

Nextflow is an incredibly powerful and flexible workflow language.

nf-core pipelines adhere to strict guidelines - if one works, they all will.

(2) 文章
https://doi.org/10.1038/s41587-020-0439-x

Correspondence | Published: 13 February 2020
Nature Biotechnology volume 38, pages276–278 (2020)
The nf-core framework for community-curated bioinformatics pipelines



2. 使用

(1)# Install nextflow
curl -s https://get.nextflow.io | bash
mv nextflow ~/bin/

(2)# Launch the RNAseq pipeline
nextflow run nf-core/rnaseq \
    --input samplesheet.csv \
    --genome GRCh37 \
    -profile docker

(3)# Install nf-core tools
pip install nf-core

# List all nf-core pipelines and show available updates
nf-core list





========================================
NextFlow 入门 (依赖 Java11)
----------------------------------------
https://github.com/nf-core/


1. Ubuntu 安装 nextflow
https://www.nextflow.io/docs/latest/getstarted.html#requirements

(1) step1: jdk11
$ sudo apt install openjdk-17-jdk-headless  # version 17.0.7+7~us1-0ubuntu1~20.04

或下载安装

$ wget https://download.oracle.com/java/17/latest/jdk-17_linux-x64_bin.tar.gz
$ tar -vxf jdk-17_linux-x64_bin.tar.gz
$ mv jdk-17.0.7 ~/software/
$ cd ~/software/

添加到路径:
$ vim /etc/profile #所有用户
$ vim ~/.bashrc #仅对当前用户
# 添加三行
JAVA_HOME=/home/wangjl/software/jdk-17.0.7
PATH=$JAVA_HOME/bin:$PATH
export JAVA_HOME PATH


重新加载环境变量
$ source ~/.bashrc

验证安装效果
$ javac -version
javac 17.0.7
$ java -version
java version "17.0.7" 2023-04-18 LTS
Java(TM) SE Runtime Environment (build 17.0.7+8-LTS-224)
Java HotSpot(TM) 64-Bit Server VM (build 17.0.7+8-LTS-224, mixed mode, sharing)


官方推荐用 jdkman 安装
https://www.nextflow.io/docs/latest/getstarted.html#requirements


(2) 安装 nextflow 
$ curl -s https://get.nextflow.io | bash
...
CAPSULE: Downloading dependency org.pf4j:pf4j-update:jar:2.3.0
CAPSULE EXCEPTION: Error resolving dependencies. while processing attribute Allow-Snapshots: false (for stack trace, run with -Dcapsule.log=verbose)
Unable to initialize nextflow environment

再试几次，终于可以了：
      N E X T F L O W
      version 23.04.1 build 5866
      created 15-04-2023 06:51 UTC (14:51 CDT)
      cite doi:10.1038/nbt.3820
      http://nextflow.io


Nextflow installation completed. Please note:
- the executable file `nextflow` has been created in the folder: /home/wangjl/Downloads
- you may complete the installation by moving it to a directory in your $PATH


转移到路径:
$ mv nextflow ~/bin/

测试 
$ nextflow -v
nextflow version 23.04.1.5866

$ nextflow help
Usage: nextflow [options] COMMAND [arg...]
...





2. 基本概念 

一个流程里可以写多个 processes，一起构成一个完整的流程。
Processes 间的通信是通过 input， output 来连接 。


简单来说，可以将process理解为流程图中的节点，而channel理解为流程图中的箭头。

channel
用于存放在process之间传递的数据。可分为队列（queue）和值（value）两种类型。

channel	/特点	/创建方法
queue	/异步、单向、消耗内容（只能读取一次）	/of , fromPath
value	/异步、单向、不消耗内容（可多次读取）	/value






========================================
|-- 入门案例 hello world：输入、输出、命令行参数
----------------------------------------
$ nextflow -version
version 23.04.1 build 5866


1. 入门案例

(0) 只有 process 的不支持了
$ cat hello1.nf
process sayHello {
    echo true

    """
    echo 'Hello world!' > file
    """
}

$ nextflow run hello1.nf -dsl1
N E X T F L O W  ~  version 23.04.1
Nextflow DSL1 is no longer supported — Update your script to DSL2, or use Nextflow 22.10.x or earlier
提示：dsl1不再支持，使用 dsl2 吧。后者必须定义 workflow。



(1) 写nf文件
$ cat hello2.nf
process sayHello{
	input:
		val cheers
	output:
		stdout
	"""
	echo $cheers
	"""
}
workflow{
	channel.of('Ciao', 'Hello', 'Holo') | sayHello | view
}

运行:
$ nextflow run hello2.nf 
N E X T F L O W  ~  version 23.04.1
Launching `hello2.nf` [serene_moriondo] DSL2 - revision: c0adb9b00c
executor >  local (3)
[b3/1c0900] process > sayHello (2) [100%] 3 of 3 ✔
Holo

Ciao

Hello



(2) 官方教程
https://www.nextflow.io/docs/latest/getstarted.html

$ cat hello.nf 
params.str = 'Hello world!'

process splitLetters {
  output:
    path 'chunk_*'

  """
  printf '${params.str}' | split -b 6 - chunk_
  """
}

process convertToUpper {
  input:
    path x
  output:
    stdout

  """
  cat $x | tr '[a-z]' '[A-Z]'
  """
}

workflow {
  splitLetters | flatten | convertToUpper | view { it.trim() }
}

$ nextflow run hello.nf
N E X T F L O W  ~  version 23.04.1
Launching `hello.nf` [lonely_liskov] DSL2 - revision: e61bd183fe
executor >  local (3)
[69/9eb7a5] process > splitLetters       [100%] 1 of 1 ✔
[fa/a75b39] process > convertToUpper (1) [100%] 2 of 2 ✔
WORLD!
HELLO

解释:
This script defines two processes. 
该脚本定义了2个过程。

The first splits a string into 6-character chunks, writing each one to a file with the prefix chunk_,
第一个把字符串分成长度为6的块，分别写入前缀是 chunk_ 的文件中。

and the second receives these files and transforms their contents to uppercase letters. 
第二个接收这些文件，把其内容转为大写字母。

The resulting strings are emitted on the result channel and the final output is printed by the view operator.

第二步中的两个处理没有先后顺序。


控制台输出的前缀“69/9eb7a5”表示文件夹，具体位置是 $PWD/work

$ ls -lth $PWD/work/69/9eb7a5212a8bd42f1e0bbd3a57fea0/
total 8.0K
-rw-rw-r-- 1 wangjl wangjl 6 May 23 19:19 chunk_aa
-rw-rw-r-- 1 wangjl wangjl 6 May 23 19:19 chunk_ab

$ cat $PWD/work/69/9eb7a5212a8bd42f1e0bbd3a57fea0/chunk_aa
Hello



==> shell 命令详解
1) printf 函数
$ printf 'hello world!\n' #只能使用单引号
hello world!
$ printf "hello world!\n"
-bash: !\n": event not found

2) split - split a file into pieces 分割文件
$ man split
split [OPTION]... [INPUT [PREFIX]]

-b, --bytes=SIZE  #put SIZE bytes per output file


$ printf 'hello world!\n' | split -b 6 -  #默认前缀是x
$ ls -lht
total 28K
-rw-rw-r--  1 wangjl wangjl    6 Jun 17 10:52 xaa
-rw-rw-r--  1 wangjl wangjl    6 Jun 17 10:52 xab
-rw-rw-r--  1 wangjl wangjl    1 Jun 17 10:52 xac
这些文件末尾不带换行的:
$ cat xaa
hello [wangjl@ZhuLab test]$ cat xab
world![wangjl@ZhuLab test]$ cat xac

添加 文件名 前缀后:
$ printf 'hello world!\n' | split -b 6 - chunk_
$ ls -lht
total 40K
-rw-rw-r--  1 wangjl wangjl    6 Jun 17 10:54 chunk_aa
-rw-rw-r--  1 wangjl wangjl    6 Jun 17 10:54 chunk_ab
-rw-rw-r--  1 wangjl wangjl    1 Jun 17 10:54 chunk_ac

3) rev - reverse lines of a file or files 按行颠倒文件
$ echo "hello" | rev
olleh

$ cat a.txt 
1234
abc
$ rev a.txt 
4321
cba






(3) 修改脚本，把大写字母改为颠倒字符串

只有修改的部分执行，其他不变的部分使用缓存。

$ echo "abcd" | rev
dcba

只修改命令：
process convertToUpper {
  input:
    path x
  output:
    stdout

  """
  rev $x
  """
}

运行时添加-resume参数：
$ nextflow run hello.nf -resume
N E X T F L O W  ~  version 23.04.1
Launching `hello.nf` [cheeky_panini] DSL2 - revision: 42dca16a3e
executor >  local (2)
[9a/6b56f1] process > splitLetters       [100%] 1 of 1, cached: 1 ✔
[ed/be428a] process > convertToUpper (2) [100%] 2 of 2 ✔
olleH
!dlrow

可以看到，第一步 splitLetters 跳过了，hash值一样，且后面注明是 cached.
建议定期清空该文件夹，以便节省磁盘空间。




(4) 命令行参数

$ nextflow run hello.nf --str 'this is a book'
N E X T F L O W  ~  version 23.04.1
Launching `hello.nf` [nostalgic_wescoff] DSL2 - revision: 42dca16a3e
executor >  local (4)
[13/af96c4] process > splitLetters       [100%] 1 of 1 ✔
[fe/52b4e6] process > convertToUpper (3) [100%] 3 of 3 ✔
i siht
ob a s
ko

可见，命令行参数--str 覆盖了nf脚本中 params.str 参数的默认值。
先截取为长度为6的字符串，然后前后反转。

注意：命令中的 --foo.bar 对应脚本中的 params.foo.bar 参数。






========================================
NextFlow 基本概念详解
----------------------------------------
https://www.nextflow.io/docs/latest/basic.html

教程:
	汇总 https://nextflow.io/blog/2023/learn-nextflow-in-2023.html
	RNA 分析流程 https://github.com/seqeralabs/nextflow-tutorial

1. 解释
nextflow 代码分为2部分，process 和 workflow。

process 构成流程的基本单元，可以将process理解为流程图中的节点，而channel理解为流程图中的箭头。

process可以包括 
	directives, 
	input, 
	output, 
	when clause, 
	script|shell|exec 等五部分


process < name > {

   [ directives ]

   input:
    <input qualifier> <input name> [from <source channel>] [attributes]

   output:
    < process outputs >

   when:
    < condition >

   [script|shell|exec]:
   < user script to be executed >
}


1) input
定义了process从哪个channel接收数据。
①只能包含1个输入块，输入块中可以包含1或多个输入声明。
②输入限定符（qualifier）声明了待接收数据的类型，包括val, file, path, env, stdin, tuple, each等。
③直接影响产生的任务数量，process会逐项消耗channel中的数据，并依次产生新任务，直到数据被完全消耗。
Nextflow会为每个任务创建一个运行目录，存放相关的文件、日志、输出等。


2) output 
定义了哪些process结果数据传输到哪个channel。
①只能包含1个输出块，输出块中可以包含1或多个输出声明。
②输出限定符包括val, file, path, env, stdout, tuple等。


3)script 
以字符串的形式定义了需要执行的命令。
①只能包含1个脚本块，脚本块中可以包含1或多行字符串。
②字符串可以通过使用单或双引号定义，而多行字符串是由三个单或双引号定义。
除了直接定义，还可以通过关键字script,shell,exec实现更加灵活的定义。
③脚本块作为bash脚本运行。


4)directives（指令）
影响process执行的可选设置，如输出相关publishDir；
调度和资源相关 executor,queue, cpus, memory, time；
异常重试相关errorStrategy, maxErrors, maxRetries等。
例如：
	tag "${prefix}"
	cpus 8
	publishDir params.outdir, mode: 'copy'

说明：
tag：给每一个过程执行命名，方便在执行日志中查看
cpus：此过程运行时的CPU数量
publishDir：结果发布路径，运行完成后将最终的结果（由output定义）拷贝（'copy'）到该路径




========================================
|-- 进程，通道和工作流（Processes, channels, and workflows）
----------------------------------------

Nextflow 工作流有三个主要部分：Processes, channels, and workflows。


1. 进程描述要运行的任务。
进程脚本可以用 Linux 平台(Bash、 Perl、 Ruby、 Python 等)执行的任何脚本语言来编写。进程为每个完整的输入集生成一个任务。每个任务都是独立执行的，不能与另一个任务交互。

在进程任务之间传递数据的唯一方式是通过称为通道(channels )的异步先进先出(FIFO)队列。

每个进程可定义一个或多个输入和输出。
进程之间的交互，以及最终管道执行流本身，都是在工作流workflow部分的IO中隐式声明的。


在下面的例子中，我们有一个包含三个元素的通道，例如，3个数据文件。我们有一个将通道作为输入的进程。由于通道有三个元素，所以该进程的三个独立实例(任务)并行运行。每个任务生成一个输出，该输出被传递到另一个通道，并用作下一个进程的输入。

channel: samples
	fastq1
	fastq2
	fastq3

process: fastqc 三个进程，分别处理
	fastqc -o ${reads}

channel: out_ch
	outdir
	outdir
	outdir

process: multiqc 一个进程，接收三个作为输入
	multiqc -o mqc_res .

chanel: mqc_ch
	outdir
	outdir
	outdir


2.工作流执行
当进程定义执行的命令或脚本时，执行程序确定该脚本在目标系统中实际如何运行。

如果未另行指定，则在本地计算机上执行进程。本地执行对于管道开发、测试和小规模工作流非常有用，但是对于大规模计算管道，通常需要高性能集群(High Performance Cluster，HPC)或云平台。

Nextflow 提供了管道的功能逻辑和底层执行平台之间的分离。通过在配置文件中定义目标执行平台，这样就可以编写一次管道，然后在计算机、计算集群或云上运行它，而无需修改工作流。

Nextflow 为批处理调度器和云平台提供开箱即用的支持，例如 Sun Grid Engine、 SLURM 作业调度器、 AWS Batch 服务和 Kubernetes。


执行环境的配置文件 nextflow.config 中定义执行环境，比如：

process {
  executor='sge'
  queue = 'cn-el6'
}




========================================
|-- Nextflow scripting language: Groovy 脚本 //todo
----------------------------------------
https://www.nextflow.io/docs/latest/script.html

1. 
Groovy User Guide  http://groovy-lang.org/documentation.html
Groovy Cheat sheet http://www.cheat-sheets.org/saved-copy/rc015-groovy_online.pdf
Groovy in Action   https://www.manning.com/books/groovy-in-action-second-edition?new=true




========================================
|-- input 的定义
----------------------------------------
1. 
(1) nf文件内
工作流外部: params.fastq="xx.fq"
process 使用: 
	input: path fastq
	或: params.fastq

在命令行中可以覆盖该参数: $ nextflow run wc.nf --fastq <input_file>



(2) 例: workflow 可以写到 process 的定义前面
$ cat wc.nf
#!/usr/bin/env nextflow
nextflow.enable.dsl=2
/* Usage: $ nextflow run wc.nf --input <input_file>
支持Java语言的两种注释 */

params.input = "WT_REP1_2_val_2.fq.gz"

workflow {
    //  Input data is received through channels
    input_ch = Channel.fromPath(params.input)

    NUM_LINES(input_ch) //process 名字的使用：类函数

    /*  Process output is accessed using the `out` channel.
        The channel operator view() is used to print process output to the terminal. */
    NUM_LINES.out.view()
}

// 惯例： process 名字大写
process NUM_LINES {
    input: path read
    output: stdout
    script:
    /* 三个双引号，能写多行命令。
	可以跨行，不用分块，不用连接。*/
    """
    printf '${read} '
    gunzip -c ${read} | wc -l
    """
}
输入是不存在的文件:
$ nextflow run wc.nf
WT_REP1_2_val_2.fq.gz 0

换一个输入文件：
$ wc -l hello.nf
26 hello.nf
$ gzip -c hello.nf > hello.nf.gz
$ nextflow run wc.nf --input=hello.nf.gz
N E X T F L O W  ~  version 23.04.1
Launching `wc.nf` [extravagant_bernard] DSL2 - revision: bb5aa3973c
executor >  local (1)
[29/9384b8] process > NUM_LINES (1) [100%] 1 of 1 ✔
hello.nf.gz 26

第三行告诉你进程已在本地执行（executor > local）。
第四行显示了进程 id 29/9384b8、进程名称、 CPU 数量、任务完成百分比以及运行了多少个进程实例。
最后一行是view操作符的输出。

像 29/9384b8 这样的十六进制数表示唯一的进程执行。这些数字也是执行每个进程的目录的前缀。
$ ls -lth work/29/9384b8abfeb50dd2ac572dd821fef4/
total 0
lrwxrwxrwx 1 wangjl wangjl 29 Jun 17 11:46 hello.nf.gz -> /home/wangjl/test/hello.nf.gz
看来程序对源文件做了个软链接。






(3) 使用参数，保存到文件 

$ cat wc2.nf
// Declare syntax version
nextflow.enable.dsl=2
// Script parameters
params.query = "/some/data/sample.fa"
params.db = "/some/path/pdb"

process blastSearch {
  input:
    path query
    path db
  output: path "top_hits.txt"
    """
    #blastp -db $db -query $query -outfmt 6 > blast_result
    #cat blast_result | head -n 10 | cut -f 2 > top_hits.txt
	cat $query $db > tmp1
	cat tmp1 > top_hits.txt
    """
}

process extractTopHits {
  input: 
	path top_hits
  output: 
	path "sequences.txt"
    """
    #blastdbcmd -db $db -entry_batch $top_hits > sequences.txt
	wc -l $db $top_hits > sequences.txt
    """
}

workflow {
   def query_ch = Channel.fromPath(params.query)
   def db_ch = Channel.fromPath(params.db)
   blastSearch(query_ch, db_ch) | extractTopHits | view
}

$ nextflow run wc2.nf //报错 todo
...
Caused by:
  No such variable: db -- Check script 'wc2.nf' at line: 25




========================================
|-- 进程 process 的 script|shell|exec，蛇棒 执行R/python脚本
----------------------------------------
https://www.nextflow.io/docs/latest/process.html


1. 使用系统变量，如 $PATH, $USER

因为都是 $开头，所以用户自己区分是使用 Nextflow variable or a Bash variable.

如果想使用系统变量，有俩个选择：
- 使用 ``` 而不是 """
- 使用 \$PATH


(1) 如果同时定义了 nf 变量和bash系统变量
$ cat in.nf
USER="tom"
process sayHello {
    output: stdout
    """
    echo 'Hello world!' $USER
    """
}

workflow{
        sayHello | view
}

使用"""是默认先替换 nf变量，再执行，结果：
$ nextflow run in.nf
Hello world! tom


=> 想使用bash变量，在$前加反斜线\，表示这个不是nf变量，执行前不替换。
USER="tom"
process sayHello {
    output: stdout
    """
    echo 'Hello world!' \$USER
    """
}

workflow{
        sayHello | view
}

$ nextflow run in.nf
Hello world! wangjl


=> 或者使用 '''，表示执行前不做nf变量替换。
USER="tom"
process sayHello {
    output: stdout
    '''
    echo 'Hello world!' $USER
    '''
}

workflow{
        sayHello | view
}

$ nextflow run in.nf
Hello world! wangjl








2. 执行脚本：shell, R, python，与 shebang(蛇棒)

默认情况下，Nextflow将流程脚本解释为Bash脚本，但您不仅限于此。

您可以使用自己喜欢的脚本语言（例如Perl，Python，Ruby，R等），甚至可以将它们混合在同一管道中。

(1) 添加蛇棒

由于解释器二进制文件的实际位置可以在各个平台上变化，因此为了使脚本更易于移植，在声明时，使用#!/usr/bin/env perl。这是使用envshell命令，后跟解释器的名称，而不是其绝对路径。

#!/usr/bin/env nextflow
#!/usr/bin/env perl


$ cat shebang.nf 
process perlStuff {
    """
    #!/usr/bin/perl

    print 'Hi there!, from perl' . '\n';
    """
}

process pythonTask {
    """
    #!/usr/bin/python

    x = 'Hello'
    y = 'world! from py2'
    print "%s - %s" % (x,y)
    """
}

workflow {
    perlStuff()
    pythonTask()
}

运行:
$ nextflow run shebang.nf 
N E X T F L O W  ~  version 23.04.1
Launching `shebang.nf` [deadly_ptolemy] DSL2 - revision: 12a14cfc3f
executor >  local (2)
[28/14c84d] process > perlStuff  [100%] 1 of 1 ✔
[fb/7718e3] process > pythonTask [100%] 1 of 1 ✔
查看：
$ cat work/28/14c84d1fbc8507a563b3f938a05195/.command.out 
Hi there!, from perl
$ cat work/fb/7718e3ae2f8ef8587819318e429a02/.command.out 
Hello - world! from py2






3. 使用条件语句控制执行的语句
必须明确指定 script: 前缀。
这其实就是 groovy 的语句。

$ cat condition.nf
mode = 'tcoffee'
params.sequences="/home/wangjl/test/a.txt"
process align {
    input:
        path sequences
    script:
    if( mode == 'tcoffee' )
        """
        echo t_coffee $sequences > out_file
        """

    else if( mode == 'mafft' )
        """
        echo mafft $sequences > out_file
        """

    else if( mode == 'clustalo' )
        """
        echo clustalo $sequences > out_file
        """
    else
        error "Invalid alignment mode: ${mode}"
}

workflow{
        align(params.sequences)
}

$ nextflow run condition.nf 
N E X T F L O W  ~  version 23.04.1
Launching `condition.nf` [elegant_agnesi] DSL2 - revision: aee301f072
executor >  local (1)
[2b/c4601f] process > align [100%] 1 of 1 ✔

$ cat work/2b/c4601fcf634ec13a22086cb835f788/out_file
t_coffee a.txt

奇怪，设置时不允许使用相抵路径，但是打印出来的又是相对路径！ //todo
原因是，运行时是在一个隔离环境中，其中的文件都是软链接。
$ ls -l work/2b/c4601fcf634ec13a22086cb835f788/
total 4
lrwxrwxrwx 1 wangjl wangjl 23 Jun 17 19:38 a.txt -> /home/wangjl/test/a.txt
-rw-rw-r-- 1 wangjl wangjl 15 Jun 17 19:38 out_file









4. Template 模板

template 就是一个 shell 脚本文件，nf 可以使用 template 函数来执行:

$ cat tpl.nf
process templateExample {
    input:    val STR

    script:
    template 'my_script.sh'
}

workflow {
    Channel.of('this', 'that') | templateExample
}

默认，查找 'my_script.sh' 文件的位置是 nf 的脚本文件 templates/ 目录，
或者是 过程定义的 module 脚本目录。
其他路径需要使用模板的绝对路径。

模板可以是任何当前环境可运行的脚本，如：
$ mkdir templates
$ vim templates/my_script.sh
#!/bin/bash
echo "process started at `date`"
echo $STR
echo "process completed"

注释:
- 模板中 $ 解释为nf变量；当运行bash模式时解释为bash变量。这对于代码编写、调试十分有利。
- 最佳实践: 模板中不要使用 \$ ，防止调试时解析错误。
- 例如，上例可以直接在 bash 中运行: 
$ STR='foo' bash templates/my_script.sh
process started at Sat Jun 17 21:27:25 CST 2023
foo
process completed


运行:
$ nextflow run tpl.nf
N E X T F L O W  ~  version 23.04.1
Launching `tpl.nf` [astonishing_tesla] DSL2 - revision: 405600ce6f
executor >  local (2)
[3d/e00652] process > templateExample (1) [100%] 2 of 2 ✔

$ cat work/3d/e00652258943212925809579456128/.command.out 
process started at Sat Jun 17 21:03:14 CST 2023
this
process completed

问题: 这里是2个输入(this, that)，为什么输出文件只有1个？ //todo



(2) 改进版，输出到标准输出
- 新增 output: stdout
- 新增 | view

process templateExample {
    input:    val STR
    output: stdout
    script:
    template 'my_script.sh'
}

workflow {
    Channel.of('this', 'that') | templateExample | view
}

运行: 标准输出是2个结果
$ nextflow run tpl.nf
N E X T F L O W  ~  version 23.04.1
Launching `tpl.nf` [distraught_yonath] DSL2 - revision: d387468d88
executor >  local (2)
[6b/bee0b7] process > templateExample (2) [100%] 2 of 2 ✔
process started at Sat Jun 17 21:32:19 CST 2023
this
process completed

process started at Sat Jun 17 21:32:19 CST 2023
that
process completed

不过，文件还是只有一个结果：
$ cat work/6b/bee0b7f2aa7bc5307027b4399c4d96/.command.out 
process started at Sat Jun 17 21:32:19 CST 2023
that
process completed







5. shell 块
和默认的 script 的区别：使用!而不是$来定义nf变量。
这样就可以同时使用nf变量和bash变量了，方便维护和阅读。

$ cat shell.nf
process myTask {
    input:
    val str

    shell:
    '''
    echo "User $USER says !{str}"
    '''
}

workflow {
    Channel.of('Hello', 'Hola', 'Bonjour') | myTask
}
注意：$USER 是bash变量，而 !{str} 是nf变量。

运行：
$ nextflow run shell.nf 
N E X T F L O W  ~  version 23.04.1
Launching `shell.nf` [shrivelled_newton] DSL2 - revision: 3f2dbfd15e
executor >  local (3)
[e6/7deddf] process > myTask (3) [100%] 3 of 3 ✔

结果依旧是只有一个，为什么少于输入个数呢？
$ cat work/e6/7deddf3ed5eea4fbbd6d0227b91b2b/.command.out 
User wangjl says Bonjour

注意： 
- shell 后使用单引号。使用双引号会导致会导致$解释为nf变量。
- !后的变量必须使用花括号。!{str}是一个合法的nf变量，而 !str 会被忽略。
- shell 也支持使用模板。模板脚本中变量定义规则同上。








6. exec 块：Native execution 原生groovy代码执行

$ cat groovy.nf
process simpleSum {
    input: val x
	output: stdout

    exec:
    println "Hello Mr. $x"
}

workflow {
    Channel.of('a', 'b', 'c') | simpleSum | view
}

运行：
$ nextflow run groovy.nf 
N E X T F L O W  ~  version 23.04.1
Launching `groovy.nf` [fervent_davinci] DSL2 - revision: e7f6ce5c0b
executor >  local (3)
[a6/330269] process > simpleSum (1) [100%] 3 of 3 ✔
Hello Mr. c
Hello Mr. b
Hello Mr. a







7. Stub 试验特性，可能改变

stub 代替 script，it is a way to perform a dry-run.



========================================
|-- input 输入：类似函数的参数
----------------------------------------
https://www.nextflow.io/docs/latest/process.html#inputs

1. 一个进程最多一个 input 块，至少包含一个输入
(1) 格式：
input:
  <input qualifier> <input name>

其中 限定符 是输入数据的类型，

(2) 限定符

Qualifier 限定符      /Semantic 语义
val    Access the input value by name in the process script.
file    (DEPRECATED) Handle the input value as a file, staging it properly in the execution context.
path    Handle the input value as a path, staging the file properly in the execution context.
env     Use the input value to set an environment variable in the process script.
stdin   Forward the input value to the process stdin special file.
tuple   Handle a group of input values having any of the above qualifiers.
each    Execute the process for each element in the input collection.



2. 实例

(1) val 类型的输入: 字面量
$ cat in_val.nf
process basicExample {
  input: val x
  exec:
    println "iprocess job $x"
}

workflow {
  def num = Channel.of(1,2,3)
  basicExample(num)
}

运行：
$ nextflow run in_val.nf
N E X T F L O W  ~  version 23.04.1
Launching `in_val.nf` [pedantic_lalande] DSL2 - revision: b0bbc6c1d8
executor >  local (3)
[90/68cb1c] process > basicExample (2) [100%] 3 of 3 ✔
iprocess job 1
iprocess job 3
iprocess job 2

可见，执行了3次，num 通道的每个值执行一次。
注意：
- 并行不能保证完成时的顺序。
- 如果进程正好只有一个输入时，可以使用管道符|作为输入。如：
workflow {
  Channel.of(1,2,3) | basicExample
}




(2) file 类型 (过时)
Nextflow 19.10.0 之前处理文件输入的标准标识符。
之后，推荐使用 path 标识符。

和path的区别： //todo




(3) path 类型

process blastThemAll {
  input: path query_file
  output: stdout
  //"blastp -query ${query_file} -db nr"
  "wc -l ${query_file}"
}

workflow {
  //def proteins = Channel.fromPath( '/some/path/*.fa' )
  def proteins = Channel.fromPath( '/home/wangjl/test/*.txt' )
  blastThemAll(proteins) | view
}


运行:
$ nextflow run in_path.nf 
0 chunk_aa.txt
2 a.txt

解释: 文件通过通道 protein 发送。进程接收后，依次执行。

还可以指定文件名
input:
	path query_file, name: 'query.fa'
或简短化:
input: path 'query.fa'


重新写：
process blastThemAll {
  input: path 'chunk_aa.txt'
  output: stdout
  "wc -l chunk_aa.txt"
}

workflow {
  def proteins = Channel.fromPath( '/home/wangjl/test/*.txt' )
  blastThemAll(proteins) | view
}
运行：
2 chunk_aa.txt
0 chunk_aa.txt
0 chunk_aa.txt

==> 这个结果很诡异。文件名不变，但是行数确实有变化。
$ wc /home/wangjl/test/*.txt
 2  2  9 /home/wangjl/test/a.txt
 0  1  6 /home/wangjl/test/chunk_aa.txt
 0  1  6 /home/wangjl/test/chunk_ab.txt
 2  4 21 total
最佳实践，nf 脚本中除了 input 中定义的文件，避免引用其他文件！


Channel.fromPath 通道工厂产生文件对象，path 也可以接收字符串路径。
- 字符必须是绝对路径，比如，/开头，或者 URI开头(file://, http://, s3://, etc)
- 不能包含特殊字符(\n, etc)

$ cat wc3.nf
process foo {
  input: path x
  output: stdout
  """
  #your_command --in $x
  wc -l $x
  """
}

workflow {
  //foo('/some/data/file.txt')
  foo('/home/wangjl/test/a.txt') | view
}

$ nextflow run wc3.nf
2 a.txt


==> stageAs 规定在工作目录中文件的命名:
process foo {
  input:
  path x, stageAs: 'data.txt'

  """
  wc -l data.txt
  """
}

workflow {
  foo('/home/wangjl/test/a.txt')
}

$ nextflow run wc4.nf
N E X T F L O W  ~  version 23.04.1
Launching `wc4.nf` [amazing_lovelace] DSL2 - revision: fbc09068a0
executor >  local (1)
[67/4b66a9] process > foo [100%] 1 of 1 ✔

$ ls -lth work/67/4b66a9bb765f7ae937931291965bd6/
total 0
lrwxrwxrwx 1 wangjl wangjl 23 Jun 19 11:02 data.txt -> /home/wangjl/test/a.txt
可见，这个文件确实被重命名为 data.txt了。




==> Multiple input files 多文件输入
path 能接受单个文件，也能接收文件集合。后者是 Groovy list数据类型。

当input是一个固定名字，而接收到一个文件集合，该文件名会被加上一个数字后缀，表示在list中的位置，比如：
$ cat echo.nf
process blastThemAll {
    input: path 'seq'
    output: stdout
    """
    echo "file: " seq*
    wc -l seq*
    """
}

workflow {
    def fasta = Channel.fromPath( "/home/wangjl/test/*.txt" ).buffer(size: 3)
    blastThemAll(fasta) | view
}

运行:
$ nextflow run echo.nf 
[33/fd14fc] process > blastThemAll (1) [100%] 1 of 1 ✔
file:  seq1 seq2 seq3
 0 seq1
 2 seq2
 0 seq3
 2 total

查看缓存文件名字:
$ ls -lth work/33/fd14fc489e6080443920cf31581286/
total 0
lrwxrwxrwx 1 wangjl wangjl 30 Jun 19 11:32 seq3 -> /home/wangjl/test/chunk_aa.txt
lrwxrwxrwx 1 wangjl wangjl 23 Jun 19 11:32 seq2 -> /home/wangjl/test/a.txt
lrwxrwxrwx 1 wangjl wangjl 30 Jun 19 11:32 seq1 -> /home/wangjl/test/chunk_ab.txt



==> wildcard 通配符 的作用。

Cardinality		/Name pattern		Staged file names
any		*		named as the source file
1	file*.ext	file.ext
1	file?.ext	file1.ext
1	file??.ext	file01.ext
many	file*.ext	file1.ext, file2.ext, file3.ext, ..
many	file?.ext	file1.ext, file2.ext, file3.ext, ..
many	file??.ext	file01.ext, file02.ext, file03.ext, ..
many	dir/*	named as the source file, created in dir subdirectory
many	dir??/*	 named as the source file, created in a progressively indexed subdirectory e.g. dir01/, dir02/, etc.
many	dir*/*	(as above)


通配符示例：
$ cat cat.nf
process blastThemAll {
    input: path 'seq?.fa'
	output: stdout
    "cat seq1.fa seq2.fa seq3.fa"
}

workflow {
    def fasta = Channel.fromPath( "/home/wangjl/test/*.txt" ).buffer(size: 3)
    blastThemAll(fasta) | view
}

$ nextflow run cat.nf 
N E X T F L O W  ~  version 23.04.1
Launching `cat.nf` [condescending_mclean] DSL2 - revision: a1e79368fe
executor >  local (1)
[c7/304dd8] process > blastThemAll (1) [100%] 1 of 1 ✔
world!1234
abc
hello

实际执行的命令:
$ cat work/c7/304dd8c1505ca96578e9cd5612102d/.command.sh
#!/bin/bash -ue
cat seq1.fa seq2.fa seq3.fa
文件列表：
$ ls -lth work/c7/304dd8c1505ca96578e9cd5612102d/
total 0
lrwxrwxrwx 1 wangjl wangjl 30 Jun 19 14:31 seq3.fa -> /home/wangjl/test/chunk_aa.txt
lrwxrwxrwx 1 wangjl wangjl 30 Jun 19 14:31 seq1.fa -> /home/wangjl/test/chunk_ab.txt
lrwxrwxrwx 1 wangjl wangjl 23 Jun 19 14:31 seq2.fa -> /home/wangjl/test/a.txt
$ cat /home/wangjl/test/chunk_aa.txt
hello $ cat /home/wangjl/test/chunk_ab.txt
world!$ cat /home/wangjl/test/a.txt
1234
abc

注意：重写名字是一个额外的特性，根本不是必须的。
正常文件名语法对于多文件也是适用的。
为了处理多文件且保持原文件名，使用变量或者通配符*。
process blastThemAll {
    input: path file
    output: stdout
    "cat $file" //保持原文件名
}
workflow {
    def fasta = Channel.fromPath( "/home/wangjl/test/*.txt" ).buffer(size: 3)
    blastThemAll(fasta) | view
}




==> 动态输入文件名字 Dynamic input file names

$ cat cat3.nf //todo 这个例子一直报错，怎么修改？
process simpleCount {
  input:
    val x
    path "${x}.txt"
  output: stdout
  """
  cat ${x}.txt | grep '>'
  """
}
workflow {
    Channel.of( "a" ) | simpleCount | view
}

解释：以上的输入文件名依赖于x的值。
这让文件在执行期间才缓存。
tip: 大多数情况下，不需要动态文件名，因为task是在自己文件夹执行的，输入文件自动保存到nf自己的文件夹中。这保证输入文件名不会互相覆盖。

一个例子：当一个任务有多个输入文件，且可能重名时。这时，一个解决方案是使用 stageAs 选项。






(4) env 输入类型
在 nf 执行上下文根据输入值，新建环境变量。

process printEnv {
    input: env HELLO
    output: stdout
    '''
    echo $HELLO world!
    '''
}

workflow {
    Channel.of('hello', 'hola', 'bonjour', 'ciao') | printEnv | view
}

运行:
$ nextflow run echo2.nf 
N E X T F L O W  ~  version 23.04.1
Launching `echo2.nf` [backstabbing_mcnulty] DSL2 - revision: ced3fe032c
executor >  local (4)
[15/9dbaa6] process > printEnv (2) [100%] 4 of 4 ✔
bonjour world!
hello world!
ciao world!
hola world!





(5) stdin 输入类型 
转发 输入值 到进程脚本的标准输入。

$ cat cat4.nf
process printAll {
  input: stdin str
  output: stdout
  """
  cat -
  """
}

workflow {
  Channel.of('hello', 'hola', 'bonjour', 'ciao')
    | map { it + '\n' }
    | printAll | view
}

$ nextflow run cat4.nf 
N E X T F L O W  ~  version 23.04.1
Launching `cat4.nf` [condescending_colden] DSL2 - revision: 0d4662e3b0
executor >  local (4)
[f7/7d3cc8] process > printAll (2) [100%] 4 of 4 ✔
hello
ciao
bonjour
hola




(6) set 输入类型 (过时)
请使用 tuple


(7) tuple 输入类型 
支持输入一个元组。

$ cat cat5.nf //一直报错，不是合法的路径，怎么修改？
process tupleExample {
    input: tuple val(x), path('latin.txt')
    output: stdout
    """
    echo "Processing $x"
    echo - latin.txt >> copy
    """
}

workflow {
  Channel.of( [1, 'alpha'], [2, 'beta'], [3, 'delta'] ) | tupleExample | view
}

上例中，tuple 输入包含一个值x和一个文件 latin.txt

一个 tuple 定义可能包含以下标识符，就是之前定义的 val, evn, path, stdin。
path 标识符和单个 path 是一样处理的。




(8) Input repeaters (each) 输入重复
集合中的每一个条目，重复执行某一个进程，每次接收一个值。

$ cat wc3.nf
process alignSequences {
  input:
  path seq
  each mode
  output: stdout
  """
  #t_coffee -in $seq -mode $mode > result
  echo $seq $mode
  """
}

workflow {
  sequences = Channel.fromPath('*.txt')
  methods = ['regular', 'espresso', 'psicoffee']

  alignSequences(sequences, methods) | view
}

$ nextflow run wc3.nf 
N E X T F L O W  ~  version 23.04.1
Launching `wc3.nf` [ridiculous_chandrasekhar] DSL2 - revision: d92ca097e8
executor >  local (6)
[5c/363fbf] process > alignSequences (3) [100%] 6 of 6 ✔
a.txt espresso
chunk_aa.txt regular
chunk_aa.txt psicoffee
a.txt regular
chunk_aa.txt espresso
a.txt psicoffee

并行不保证顺序。
上例中，sequences通道中的每个文件，能触发3个任务。这特别适用于测试同一个命令的不同参数。





==> repeat 选项也适用于输入文件。
process alignSequences {
  input:
  path seq
  each mode
  each path(lib)

  """
  t_coffee -in $seq -mode $mode -lib $lib > result
  """
}

workflow {
  sequences = Channel.fromPath('*.fa')
  methods = ['regular', 'espresso']
  libraries = [ file('PQ001.lib'), file('PQ002.lib'), file('PQ003.lib') ]

  alignSequences(sequences, methods, libraries)
}

以上文件中，每个sequences 通道触发6个比对任务，3个是regular 方法，3个是 espresso 方法。

实际测试:
$ cat repeats.nf
process alignSequences {
  input:
  path seq
  each mode
  each path(lib)
  output: stdout
  """
  #t_coffee -in $seq -mode $mode -lib $lib > result
  echo "-in $seq -mode $mode -lib $lib"
  """
}

workflow {
  sequences = Channel.fromPath('*.txt')
  methods = ['regular', 'espresso']
  libraries = [ file('xaa.lib'), file('xab.lib'), file('xac.lib') ]
  alignSequences(sequences, methods, libraries) | view
}

运行: 2个文件触发12个任务。
$ nextflow run repeats.nf 
N E X T F L O W  ~  version 23.04.1
Launching `repeats.nf` [infallible_linnaeus] DSL2 - revision: 936e9b0b5a
executor >  local (12)
[a1/287073] process > alignSequences (11) [100%] 12 of 12 ✔
-in chunk_aa.txt -mode espresso -lib xaa.lib
-in chunk_aa.txt -mode espresso -lib xab.lib
-in a.txt -mode regular -lib xab.lib
-in a.txt -mode espresso -lib xab.lib
-in a.txt -mode espresso -lib xaa.lib
-in chunk_aa.txt -mode regular -lib xaa.lib
-in a.txt -mode regular -lib xac.lib
-in chunk_aa.txt -mode regular -lib xab.lib
-in a.txt -mode regular -lib xaa.lib
-in chunk_aa.txt -mode espresso -lib xac.lib
-in a.txt -mode espresso -lib xac.lib
-in chunk_aa.txt -mode regular -lib xac.lib

注意：
- 多个 each 就是这些变量的排列组合。
- 输入 each 现在不支持 tuple。但是可以通过一个 tuple 通道模拟：使用 combine 或 cross 操作子来产生通道之间的组合。






==> Multiple input channels 多输入通道
进程的一个重要特点是，可以处理多个通道的输入。

当声明2个或更多process作为进程输入时，进程等待，直到有一个完整的输入配置，就是每个通道获取一个值。
这个条件达到时，进程从每个通道消耗一个值，启动一个任务。
重复该逻辑，直到一个或多个通道为空。

作为一个结果，通道值会逐个消耗，任何一个空通道都会导致进程等待，即使其他通道有值。

比如：
$ cat echo1.nf
process foo {
  input:
  val x
  val y
  output: stdout
  script:
  """
  echo $x and $y
  """
}

workflow {
  x = Channel.of(1, 2)
  y = Channel.of('a', 'b', 'c')
  foo(x, y) | view
}

运行：
$ nextflow run echo1.nf 
N E X T F L O W  ~  version 23.04.1
Launching `echo1.nf` [focused_linnaeus] DSL2 - revision: e299d33834
executor >  local (2)
[f1/ab3e4e] process > foo (2) [100%] 2 of 2 ✔
1 and a
2 and b
执行次数由最短的通道决定。



=> 当使用 value 通道时，是另一套语法。
Channel.value() 工厂函数或其他非通道的值会触发。
根据定义，值通道绑定一个值，可以被阅读无数次。
所以，当混合一个值通道和一个或更多(队列)通道时，不影响进程终止，因为这些值是可重复使用的。
例:
$ cat echo2.nf
process bar {
  input:
  val x
  val y
  output: stdout
  script:
  """
  echo $x and $y
  """
}

workflow {
  x = Channel.value(1)
  y = Channel.of('a', 'b', 'c')
  bar(x, y) | view
}

运行:
$ nextflow run echo2.nf 
N E X T F L O W  ~  version 23.04.1
Launching `echo2.nf` [confident_cray] DSL2 - revision: 8149e8e3c6
executor >  local (3)
[a8/77cd9a] process > bar (1) [100%] 3 of 3 ✔
1 and c
1 and b
1 and a

以上的 bar 被执行3次，因为x是value通道，不限制读取次数。而of通道每一个元素只能使用一次。

注意： 
通常，多个input通道用于进程中组合不同的输入：使用 each 标识符或 value 通道。
使用多个通道队列作为输入，等价于使用 merge 操作符。不推荐这么做，因为可能导致输入的组合不符合预期。







========================================
|-- output 输出
----------------------------------------
https://www.nextflow.io/docs/latest/process.html#outputs

1. 概述
一个进程只能由最多一个 output 块，其中最少包含一个 output。

(1)语法：
output:
  <output qualifier> <output name> [, <option>: <option value>]
一个输出对象包含一个标识符，一个名字。还有一些可选项。

进程触发后，每个进程输出返回一个通道。
如下例子展示访问进程中的输出通道的方法。

(2) 输出修饰符
Qualifier    Semantic
val      Emit the variable with the specified name.
file     (DEPRECATED) Emit a file produced by the process with the specified name.
path     Emit a file produced by the process with the specified name.
env      Emit the variable defined in the process environment with the specified name.
stdout   Emit the stdout of the executed process.
tuple    Emit multiple values.





2. 例子
(1) val 输出类型 
输出一个进程定义的 nf 变量。
常用于输出 input 块中定义的变量：

$ cat echo3.nf
process foo {
  input:  each x
  output: val x
  """
  echo $x > file
  """
}
workflow {
  methods = ['prot', 'dna', 'rna']
  receiver = foo(methods)
  receiver.view { "Received: $it" }
}

运行：
$ nextflow run echo3.nf 
N E X T F L O W  ~  version 23.04.1
Launching `echo3.nf` [insane_bell] DSL2 - revision: 17c613ad7e
executor >  local (3)
[cb/766a14] process > foo (1) [100%] 3 of 3 ✔
Received: dna
Received: rna
Received: prot



==> 输出值可以是一个值字面量，一个输入变量，或者其他进程中的nf变量，或值表达式。

$ cat out.nf
process foo {
  input:
  path infile

  output:
  val x
  val 'BB11'
  val "${infile.baseName}.out"

  script:
  x = infile.name
  """
  cat $x > file
  """
}

workflow {
  ch_dummy = Channel.fromPath('*').first()
  (ch_var, ch_str, ch_exp) = foo(ch_dummy)

  ch_var.view { "ch_var: $it" }
  ch_str.view { "ch_str: $it" }
  ch_exp.view { "ch_exp: $it" }
}

运行：
$ nextflow run out.nf 
N E X T F L O W  ~  version 23.04.1
Launching `out.nf` [insane_ptolemy] DSL2 - revision: b78cb73ca0
executor >  local (1)
[b9/b24ed2] process > foo [100%] 1 of 1 ✔
ch_var: echo2.nf
ch_str: BB11
ch_exp: echo2.out


(2) file 输出类型

Nextflow 19.10.0 之前 file 标识符是处理输出文件的标准方法。之后，推荐使用 path 而不是 file。
区别：
- file 把":"作为路径分隔符
	* file 'foo:bar' 识别为 foo 和 bar两个
	* path 'foo:bar' 仅捕获一个单文件名字 "foo:bar"
- file 不支持 path 的其他可选参数



(3) path 输出类型 
path 标识符能在一个进程中输出一个或多个文件。

$ cat out2.nf
process randomNum {
  output:
  path 'result.txt'

  '''
  echo $RANDOM > result.txt
  '''
}

workflow {
  numbers = randomNum()
  numbers.view { "Received: ${it.text}" }
}

运行：
$ nextflow run out2.nf 
Received: 21729

上例中，randomNum 进程创建一个文件 result.txt，内容是一个随机数。
因为 path 路径是同名的，所以那个文件被对应的 输出通道 触发。下游带兼容输入通道的进程将能接收它。



==> path 输出的可选项：
Name     Description
glob     When true the specified name is interpreted as a glob pattern (default: true)
hidden    When true hidden files are included in the matching output files (default: false)
	当true时，隐藏文件包含在匹配的输出文件中。
followLinks    When true target files are return in place of any matching symlink (default: true)
type        Type of paths returned, either file, dir or any (default: any, or file if the specified file name pattern contains a double star (**))
maxDepth    Maximum number of directory levels to visit (default: no limit)
includeInputs    When true any input files matching an output file glob pattern are included.

圆括号对输入和输出是可选的，但是当设置可选选项时且有超过一个输入或输出修饰符，必须使用圆括号，以便nf确定修饰哪个修饰符：


例1: 单个输出文件
process foo {
  output:
  path 'result.txt', hidden: true

  '''
  echo 'another new line' >> result.txt
  '''
}
workflow {
  foo() | view
}
//todo 没对比出来true和false的差别。



例2: 多个输出文件 //todo 还是没对比出来 hidden 干啥用的？！
$ cat echo5.nf
process foo {
  output:
  tuple path('last_result.txt'), path('result.txt', hidden: true)

  '''
  echo 'another new line' >> result.txt
  echo 'another new line' > last_result.txt
  '''
}
workflow {
  foo() | view
}



==> Multiple output files
$ cat printf.nf
process splitLetters {
    output:
    path 'chunk_*'

    '''
    printf 'Hola' | split -b 1 - chunk_
    '''
}

workflow {
    splitLetters
        | flatten
        | view { "File: ${it.name} => ${it.text}" }
}

运行：
$ nextflow run printf.nf 
File: chunk_aa => H
File: chunk_ab => o
File: chunk_ac => l
File: chunk_ad => a

默认，所有匹配文件都输出为一个文件列表。
然而，上文用了 flatten 操作符，把文件列表转为通道，分别对应到不同的文件。

一些全局模式的缺陷：
- 不包含输入文件（除非 includeInputs 设置为 true）
- 包含目录，除非使用 ** 模式对目录做递归。

警告：尽管与glob输出声明匹配的 输入文件 不包括在结果输出通道中，但这些文件仍然可以从任务临时目录传输到原始任务工作目录。
所以，避免文件复制的方法，是在定义输出文件时避免使用松散的通配符，比如 path '*'。
而是使用一个前缀或后缀，精确匹配所需要的文件，比如 path 'prefix_*.sorted.bam'


glob 语法: https://docs.oracle.com/javase/tutorial/essential/io/fileOps.html#glob






(4) Dynamic output file names 动态输出文件名
像input中一样，使用 global 上下文环境。比如： 

process align {
  input:
  val species
  path seq

  output:
  path "${species}.aln"

  """
  t_coffee -in $seq > ${species}.aln
  """
}

上文每个进程产生一个比对文件，输出文件名依赖于输入 species 的真实值。

tip: nf 中输出文件的管理常有误解。
- 其他工具要组织输出文件，防止互相覆盖，方便下游分析。
- nf中不需要，因为每个进程有自己的文件夹，不同任务不会互相覆盖。metadata 可以使用 tuple 输出标识符，而不是包含到输出文件名中。
- 需要管理输出文件命名的一个情况是使用 publishDir 指令指定输出的路径。
如果2个任务有同样的输出文件名，且使用了 publishDir 放到同一个路径，后一个会覆盖前一个。
可以在 publishDir 指令旁边使用 saveAs 指令。
- 总的来说，优先使用静态名字，因为更简单更便携。




(5) env 输出类型

可以使用 env ，把进程执行环境中定义的变量作为输出变量。

$ cat env.nf
process myTask {
    output:
    env FOO

    script:
    '''
    FOO=$(ls -a)
    '''
}

workflow {
    myTask | view { "directory contents: $it" }
}

输出:
$ nextflow run env.nf 
N E X T F L O W  ~  version 23.04.1
Launching `env.nf` [backstabbing_mccarthy] DSL2 - revision: 8c90cb25d6
executor >  local (1)
[f7/9e947b] process > myTask [100%] 1 of 1 ✔
directory contents: . .. .command.begin .command.err .command.log .command.out .command.run .command.sh

我的理解：是捕获的nf内产生的变量？ //todo




(6) stdout 输出类型
process sayHello {
    output:
    stdout

    """
    echo Hello world!
    """
}

workflow {
    sayHello | view { "I say... $it" }
}



(7) set 输出类型（过时，请使用 tuple）

(8) tuple 输出类型 
tuple 允许单个通道输出多个值。
适用于欧联 metadata和输出。

process blast {
  input:
    val species
    path query

  output:
    tuple val(species), path('result')

  script:
    """
    #blast -db nr -query $query > result
	echo species
    echo "-db nr -query $query" > result
    """
}

workflow {
  ch_species = Channel.from('human', 'cow', 'horse')
  ch_query = Channel.fromPath('*.txt')

  blast(ch_species, ch_query)
}

//todo 不懂，怎么输出2个？

一个任务的输入是 species 和 query 一对值。
每个任务产生一个新的元组，包含一个 species 值和一个 result 文件。


一个 tuple 定义包含以下 标识符，之前介绍过的 val, path, env, stdout.
path 标识符和单独使用 path 的规则是一样的。




(9) 可选输出

大多时候，一个输出定义的进程产生一个输出。
然而，有些不产生输出的进程也是合法的。这时，optional: true 可以添加到 输出定义中，告诉nf如果声明的输出没有产生不要认为进程失败。

output:
    path("output.txt"), optional: true




========================================
|-- when 条件语句
----------------------------------------
https://www.nextflow.io/docs/latest/process.html#when

必须满足这些条件才执行进程。条件可以是任何返回布尔值的表达式。

适用于根据输入和参数，判断是否执行的情况：


process find {
  input:
  path proteins
  val dbtype

  when:
  proteins.name =~ /^BB11.*/ && dbtype == 'nr'

  script:
  """
  blastp -query $proteins -db nr
  """
}
Tip: 最佳实践是，最好在nf块中定义逻辑，比如使用 if 语句或者通道操作子，让进程更方便移植。






========================================
|-- Directives 指令
----------------------------------------
https://www.nextflow.io/docs/latest/process.html#directives

指令，是对当前进程有影响的可选设置。

必须定义在顶部，在任何其他声明块（input, output, etc）前，
语法如下： name value [, value2 [,..]]

有些指令对几乎所有进程可用，有些依赖当前执行器的定义。



1. accelerator 加速指令(GPU)

process foo {
    accelerator 4, type: 'nvidia-tesla-k80'

    script:
    """
    your_gpu_enabled --command --line
    """
}

需要4个 nvidia-tesla-k80 类型的 GPU。


2. afterScript 进程后处理
用于清理数据

组合使用 容器指令，afterScript 是在容器外执行，也就是宿主机。


3. beforeScript 进程前执行
主进程运行前执行。用于初始化 集群环境，或者其他 自定义初始化。

process foo {
  beforeScript 'source /cluster/bin/setup'

  """
  echo bar
  """
}

注意：当和 容器指令一起使用时，beforeScript 是在容器外执行的，也就是宿主机执行。



4. cache 缓存 

打开缓存，就会跳过已经执行过的步骤。

缓存依赖一个unique key，通过索引 进程脚本和输入来确定。
此 key 用于惟一地标识流程执行产生的输出。

缓存默认打开，可以通过 cache false 指令关闭。

process noCacheThis {
  cache false

  script:
  <your command string here>
}



==> cache 指令的可能指如下：

Value    Description
false    Disable cache feature.
true (default)  Enable caching. Cache keys are created indexing input files meta-data information (name, size and last update timestamp attributes).
'deep'    Enable caching. Cache keys are created indexing input files content.
'lenient'   Enable caching. Cache keys are created indexing input files path and size attributes (this policy provides a workaround for incorrect caching invalidation observed on shared file systems due to inconsistent files timestamps).





5. clusterOptions 选项 

集群设置。可用于请求非标准资源，或者nf不支持的集群特性？？

Note: 仅用于 grid 执行器。













5. conda 指令

https://www.nextflow.io/docs/latest/process.html#conda

声明一个 conda 环境

process foo {
  conda 'bwa=0.7.15'

  '''
  your_command --here
  '''
}

多个条件使用空格分开，比如 bwa=0.7.15 fastqc=0.11.5




6. spack 指令 

process foo {
  spack 'bwa@0.7.15'

  '''
  your_command --here
  '''
}

多个条件使用空格分开，比如：bwa@0.7.15 fastqc@0.11.5





7. container 指令 
在容器中执行脚本。
需要启动Docker 守护进程。

process runThisInDocker {
  container 'dockerbox:tag'

  """
  <your holy script here>
  """
}

Tip: 容器是一个很好的可重复环境。

Note: 原生执行的进程会忽略该指令。
原生执行就是 exec 后的语句：https://www.nextflow.io/docs/latest/process.html#process-native





8. containerOptions 选项 

容器执行选项：Docker, Singularity 等。
设置，比如 mount a path:

process runThisWithDocker {
    container 'busybox:latest'
    containerOptions '--volume /data/db:/db'

    output:
    path 'output.txt'

    '''
    your_command --data /db > output.txt
    '''
}

警告：该特性不支持 Kubernetes and Google Life Sciences executors



9. cpus 多进程控制CPU核数

process big_job {
  cpus 8
  executor 'sge'

  """
  blastp -query input_sequence -num_threads ${task.cpus}
  """
}





10. debug 指令

默认，命令执行产生的 stdout 会被忽视。
通过设定 debug true，可以转发 stdout 到当前正在运行的顶部 stdout 文件，展示到shell终端。

process sayHello {
  debug true

  script:
  "echo Hello"
}

测试: 没有 debug true 就看不到shell中的输出。
process sayHello {
  debug true

  "echo Hello"
}

workflow{
        sayHello()
}
运行：
$ nextflow run echo3.nf 
Hello





11. disk 指令 

使用多少本地磁盘。

process big_job {
    disk '2 GB'
    executor 'cirrus'

    """
    your task script here
    """
}

可用的后缀：
Unit    Description
B     Bytes
KB    Kilobytes
MB    Megabytes
GB    Gigabytes
TB    Terabytes

该指令仅对部分执行器有效。
https://www.nextflow.io/docs/latest/executor.html#executor-page



12. echo 指令 (从 version 22.04.0 起，推荐使用 debug)


13. errorStrategy 指令 
默认，出错时进程立刻停止。这也导致整个流程终止。

Name  Executor
terminate   Terminates the execution as soon as an error condition is reported. Pending jobs are killed (default)
finish    Initiates an orderly pipeline shutdown when an error condition is raised, waiting the completion of any submitted job.
ignore    Ignores processes execution errors.
retry    Re-submit for execution a process returning an error condition.

当设置 errorStrategy ignore 时，遇到错误不停止，仅仅是报告一个错误事件。

process ignoreAnyError {
  errorStrategy 'ignore'

  script:
  <your command string here>
}
注意：一个命令返回一个非0退出状态，表示命令失败。


retry 表示出错后再试，再试的次数定义在 maxRetries 和 maxErrors 指令中。
process retryIfFail {
  errorStrategy 'retry'

  script:
  <your command string here>
}



14. executor 执行器 

执行环境，默认定义在 nextflow.config 文件的全局中。

https://www.nextflow.io/docs/latest/process.html#executor

process doSomething {
  executor 'sge'

  script:
  <your script here>
}


15. ext 用于作为命名空间

process mapping {
  container "biocontainers/star:${task.ext.version}"

  input:
  path genome
  tuple val(sampleId), path(reads)

  """
  STAR --genomeDir $genome --readFilesIn $reads
  """
}

版本号可以定义在配置文件中 nextflow.config：
process.ext.version = '2.5.3'


... 



16. memory 内存 

process big_job {
    memory '2 GB'
    executor 'sge'

    """
    your task script here
    """
}

可用的后缀： 
Unit   Description
B   Bytes
KB  Kilobytes
MB  Megabytes
GB  Gigabytes
TB  Terabytes




17. module 模块

指定软件的版本号：
process manyModules {
   module 'ncbi-blast/2.2.27:t_coffee/10.0:clustalw/2.1'

   """
   blastp -query <etc..>
   """
}



18. penv 指令

并行运行环境。

process big_job {
  cpus 4
  penv 'smp'
  executor 'sge'

  """
  blastp -query input_sequence -num_threads ${task.cpus}
  """
}



19. pod 指令 

定义 pod 特异的设定，比如使用 k8s 的 环境变量，密码，配置地图等。

process your_task {
  pod env: 'FOO', value: 'bar'
  '''
  echo $FOO
  '''
}


20. publishDir 指令 

把输出文件发布到该指令指定的文件夹中。

process foo {
    publishDir '/data/chunks'

    output:
    path 'chunk_*'

    '''
    printf 'Hola' | split -b 1 - chunk_
    '''
}
运行后，/data/chunks 中就可以看到 chunk_* 输出文件。

注意：仅仅是 output: 块中声明的发布，而不是 进程中的全部输出。
publishDir 指令可以被多次定义，方便不同规则输出文件到不同的文件夹。


多个指令写一行时，要使用都好隔开:
process foo {
    publishDir '/data/chunks', mode: 'copy', overwrite: false

    output:
    path 'chunk_*'

    '''
    printf 'Hola' | split -b 1 - chunk_
    '''
}

警告：复制文件是异步的。不要在随后文件访问该文件夹的东西，要使用 通道。





21. queue 指令
针对部分执行器有效。

process grid_job {
    queue 'long'
    executor 'sge'

    """
    your task script here
    """
}



22. resourceLabels 指令 

自定义键值对，nf应用资源来执行进程。

process my_task {
  resourceLabels region: 'some-region', user: 'some-username'

  '''
  <task script>
  '''
}


23. scratch 指令 
降低 NFS  开销。

process simpleTask {
  scratch true

  output:
  path 'data_out'

  '''
  <task script>
  '''
}

... 




========================================
|-- 通道 Channels //todo
----------------------------------------
https://www.nextflow.io/docs/latest/channel.html

1. nf 基于 Dataflow programming model，进程之间通过 通道 交流。

(1)通道的2个特性：
- 异步发送信息，立刻发送而无需等待接收方进程响应。
- 接收数据是阻塞操作，等待直到消息接收完毕。


(2)通道类型: queue channels 和 value channels.

1)队列通道是非阻塞的、无方向FIFO队列，连接2个进程，通道工厂或操作子。

创建方法：
- 工厂方法：_channel-of, _channel-path, etc
- 通道操作符链接起来： map, flatMap, etc
- 进程输出声明


2) 值通道 
值通道，或者说 单例通道，绑定一个值，可以读无数次。

创建方式：
- the value factory
- 返回一个值的操作子：first, last, collect, count, min, max, reduce, sum, etc.

单个值触发的是隐式的值通道。
输入都是数值的进程，也是隐式创建值通道作为输出。


process foo {
  input:
  val x

  output:
  path 'x.txt'

  """
  echo $x > x.txt
  """
}

workflow {
  result = foo(1)
  result.view { "Result: ${it}" }
}

因为 foo 进程被单个值触发，而不是一个通道，输入隐式的转为一个值通道，输出也作为一个值通道。





2. Channel factory 通道工厂函数

从 version 20.07.0，channel 作为 Channel 的别名，所以工厂方法可以写作：channel.of() or Channel.of()。

(1) empty 
创建一个空通道，不发射任何值。


(2) from (不推荐了)
推荐使用  of or fromList

创建一个通道，发射的数字就是参数列表的值。
ch = Channel.from( 1, 3, 5, 7 )
ch.subscribe { println "value: $it" }


创建一个范围的数字和字符串：
zeroToNine = Channel.from( 0..9 )
strings = Channel.from( 'A'..'Z' )
参数是 Java 的 Collection 接口。
以下效果等同：
Channel.from( 1, 3, 5, 7, 9 )   //多参数
Channel.from( [1, 3, 5, 7, 9] ) //单一list对象

但是提供超过一个参数时，作为单个发射:
Channel.from( [1, 2], [5,6], [7,9] ) //三个元素，每个是2元素list


(3) fromList (version 19.10.0 or later.)
创建一个通道，参数是一个list:
Channel
    .fromList( ['a', 'b', 'c', 'd'] )
    .view { "value: $it" }
输出：
value: a
value: b
value: c
value: d


(4) fromPath 
发射一个或多个文件路径：
myFileChannel = Channel.fromPath( '/data/some/bigfile.txt' )
注意： fromPath 不检查文件是否存在。
当 fromPath 包含 * 或 ? 通配符时， 作为 glob 路径匹配器:
https://docs.oracle.com/javase/tutorial/essential/io/fileOps.html#glob

myFileChannel = Channel.fromPath( '/data/big/*.txt' )
匹配路径 /data/big/ 下的 txt后缀的文件。

Tip: 两个** 是查找整个路径。花括号指定一个模式集合：
files = Channel.fromPath( 'data/**.fa' ) //查找 data/ 下及其子文件中fa后缀的文件
moreFiles = Channel.fromPath( 'data/**/*.fa' )
pairFiles = Channel.fromPath( 'data/file_{1,2}.fq' )

(5) 














========================================
配置文件
----------------------------------------
教程:
https://blog.csdn.net/u011262253/article/details/107919629
https://www.cnblogs.com/xiezh/p/16859336.html

包含变量引用的字符串必须用 双引号字符 而不是单引号字符包装。

配置注释
配置文件使用与Groovy或Java编程语言相同的注释约定。因此，用于//注释单行或/*… */注释多行中的块。






========================================
----------------------------------------





========================================
----------------------------------------



========================================
----------------------------------------



========================================
----------------------------------------



========================================
----------------------------------------





========================================
----------------------------------------



========================================
----------------------------------------



========================================
----------------------------------------



========================================
----------------------------------------





========================================
----------------------------------------



========================================
----------------------------------------



========================================
----------------------------------------



========================================
----------------------------------------



