NGS statistics 统计学和统计学参数

统计学尽量不写，因为太多参数
paper中常见的统计学，还是要硬啃的。


本文记录paper中遇到的统计学。
还有一个R和数理统计学: R/R03-statistics.txt 




========================================
权威统计学资料
----------------------------------------
《Introduction to Statistics With Python》 https://github.com/thomas-haslwanter/statsintro_python

有很多统计学和基本R使用案例: http://www.instantr.com/

R与统计学(卡方检验等)： http://www.sthda.com/english/wiki/r-basic-statistics


多组的比较 kruskal-wallis http://www.sthda.com/english/wiki/kruskal-wallis-test-in-r


推荐统计学和R教程：
1.An R Companion for the Handbook of Biological Statistics https://rcompanion.org/rcompanion/index.html
2.配套  The Handbook of Biological Statistics.  http://www.biostathandbook.com/
3. https://rcompanion.org/documents/RCompanionBioStatistics.pdf







========================================
如何看懂NCBI BLAST输出结果
----------------------------------------
http://www.cnblogs.com/emanlee/archive/2011/11/11/2245397.html

解读报告前需要掌握的概念
alignments 代表比对上的两个序列

hits 表示两个序列比对上的片段

Score 比对得分，如果序列匹配上得分，不一样，减分，分值越高，两个序列相似性越高 
E Value 值越小，越可信，相对的一个统计值。 
Length 输入序列的长度 
Identities 一致性，就是两个序列有多少是一样的 
Query 代表输入序列 
Sbjct 代表数据库中的序列


from: http://blog.163.com/henry_by/blog/static/572653582010101343853958/




========================================
|-- blast+
----------------------------------------
download:
	ftp://ftp.ncbi.nih.gov/blast/executables/blast+/
	ftp://ftp.ncbi.nih.gov/blast/executables/release/2.2.18
	ftp://ftp.ncbi.nih.gov/blast/executables/blast+/2.5.0/


blast formatdb 使用方法介绍
http://www.cnblogs.com/emanlee/archive/2011/11/18/2254604.html


megablast 采用贪婪式算法，速度较一般blast快，多用于数据量大且序列相似性较高的情况。
http://www.cnblogs.com/emanlee/archive/2011/11/19/2254863.html



========================================
k-means k均值聚类的弱点/缺点
----------------------------------------
http://www.cnblogs.com/emanlee/archive/2012/03/06/2381617.html

Similar to other algorithm, K-mean clustering has many weaknesses:

1 When the numbers of data are not so many, initial grouping will determine the cluster significantly.  当数据数量不是足够大时，初始化分组很大程度上决定了聚类，影响聚类结果。 
2 The number of cluster, K, must be determined before hand.  要事先指定K的值。 
3 We never know the real cluster, using the same data, if it is inputted in a different order may produce different cluster if the number of data is a few. 数据数量不多时，输入的数据的顺序不同会导致结果不同。 
4 Sensitive to initial condition. Different initial condition may produce different result of cluster. The algorithm may be trapped in the local optimum. 对初始化条件敏感。 
5 We never know which attribute contributes more to the grouping process since we assume that each attribute has the same weight. 无法确定哪个属性对聚类的贡献更大。 
6 weakness of arithmetic mean is not robust to outliers. Very far data from the centroid may pull the centroid away from the real one. 使用算术平均值对outlier不鲁棒。 
7 The result is circular cluster shape because based on distance.  因为基于距离，故结果是圆形的聚类形状。

 

One way to overcome those weaknesses is to use K-mean clustering only if there are available many data. To overcome outliers problem, we can use median instead of mean.  克服缺点的方法： 使用尽量多的数据；使用中位数代替均值来克服outlier的问题。

Some people pointed out that K means clustering cannot be used for other type of data rather than quantitative data. This is not true! See how you can use multivariate data up to n dimensions (even mixed data type) here. The key to use other type of dissimilarity is in the distance matrix.

 

http://people.revoledu.com/kardi/tutorial/kMean/Weakness.htm










========================================
多重比较的p值校正: Adjust P-values for Multiple Comparisons
----------------------------------------

根据NCBI GEO官网，p值校正方法包括： https://www.ncbi.nlm.nih.gov/geo/info/geo2r.html#adjustment_references

Apply adjustment to the P-values. 
 Benjamini & Hochberg (False discovery rate)
 Benjamini & Yekutieli
 Bonferroni
 Hochberg
 Holm
 Hommel
 None
#

https://stat.ethz.ch/R-manual/R-devel/library/stats/html/p.adjust.html

Description: Given a set of p-values, returns p-values adjusted using one of several methods.

使用
p.adjust(p, method = p.adjust.methods, n = length(p))

p.adjust.methods
# c("holm", "hochberg", "hommel", "bonferroni", "BH", "BY", "fdr", "none")


参数：
p:	numeric vector of p-values (possibly with NAs). Any other R object is coerced by as.numeric.
method:	correction method. Can be abbreviated.
n:	number of comparisons, must be at least length(p); only set this (to non-default) when you know what you are doing!


细节：
The adjustment methods include the Bonferroni correction ("bonferroni") in which the p-values are multiplied by the number of comparisons. 

Less conservative corrections are also included by Holm (1979) ("holm"), Hochberg (1988) ("hochberg"), Hommel (1988) ("hommel"), Benjamini & Hochberg (1995) ("BH" or its alias "fdr"), and Benjamini & Yekutieli (2001) ("BY"), respectively. 

A pass-through option ("none") is also included. 

The set of methods are contained in the p.adjust.methods vector for the benefit of methods that need to have the method as an option and pass it on to p.adjust.



例子：
require(graphics)

set.seed(123)
x <- rnorm(50, mean = c(rep(0, 25), rep(3, 25)))
p <- 2*pnorm(sort(-abs(x)))

round(p, 3)
round(p.adjust(p), 3)
round(p.adjust(p, "BH"), 3)

## or all of them at once (dropping the "fdr" alias):
p.adjust.M <- p.adjust.methods[p.adjust.methods != "fdr"]
p.adj    <- sapply(p.adjust.M, function(meth) p.adjust(p, meth))
p.adj.60 <- sapply(p.adjust.M, function(meth) p.adjust(p, meth, n = 60))
stopifnot(identical(p.adj[,"none"], p), p.adj <= p.adj.60)
round(p.adj, 3)
## or a bit nicer:
noquote(apply(p.adj, 2, format.pval, digits = 3))


## and a graphic:
matplot(p, p.adj, ylab="p.adjust(p, meth)", type = "l", asp = 1, lty = 1:6,
        main = "P-value adjustments")
legend(0.7, 0.6, p.adjust.M, col = 1:6, lty = 1:6)

## Can work with NA's:
pN <- p; iN <- c(46, 47); pN[iN] <- NA
pN.a <- sapply(p.adjust.M, function(meth) p.adjust(pN, meth))
## The smallest 20 P-values all affected by the NA's :
round((pN.a / p.adj)[1:20, ] , 4)






ref:
Benjamini, Y., and Hochberg, Y. (1995). Controlling the false discovery rate: a practical and powerful approach to multiple testing. Journal of the Royal Statistical Society Series B, 57, 289-300.
Benjamini, Y., and Yekutieli, D. (2001). The control of the false discovery rate in multiple testing under dependency. Annals of Statistics 29, 1165-1188.
Holm, S. (1979). A simple sequentially rejective multiple test procedure. Scandinavian Journal of Statistics, 6, 65-70.
Hommel, G. (1988). A stagewise rejective multiple test procedure based on a modified Bonferroni test. Biometrika, 75, 383-386.
Hochberg, Y. (1988). A sharper Bonferroni procedure for multiple tests of significance. Biometrika, 75, 800-803.
Shaffer, J. P. (1995). Multiple hypothesis testing. Annual Review of Psychology, 46, 561-576.
Sarkar, S. (1998). Some probability inequalities for ordered MTP2 random variables: a proof of Simes conjecture. Annals of Statistics, 26, 494-504.
Sarkar, S., and Chang, C. K. (1997). Simes' method for multiple hypothesis testing with positively dependent test statistics. Journal of the American Statistical Association, 92, 1601-1608.
Wright, S. P. (1992). Adjusted P-values for simultaneous inference. Biometrics, 48, 1005-1013.




========================================
|-- 多重假设检验：Bonferroni 和 FDR (R语言实现)
----------------------------------------
1.概念
FDR，Q value，adjust p value
p-value：衡量一次检验假阳性率的指标（False positive rate） ；
q value：衡量错误发现率的指标（False discovery rate，简称FDR，所有检验中假阳性的概率）。即使用Q value的这个参 数预估FDR。Q value 需要利用公式从p value 校正计算后得到，所以Q value 通常又被称为adjusted p value。所以一般情况下：我们可以认为Q value = FDR = adjusted p value，即三者是一个东西，虽然有些定义上的细微区别，但是问题也不大。


2.矫正
如要使用的校正办法有两种：Bonferroni 校正；FDR（FalseDiscovery Rate） 校正
(1).Bonferroni 校正
Bonferroni 校正法可以称作是“最简单粗暴有效”的校正方法，它拒绝了所有的假阳性结果发生的可能性，通过对p值的阈值进行校正来实现消除假阳性结果。

Bonferroni 校正的公式为p*(1/n)，其中p为原始阈值，n为总检验次数。

如果像我们举的例子一样，原始的P值为0.05，检验次数为10000次，那么在Bonferroni 校正中，校正的阈值就等于5%/ 10000 = 0.000005，所有P值超过0.00005的结果都被认为是不可靠的。这样的话假阳性结果在10000次检验中出现的次数为 10000 * 0.000005 =0.5，还不到1次。

但是这也存在问题：Bonferroni 委实太过严格，被校正后的阈值拒绝的不只有假阳性结果，很多阳性结果也会被它拒绝。



(2).FDR（FalseDiscovery Rate） 校正
相对Bonferroni 来说，FDR温和得多，这种校正方法不追求完全没有假阳性结果，而是将假阳性结果和真阳性的比例控制在一定范围内。

举个例子，我们最开始设定的情况中进行了10000次检验，这次我们设定FDR<0.05，如果我们的检验对象为差异表达的基因，那么在10000次检验中假如得到了500个基因，那么这500个基因中的假阳性结果小于 500*5% = 25 个。

FDR的计算方法有很多种，这里介绍一个比较常用的：

1)BH（Benjaminiand Hochberg）法：
BH 法需要将总计m次检验的结果按由小到大进行排序，k为其中一次检验结果的P值所对应的排名。
找到符合原始阈值α的最大的k值，满足P(k)<=α*k/m，认为排名从1到k的所有检验存在显著差异，并计算对应的q值公式为q = p*(m/k)。
举个例子，如果我们有总共六个结果进行FDR校正：

Gene	p-value 
G1	P1=0.053
G2	P2=0.001
G3	P3=0.045
G4	P4=0.03
G5	P5=0.02
G6	P6=0.01

Order:
G2	P2=0.001
G6	P6=0.01
G5	P5=0.02
G4	P4=0.03
G3	P3=0.045
G1	P1=0.053

按α=0.05进行计算：
排名第四的 P (4) = 0.03 < 0.05*4/6 = 0.033，符合要求
排名第五的 P (5)= 0.045 > 0.05*5/6 = 0.041，不满足P(k)<=α*k/m. 
因此在这个列表里排名前四的G2,G6,G5,G4 为具有显著差异的基因。


我们也可以用q值进行FDR校正：
G2	P2=0.001	q2=0.001*6/1=0.006
G6	P6=0.01	q6=0.01*6/2=0.03
G5	P5=0.02	q5=0.02*6/3=0.04
G4	P4=0.03	q4=0.03*6/4=0.045
G3	P3=0.045	q3=0.045*6/5=0.054
G1	P1=0.053	q1=0.053*6/6=0.053
其中，G3的q值大于0.05，故G2,G6,G5,G4 为具有显著差异的基因。





3. R语言实例：adj p value
############ 循环实现矫正
compareL=data.frame(
  p.value=c(1.423900e-06, 2.187725e-06, 3.555254e-06, 5.761348e-06, 6.274032e-06, 1.046657e-05, 2.897417e-05, 3.537313e-05, 4.001844e-05,
            6.336900e-05, 6.385193e-05, 6.845141e-05, 8.500831e-05, 8.849766e-05, 9.792548e-05, 1.050767e-04, 1.421291e-04, 1.724226e-04,
            1.850125e-04, 1.944649e-04)
)
head( compareL )
n=nrow(compareL);n #20
qvalues=c()
for(i in seq(1,n)){
  if(i%%5==0) print(i) #进度条
  q=compareL$p.value[i]*n/i
  qvalues=c(qvalues, q)
}
length(qvalues) #
qvalues[1:5] 
# 2.847800e-05 2.187725e-05 2.370169e-05 2.880674e-05 2.509613e-05
#
############ R函数矫正 test for adj.p value function
qvalues2=p.adjust(p=compareL$p.value, method = "fdr")
qvalues2[1:5]
# 2.187725e-05 2.187725e-05 2.370169e-05 2.509613e-05 2.509613e-05
#这个函数和上述for循环结果完全一样。



(2) p.adjust.methods
# c("holm", "hochberg", "hommel", "bonferroni", "BH", "BY",
#   "fdr", "none")

p.adjust(p=compareL$p.value) # 默认的矫正方法是?
# 2.847800e-05 4.156677e-05 6.399457e-05 9.794292e-05 1.003845e-04
#
p.adjust(p=compareL$p.value, method = "holm")
# 2.847800e-05 4.156677e-05 6.399457e-05 9.794292e-05 1.003845e-04

p.adjust(p=compareL$p.value, method = "BH") #就是 'fdr'
# [1] 2.187725e-05 2.187725e-05 2.370169e-05 2.509613e-05 2.509613e-05






refer: https://www.jianshu.com/p/949626b18e69



========================================
|-- Benjamini correction == FDR == adjusted p-value
----------------------------------------
https://www.biostars.org/p/293613/

Benjamini correction is your false discovery rate and it is your adjusted p-value. So you should forget about your p-value after correction. So your test is significant if your adjusted p-value is smaller than criteria (such as 0.05 or 0.01). If you want to more about multiple testing, you can check here




========================================
****** 参数检验 ******
----------------------------------------



========================================
方差分析的原理, 方差分析表
----------------------------------------
https://www.bilibili.com/video/BV1X441187gE?p=1


1. 单因素方差分析 
一共N个数据，分为1,2,...,k组。

(1)组间差异
SSB=累加nj*(xjbar-xbar)^2; 自由度为k-1;
组间均方 MSB^2表示(between)=累加ni*(xibar-xbar)^2/(k-1);

(2)组内差异，也叫误差
SSW=累加(x-xjbar)^2; 自由度为N-k;
MSW^2=累加(x-xibar)^2/(N-k); 也记做 MSE。

(3) 总方差 
SST=累加(x-xbar)^2, 自由度为N-1;

(4)单因素方差分析表:
###############
来源  SS   df  MS  F 
组间  SSB; k-1;  F=MSB/MSE;
误差  SSW; N-k;  作分母
总共  SST; N-1;
###############
检验: 
- 自由度k-1 + N-k=N-1, 能对应上;
- SST=SSB+SSW;

(5)H0: 组间没有显著差异。
F=MSB^2/MSW^2, F在临界值为a=0.05 自由度为(k-1, N-k) 的F值为Fa, 如果F>Fa,则拒绝H0, 认为组间有显著差异。

然后还要逐步检验，看哪些组之间有差异。




例: 三组学生，每组5个人，A组都是90分，B组都是80分，C组都是50分。
求分组之间是否有显著差异。
解: H0: 组间没有显著差异。
组内均方 
MSb=累加nj*(xjbar-xbar)^2/(k-1)=[ 5*(90-73.3)^2+ 5*(80-73.3)^2+ 5*(50-73.3)^2]/(3-1)

组内均方，也叫误差
MSw=MSe=累加(x-xjbar)^2 /(N-k)=[ (90-90)^2+..共5个90分减去该组平均分.+(90-90)^2+...+(50-50)^2] /(15-3)=0
这个例子比较极端，分母为0了
F=MSb/MSw=无穷大，超过了F在a=0.05 自由度为(2,12)的阈值，
所以p值太小，认为小概率事件在一次事件中不可能发生，否定H0，认为组间差异显著。







2. 多因素方差分析(以两因素为例，考虑交叉因素)
http://www.biye5u.com/article/R/2019/6403.html


(1)示例数据是两分组(比如男女)，三水平的(group1,group2,group3)
		condition1, condition2,... condition2 s
group1   x11  x12  x1s
group2   x21  x22  x2s
...
group r   xr1  xr2 xrs

总行数R=r行, 总列数C=s列; 总分组K=r*s; 为了防止标记混乱，后面尽量使用R和C；
该实验重复L次，总数据个数N=r*s*l; 


SST=SSM+SSE; 总方差=模型+误差
其中 SSM=A+B+AxB，所以 
SST=SSA + SSB + SSAxB +SSE;


0) 为求AxB的交叉效应，需要先求模型方差=把数据按照行和列分组，每组均值-总方差，求平方和;
SSM=累加( nj*(xj_bar-x_bar)^2 )，自由度为 K-1=R*C-1;
该值不写到方差分析表中。


1) 行间方差 = 数据分行，每行求平均值，行平均值和总均值的差，再求平方和。
SSR=累加( nR*(xR_bar-x_bar)^2 )，自由度为 R-1;

2) 列间方差 = 每列均值-总均值，再求平方和；
SSC=累加( nC*(xC_bar-x_bar)^2 )，自由度为 C-1;

3) 行列交叉效应 
SSAxB=SSM-SSA-SSB; 自由度为 (R-1)(C-1);

4) 误差，也就是组内均方差的和=按照行列交叉分组，每组内元素和该组均值的差，求平方和;
SSE=累加( (x-x_bar)^2 ), 自由度为 N-RC;

5) 总方差和=每个元素和总均值的差，求平方和;
SST=累加( (x-x_bar)^2 ), 自由度为 N-1;

验算
1) SSM=SSA+SSB+SSAB;
2) 自由度 T=A+B+AB+E; R-1+C-1+(R-1)(C-1)+N-RC=R+C-2+RC-R-C+1+N-RC=N-1;


两因素方差分析表:
###############
来源  SS  df  MS  F 
A行间 SSR R-1  Fa
B列间 SSC C-1  Fb
AxB交叉 SSAB (R-1)(C-1)  Baxb
E误差 SSE (N-RC)  做分母
T总共 SST N-1
###############
求F值，求该自由度下的p值，看是否足够小而拒绝H0.
MS=SS/df; 

FR=SSR/SSE; F~(r-1, (r-1)(s-1))
FC=SSC/SSE; F~(s-1, (r-1)(s-1))
FRC=(SSM-SSA-SSB)/SSE; F~(N-rs, (r-1)(s-1))



例: 把横竖表 “宽变长” 得到如下表:
groupA是3行分组；
sexB是2列分组: 男女;
x是观测指标；问A和B哪个分组是显著的。
实验重复5次。一共3*2*5=30个观测值;

groupA	sexB	x
1	1	12
1	1	15
1	1	16
1	1	17
1	1	14
2	1	14
2	1	17
2	1	19
2	1	20
2	1	17
3	1	25
3	1	27
3	1	29
3	1	24
3	1	22
1	2	21
1	2	19
1	2	18
1	2	24
1	2	25
2	2	21
2	2	20
2	2	23
2	2	27
2	2	25
3	2	37
3	2	34
3	2	36
3	2	26
3	2	29

1) 先求总平均数 x_bar	22.43333333
2) A
groupA	mean	n	xRowbar-xbar方	SSR	df	ms
1	18.1	10	18.77777778	651.4666667	2	325.7333333
2	20.3	10	4.551111111			
3	28.9	10	41.81777778			

3) B
groupB	mean	n	xColbar-xbar方	SSC	df	ms
1	19.2	15	10.45444444	313.6333333	1	313.6333333
2	25.66666667	15	10.45444444			

4) 模型
groupM	mean	n	xjbar-xbar方	SSM	df	ms
11	14.8	5	58.26777778	966.9666667	5	193.3933333
21	17.4	5	25.33444444			
31	25.4	5	8.801111111			
12	21.4	5	1.067777778			
22	23.2	5	0.587777778			
32	32.4	5	99.33444444			

5) 交叉AxB=M-A-B;
SSCross	df	ms
1.866666667	2	0.933333333

6) 总差异=(每个值-总xbar)^2求和
excel中使用原数据表每行-总xbar，平方后再sum；
SST	df	ms
1191.366667	29	41.0816092

7) 误差=(x-每行列分组xbar)^2求和
excel中先计算每个行列分组内的均值xjbar AVERAGEIFS(C:C,A:A,A2,B:B,B2)
每行-xjbar,平方后再sum;
SSE	df	ms
224.4	24	9.35

8)方差分析表
model	966.9666667	5	193.3933333	20.68377897	2.620654147	Yes	5.43052E-08 这一行不写

来源	SS	df	ms	F	F(a=0.05)	sig	Pvalue
rowA	651.4666667	2	325.7333333	34.83778966	3.402826105	Yes	7.99868E-08
columnB	313.6333333	1	313.6333333	33.54367201	4.259677214	Yes	5.69894E-06
crossAxB	1.866666667	2	0.933333333	0.099821747	3.402826105	no	0.905372469
Error	224.4	24	9.35				
total	1191.366667	29	41.0816092				






========================================
|-- R语言进行方差分析(1-way)
----------------------------------------
ggpubr, ggsci, ggsignif, car, userfriendlyscience

data(ToothGrouth)
ToothGrouth$dosef=factor(ToothGrouth$dose,ordered=T);


1. 单因素方差分析 https://www.jianshu.com/p/cf0f637d5db7
group value
1 95
1 90
1 99
2 80
2 82
2 89
3 50
3 52
3 56

data1=read.table('clipboard', header=T); data1
data1$group=as.factor(data1$group) #分组变量必须是因子！！！


(1) 正态性检验 
shapiro.test(data1$group)
shapiro.test(data1$value)

shapiro.test( rnorm(200) ) #p-value = 0.4489 p太大接受H0: 来自正态分布样本;

(2) 方差齐性检验
# leveneTest(value~group, data1) #安装不上包
bartlett.test(value~group, data1) #p-value = 0.8449 无法拒绝H0:方差相等的群体

#方差齐性 summary(aov())
#方差不齐性，使用Welch's anova: oneway.test();




(3) 单因素 anova
aov1=aov(value~group, data1)
summary(aov1)
## 结果
            Df Sum Sq Mean Sq F value   Pr(>F)    
group        2   2846  1423.0    82.1 4.38e-05 ***
Residuals    6    104    17.3                     
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

group之间差异显著；


(4)也有人认为对残差进行正态性、方差齐性检验
# 提取残差
res1=residuals(aov1); res1
res1_2=aov1$residuals; res1_2
#检验残差的正态性
shapiro.test(res1)  #期望这个p>0.05
qqplot(names(res1), names(res1)) #画QQ图可视化

#
leveneTest(res1~group, data1) #期望这个p>0.05



(5) 多重检验，看哪个分组之间显著，方法有很多，常见的有:

1)多重比较 https://bbs.pinggu.org/thread-2744833-1-1.html
summary(fm1 <- aov(breaks ~ wool + tension, data = warpbreaks))
TukeyHSD(fm1, "tension", ordered = TRUE)

> TukeyHSD(aov1)
#  Tukey multiple comparisons of means
#     95% family-wise confidence level
# 
# Fit: aov(formula = value ~ group, data = data1)
# 
# $group
#     diff       lwr         upr     p adj
# 2-1  -11 -21.43013  -0.5698725 0.0407381
# 3-1  -42 -52.43013 -31.5698725 0.0000423
# 3-2  -31 -41.43013 -20.5698725 0.0002403


2) 两两比较
pairwise.t.test(data1$value, data1$group)
# Pairwise comparisons using t tests with pooled SD 
# data:  data1$value and data1$group 
#  1       2      
#2 0.0178  -     
#3 5.1e-05 0.0002
#
#P value adjustment method: holm 
结论: 可见两两检测(1-2,1-3,2-3)，都是有显著差异的。

#也可以指定其他的矫正方法，组数比较多还是推荐fdr
p.adjust.methods 
#[1] "holm" "hochberg" "hommel" "bonferroni" "BH" "BY" "fdr" "none" 
pairwise.t.test(data1$value, data1$group, p.adjust.method = "BH")





(6) # 画图
library(ggplot2)
data1$group=as.factor(data1$group);
ggplot(data1, aes(x=group, y=value, fill=group ))+
  stat_boxplot(geom="errorbar")+
  geom_boxplot()+
  geom_jitter()+
  theme_classic(base_size=16) #基准字号变大


(7) welch anova 对于不满足方差齐性的数据
oneway.test(value~group, data1, var.equal=F)
不返回残差，不能检验。
#One-way analysis of means (not assuming equal variances)
#
#data:  value and group
#F = 90.029, num df = 2.000, denom df = 3.828, p-value = 0.0006046


oneway.test(value~group, data1, var.equal=T) #var.equal=T则是经典方法，结果同上
#One-way analysis of means
#data:  value and group
#F = 82.096, num df = 2, denom df = 6, p-value = 4.382e-05

(8) 事后检验 #函数不存在
with(data1, 
	posthocTGH(value,group, method="games-howell")
)



(9) 如果不符合正态性，就要使用非参数检验了
kruskal.test(value~group, data1)
#Kruskal-Wallis rank sum test
#data:  value by group
#Kruskal-Wallis chi-squared = 7.2, df = 2, p-value = 0.02732

虽然p<0.05，拒绝H0，认为有group间差异，
但是p值比刚才要大，检验效力没有参数检验强。不容易纳伪，但是更容易弃真；


非参数的两两检验
with(data1, 
	pairwise.wilcox.test(value, group, exact=F)
)

#Pairwise comparisons using Wilcoxon rank sum test 
#
#data:  value and group 
#  1    2   
#2 0.24 -   
#3 0.24 0.24
#P value adjustment method: holm 
非参数的两两检验的结论是，两两之间差异不显著。



========================================
|-- R语言进行方差分析(2-way)
----------------------------------------
数据见上文。

1. 数据 
data2=read.table('clipboard', header=T)
data2

groupA	sexB	x
1	1	12
1	1	15
1	1	16
1	1	17
1	1	14
2	1	14
2	1	17
2	1	19
2	1	20
2	1	17
3	1	25
3	1	27
3	1	29
3	1	24
3	1	22
1	2	21
1	2	19
1	2	18
1	2	24
1	2	25
2	2	21
2	2	20
2	2	23
2	2	27
2	2	25
3	2	37
3	2	34
3	2	36
3	2	26
3	2	29


2 两因素，有交叉效应和没有交叉效应两种情况。
data2$groupA=as.factor(data2$groupA) #必须转为因子！
data2$sexB=as.factor(data2$sexB)

# aov2=aov(x~groupA+sexB, data2) #没交叉效应

aov2=aov(x~groupA*sexB, data2)  #交叉效应
#aov2=aov(x~groupA+sexB+groupA:sexB, data2)  #交叉效应
summary(aov2)
## 结果
#            Df Sum Sq Mean Sq F value  Pr(>F)    
#groupA       2  651.5   325.7   34.84 8.0e-08 ***
#sexB         1  313.6   313.6   33.54 5.7e-06 ***
#groupA:sexB  2    1.9     0.9    0.10   0.905    
#Residuals   24  224.4     9.4                    
#---
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

和之前excel手算的结果一致。
交互作用不显著。


(2) 诊断模型
res2=residuals(aov2);
shapiro.test(res2) #p>0.05
ggqqplot(res2) #没有这个函数
leveneTest(res2~groupA*sexB, dat2) #没有这个函数


(3) 两两比较，及可视化
> TK=TukeyHSD(aov2, 'groupA:sexB'); TK
# Tukey multiple comparisons of means
#    95% family-wise confidence level
#
# Fit: aov(formula = x ~ groupA * sexB, data = data2)
#
# $`groupA:sexB`
#         diff        lwr      upr     p adj
# 2:1-1:1  2.6 -3.3795101  8.57951 0.7580309
# 3:1-1:1 10.6  4.6204899 16.57951 0.0001624 **
# 1:2-1:1  6.6  0.6204899 12.57951 0.0245686 *
# 2:2-1:1  8.4  2.4204899 14.37951 0.0026899 **
# 3:2-1:1 17.6 11.6204899 23.57951 0.0000000 **
# 3:1-2:1  8.0  2.0204899 13.97951 0.0044533 **
# 1:2-2:1  4.0 -1.9795101  9.97951 0.3360790
# 2:2-2:1  5.8 -0.1795101 11.77951 0.0609450
# 3:2-2:1 15.0  9.0204899 20.97951 0.0000008 **
# 1:2-3:1 -4.0 -9.9795101  1.97951 0.3360790
# 2:2-3:1 -2.2 -8.1795101  3.77951 0.8608062
# 3:2-3:1  7.0  1.0204899 12.97951 0.0152655 *
# 2:2-1:2  1.8 -4.1795101  7.77951 0.9345076
# 3:2-1:2 11.0  5.0204899 16.97951 0.0000978 **
# 3:2-2:2  9.2  3.2204899 15.17951 0.0009715 **
## 需要手动挑选出显著的行; 后面的星号是我手工添加的;
TK2=as.data.frame( TK$`groupA:sexB`)
TK2[which(TK2$`p adj`<0.05),]


1) 或者boxplot可视化看一下
ggplot(data2, aes(x=groupA, y=x, fill=sexB))+
  stat_boxplot(geom='errorbar')+
  geom_boxplot()
# aes中x是一个分组，fill是第二个分组;
可见: 性别2普遍比1高; 分组123呈递增趋势;



2) 可视化方法2: 画出两两比较的置信区间;
> TK=TukeyHSD(aov2, 'groupA:sexB')
> plot(TK) #置信区间跨过0的就是没有差异的。
# 为什么有15条线? 3*2=6组，两两比较 C(6,2)=6!/(2!4!)=5*6/2=15;

# 缺点: y坐标组名字有遗漏，使用ggplot2重绘

3) 使用ggplot2重绘置信区间图
TK2=as.data.frame( TK$`groupA:sexB`)
TK2$pair=rownames(TK2); #画图的坐标
TK2$sig=cut(TK2$`p adj`, breaks=c(0,0.01, 0.05,1), labels=c('P<0.01', 'P<0.05', 'NS'), right=F)
# right=F 表示右为开区间,则[0,0.05), [0.05,1)

#版本1,
ggplot(TK2, aes(x=`p adj`, y=pair, color=sig))+
  geom_errorbarh(aes(xmin=lwr, xmax=upr))+
  geom_point(aes(x=diff))
#

#版本2: 更精细;
ggplot(TK2, aes(x=`p adj`, y=pair, color=sig))+
  geom_errorbarh(aes(xmin=lwr, xmax=upr), height=0.2)+ #bar的长度。height设置bar的高度
  geom_point(aes(x=diff))+ #点
  geom_vline(xintercept = 0, lty=2)+ #竖线，line type 线形 2为虚线
  labs(x=NULL, y=NULL, title="95% family-wise confidence level", color="Significance")+
  theme_classic()
#








3. gl()函数和两因素方差分析实例

(1) 介绍一个产生因子的函数 gl
gl(4,1,12) #n个level, k个重复，总共length个
#[1] 1 2 3 4 1 2 3 4 1 2 3 4
#Levels: 1 2 3 4

gl(4,3,12) #n个level, 
#[1] 1 1 1 2 2 2 3 3 3 4 4 4
#Levels: 1 2 3 4



(2)实例
行:销售地区（A）	列:包装方法（B）
    B1	B2	B3	B4
A1	45	75	30	40
A2	50	50	40	48
A3	35	65	50	53

X<-c(45,75,30,40,50,50,40,48,35,65,50,53)
A<-c(1,1,1,1,2,2,2,2,3,3,3,3)
#或者A<-gl(3,4)

B<-rep(c(1:4),3)
#或者B<-gl(4,1,12)

dat<-data.frame(X,A,B)

re<-aov(X~A+B,data=dat)
summary(re)
## 方差分析表
           Df Sum Sq Mean Sq F value Pr(>F)
A            2   33.2    16.6   0.145  0.868
B            3  963.6   321.2   2.809  0.130
Residuals    6  686.2   114.4  
因为P>0.05，所以A因素和B因素对食品销量没有显著影响。







========================================
方差分析(analysis of variance, 简写为ANOVA)
----------------------------------------
方差分析(analysis of variance, 简写为ANOVA)是工农业生产和科学研究中分析试验数据的一种有效的统计方法. 引起观测值不同(波动)的原因主要有两类: 一类是试验过程中随机因素的干扰或观测误差所引起不可控制的的波动, 另一类则是由于试验中处理方式不同或试验条件不同引起的可以控制的波动.

方差分析的主要工作就是将观测数据的总变异(波动)按照变异的原因的不同分解为因子效应与试验误差，并对其作出数量分析，发现多组数据之间的差异显著性，比较各种原因在总变异中所占的重要程度，以此作为进一步统计推断的依据.

在进行方差分析之前先对几条假设进行检验，由于随机抽取，假设总体满足独立、正态，考察方差齐次性（用bartlett检验）.





1.正态性检验
在进行方差分析前先对输入数据做正态性检验。
对数据的正态性，利用Shapiro-Wilk正态检验方法(W检验)，它通常用于样本容量n≤50时，检验样本是否符合正态分布。

R中，函数shapiro.test()提供了W统计量和相应P值，所以可以直接使用P值作为判断标准(P值大于0.05说明数据正态)，其调用格式为shapiro.test(x)，参数x即所要检验的数据集，它是长度在3到5000之间的向量。

(1)
nx <- c(rnorm(10));nx
#[1] -0.83241783 -0.29609562 -0.06736888 -0.02366562 0.23652392 0.97570959
#[7] -0.85301145 1.51769488 -0.84866517 0.20691119
shapiro.test(nx)
#Shapiro-Wilk normality test
#data: nx
#W = 0.9084, p-value = 0.2699

检验结果，因为p 值小于W 值，所以数据为正态分布.

(2)更多正态性检验见：R语言做正态分布检验 https://www.cnblogs.com/blueicely/archive/2013/01/08/2850929.html
其中，D检验(Kolmogorov - Smirnov)是比较精确的正态检验法。

SPSS 规定:当样本含量3 ≤n ≤5000 时,结果以Shapiro - Wilk (W 检验) 为准,当样本含量n > 5000 结果以Kolmogorov - Smirnov 为准。
SAS 规定:当样本含量n ≤2000 时,结果以Shapiro - Wilk (W 检验) 为准,当样本含量n >2000 时,结果以Kolmogorov - Smirnov (D 检验) 为准。








2. 方差齐性检验
方差分析的另一个假设：方差齐性，需要检验不同水平下的数据方差是否相等。R中最常用的是Bartlett检验,bartlett.test()调用格式为
bartlett.test(x，g…)
其中，参数X是数据向量或列表(list) ; g是因子向量，如果X是列表则忽略g.当使用数据集时，也通过formula调用函数:
bartlett.test(formala, data, subset，na.action…)
formula是形如lhs一rhs的方差分析公式;data指明数据集:subset是可选项，可以用来指定观测值的一个子集用于分析:na.action表示遇到缺失值时应当采取的行为。

> x=c(x1,x2,x3)
> account=data.frame(x,A=factor(rep(1:3,each=7)))
> bartlett.test(x~A,data=account)
# Bartlett test of homogeneity of variances
# data: x by A
# Bartlett's K-squared = 0.13625, df = 2, p-value = 0.9341
由于P值远远大于显著性水平a=0.05，因此不能拒绝原假设，我们认为不同水平下的数据是等方差的。








3. 方差分析：F-Test
In R the function var.test allows for the comparison of two variances using an F-test.Although it is possible to compare values of s2 for two samples, there is no capability within R for comparing the variance of a sample,s2,to the variance of a population, σ2. The syntax for the testing variances is :

var.test(X, Y, ratio = 1, alternative = "two.sided", conf.level = 0.95)


> std.method<-c( 21.62, 22.20, 24.27, 23.54, 24.25, 23.09, 21.01 )
> new.method<-c(21.54 ,20.51 ,22.31, 21.30, 24.62, 25.72, 21.54 ) 
> var(std.method); var(new.method) 
[1] 1.638495
[1] 3.690329
> var.test(std.method, new.method)    

	F test to compare two variances

data:  std.method and new.method
F = 0.444, num df = 6, denom df = 6, p-value = 0.3462
alternative hypothesis: true ratio of variances is not equal to 1
95 percent confidence interval:
 0.07629135 2.58395513
sample estimates:
ratio of variances 
         0.4439971

#


1）判断组间是否有差别
R中的函数aov()用于方差分析的计算，其调用格式为:
aov(formula, data = NULL, projections =FALSE, qr = TRUE,contrasts = NULL, ...)

其中的参数formula表示方差分析的公式，在单因素方差分析中即为x~A ;
data表示做方差分析的数据框:projections为逻辑值，表示是否返回预测结果;
qr同样是逻辑值，表示是否返回QR分解结果，默认为TRUE;
contrasts是公式中的一些因子的对比列表;
通过函数summary()可列出方差分析表的详细结果。


以淀粉为原料生产葡萄的过程中, 残留许多糖蜜, 可作为生产酱色的原料. 在生产酱色的过程之前应尽可能彻彻底底除杂, 以保证酱色质量.为此对除杂方法进行选择. 在实验中选用5种不同的除杂方法, 每种方法做4次试验, 即重复4次, 结果见表.
除杂方法 / 除杂量X
A1/ 25.6 22.2 28 29.8
A2/ 24.4 30.0 29.0 27.5
...


> X<-c(25.6, 22.2, 28.0, 29.8, 24.4, 30.0, 29.0, 27.5, 25.0, 27.7,
       23.0, 32.2, 28.8, 28.0, 31.5, 25.9, 20.6, 21.2, 22.0, 21.2)
> A<-factor(rep(1:5, each=4))
> miscellany<-data.frame(X, A)
> miscellany
     X A
1  25.6 1
2  22.2 1
3  28.0 1
4  29.8 1
5  24.4 2
6  30.0 2
...
> aov.mis<-aov(X~A, data=miscellany)
> aov.mis
# Call:
#    aov(formula = X ~ A, data = miscellany)
# 
# Terms:
#                       A Residuals
# Sum of Squares  131.957   114.915
# Deg. of Freedom       4        15
# 
# Residual standard error: 2.767851
# Estimated effects may be unbalanced

> summary(aov.mis)
            Df Sum Sq Mean Sq F value Pr(>F)  
A            4  132.0   32.99   4.306 0.0162 *
Residuals   15  114.9    7.66                 
---
Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

代码解释
上述结果中, Df表示自由度; sum Sq表示平方和; Mean Sq表示均方和;
F value表示F检验统计量的值, 即F比; Pr(>F)表示检验的p值; A就是因素A;
Residuals为残差.
可以看出, F = 4.3061 > F0.05(5-1, 20-5) = 3.06, 或者p=0.01618<0.05,
说明有理由拒绝原假设, 即认为五种除杂方法有显著差异.



2）如果有差别，判断是哪两组间有差别
其中，上述所得结果为5个除杂方法之间的差异显著性分析，如果假设上述5中处理中A1为对照组，其余A2,A3,A4,A5均为处理组，现在若想分析一个对照和多个处理间的差异显著性，可以通过以下代码实现：

> A1A2<-miscellany[1:8,]
> A1A2
     X A
1 25.6 1
2 22.2 1
...
> an.aov.mis<-aov(X~A, data=A1A2)
> summary(an.aov.mis)
            Df Sum Sq Mean Sq F value Pr(>F)
A            1   3.51   3.511   0.419  0.542
Residuals    6  50.31   8.385


即选取对照为一组数据，处理为另一组，缺点是对于多个处理一个对照需要重复此操作，现在还没找到好的处理办法，希望以后能学到或者有谁知道望相告。
最近总结出的另一个比较有效的办法：
接上aov()的F检验通过summary(aov.mis)看出五种除杂方法有显著差异.接下来考察具体的差异（多重比较）通过 TukeyHSD()函数：

> TukeyHSD(aov.mis)
##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = X ~ A, data = miscellany)
## 
## $A
##       diff        lwr        upr     p adj
## 2-1  1.325  -4.718582  7.3685818 0.9584566
## 3-1  0.575  -5.468582  6.6185818 0.9981815
## 4-1  2.150  -3.893582  8.1935818 0.8046644
## 5-1 -5.150 -11.193582  0.8935818 0.1140537
## 3-2 -0.750  -6.793582  5.2935818 0.9949181
## 4-2  0.825  -5.218582  6.8685818 0.9926905
## 5-2 -6.475 -12.518582 -0.4314182 0.0330240
## 4-3  1.575  -4.468582  7.6185818 0.9251337
## 5-3 -5.725 -11.768582  0.3185818 0.0675152
## 5-4 -7.300 -13.343582 -1.2564182 0.0146983
#TukeyHSD图
> plot(TukeyHSD(aov.mis))

注意：可以看出上述结果是所有分组间的两两比较，但经常我们所需要的仅仅是一个对照组和其他几个处理组间的比较，这时multcomp包是不错的选择；


a = c(56,60,44,53)
b = c(29,38,18,35)
c = c(11,25,7,18)
d = c(26,44,20,32)
strains.frame = data.frame(a, b, c, d)
strains = stack(strains.frame)  #stack是reshape2包中的一个函数，用于将宽格式数据转化为长格式；
colnames(strains) = c("weight", "group")
##常规的两两相互比较计算
TukeyHSD( aov(weight ~ group, data=strains) )
library(multcomp)
summary(glht(aov(weight ~ group, data=strains), linfct=mcp(group="Dunnett")))
## The first group ("a" in this example) is used as the reference group. 
## If this is not the case, use the relevel() command to set the reference.
strains$group = relevel(strains$group, "b")
str(strains)
head(strains)
summary(glht(aov(weight ~ group, data=strains), linfct=mcp(group="Dunnett")))
plot(glht(aov(weight ~ group, data=strains), linfct=mcp(group="Dunnett")))


More: http://barcwiki.wi.mit.edu/wiki/SOPs/anova

multcomp包部分参数解释：
glht：General Linear Hypotheses，General linear hypotheses and multiple comparisons for parametric models, including generalized linear models, linear mixed effects models, and survival models.
linfct：a specification of the linear hypotheses to be tested，即指定之前的线性model将用于何种检验。
mcp (Multiple comparisons)：多重比较的意思，For each factor, which is included in model as independent variable, a contrast matrix or a symbolic description of the contrasts can be specified as arguments to mcp，其参数意思为Tukey’s all-pair comparisons or Dunnett’s comparison with a control.


> person <- rep(c(1:10),2)
> treat <- c("A","B","A","A","B","B","A","B","A","B","B","A","B","B","A","A","B","A","B","A")
> phase <- rep(c(1,2),each=10)
> x <- c(760,860,568,780,960,940,635,440,528,800,770,855,602,800,958,952,650,450,530,803)
> data46 <- data.frame(person,treat,phase,x)
> data46$person<-factor(data46$person)
> data46
   person treat phase   x
1       1     A     1 760
2       2     B     1 860
...
> result<-aov(x~phase+person+treat,data=data46)
> summary(result)
            Df Sum Sq Mean Sq  F value   Pr(>F)    
phase        1    490     490    9.925   0.0136 *  
person       9 551111   61235 1240.195 1.32e-11 ***
treat        1    198     198    4.019   0.0799 .  
Residuals    8    395      49                      
---
Signif. codes:  0 ?**?0.001 ?*?0.01 ??0.05 ??0.1 ??1

观察p adj值发现两两二者间的方差显著性.

据上述结果可以填写下面的方差分析表:
方差来源  |自由度 /平方和 /均方和 /F比 /p值
因素A     |4  /131.95 /32.989 /4.3061 /0.01618
误差      |15 /114.915 /7.661
总和      |19 /246.872

再通过函数plot( )绘图可直观描述5种不同除杂方法之间的差异, R中运行命令
> plot(miscellany$X~miscellany$A)

从图形上也可以看出, 5种除杂方法产生的除杂量有显著差异, 特别第5种与前面的4种, 而方法1与3, 方法2与4的差异不明显。



ref:
http://www.360doc.com/content/18/0731/12/46931810_774642090.shtml








========================================
Performing a binomial test in R 二项分布检验
----------------------------------------
paper说："one-tailed binomial test"?
The global tendency for 3′ UTR shortening or lengthening in one cell cluster relative to another was tested using a one-tailed binomial test.

1. Binomial test
A binomial test compares the number of successes observed in a given number of trials with a hypothesised probability of success. The test has the null hypothesis that the real probability of success is equal to some value denoted p, and the alternative hypothesis that it is not equal to p. The test can also be performed with a one-sided alternative hypothesis that the real probability of success is either greater than p or that it is less than p.

二项检验将在给定数量的试验中观察到的成功数量与假设的成功概率进行比较。
零假设是：观察值的真实概率等于一个给定的p，备择假设是不等于p。
该检验也可以进行单边备择检验，看p是大于或者小于p。

(1)
> binom.test(nsuccesses, ntrials, p) # 成功的观察数, 实验次数, 假设的p值
where nsuccesses is the number of successes observed, 
ntrials is the total number of trials 
and p is the hypothesised probability of success.

(2)
Alternatively you can give the number of successes and the number of failures observed, as shown below.
> binom.test(c(nsuccesses, nfailures), p) #(c(成功数, 失败数), 概率)

(3)To perform a one-sided test, set the alternative argument to "less" or "greater" as required.
> binom.test(nsuccesses, ntrials, p, alternative="greater") #单边检验


(4)The output includes a 95% confidence interval for the true probability. To adjust the size of this interval, use the conf.level argument as shown.

> binom.test(nsuccesses, ntrials, p, conf.level=0.99) #指定阈值






2. 实例 Example: Binomial test for die(色子) rolls
In a game, you suspect your opponent is using a die which is biased to roll a six greater than 1/6 of the time. Suppose you want to prove this by rolling the die 300 times and using a binomial test to determine whether the probability of rolling a six is equal to 1/6. A one-tailed test with a significance level of 0.05 will be used.

你怀疑对手用的色子投出6的概率超过1/6。
你做了一个实验，投300次，看出现6的概率是否等于1/6。
在0.05水平，单尾检验。

You roll the die 300 times and throw a total of 60 sixes. To perform the test, use the command:

> binom.test(60, 300, 1/6, alternative="greater")

## Exact binomial test
## 
## data:  60 and 300
## number of successes = 60, number of trials = 300, p-value = 0.07299
## alternative hypothesis: true probability of success is greater than 0.1666667
## 95 percent confidence interval:
##  0.1626847 1.0000000
## sample estimates:
## probability of success 
##                    0.2

From the output you can see that the p-value is 0.07299. As this is not less that the significance level of 0.05, we cannot reject the null hypothesis that the probability of rolling a six is 1/6. This means that there is no evidence to prove that the die is not fair.
p>0.05，无法拒绝原假设。也就是没有证据表明色子不公平。



http://www.instantr.com/2012/11/06/performing-a-binomial-test/





========================================
卡方检验 chi-squared tests: 列联表也称为 contingency table, 拟合优度检验
----------------------------------------
x2检验（chi-square test） http://www.cnblogs.com/emanlee/archive/2008/10/25/1319569.html


1.有两类：
There are two types of chi-square tests. Both use the chi-square statistic and distribution for different purposes:

(1)卡方拟合优度检验 chi-square goodness of fit test determines if a sample data matches a population. For more details on this type, see: Goodness of Fit Test.

(2)卡方独立性检验 A chi-square test for independence compares two variables in a contingency table to see if they are related. In a more general sense, it tests to see whether distributions of categorical variables differ from each another.

- A very small chi square test statistic means that your observed data fits your expected data extremely well. In other words, there is a relationship.
- A very large chi square test statistic means that the data does not fit very well. In other words, there isn’t a relationship.

The formula for the chi-square statistic used in the chi square test is:
卡方和 = 求和(i=1 to n) (O-E)**2 /E
- “O” is your observed value and 
- E is your expected value. 

检查自由度df=(row-1)*(col-1),p=0.05的临界值。

https://blog.csdn.net/flowingflying/article/details/8076296
实际观察次数O与某理论次数(E又称期望次数)之差的平方再除以理论次数乃是一个与抽样分布之一的χ2分布非常近似的次数分布。

如同n足够大是，二项分布和正态分布非常吻合一样，这里也不做理解证明，由法国数学家Pearson给出，就当给了个工具，我们相信工具有效，来使用工具，常用于检查出现频率。





2. 实例: 独立性检验
数据: 夫妻家务劳动分工
	Wife	Alternating	Husband	Jointly
Laundry	156	14	2	4
Main_meal	124	20	5	4
Dinner	77	11	7	13
Breakfeast	82	36	15	7
Tidying	53	11	1	57
Dishes	32	24	4	53
Shopping	33	23	9	55
Official	12	46	23	15
Driving	10	51	75	3
Finances	13	13	21	66
Insurance	8	1	53	77
Repairs	0	3	160	2
Holidays	0	1	6	153

# Import the data
file_path <- "http://www.sthda.com/sthda/RDoc/data/housetasks.txt"
housetasks <- read.delim(file_path, row.names = 1)
# head(housetasks)

#1画图
#install.packages("gplots")
library("gplots")
# 1. convert the data as a table
dt <- as.table(as.matrix(housetasks))
# 2. Graph
balloonplot(t(dt), main ="housetasks", xlab ="", ylab="",
            label = FALSE, show.margins = FALSE)
#2马赛克图
library("graphics")
mosaicplot(dt, shade = TRUE, las=2, main = "housetasks")
#3又一个可视化
# install.packages("vcd")
library("vcd")
# plot just a subset of the table
assoc(head(dt, 5), shade = TRUE, las=3)


#做卡方检验，只需要一句
chisq <- chisq.test(housetasks)
chisq
## 	Pearson's Chi-squared test
## 
## data:  housetasks
## X-squared = 1944.5, df = 36, p-value < 2.2e-16
结论： p<0.05，拒绝零假设，也就是行和列相关，夫妻和做的家务有明确对应关系。





探究哪些因素对卡方的贡献：
str(chisq)
chisq$observed #观察值
round(chisq$expected,2) #期望值

#
# Pearson residuals (r): r=(o-e)/sqrt(e)
round(chisq$residuals, 3)

#
# 残差图: 正相关blue，表示行和列有正关联。负相关red
library(corrplot)
corrplot(chisq$residuals, is.cor = FALSE)
## For a given cell, the size of the circle is proportional to the amount of the cell contribution.


#每个cell对卡方值的贡献 contrib=r**2/卡方
# Contibution in percentage (%)
contrib <- 100*chisq$residuals^2/chisq$statistic
round(contrib, 3)
# Visualize the contribution
corrplot(contrib, is.cor = FALSE)





3. 实例： 拟合优度检验
http://www.sthda.com/english/wiki/chi-square-goodness-of-fit-test-in-r

The chi-square goodness of fit test is used to compare the observed distribution to an expected distribution, in a situation where we have two or more categories in a discrete data. In other words, it compares multiple observed proportions to expected probabilities.
比较每一份的比例，是否和期望的概率一致。


Suppose that, in the region where you collected the data, the ratio of red, yellow and white tulip is 3:2:1 (3+2+1 = 6). This means that the expected proportion is:
3/6 (= 1/2) for red
2/6 ( = 1/3) for yellow
1/6 for white


R语言：
tulip <- c(81, 50, 27) #实际抽样的结果
res <- chisq.test(tulip, p = c(1/2, 1/3, 1/6))
res

## 	Chi-squared test for given probabilities
## 
## data:  tulip
## X-squared = 0.20253, df = 2, p-value = 0.9037
p>0.05，无法拒绝零假设。也就是认为采样符合期望的比例。


#拿到p值
res$p.value #[1] 0.9036928




描述： https://www.statisticshowto.datasciencecentral.com/probability-and-statistics/chi-square/
R语言： http://www.sthda.com/english/wiki/chi-square-test-of-independence-in-r



========================================
|-- Fisher’s Exact Test in R (代替卡方检验，2x2列联表 计数比较少的时候)
----------------------------------------
1.Fisher’s Exact Test is a test of significance that is used in place of a Chi Square Test in 2×2 tables when the sample sizes are small.

This tutorial explains how to conduct Fisher’s Exact Test in R.
https://www.statology.org/how-to-conduct-fishers-exact-test-in-r/


#step1 create 2x2 dataset
data = matrix(c(2,5,9,4), nrow = 2)
#view dataset
data
# 2 9
# 5 4
#step2 To conduct Fisher’s Exact Test, we simply use the following code:
fisher.test(data)
#
#	Fisher's Exact Test for Count Data
#
#data:  data
#p-value = 0.1597
#alternative hypothesis: true odds ratio is not equal to 1
#95 percent confidence interval:
# 0.0130943 1.8397543
#sample estimates:
#odds ratio 
# 0.1957871 



In Fisher’s Exact Test, the null hypothesis is that the two columns are independent (or equivalently, that the odds ratio is equal to 1). To determine if the two columns are independent, we can look at the p-value of the test. In this case the p-value is 0.1597, which tells us we do not have sufficient evidence to reject the null hypothesis. Thus, we cannot say that there is any statistically significant difference between the two columns.
原假设是两列是独立的，或者说 odds ratio 是1。
为了检验两列是否独立，可以看p值。本例中p=0.1597，并不能拒绝原假设。
我们不能说两列有显著差异。

Note that the odds ratio is 0.1957871. Since the p-value of the test is 0.1597, this tells us that the odds ratio is not significantly different than 1.
因为p不显著，odds ratio 是 0.1957871，和1没有显著差异。

The output of the test also gives us a 95% confidence interval for the odds ratio, which is:
(0.0130943, 1.8397543)

Since the number “1” is within this ratio, it confirms that the odds ratio is not significantly different than 1 (assuming we use alpha level 0.05).







2.Fisher’s Exact Test of Independence
https://rcompanion.org/rcompanion/b_07.html


### Chipmunk example, Fisher’s exact test, p. 80
Input =("
        Distance    Trill  No.trill
        10m        16     8
        100m        3    18
        ")
Matriz = as.matrix(read.table(textConnection(Input),
                              header=TRUE,
                              row.names=1))
Matriz
#     Trill No.trill
#10m     16        8
#100m     3       18
fisher.test(Matriz, alternative="two.sided")

#	Fisher's Exact Test for Count Data
#
#data:  Matriz
#p-value = 0.0006862
#alternative hypothesis: true odds ratio is not equal to 1
#95 percent confidence interval:
#  2.32073 77.46500
#sample estimates:
#odds ratio 
#  11.23249







3.








http://www.utstat.toronto.edu/~brunner/oldclass/312f12/lectures/312f12FisherWithR.pdf








========================================
非参数检验: Mann-whitney U test(== Wilcoxon rank sum test)， 及R/Python代码
----------------------------------------

Q: Mann Whitney U test 和Wilcoxon test是什么关系
A: 这两者都是 适用与不知总体分布形态的，两独立样本，知小样本资料的非参数检验。都是 秩和检验，SPSS读的是Mann-Whitney U检验的结果道。

Wilcoxon signed-rank test应用于两个related samples，

Mann–Whitney U test也叫回Wilcoxon rank-sum test，应用于两个independent samples的情况。

公式和统计量不大一样，结果也略有所差异，但这不大影响使用答这两种方法。
samples size小的时候，是有列表的，sample size大到20左右时，就可以使用正态分布来近似，不查表了





1.对分组变量的差异显著性检验是微生物生态数据分析中常见的内容。

T-test是最为常用的检验方法，但t-test要求数据符合正态分布，在不符合正态分布的时候检验准确性要大打折扣。检验数据是否符合正态分布的方法可见往期推文“看SPSS如何检验数据是否服从正态分布”。如果被检数据不符合正态分布怎么办呢？

Wilcoxon test无需数据服从正态分布，适合在数据总体方差未知或知道甚少的情况下使用。
相应的缺点是，在数据符合正态分布的情况下，检验的准确性要比t-test低。下面介绍如何在R中实现Wilcoxon test。


曼-惠特尼U检验又称“曼-惠特尼秩和检验”，是由H.B.Mann和D.R.Whitney于1947年提出的。
它假设两个样本分别来自除了总体均值以外完全相同的两个总体，目的是检验这两个总体的均值是否有显著的差别。

Mann-Whitney U 检验是用得最广泛的两独立样本秩和检验方法。简单的说，该检验是与独立样本t检验相对应的方法，当正态分布、方差齐性等不能达到t检验的要求时，可以使用该检验。
其假设基础是：若两个样本有差异，则他们的中心位置将不同。


wilcoxon秩和及wilcoxon符号秩检验是对原假设的非参数检验，在不需要假设两个样本空间都为正态分布的情况下，测试它们的分布是否完全相同。






2.利用R进行Mann-Whitney U test检验(wilcox_test)：
Wilcoxon test使用方法和t-test类似，在R中输入‘?wilcox.test()’即可查看使用方法。如下：
Description: Performs one- and two-sample Wilcoxon tests on vectors of data; the latter is also known as ‘Mann-Whitney’ test.

Usage:wilcox.test(x, ...)

(1)## Default S3 method:
wilcox.test(x, y = NULL,
            alternative = c("two.sided", "less", "greater"),
            mu = 0, paired = FALSE, exact = NULL, correct = TRUE,
            conf.int = FALSE, conf.level = 0.95, ...)
#
非配对数据，样本个数不一定一样，比较均值大小。在R中执行wilcox.test(x, y, alternative ='two.sided')。
这里两处理的样品数目可以不等。我们不知道x和y谁大谁小，所以我们选择双尾检验（‘two.sided’）。如果要验证x是否显著大于y，可以选择‘greater’；验证x是否显著小于y，可以选择‘less’。
#
处理前后的配对数据，比较均值大小。则在R中执行wilcox.test(x, y, alternative ='two.sided',paired=T)。
这里各样品处理前后数据要一一对应，数目相等。同样地，用‘greater’或‘less’可以验证x是否显著大于或小于y。

(2)## S3 method for class 'formula'
wilcox.test(formula, data, subset, na.action, ...)



因为有公式，还是看原文好。
有书了尽量看书。
refer:
1.https://blog.csdn.net/qq_34734303/article/details/80296316
2.https://www.jianshu.com/p/8c0e7ce7a290








3.实例
>s1<-c(6,1,1,1,1,1)
>s2<-c(5,5,5,5,5,0)
>s<-c(s1,s2)
>type<-c(rep(1,6),rep(2,6))
>wd<-as.dataframe(cbind(s,as.factor(type)))
>wilcox_test(s~type,data=wd)
  Asymptotic Wilcoxon-Mann-Whitney test
data:data by type(1,2)
Z=-1.2086,p-value=0.2268
alternative hypothesis:true mu is not equal to 0

根据结果显示，p-value值大于0.05，认为支持零假设，两个样品无差异。





##### (1). 在R中利用wilcox.test函数进行曼-惠特尼U检验。
用来检验两组独立样品是否来自两组不同的样品。不要求样本数量必须相等。
曼-惠特尼U检验Mann–Whitney Test: 两个独立样本，均匀分布，非正太分布, 两组样本量必须大于20
t检验假设两个样本的数据集之间的差别符合正态分布（当两个样本集都符合正态分布时，t检验效果最佳）


例1
library(stats)
data("mtcars")
boxplot(mtcars$mpg~mtcars$am, ylab='mpg', names = c('automatic','manual'))
## 手动、自动挡mpg每英里耗油量。

#执行wilcoxon秩和检验验证自动档手动档数据分布是否一致
## wilcox.test(mtcars$mpg[mtcars$am==0],mtcars$mpg[mtcars$am==1])（与下面等价）
> wilcox.test(mpg ~ am, data=mtcars)
## 	Wilcoxon rank sum test with continuity correction
## data:  mpg by am
## W = 42, p-value = 0.001871
## alternative hypothesis: true location shift is not equal to 0

原假设为两种变速器的油耗完全相同，p-value小于0.05，拒绝原假设，意味着两种变速器的油耗有显著差异。



例2
## Formula interface.
boxplot(Ozone ~ Month, data = airquality)
wilcox.test(Ozone ~ Month, data = airquality, subset = Month %in% c(5, 8)) ## 看5月和8月是否有显著区别？
##
	Wilcoxon rank sum test with continuity correction
data:  Ozone by Month
W = 127.5, p-value = 0.0001208
alternative hypothesis: true location shift is not equal to 0
## p<0.05，决绝零假设，也就是两组有显著差别。







### (2) 威尔科克森符号秩检验实现(处理前后、配对数据)
配对样本，均匀分布，非正太分布: Wilcoxon signed-rank test。Wilcoxon Signed-Rank Test, 用来进行配对样品的非参数检验。

# 一个样本：使用药物前后病情指数，配对样本。
x <- c(1.83,  0.50,  1.62,  2.48, 1.68, 1.88, 1.55, 3.06, 1.30)
y <- c(0.878, 0.647, 0.598, 2.05, 1.06, 1.29, 1.06, 3.14, 1.29)
wilcox.test(x, y, paired = TRUE, alternative = "greater") #要指定单尾测试，我们将替代参数设置为greater。
wilcox.test(y - x, alternative = "less")    # The same.
wilcox.test(y - x, alternative = "less",
            exact = FALSE, correct = FALSE) # H&W large sample
# approximation
## Wilcoxon signed rank test
## data:  x and y
## V = 40, p-value = 0.01953
## alternative hypothesis: true location shift is greater than 0
p<0.05，拒绝零假设，因此治疗前后是有差异的。






4. Nonparametric Comparison of Two Groups:
Mann–Whitney Test
If the measurement values from two groups are not normally distributed we have to resort to a nonparametric test. 
The most common nonparametric test for the comparison of two independent groups is the Mann–Whitney(–Wilcoxon) test.
Watch out, because this test is sometimes also referred to as Wilcoxon rank-sum test. 
This is different from the Wilcoxon signed rank sum test! 
注意和Wilcoxon signed rank sum test不同！

The test-statistic for this test is commonly indicated with u:
u_statistic, pVal = stats.mannwhitneyu(group1, group2)

https://github.com/thomas-haslwanter/statsintro_python/tree/master/ISP/Code_Quantlets/08_TestsMeanValues/twoGroups








========================================
|-- Wilcoxon 检验之 rank-sum(秩和检验，独立样本) 与 signed-rank(符号秩检验，配对样本) 的区分
----------------------------------------
Wilcoxon rank-sum test（我翻译为秩和检验）和 Wilcoxon signed-rank test（我翻译为符号秩检验）。

Frank Wilcoxon (1892—1965) 是美国的统计学家，发表了 70 篇左右论文，但其最大的贡献就是这 2 个以他名字命名的非参假设检验方法：秩和检验 和 符号秩检验。
他在 1945 年发表的论文 1 中将二者分别称为 非成对检验 （unpaired experiment）和 成对检验（paired comparison）。 正是因为其巨大影响力使得这两个检验方法都以他的名字命名，并流传下来。


假设检验有点类似于我们高中数学中常见的“反证法”，即提出一个错误的假设，然后证明它是错的。那么我们提出的假设叫做 原假设 (Null Hypothesis)，简写为 H0，应为一般假设没有区别，也叫零假设，承认没有区别。
我们备选的假设叫做 备选假设 (Alternative Hypothesis)，简写为 Hα或H1。是零假设的否定，也就是有差别。
注意，在假设检验中只有 2 个假设，即原假设和备选假设，我们的目的就是要拒绝原假设。





1.Wilcoxon rank-sum test 定义如下，

In statistics, the Mann–Whitney U test (also called the Mann–Whitney–Wilcoxon (MWW), Wilcoxon rank-sum test, or Wilcoxon–Mann–Whitney test) is a nonparametric test.
This test can be used to determine whether two independent samples were selected from populations having the same distribution. 2

概念： 在统计学中，Wilcoxon rank-sum test（威尔科克森秩和检验）也叫 Mann-Whitney U test（曼-惠特尼 U 检验），或者 Wilcoxon-Mann-Whitney test。

秩和检验是一个非参的假设检验方法，一般用来检测 2 个数据集是否来自于相同分布的总体。特别地，秩和检验不要求 2 个数据集大小相同，也就是说进行秩和检验并不是两两成对比较，这一点区别于下面描述的符号秩检验。

例子:
x1=c(9,5,8,7,10,6,7) #n1=7个元素
x2=c(7,4,5,6,3,6,4,4) #n2=8个元素

step1: 排序，记下每个数的顺序
遇到相同的数字，则他们的rank取平均rank。
计算rank之和
R1=sum( c(14,5.5,13,11,15,8,11) )=77.5
R2=sum( c(11,3,5.5,8,1,8,3,3) )=42.5

step2:令T表示样本小的秩和，T=R1=77.5，根据公式计算：
U1=n1*n2 + n1*(n1+1)/2 -T=6.5
U2=n1*n2 -U1=49.5

step3: 由于U1更小，查Wilcoxon双尾临界表，当alpha=0.05，n1=7,n2=8的临界值是10.
由于U1=6.5<10，所以拒绝原假设。
结论：x1和x2存在显著性差异，他们来自不同的总体。


(1)Python中使用scipy包的stats.mannwhitneyu() 函数来实现秩和检验
from scipy import stats
def wilcoxon_rank_sum_test(x, y):
    res = stats.mannwhitneyu(x ,y)
    print(res)

x=[9,5,8,7,10,6,7]
y=[7,4,5,6,3,6,4,4]
wilcoxon_rank_sum_test(x,y)
## MannwhitneyuResult(statistic=6.5, pvalue=0.006966479792405637)
得到的统计量，就是我们的U1值。 
结论：p<0.05,拒绝零假设，有显著差异。



(2) R语言版本:
x=c(9,5,8,7,10,6,7)
y=c(7,4,5,6,3,6,4,4)
wilcox.test(x,y)
## 
# Wilcoxon rank sum test with continuity correction
# data:  x and y
# W = 49.5, p-value = 0.01393
#alternative hypothesis: true location shift is not equal to 0
#
## 怎么做连续性矫正？ //todo
#
wilcox.test(x,y, correct=F)
## Wilcoxon rank sum test
## data:  x and y
## W = 49.5, p-value = 0.01182
## alternative hypothesis: true location shift is not equal to 0









2. Wilcoxon 符号秩检验, 配对数据。最好20组数据以上。
根据 wikipedia 解释， Wilcoxon signed-rank test 定义如下，

A Wilcoxon signed-rank test is a nonparametric test that can be used to determine whether two dependent samples were selected from populations having the same distribution. 

概念： Wilcoxon signed-rank test（威尔科克森符号秩检验）也是一种非参的假设检验方法，它成对的检查 2 个数据集中的数据（即 paired difference test）来判断 2 个数据集是否来自相同分布的总体。

ID	y1  y2 sign abs rank
0	125	110	+1	15	7
1	115	122	-1	7	3
2	130	125	+1	5	1.5
3	140	120	+1	20	9
4	140	140	-	0	-
5	115	124	-1	9	4
6	140	123	+1	17	8
7	125	137	-1	12	6
8	140	135	+1	5	1.5
9	135	145	-1	10	5

step1: 配对数据求差，求绝对值abs，按照abs排序得到rank列。
对于abs=0的，舍弃，如ID=4的行。因为零假设的差异是0为中心的，观察值恰好是0不能提供决绝零假设的信息。过多，则降低统计功效。
对于abs相同的，取rank的平均值，如ID=2和8的行，(1+2)/2

step2: 根据sign列和rank列，分别计算大于0的秩和Wplus，和小于0的秩和Wminus。
Wplus=7+1.5+9+8+1.5=27
Wminus=3+4+6+5=18
## 感觉这个不准： 最终的秩 W=abs(Wplus - Wminus)=9
## 这个靠谱：在零假设下，W+和W-应差不多。因而，当其中之一很小时，应怀疑零假设。在此，取检验统计量W=min(W+,W-)=18


step3: 根据W，查表，alpha=0.05, n=9时的临界值是5，而我们计算出的W=9>5，因此不能拒绝原假设。//why?需要看概率分布图
结论：y1和 y2无显著性差异，他们来自于分布相同的总体。




(1)在 python 中我们调用 scipy 包来里的 stats.wilcoxon() 函数来实现秩和检验
from scipy import stats
def wilcoxon_signed_rank_test(y1, y2):
    res = stats.wilcoxon(y1, y2)
    print(res)
#
y1=[125, 115, 130, 140, 140, 115, 140, 125, 140, 135]
y2=[110, 122, 125, 120, 140, 124, 123, 137, 135, 145]
wilcoxon_signed_rank_test(y1,y2)
###
#  UserWarning: Warning: sample size too small for normal approximation.
#   warnings.warn("Warning: sample size too small for normal approximation.")
WilcoxonResult(statistic=18.0, pvalue=0.5936305914425295)

给出的统计量18就是min(Wplus, Wminus).
p=0.59>0.05, 无法拒绝原假设，也就是可能无差异。


如果p值较小(比如小于或等于给定的显著性水平，譬如0.05)则可以拒绝零假设。
如果p值较大则没有充分的证据来拒绝零假设，但不意味着接受零假设。


之所以出现 Warning 信息是因为我们的数据量太少，一般来讲大于 20 是比较合适做假设检验的。






(2)R 语言版本：
y1=c(125, 115, 130, 140, 140, 115, 140, 125, 140, 135)
y2=c(110, 122, 125, 120, 140, 124, 123, 137, 135, 145)
wilcox.test(y1, y2, paired = TRUE, alternative = "greater")
###
# Wilcoxon signed rank test with continuity correction
# data:  y1 and y2
# V = 27, p-value = 0.3176
# alternative hypothesis: true location shift is greater than 0
#
wilcox.test(y1 - y2, alternative = "greater", exact = F, correct = F) #不矫正





为什么R和手算、Python版本的P值都不一样呢？


refer
https://blog.csdn.net/chikily_yongfeng/article/details/82255575
Wikipedia. Wilcoxon rank-sum test. link: https://en.wikipedia.org/wiki/Mann-Whitney_U_test
Wikipedia. Wilcoxon signed-rank test. link: https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test
https://blog.csdn.net/weixin_34067980/article/details/85890225






========================================
|-- Kruskal-Wallis Test 单因素方差分析的非参版/ 两样本Wilcoxon检验的多样本版
----------------------------------------
Kruskal-Wallis Test in R
http://www.sthda.com/english/wiki/kruskal-wallis-test-in-r

Kruskal-Wallis test by rank is a non-parametric alternative to one-way ANOVA test, which extends the two-samples Wilcoxon test in the situation where there are more than two groups. It’s recommended when the assumptions of one-way ANOVA test are not met. This tutorial describes how to compute Kruskal-Wallis test in R software.

## Kruskal-Wallis rank sum test?



1. Kruskal-Wallis Test
http://www.r-tutor.com/elementary-statistics/non-parametric-methods/kruskal-wallis-test

A collection of data samples are independent if they come from unrelated populations and the samples do not affect each other. Using the Kruskal-Wallis Test, we can decide whether the population distributions are identical without assuming them to follow the normal distribution.

例子:
在名为 airquality 的内置数据集中，记录了纽约1973年5月至9月的每日空气质量测量数据。臭氧密度在数据框中 Ozone 列。
> head(airquality) 
  Ozone Solar.R Wind Temp Month Day 
1    41     190  7.4   67     5   1 
2    36     118  8.0   72     5   2 
    .....

Problem问题
Without assuming the data to have normal distribution, test at .05 significance level if the monthly ozone density in New York has identical data distributions from May to September 1973.
不用假设数据符合正态分布，检验每月抽样浓度分布是否在0.05显著性水平上一致？

Solution解答
The null hypothesis is that the monthly ozone density are identical populations. To test the hypothesis, we apply the kruskal.test function to compare the independent monthly data. The p-value turns out to be nearly zero (6.901e-06). Hence we reject the null hypothesis.
零假设：每月抽样浓度是相同的总体。
为了检验，使用 kruskal.test 函数，检验每月数据的独立性，p值很小接近于零。所以拒绝零假设。

> kruskal.test(Ozone ~ Month, data = airquality) 
#
#        Kruskal-Wallis rank sum test 
# 
#data:  Ozone by Month 
#Kruskal-Wallis chi-squared = 29.267, df = 4, p-value = 6.901e-06

Answer答案
At .05 significance level, we conclude that the monthly ozone density in New York from May to September 1973 are nonidentical populations.
每月的分布不是相同的。






2.Kruskal-Wallis Test
https://www.statisticssolutions.com/kruskal-wallis-test/

The Kruskal-Wallis test is a nonparametric (distribution free) test, and is used when the assumptions of one-way ANOVA are not met.  
非参数检验，适用于 one-way ANOVA 条件达不到的情形。

Both the Kruskal-Wallis test and one-way ANOVA assess for significant differences on a continuous dependent variable by a categorical independent variable (with two or more groups).  
Kruskal-Wallis test and 单因素方差分析用来评估在一个分类独立变量(2组或更多组)时，一个连续的因变量的显著差异，

In the ANOVA, we assume that the dependent variable is normally distributed and there is approximately equal variance on the scores across groups. However, when using the Kruskal-Wallis Test, we do not have to make any of these assumptions.  
ANOVA 假设因变量是正态分布的，组间变异程度近似。而Kruskal-Wallis检验不需要这些假设。

Therefore, the Kruskal-Wallis test can be used for both continuous and ordinal-level dependent variables.  However, like most non-parametric tests, the Kruskal-Wallis Test is not as powerful as the ANOVA.
所以，Kruskal-Wallis test 可以用于连续性或者排序型因变量。然而，和大多数非参数检验一样，效力比不上ANOVA。


Null hypothesis: Null hypothesis assumes that the samples (groups) are from identical populations.
零假设：每组样品都来自同一个总体。

Alternative hypothesis: Alternative hypothesis assumes that at least one of the samples (groups) comes from a different population than the others.


Example questions answered:
i)How do test scores differ between the different grade levels in elementary school?
ii)Do job satisfaction scores differ by race?

The distribution of the Kruskal-Wallis test statistic approximates a chi-square distribution, with k-1 degrees of freedom, if the number of observations in each group is 5 or more.  If the calculated value of the Kruskal-Wallis test is less than the critical chi-square value, then the null hypothesis cannot be rejected.  If the calculated value of Kruskal-Wallis test is greater than the critical chi-square value, then we can reject the null hypothesis and say that at least one of the samples comes from a different population.
和自由度为1的卡方检验近似，如果每组观测值>=5。
如果p很小，否定原假设，就是至少一个组来自另一个总体。

Assumptions
1. We assume that the samples drawn from the population are random.
2. We also assume that the observations are independent of each other.
3. The measurement scale for the dependent variable should be at least ordinal.







3.Kruskal-Wallis test (H-test) 是 Wilcoxon test 的延伸，用于检验一系列非配对数据是否来自于同一个总体。
The Kruskal-Wallis test (H-test) is an extension of the Wilcoxon test and can be used to test the hypothesis that a number of unpaired samples originate from the same population. 

In MedCalc, Factor codes are used to break-up the (ordinal) data in one variable into different sample subgroups. If the null-hypothesis, being the hypothesis that the samples originate from the same population, is rejected (P<0.05), then the conclusion is that there is a statistically significant difference between at least two of the subgroups.

https://www.medcalc.org/manual/kruskal-wallis_test.php






========================================
转录组差异表达筛选的真相
----------------------------------------
可惜，TPM、FPKM等方法已经对测序深度进行了均一化，所以生来就是用来比较样品内不同基因表达差异的，用于不同样品间同一基因的差异表达分析并不合适，很多信息已经被抹去了。


其实统计学家也很无奈啊，看看我们转录组实验得到的这些数据吧：我们的实验只进行少得可怜的生物学重复（n<10），而且，任何基因的表达量都不能是负数，这些数据并不符合正态分布，用于表征表达量的counts是非连续的（芯片信号是连续的），RNA-seq数据的离散通常是高度扭曲的，方差往往会大于均值……，就这些奇怪的特征，使得准确估计方差并没有想象的那么容易。


我们面临两个核心问题：
基因表达数据适合用什么统计学分布进行差异显著性检验？
如何利用少量生物学重复数据估算基因表达的标准差？



我们不去抖旧包袱，反正经过各种较量，大家普遍接受生物学重复这么少的情况下，RNA-seq数据用负二项分布（Negative binomialdistribution，通常写作NB）进行显著性检验是较合适的。

但，在生物学重复很少时，我们是很难准确计算每个基因表达的标准差的（相当于这个数据集的离散程度）。我们很可能会低估数据的离散程度。

被逼无奈的科学家提出了一个假设：表达丰度相似的基因，在总体上标准差应该也是相似的。我们把不同生物学重复中表达丰度相同的基因的总标准差取个平均值，低于这个值的都用这个值，高于这个值的就用算出来的值。







refer:
生信百科 2017-06-02 https://mp.weixin.qq.com/s/VcjnvI5FqwOFEC9wSUfdSw



========================================
MA plot 
----------------------------------------
MA plot即M-versus-A plot，在芯片数据处理出现之前也称为Bland-Altman plot，是由发明者名字命名的，而MA plot是对M与A作图而得名，M是minus的缩写，代表两个值之差，A是add的缩写，代表两个值之和。有研究者也把MA plot称为Ratio-Intensity (RI) plots，同时MA也正好是micro-array的简写。


MA plot的作用是为了展示两个值几乎相等的变量（x和y）之间的关系，为了展示两个变量之间的变化关系，大多数人的思维都是把x与y分别作为横轴和纵轴进行绘图，如果y=x，则该图呈45度角的直线（如下图中左边图的蓝色直线），可以通过查看点形成的直线偏离预期直线的多少来衡量系统偏差，然而该图存在以下几个缺点：

1. 人的视觉对水平线比更敏感
2. 不同坐标轴的刻度可能会使预期参考直线偏离45度
3. 很难从直观上衡量偏离一条线性的大小


MA plot的处理方法是把该直线顺时针旋转45度，把参考对角线变为直线，具体做法是把(x+y)/2作为横轴，(y-x)作为纵轴，则参考直线变为一条水平线，如下方右图，这样可以很清楚的在视觉上展示两个相等的变量之间偏离参考值的大小，即存在的系统误差的大小


图：MA plot与传统的y-x plot


对于芯片数据中信号值x和y的比较，一般先对它们进行log2处理，再进行Minus（log2{Y}-log2{x}=log2(y/x））和Add（(log2{x}+log2{y})/2）做MA plot，为什么使用log2处理的原因如下：

1. 取对数后的两组数据的值差异比不取对数时更独立于其值大小
2. 对于取对数后的值标准化只需简单的加法即可
3. 取对数后使分布不太过度偏斜
4. 取对数后使变异大小跨度更真实
5. 取log2而不取ln或log10是因为芯片的信号值大小范围为0~2^16-1的整数值（一般都是用计算机的16位来存储信号强度值）

参考：
http://bmbolstad.com/Dissertation/Bolstad_2004_Dissertation.pdf
http://bioinformatics.mdanderson.org/MicroarrayCourse/Lectures10/r3_bw.pdf
http://www.jstor.org/stable/24307038?seq=1#page_scan_tab_contents

ref:
https://www.jianshu.com/p/cdfac0bfb733



========================================
如何轻松绘制基因表达聚类趋势图
----------------------------------------

http://tool.biomooc.com/R_scripts/





========================================
相关系数: pearson correlation, spearman correlation, kendall correlation coefficient (定义、适用范围、意义、代码实现)
----------------------------------------
cor(x, y = NULL, use = "everything",
    method = c("pearson", "kendall", "spearman"))
#


1. 区别
(1)答案1
pearson相关系数和spearman相关系数的区别？

(1).连续数据，正态分布，线性关系，用pearson相关系数是最恰当，当然用spearman相关系数也可以，效率没有pearson相关系数高。
(2).上述任一条件不满足，就用spearman相关系数，不能用pearson相关系数。
(3).两个定序测量数据之间也用spearman相关系数，不能用pearson相关系数。

通常情况下默认用复pearson相关系数，数据分布呈现出不正态时制用Spearman相关系数。

在SPSS软件相关分析中,pearson(皮尔逊),kendall（肯德尔）和spearman（斯伯曼/斯皮尔曼）三种相关分析方法有什么异同？ 


(2)答案2

两个连续变量间呈线性相关时，使用Pearson积差相关系数，
不满足积差相关分析的适用条件时，使用Spearman秩相关系数来描述。

Spearman相关系数又称秩相关系数，是利用两变量的秩次大小作线性相关分析，对原始变量的分布不作要求，属于非参数统计方法，适用范围要广些。

对于服从Pearson相关系数的数据亦可计算Spearman相关系数，但统计效能要低一些。

Pearson相关系数的计算公式可以完全套用Spearman相关系数计算公式，但公式中的x和y用相应的秩次代替即可。


Kendall'stau-b等级相关系数：用于反映分类变量相关性的指标，适用于两个分类变量均为有序分类的情况。



对相关的有序变量进行非参数相关检验；取值范围在[-1, 1]之间，此检验适合于正方形表格；
	计算积距pearson相关系数，连续性变量才可采用;
	计算Spearman秩相关系数，适合于定序变量或不满足正态分布假设的等间隔数据;
	计算Kendall秩相关系数，适合于定序变量或不满足正态分布假设的等间隔数据。



(3) 实例区分

当比较的两个变量是单调相关的，比如tanh函数，即使它们的关系不是线性的，Spearman相关性为1。这意味着x值大于给定数据点的所有数据点也将具有更大的y值。相比之下，这并没有给出完美的Pearson相关性。


#正相关的例子
x=seq(-15,15, by=0.2)
y=(exp(x) - exp(-x) )/(exp(x) + exp(-x) )
RSp=cor.test(x,y, method = 'pearson');RSp #0.89
RSs=cor.test(x,y, method = 'spearman');RSs #1

plot(x,y, type='o', main=paste0("rho_p=",round(RSp$estimate,2), "(p=",RSp$p.value, ')\n',
                                "rho_s=",round(RSs$estimate,2), "(p=",RSs$p.value, ')')  )


## 负相关的例子
x=seq(-15,15, by=0.2)
y=exp(-x)
RSp=cor.test(x,y, method = 'pearson');RSp #-0.43
RSs=cor.test(x,y, method = 'spearman');RSs #-1





2. 定义和代码实现

(1). person correlation coefficient（皮尔森相关性系数）
两个变量(X, Y)的皮尔森相关性系数(ρX,Y)等于它们之间的协方差cov(X,Y)除以它们各自标准差的乘积(σX, σY)。

cor(X,Y)=cov(X,Y)/ sqrt( var(X) * var(Y) )


公式的分母是变量的标准差，这就意味着计算皮尔森相关性系数时，变量的标准差不能为0（分母不能为0），也就是说你的两个变量中任何一个的值不能都是相同的。如果没有变化，用皮尔森相关系数是没办法算出这个变量与另一个变量之间是不是有相关性的。

就好比我们想研究人跑步的速度与心脏跳动的相关性，如果你无论跑多快，心跳都不变（即心跳这个变量的标准差为0），或者你心跳忽快忽慢的，却一直保持一个速度在跑（即跑步速度这个变量的标准差为0），那我们都无法通过皮尔森相关性系数的计算来判断心跳与跑步速度到底相不相关。


假设你现在做了个生物学实验，喜得以下两个变量：
X1=c(1, 2, 3, 4, 5, 6)
Y1=c(0.3, 0.9, 2.7, 2, 3.5, 5)

mean(X1)  #平均值 3.5
mean(Y1)  #2.4

var(X1)    #方差 3.5
var(Y1) #3.976

sd(X1)     #标准差 sd(X1)     #标准差
sd(Y1) #1.725109

cov(X1,Y1)  #协方差 3.06

cor(X1,Y1,method="pearson")  #皮尔森相关性系数 0.9481367

cov(X1,Y1)/(sd(X1)*sd(Y1)) #0.9481367

此外，从上面的公式我们知道，皮尔森相关性系数是协方差与标准差的比值，所以它对数据是有比较高的要求的：
第一， 实验数据通常假设是成对的来自于正态分布的总体。
为啥通常会假设为正态分布呢？
因为我们在求皮尔森相关性系数以后，通常还会用t检验之类的方法来进行皮尔森相关性系数检验，而 t检验是基于数据呈正态分布的假设的。

## 获取p值：
rs=cor.test(X1,Y1);rs
str(rs)
rs$p.value #0.003964957 p值
#rs$estimate
#str(rs$estimate)
#attr(rs$estimate, which="names") #"cor"
as.numeric(rs$estimate) #0.9481367 相关系数

第二， 实验数据之间的差距不能太大，或者说皮尔森相关性系数受异常值的影响比较大。比如刚才心跳与跑步的例子，万一这个人的心脏不太好，跑到一定速度后承受不了，突发心脏病，那这时候我们会测到一个偏离正常值的心跳（过快或者过慢，甚至为0），如果我们把这个值也放进去进行相关性分析，它的存在会大大干扰计算的结果的。




(2) spearman correlation coefficient（斯皮尔曼相关性系数）
斯皮尔曼相关性系数，通常也叫斯皮尔曼秩相关系数。“秩”，可以理解成就是一种顺序或者排序，那么它就是根据原始数据的排序位置进行求解，这种表征形式就没有了求皮尔森相关性系数时那些限制。下面来看一下它的计算公式：

表示通常的Pearson相关系数，但应用于秩变量：秩变量的协方差 / 秩变量的标准偏差乘积。

简化后：
ro = 1 -  6*累加(di ** 2 ) / [n(n**2-1)]


计算过程就是：首先对两个变量（X, Y）的数据进行排序，然后记下排序以后的位置（X’, Y’），（X’, Y’）的值就称为秩次，秩次的差值就是上面公式中的di，n就是变量中数据的个数，最后带入公式就可求解结果。举个例子吧，假设我们实验的数据如下：


X     Y   X1  Y1 di
11    2   2   1  1
490  75   6   6  0
14    3   3   2  1
43   44   5   5  0
30    7   4   3  1
3    42   1   4  3


把秩序X1,Y1带入person相关系数公式中，cor(X,Y)=cov(X,Y)/ sqrt( var(X) * var(Y) )
就得到spearman相关系数：
X1=rank(X) #注意！不能用order()!
Y1=rank(Y)
cov(X1,Y1)=2.3
cov(X1,Y1)/sqrt(var(X1)*var(Y1)) #[1] 0.6571429


带入快捷公式，求得斯皮尔曼相关性系数：ρs= 1-6*(1+1+1+9)/6/35=0.657


也就是说，我们不用管X和Y这两个变量具体的值到底差了多少，只需要算一下它们每个值所处的排列位置的差值，就可以求出相关性系数了。这下理解起来是不是容易多了！还是用上面的数据，下面写下代码实现：

> X=c(11,490,14,43,30,3)
> Y=c(2,75,3,44,7,42)
> cor(X,Y,method="spearman") 
[1] 0.6571429

# 检验显著性
> rs=cor.test(X,Y,method="spearman") 
> rs$estimate  #0.6571429 
> rs$p.value #0.175




(3). kendall correlation coefficient（肯德尔相关性系数）
肯德尔相关性系数，又称肯德尔秩相关系数，它也是一种秩相关系数，不过它所计算的对象是分类变量。
分类变量可以理解成有类别的变量，可以分为
无序的，比如性别（男、女）、血型（A、B、O、AB）；
有序的，比如肥胖等级（重度肥胖，中度肥胖、轻度肥胖、不肥胖）。
通常需要求相关性系数的都是有序分类变量。

举个例子。比如评委对选手的评分（优、中、差等），我们想看两个（或者多个）评委对几位选手的评价标准是否一致；或者医院的尿糖化验报告，想检验各个医院对尿糖的化验结果是否一致，这时候就可以使用肯德尔相关性系数进行衡量。


由于数据情况不同，求得肯德尔相关性系数的计算公式不一样，一般有3种计算公式，在这里就不繁琐地列出计算公式了，直接给出R语言的计算函数：

还是用cor函数求，这时候把method这个参数设成“kendall”，这时我们假设老师对选手的评价等级---3表示优，2表示中，1表示差：

> X=c(3,1,2,2,1,3)
> Y=c(1,2,3,2,1,1)
> cor(X,Y,method="kendall") 
[1] -0.2611165

> cor.test(X,Y,method="kendall")  #p-value = 0.5173

这时候就可以理解为两位老师对选手们的看法是呈相反趋势的，不过这种相反的程度不很大。






ref:
http://blog.sina.com.cn/s/blog_69e75efd0102wmd2.html
https://blog.csdn.net/ZJZJ0320/article/details/82350177
https://blog.csdn.net/ChenVast/article/details/83022649



========================================
|-- R相关系数计算函数 use 的取值的意义
----------------------------------------
cor(x, y = NULL, use = "everything",
    method = c("pearson", "kendall", "spearman"))
#
na.rm: logical. Should missing values be removed?

use: an optional character string giving a method for computing covariances in the presence of missing values. This must be (an abbreviation of) one of the strings "everything", "all.obs", "complete.obs", "na.or.complete", or "pairwise.complete.obs".



示例: 输入数据框，计算列之间的相关系数
dt=data.frame(
  x=c(1,2,3,4,5,NA,6,7),
  y=c(3,4,NA,7,8,NA,NA,6),
  z=c(4,5,6,NA,9,10,11,12)
);dt
#    x  y  z
# 1  1  3  4
# 2  2  4  5
# 3  3 NA  6
# 4  4  7 NA
# 5  5  8  9
# 6 NA NA 10
# 7  6 NA 11
# 8  7  6 12



1. 默认 everything 只要有一个NA则结果也是NA
> cor(dt)
   x  y  z
x  1 NA NA
y NA  1 NA
z NA NA  1





2.complete.obs 就是所有行出现NA，就去掉该行。
也就是一行中只要出现na，整行就会被去除掉。

> cor(dt, use="complete.obs")
          x         y         z
x 1.0000000 0.7779078 0.9986590
y 0.7779078 1.0000000 0.7522874
z 0.9986590 0.7522874 1.0000000

> cor(dt[c(1,2,5,8),]$x, dt[c(1,2,5,8),]$y)
[1] 0.7779078

> cor(dt[c(1,2,5,8),]$x, dt[c(1,2,5,8),]$z)
[1] 0.9986590

> cor(dt[c(1,2,5,8),]$z, dt[c(1,2,5,8),]$y)
[1] 0.7522874






3. 如果是 pairwise.complete.obs，就是比较的2个，去掉出现NA的行。
取na稍微温和点，只局限在正在比较的两列之间，出现na的行去掉。

> cor(dt, use="pairwise.complete.obs")
          x         y         z
x 1.0000000 0.7372609 0.9953212
y 0.7372609 1.0000000 0.7522874
z 0.9953212 0.7522874 1.0000000


> cor(dt[-c(3,6,7),]$x, dt[-c(3,6,7),]$y)
[1] 0.7372609
> cor(dt[-c(4,6),]$x, dt[-c(4,6),]$z)
[1] 0.9953212
> cor(dt[-c(3,4,6,7),]$y, dt[-c(3,4,6,7),]$z)
[1] 0.7522874






4. na.or.complete，结果和 complete.obs 一样，不知道啥区别？ //todo
> cor(dt, use="na.or.complete")
          x         y         z
x 1.0000000 0.7779078 0.9986590
y 0.7779078 1.0000000 0.7522874
z 0.9986590 0.7522874 1.0000000

> cor(dt, use="complete.obs")
          x         y         z
x 1.0000000 0.7779078 0.9986590
y 0.7779078 1.0000000 0.7522874
z 0.9986590 0.7522874 1.0000000






ref:
1. "complete.obs" https://bbs.pinggu.org/thread-3992878-1-1.html



========================================
mean±SEM, mean±SD, mean±SE有何区别，都是可使用的吗？
----------------------------------------
问题:
看了很多外文文献，有的统计结果中以mean±SEM表示, 有的以mean±SD表示, 也有以mean±SE表示，国内多半以x±s表示，请问哪一种是最恰当的。
SEM、SE应该是标准误，SD和s应该是标准差，所以简单的说要以标准误表示，还是标准差表示呢?
柱状图上的T，即标准差（误）应该是标准误还是标准差呢？


我的理解:
(1)假设一个实验，一周测量一次某植物的高度，一次实验至少3盆花，然后测量4周，每周就有3个数字，可以求该时间点的mean+-sd; 可以画图了height~week plot。
注: 每个点背后有3个植物。

(2)然后可能导师怕该实验是偶然发生的，又让其他学生重复进行了2次。
然后每个时间点就有3个mean了，然后计算这3个mean的mean和sd，记作mean+-se，又可以画图了height~week plot。
注: 每个点背后有3*3=9个植物。

简言之：你做了一次实验，就用mean+-sd; 重复该实验多次，就用mean+-se; 
明显后者更好，但是很多时候，受到时间和经费限制，实验不能重复。



1. 分析1
(1) 定义
mean表示都是平均数。

mean±SD表示的是均数加减标准差。
mean±SEM与mean±SE表示的意义相同，即均数加减标准误。

SD全称standard deviation标准差，又常称均方差，是离均差平方的算术平均数的平方根，用σ表示。
SEM是standard error of mean是平均数的抽样误差，反应平均数的抽样准确性。


(2) 用法
前者表示定量资料抽样分布的均数的分布情况，而后者表示定量资料（满足或近似满足正态分布）的个体测量值的分布情况，意义完全不同。一般情况下是以均数加减标准差来表示。


SEM计估计值的准确性无法度量，但可以用统计方法来测量。

测试的误差来源包括系统误差和采样误差，这些误差都不容易克服。采样误差是由许多无法控制的内部和外部因素引起的，这些因素都是偶然的，即使在测试中非常小心也很难消除，但可以通过增加重复次数来减少。

小样本（n≤30）取平均值±标准差，大样本（n>30）取平均值±标准误差。


(3) 类型不同
标准差是方差的算术平方根。标准差可以反映数据集的离专散程度。如果平均值相同，则标准差可能不相同。

标准误差是用样品的标准偏差除以样品容量的平方根来计算的，标准误差受样本量影响较大，样本量越大，标准误差越小，抽样误差越小，说明样本能够更好地代表种群。







2.区分2
你写错了，均数±标准数。

假设天空有1000000万颗星星。每颗星星的直径都不同。    
你第一次观察了300个星星的直径，然后顺便求了一下他们的 平均直径 把这个平均直径记作A  （或许你会顺便计算一下这300颗星星的标准差记作A1）。

第二次，你又心血来潮，去观察了另外300颗星星得到了这些星星的 平均直径 记作 B，其标准差记作B1。

等有一天你观察了26次时候，你得到了26个平均数(A-----Z)和26个标准差（A1--------Z1）。。。
然后你看星星都烦死了，懒得再去观察很多了。。。。。

这个时候你想用现在获得的数据去 估计 这1000000万 个星星的平均直径，可若是要对你之上研究过的 26×300=7800  颗星星做平均直径， 那么你得到的是什么？？？？

我相信你知道结果你会哭晕在厕所，因为那样做得到的  平均直径  是7800颗星星的平均直径，跟1000000万颗星星的平均直径   恐怕就是一毛钱的关系。
那么应该怎么做呢？
神一般的人物研究早就研究过了，将你之前得到的那26个 平均直径（A----Z，这里要非常清醒的知道A,B…都是之前计算出来的平均数）将这些平均数先相加再求平均值    这样就得到了一个【平均数的平均数】，称之为 平均数 ，对！就是平均数。

之前观察了的300颗星星我们除了求其平均数，标准差。那么现在我们想求一下这 26个平均数的 标准差，很简单公式大家都会，那么求出来的数叫标准差吗？
no。。。它有了新名字叫 标准误，标准误≠标准差(它们的来头不一张)。。。

个人感觉对于300颗星星  每个星星的直径 你都一清二楚，所以均数就是均数，标准差就是标准差，你敢拍着胸脯说。     而1000000万颗星星，不是每个星星的直径我们都知道，所以均数还叫均数，而标准差变成了标准误。这是为了区分，还是为了没把握。我觉得的是没把握所以才区分。







ref:
https://www.dxy.cn/bbs/newweb/pc/post/17685297


========================================
----------------------------------------




========================================
----------------------------------------


========================================
----------------------------------------


========================================
----------------------------------------



========================================
----------------------------------------




========================================
----------------------------------------


========================================
----------------------------------------



========================================
----------------------------------------




========================================
----------------------------------------


========================================
----------------------------------------


========================================
----------------------------------------



========================================
----------------------------------------




========================================
----------------------------------------


========================================
----------------------------------------



========================================
----------------------------------------




========================================
----------------------------------------



========================================
----------------------------------------


========================================
----------------------------------------


========================================
----------------------------------------


========================================
----------------------------------------

