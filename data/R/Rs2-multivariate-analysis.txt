中文名: 多元统计分析
外文名: Multivariate statistical analysis

多元统计分析是经典统计学发展起来的一个分支，是一种多指标（也称多变量）综合分析方法，可以在多指标相互关联情况下分析其统计规律，在研究经济社会现象中具有广泛应用。




========================================
相关资料
----------------------------------------
https://careerfoundry.com/en/blog/data-analytics/multivariate-analysis/
https://zhuanlan.zhihu.com/p/345000878







========================================
多元统计检验: Hotelling T^2 检验(对应t检验)，wilks (对应F检验) //todo
----------------------------------------
1. 将p(>=2)个应变量分开进行p次单变量分析的缺点
(1) 信息利用率低: 多应变量间内在联系
(2) 概括性低: 各指标检验结果不一致时
(3) I 类错误的概率 提高。

宜用多元统计分析方法
    - Hotelling: 对应t (2组)
    - wilks: 对应F (k 组)



2. 多元统计量: 均值向量、协方差矩阵、相关矩阵。

(1) 向量: 既有大小又有方向，又叫矢量，vector 没有起点和终点
与标量对应：只有大小。

例: n个观察对象，每个观察对象有p个观察指标x1,x2,...,xp时，p个观测指标的样本均数构成一个p维样本均数向量 X_bar:
   X_bar = (x1_bar, x2_bar, ..., xp_bar)^T




3. Hotelling T^2 检验和多元方差分析
(1) p个样本同时检验 => 组间差别，应变量关系
t-test 的推广，1个x而且其水平数为2(2组): p个y

1) 样总比较: 多元正态、1标准值（总体均数向量mu0）
    H0: mu = mu0
2) 配对比较: 配对差值 -> 样本均数向量与总体0比较

3) 两样比较: 多元正态，多元协方差矩阵相等
    H0: mu1=mu2


(2) 多元方差分析 manova







ref:
https://max.book118.com/html/2020/0327/5113200112002233.shtm



========================================
多元回归
----------------------------------------

1. 入门

head(iris)
df1=iris[,1:4]
colnames(df1)=c("Y", paste0("X", 1:3))

> head(df1)
    Y  X1  X2  X3
1 5.1 3.5 1.4 0.2
2 4.9 3.0 1.4 0.2



(1) 建模
> lm.sol<-lm(Y ~ X1+X2, data=df1)
> lm.sol
Call:
lm(formula = Y ~ X1 + X2, data = df1)

Coefficients:
(Intercept)           X1           X2  
     2.2491       0.5955       0.4719  



> summary(lm.sol)
Call:
lm(formula = Y ~ X1 + X2, data = df1)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.96159 -0.23489  0.00077  0.21453  0.78557 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  2.24914    0.24797    9.07 7.04e-16 ***
X1           0.59552    0.06933    8.59 1.16e-14 ***
X2           0.47192    0.01712   27.57  < 2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.3333 on 147 degrees of freedom
Multiple R-squared:  0.8402,	Adjusted R-squared:  0.838 
F-statistic: 386.4 on 2 and 147 DF,  p-value: < 2.2e-16

从计算结果看，回归系数与回归方程的检验都是显著的。因此，回归方程为
Y_hat = 2.24914 + 0.59552*X1 + 0.47192*X2



残差的QQ图:
> plot(lm.sol, 2)




(2) 预测
当多元线性回归方程经过检验是显著的，且每一个系数均显著不为0时，可用次方程做预测。

# 5.1 3.5 1.4 0.2
> newData <- data.frame(X1 = 3.5, X2 = 1.4, X3=0.2)
> lm.pred<-predict(lm.sol, newData, interval="prediction", level=0.95)
> lm.pred

       fit      lwr      upr
1 4.994165 4.328875 5.659455

求得的 估计值为 y0_hat=4.994165，响应的Y的概率为0.95的预测区间为 [4.328875, 5.659455]




(3) 修正拟合模型
形式为 new.model <- update(old.model, new.formula)
在 new.formula 中，其相应的名字由'.'组成，可以被用于表示“旧模型公式中相应的部分”。例如:

fm5 <- lm(y ~ x1 + x2 + x3 + x4 + x5, data = production)
fm6 <- update(fm5, . ~ . + x6)
smf6 <- update(fm6, sqrt(.) ~ .)

更新后模型中包含第6个变量。
再更新后，模型中响应变量使用了平方根变换。


例:
> lm.sol2 = update(lm.sol, .~.+X3)
> lm.sol2 

Call:
lm(formula = Y ~ X1 + X2 + X3, data = df1)

Coefficients:
(Intercept)           X1           X2           X3  
     1.8560       0.6508       0.7091      -0.5565  


> summary(lm.sol2)
Call:
lm(formula = Y ~ X1 + X2 + X3, data = df1)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.82816 -0.21989  0.01875  0.19709  0.84570 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  1.85600    0.25078   7.401 9.85e-12 ***
X1           0.65084    0.06665   9.765  < 2e-16 ***
X2           0.70913    0.05672  12.502  < 2e-16 ***
X3          -0.55648    0.12755  -4.363 2.41e-05 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.3145 on 146 degrees of freedom
Multiple R-squared:  0.8586,	Adjusted R-squared:  0.8557 
F-statistic: 295.5 on 3 and 146 DF,  p-value: < 2.2e-16




(4) 还可以使用二次方拟合
> lm2.sol<-lm(Y~X2+I(X2^2), data=df1)
> lm2.sol

Call:
lm(formula = Y ~ X2 + I(X2^2), data = df1)

Residuals:
    Min      1Q  Median      3Q     Max 
-1.0684 -0.2348  0.0121  0.2049  0.9146 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  5.05833    0.14036  36.038  < 2e-16 ***
X2          -0.16435    0.09427  -1.743   0.0834 .  
I(X2^2)      0.08146    0.01318   6.181 5.96e-09 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.3639 on 147 degrees of freedom
Multiple R-squared:  0.8095,	Adjusted R-squared:  0.8069 
F-statistic: 312.3 on 2 and 147 DF,  p-value: < 2.2e-16









========================================
|-- 逐步回归: step(), add1(), drop1()
----------------------------------------
step(object, scope, scale = 0,
	direction = c("both", "backward", "forward"),
	trace = 1, keep = NULL, steps = 1000, k = 2, ...)

1. 例子: 水泥凝固放热Y 与 四种成分X1-4的关系
cement<-data.frame(
	X1=c( 7, 1, 11, 11, 7, 11, 3, 1, 2, 21, 1, 11, 10),
	X2=c(26, 29, 56, 31, 52, 55, 71, 31, 54, 47, 40, 66, 68),
	X3=c( 6, 15, 8, 8, 6, 9, 17, 22, 18, 4, 23, 9, 8),
	X4=c(60, 52, 20, 47, 33, 22, 6, 44, 22, 26, 34, 12, 12),
	Y =c(78.5, 74.3, 104.3, 87.6, 95.9, 109.2, 102.7, 72.5,
		93.1,115.9, 83.8, 113.3, 109.4)
)
lm.sol<-lm(Y ~ X1+X2+X3+X4, data=cement)

> summary(lm.sol)
Call:
lm(formula = Y ~ X1 + X2 + X3 + X4, data = cement)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.1750 -1.6709  0.2508  1.3783  3.9254 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)  
(Intercept)  62.4054    70.0710   0.891   0.3991  
X1            1.5511     0.7448   2.083   0.0708 .
X2            0.5102     0.7238   0.705   0.5009  
X3            0.1019     0.7547   0.135   0.8959  
X4           -0.1441     0.7091  -0.203   0.8441  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 2.446 on 8 degrees of freedom
Multiple R-squared:  0.9824,	Adjusted R-squared:  0.9736 
F-statistic: 111.5 on 4 and 8 DF,  p-value: 4.756e-07





(1) 使用 step() 做逐步回归
> lm.step<-step(lm.sol)
Start:  AIC=26.94
Y ~ X1 + X2 + X3 + X4

       Df Sum of Sq    RSS    AIC
- X3    1    0.1091 47.973 24.974
- X4    1    0.2470 48.111 25.011
- X2    1    2.9725 50.836 25.728
<none>              47.864 26.944
- X1    1   25.9509 73.815 30.576

Step:  AIC=24.97
Y ~ X1 + X2 + X4

       Df Sum of Sq    RSS    AIC
<none>               47.97 24.974
- X4    1      9.93  57.90 25.420
- X2    1     26.79  74.76 28.742
- X1    1    820.91 868.88 60.629


第一轮使用全部变量做回归，AIC为26.94.

去掉X3后得到回归方程的AIC值为 24.97。
去掉X4后得到回归方程的AIC值为 25.011。
依次类推，由于去掉X3可以使AIC达到最小，因此去掉X3并进行下一轮计算。

结果去掉谁都不会使AIC降低，所以运算终止，得到“最优”回归方程。


查看计算结果：
> summary(lm.step)

Call:
lm(formula = Y ~ X1 + X2 + X4, data = cement)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.0919 -1.8016  0.2562  1.2818  3.8982 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  71.6483    14.1424   5.066 0.000675 ***
X1            1.4519     0.1170  12.410 5.78e-07 ***
X2            0.4161     0.1856   2.242 0.051687 .  
X4           -0.2365     0.1733  -1.365 0.205395    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 2.309 on 9 degrees of freedom
Multiple R-squared:  0.9823,	Adjusted R-squared:  0.9764 
F-statistic: 166.8 on 3 and 9 DF,  p-value: 3.323e-08





2. 其他2个逐步回归函数
add1(object, scope, ...)
drop1(object, scope, ...)

add1(object, scope, scale=0, test=c("none", "Chisq"),
	k=2, trace=FALSE, ...)
drop1(object, scope, scale=0, test=c("none", "Chisq"),
	k=2, trace=FALSE, ...)

add1(object, scope, scale=0, test=c("none", "Chisq", "F"),
	x=NULL, k=2, ...)
drop1(object, scope, scale=0, all.cols=TRUE,
	test=c("none", "Chisq", "F"), k=2, ...)


其中 object 是由拟合模型构成的对象。 
scope 是模型考虑增加或去掉项构成的公式。
scale 是用于计算 Cp 的残差的均方估计值，缺省值为 0 或 NULL。

(1) 使用 drop1() 计算
> drop1(lm.step)
Single term deletions

Model:
Y ~ X1 + X2 + X4
       Df Sum of Sq    RSS    AIC
<none>               47.97 24.974
X1      1    820.91 868.88 60.629
X2      1     26.79  74.76 28.742
X4      1      9.93  57.90 25.420

从运算结果看，去掉X4后AIC值增加最少。
除了AIC准则外，残差的平方和也是逐步回归的重要指标之一。直观看，拟合越好的，残差平方和应该越小。去掉X4后残差的平方和上升(9.93)最少。
从这2项指标看，应该再去掉变量X4。


> lm.opt<-lm(Y ~ X1+X2, data=cement); summary(lm.opt)

Call:
lm(formula = Y ~ X1 + X2, data = cement)

Residuals:
   Min     1Q Median     3Q    Max 
-2.893 -1.574 -1.302  1.363  4.048 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept) 52.57735    2.28617   23.00 5.46e-10 ***
X1           1.46831    0.12130   12.11 2.69e-07 ***
X2           0.66225    0.04585   14.44 5.03e-08 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 2.406 on 10 degrees of freedom
Multiple R-squared:  0.9787,	Adjusted R-squared:  0.9744 
F-statistic: 229.5 on 2 and 10 DF,  p-value: 4.407e-09

这个结果应该还是满意的，因为所有的检验均是显著的。
最后得到最优的回归方程为:
Y_hat = 52.58 + 1.468*X1 + 0.6622*X2





========================================
----------------------------------------



========================================
----------------------------------------



========================================
----------------------------------------





========================================
----------------------------------------



========================================
----------------------------------------



========================================
----------------------------------------





========================================
----------------------------------------



========================================
----------------------------------------



========================================
----------------------------------------





========================================
----------------------------------------



========================================
----------------------------------------



========================================
----------------------------------------




========================================
----------------------------------------



========================================
----------------------------------------



========================================
----------------------------------------





========================================
----------------------------------------



========================================
----------------------------------------



========================================
----------------------------------------





========================================
----------------------------------------



========================================
----------------------------------------



========================================
----------------------------------------





========================================
----------------------------------------



========================================
----------------------------------------



========================================
----------------------------------------


