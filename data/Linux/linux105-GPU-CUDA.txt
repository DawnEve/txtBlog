linux105-GPU-CUDA





========================================
查看显卡及安装显卡驱动 (Ubuntu 系统 + Quadro P2000 显卡)
----------------------------------------
步骤：
	查看显卡型号；
	到硬件官网根据型号和平台下载runfile；
	运行该runfile；
	测试 msi 是否显示显卡状态。


1. 查看显卡型号
$ sudo lshw -c video
[sudo] password for wangjl: 
  *-display                 
       description: VGA compatible controller
       product: GP106GL
       vendor: NVIDIA Corporation
       physical id: 0
       bus info: pci@0000:65:00.0
       version: a1
       width: 64 bits
       clock: 33MHz
       capabilities: pm msi pciexpress vga_controller bus_master cap_list rom
       configuration: driver=nvidia latency=0  ##使用的网卡驱动名称
       resources: irq:44 memory:d7000000-d7ffffff memory:c0000000-cfffffff memory:d0000000-d1ffffff ioport:b000(size=128) memory:c0000-dffff
#
可以看到你的显卡信息，比如我的就是 product: GP106GL


(2) 查看显卡信息
$ lspci|grep -i vga
65:00.0 VGA compatible controller: NVIDIA Corporation GP106GL [Quadro P2000] (rev a1)

nvidia GPU 信息
$ lspci | grep -i nvidia
65:00.0 VGA compatible controller: NVIDIA Corporation GP106GL [Quadro P2000] (rev a1)
65:00.1 Audio device: NVIDIA Corporation GP106 High Definition Audio Controller (rev a1)  #声卡，先忽略

前边的序号 “00:0f.0″是显卡的代号(这里是用的虚拟机);
查看指定显卡的详细信息用以下指令：
$ lspci -v -s 65:00.0
65:00.0 VGA compatible controller: NVIDIA Corporation GP106GL [Quadro P2000] (rev a1) (prog-if 00 [VGA controller])
	Subsystem: Dell GP106GL [Quadro P2000]
	Flags: bus master, fast devsel, latency 0, IRQ 47, NUMA node 0
	Memory at d7000000 (32-bit, non-prefetchable) [size=16M]
	Memory at c0000000 (64-bit, prefetchable) [size=256M]
	Memory at d0000000 (64-bit, prefetchable) [size=32M]
	I/O ports at b000 [size=128]
	Expansion ROM at 000c0000 [virtual] [disabled] [size=128K]
	Capabilities: <access denied>
	Kernel driver in use: nvidia
	Kernel modules: nvidiafb, nouveau, nvidia_drm, nvidia

这个 Quadro P2000 才是更广为人知的名字。



(3). 查看是否安装驱动
## 第一行输出便有硬件厂商、型号名称/序列号和PCI  ID。
$ lspci -vnn | grep VGA -A 12 

65:00.0 VGA compatible controller [0300]: NVIDIA Corporation GP106GL [10de:1c30] (rev a1) (prog-if 00 [VGA controller])
	Subsystem: Dell GP106GL [Quadro P2000] [1028:11b3]
	Flags: bus master, fast devsel, latency 0, IRQ 44, NUMA node 0
	Memory at d7000000 (32-bit, non-prefetchable) [size=16M]
	Memory at c0000000 (64-bit, prefetchable) [size=256M]
	Memory at d0000000 (64-bit, prefetchable) [size=32M]
	I/O ports at b000 [size=128]
	Expansion ROM at 000c0000 [disabled] [size=128K]
	Capabilities: <access denied>
	Kernel driver in use: nvidia
	Kernel modules: nvidiafb, nouveau, nvidia_drm, nvidia

65:00.1 Audio device [0403]: NVIDIA Corporation GP106 High Definition Audio Controller [10de:10f1] (rev a1)


具体型号: Dell GP106GL [Quadro P2000]





2.查找你的显卡的驱动(可跳过)
(1) 去NVDIA driver search page搜索你的显卡需要的驱动型号并下载(如图）。
https://www.nvidia.com/Download/Find.aspx

Name	Version	Release Date
Linux x64 (AMD64/EM64T) Display Driver NFB	465.31	May 18, 2021
Linux x64 (AMD64/EM64T) Display Driver NVIDIA Certified	460.80	May 11, 2021
Linux x64 (AMD64/EM64T) Display Driver NFB	465.27	April 29, 2021
Linux x64 (AMD64/EM64T) Display Driver NVIDIA Certified	450.119.03	April 19, 2021



(2)为了再次确认一遍，你还可以使用这个命令查看你可以使用的驱动：
$ ubuntu-drivers devices

$ ubuntu-drivers devices
== /sys/devices/pci0000:64/0000:64:00.0/0000:65:00.0 ==
modalias : pci:v000010DEd00001C30sv00001028sd000011B3bc03sc00i00
vendor   : NVIDIA Corporation
model    : GP106GL [Quadro P2000]
manual_install: True
driver   : nvidia-driver-460-server - distro non-free
driver   : nvidia-driver-450 - third-party free
driver   : nvidia-driver-465 - third-party free recommended
driver   : nvidia-driver-455 - third-party free
driver   : nvidia-driver-390 - distro non-free
driver   : nvidia-driver-450-server - distro non-free
driver   : nvidia-driver-418-server - distro non-free
driver   : nvidia-driver-460 - third-party free
driver   : nvidia-driver-418 - third-party free
driver   : xserver-xorg-video-nouveau - distro free builtin

如果结果显示和搜索到的驱动版本一样，推荐也是390.67，那我们可以安心安装390.67版本。
但是结果显示的并没有390.67，为了避免出错，建议选择结果显示中的版本号，如460.80。



2022.10.26 又试了一次:
$ ubuntu-drivers devices
== /sys/devices/pci0000:64/0000:64:00.0/0000:65:00.0 ==
modalias : pci:v000010DEd00001C30sv00001028sd000011B3bc03sc00i00
vendor   : NVIDIA Corporation
model    : GP106GL [Quadro P2000]
driver   : nvidia-driver-470 - distro non-free
driver   : nvidia-driver-390 - distro non-free
driver   : nvidia-driver-515-server - distro non-free
driver   : nvidia-driver-510 - distro non-free
driver   : nvidia-driver-450-server - distro non-free
driver   : nvidia-driver-510-server - distro non-free
driver   : nvidia-driver-470-server - distro non-free
driver   : nvidia-driver-515 - distro non-free recommended
driver   : nvidia-driver-418-server - distro non-free
driver   : nvidia-driver-520 - distro non-free
driver   : xserver-xorg-video-nouveau - distro free builtin

https://us.download.nvidia.com/XFree86/Linux-x86_64/515.76/NVIDIA-Linux-x86_64-515.76.run







3. 安装驱动（跳过，老记录）

(1). 禁用nouveau。
打开终端，输入：
$ sudo gedit /etc/modprobe.d/blacklist.conf

在blacklist.conf文件末尾加上这两行，并保存：
blacklist nouveau
options nouveau modeset=0

然后执行命令：

$ sudo update-initramfs -u  //应用更改

重启系统，验证是否禁用nouveau：

lsmod | grep nouveau
没有信息返回说明已禁用（如图）




(2)安装NVIDIA驱动。
方法一：跳过
打开系统设置->软件和更新->附加驱动->选择NVIDIA驱动->应用更改（如图）



方法二：采用
进入命令行界面：

Ctrl+Alt+F1  //（深坑：笔记本的F键有小键盘，需加上Fn），之后输入用户名和密码登录即可。

关闭图形界面：
sudo service lightdm stop

卸载旧版本nvidia驱动：
sudo apt-get remove --purge nvidia*

给驱动run文件赋予执行权限：
chmod  a+x NVIDIA-Linux-x86_64-396.18.run //对应自己下载的驱动名称
chmod  a+x NVIDIA-Linux-x86_64-515.76.run

安装nvidia驱动:
sudo ./NVIDIA-Linux-x86_64-396.18.run -no-x-check -no-nouveau-check -no-opengl-files //只有禁用opengl这样安装才不会出现循环登陆的问题

-no-x-check：安装驱动时关闭X服务
-no-nouveau-check：安装驱动时禁用nouveau
-no-opengl-files：只安装驱动文件，不安装OpenGL文件

$ sudo ./NVIDIA-Linux-x86_64-515.76.run
安装失败，卸载旧版本后，可能要重启，才能接着安装。
使用如下命令：
$ sudo apt install nvidia-340

安装过程中的选项：
The distribution-provided pre-install script failed! Are you sure you want to continue? 选择 yes 继续。
Would you like to register the kernel module souces with DKMS? This will allow DKMS to automatically build a new module, if you install a different kernel later?  选择 No 继续。
问题没记住，选项是：install without signing
问题大概是：Nvidia's 32-bit compatibility libraries? 选择 No 继续。
Would you like to run the nvidia-xconfigutility to automatically update your x configuration so that the NVIDIA x driver will be used when you restart x? Any pre-existing x confile will be backed up.  选择 Yes

这些选项如果选择错误可能会导致安装失败，没关系，只要前面不出错，多尝试几次就好。

打开图形界面：
sudo service lightdm start


(3)查看NVIDIA版本检验是否安装完成
$ nvidia-smi

$ nvidia-smi
Wed May 19 11:29:43 2021       
+------------ ----------------- ---------------------- -----------------------+
| NVIDIA-SMI 460.27.04    Driver Version: 460.27.04    CUDA Version: 11.2     |
|------------ ------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|============= =================+======================+========== ===========|
|   0  Quadro P2000        Off  | 00000000:65:00.0 Off |                  N/A |
| 78%   40C    P0    19W /  75W |      0MiB /  5050MiB |      0%      Default |
|                               |                      |                  N/A |
+------------ ------------------+----------------------+----------------------+
                                                                               
+------------- ----------------- ------------------ ------------ -------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|============ =================== ================== ======== ================|
|  No running processes found                                                 |
+------------ ------------------- ------------------ -------- ----------------+




4. 安装显卡驱动(2023.5)
(1) 下载驱动
https://www.nvidia.com/Download/Find.aspx

NVIDIA RTX/ Quadro,  Linux 64-bit;
Quadro Series, En;
Quadro P2000, All

https://www.nvidia.com/download/driverResults.aspx/204837/en-us/
394MB;


(2) 安装nvidia驱动:
$ chmod  a+x NVIDIA-Linux-x86_64-525.116.04.run #20230510

$ sudo ./NVIDIA-Linux-x86_64-525.116.04.run -no-x-check -no-nouveau-check -no-opengl-files //只有禁用opengl这样安装才不会出现循环登陆的问题


安装弹出对话框：
An alternate method of installing the NVIDIA driver was detected. (This is usually a package provided by your distributor.) A driver installed via that method may integrate better with your system than a driver installed by nvidia-installer. 
  Please review the message provided by the maintainer of this alternate installation method and decide how to proceed:
					  Continue installation                                                               Abort installation
 The NVIDIA driver provided by Ubuntu can be installed by launching the "Software & Updates" application, and by selecting the NVIDIA driver from the "Additional Drivers" tab.
选了第一个。
进入安装新界面：
Install NVIDIA's 32-bit compatibility libraries? Yes;
Would you like to register the kernel module sources with DKMS? This will allow DKMS to automatically build a new module, if your kernel changes later.  Yes;

Would you like to run the nvidia-xconfig utility to automatically update your X configuration file so that the NVIDIA X driver will be used when you restart X?  Any pre-existing X configuration file will be backed up. Yes
Your X configuration file has been successfully updated.  Installation of the NVIDIA Accelerated Graphics Driver for Linux-x86_64 (version: 525.116.04) is now complete.  OK


(3) 检查安装效果
刚才已自动安装测试命令
## sudo apt install nvidia-340
$ nvidia-smi

Tue May  9 22:29:02 2023       
+---------------- -------------- ---------------------- ----------------------+
| NVIDIA-SMI 525.116.04   Driver Version: 525.116.04   CUDA Version: 12.0     |
|--------------- ---------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|=============== ===============+======================+======================|
|   0  Quadro P2000        Off  | 00000000:65:00.0 Off |                  N/A |
| 84%   45C    P0    20W /  75W |      0MiB /  5120MiB |      2%      Default |
|                               |                      |                  N/A |
+--------------- ---------------+----------------------+----------------------+
                                                                               
+--------------- --------------- ---------------------- ----------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============== =============== ======================= =====================|
|  No running processes found                                                 |
+--------------- --------------- ----------------------- ---------------------+


参数解释：https://zhuanlan.zhihu.com/p/473129288

表格中会显示显卡的一些信息，第一行是版本信息，第二行是标题栏，第三行就是具体的显卡信息了，如果有多个显卡，会有多行，每一行的信息值对应标题栏对应位置的信息。
* GPU：编号，这里是0和1
* Fan：风扇转速，在0到100%之间变动，第一个是84%

* Name：显卡名，这里两块都是 Quadro P2000
* Temp：显卡温度，第一个是45摄氏度

* Perf：性能状态，从P0到P12，P0性能最大，P12最小

* Persistence-M：持续模式的状态开关，该模式耗能大，但是启动新GPU应用时比较快，这里是off
* Pwr：能耗

* Bus-Id：GPU总线

* Disp.A：表示GPU的显示是否初始化
* Memory-Usage：显存使用率

* GPU-Util：GPU利用率，第一个是2%

* Compute M.：计算模式










ref:
https://blog.csdn.net/qiancaobaicheng/article/details/95096354
https://www.cnblogs.com/vcan123/p/11902213.html

========================================
|-- Ubuntu 20.04 安装 CUDA 12.0
----------------------------------------

本文将介绍如何在Ubuntu 20.04中安装CUDA开发工具，搭建CUDA编程环境。

1. [失败] 请跳过直接看2
https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&Distribution=Ubuntu&target_version=20.04&target_type=deb_network
$ wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-keyring_1.0-1_all.deb
$ sudo dpkg -i cuda-keyring_1.0-1_all.deb
$ sudo apt-get update
$ sudo apt-get -y install cuda
Some packages could not be installed. This may mean that you have requested an impossible situation or ...

没装上，找到一个之前安装的老版本：
/usr/local/cuda-11.2/bin/nvcc

$ /usr/local/cuda-11.2/bin/nvcc --version
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2020 NVIDIA Corporation
Built on Mon_Nov_30_19:08:53_PST_2020
Cuda compilation tools, release 11.2, V11.2.67
Build cuda_11.2.r11.2/compiler.29373293_0


添加到路径：
$ vim ~/.bashrc  #添加一行
export PATH=/usr/local/cuda-11.2/bin/:$PATH
export LD_LIBRARY_PATH=/usr/local/cuda-11.2/lib64\
                         ${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}

但是显卡驱动是要去cuda12.0.
经过测试，nvcc编译的c语言小程序无法调用GPU。说明cuda版本和显卡驱动必须匹配，至少大版本必须一致（11.x）。




2. 使用runfile进行安装 cuda
参考: https://zhuanlan.zhihu.com/p/432092988

已安装好显卡驱动，才能接着安装CUDA。

(1)下载与安装
https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&Distribution=Ubuntu&target_version=20.04&target_type=runfile_local
$ wget https://developer.download.nvidia.com/compute/cuda/12.1.1/local_installers/cuda_12.1.1_530.30.02_linux.run
$ sudo sh cuda_12.1.1_530.30.02_linux.run


在安装过程中我们需要根据提示进行一些设置：
	终止用户许可协议(End User License Agreement)，输入accept然后按回车进行下一步。
	安装GPU驱动。
	安装CUDA开发工具，需要设置安装路径和是否创建/usr/local/cuda软链接，可以直接按回车用默认的即可。
	//我没看到：安装CUDA例程，默认会安装在$(HOME)/NVIDIA_CUDA-11.0_Samples路径下。

	标准输出：
	===========
	= Summary =
	===========

	Driver:   Installed
	Toolkit:  Installed in /usr/local/cuda-12.1/

	Please make sure that
	 -   PATH includes /usr/local/cuda-12.1/bin
	 -   LD_LIBRARY_PATH includes /usr/local/cuda-12.1/lib64, or, add /usr/local/cuda-12.1/lib64 to /etc/ld.so.conf and run ldconfig as root

	To uninstall the CUDA Toolkit, run cuda-uninstaller in /usr/local/cuda-12.1/bin
	To uninstall the NVIDIA Driver, run nvidia-uninstall
	Logfile is /var/log/cuda-installer.log

(2) 安装好以后，需要设置一些环境变量：
	$ vim ~/.bashrc #添加几行
	export PATH=/usr/local/cuda-12.1/bin:$PATH
	export LD_LIBRARY_PATH=/usr/local/cuda-12.1/lib64:$LD_LIBRARY_PATH
	## export C_INCLUDE_PATH=/usr/local/cuda-12.1/include:$C_INCLUDE_PATH
	## export CPLUS_INCLUDE_PATH=/usr/local/cuda-12.1/include:$CPLUS_INCLUDE_PATH
	
	$ source ~/.bashrc

如果要卸载安装好的CUDA，可以执行如下命令：
	sudo /usr/local/cuda-11.0/bin/cuda-uninstaller


(3)检测
$ nvcc -V
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2023 NVIDIA Corporation
Built on Mon_Apr__3_17:16:06_PDT_2023
Cuda compilation tools, release 12.1, V12.1.105
Build cuda_12.1.r12.1/compiler.32688072_0

$ which nvcc
/usr/local/cuda-12.1/bin/nvcc


查看显卡驱动:
$ nvidia-smi
Wed May 10 23:04:39 2023       
| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1  









========================================
CentOS7 的显卡 A100 40GB: 安装驱动和CUDA
----------------------------------------
ZhuLab server.

1. 查看显卡型号
(1) 显卡数量
$ sudo lshw -c video
[sudo] password for wangjl: 
  *-display                 
       description: 3D controller
       product: GA100 [GRID A100 PCIe 40GB]
       vendor: NVIDIA Corporation
       physical id: 0
       bus info: pci@0000:21:00.0
       version: a1
       width: 64 bits
       clock: 33MHz
       capabilities: pm bus_master cap_list
       configuration: driver=nvidia latency=0
       resources: iomemory:2c00-2bff iomemory:2d00-2cff irq:404 memory:cd000000-cdffffff memory:2c000000000-2cfffffffff memory:2d000000000-2d001ffffff
  *-display
       description: VGA compatible controller
       product: Integrated Matrox G200eW3 Graphics Controller
       vendor: Matrox Electronics Systems Ltd.
       physical id: 0
       bus info: pci@0000:62:00.0
       version: 04
       width: 32 bits
       clock: 66MHz
       capabilities: pm vga_controller bus_master cap_list rom
       configuration: driver=mgag200 latency=64 maxlatency=32 mingnt=16
       resources: irq:256 memory:de000000-deffffff memory:e7808000-e780bfff memory:e7000000-e77fffff

显卡类型：GRID A100 PCIe 40GB
另一个不是N卡，仅用于显示。

(2) 查看显卡信息
$ lspci|grep -i vga
62:00.0 VGA compatible controller: Matrox Electronics Systems Ltd. Integrated Matrox G200eW3 Graphics Controller (rev 04)

(3) nvidia GPU 信息
$ lspci | grep -i nvidia
21:00.0 3D controller: NVIDIA Corporation GA100 [GRID A100 PCIe 40GB] (rev a1)

前边的序号 “00:0f.0″是显卡的代号(这里是用的虚拟机);
查看指定显卡的详细信息用以下指令：
$ lspci -v -s 21:00.0
21:00.0 3D controller: NVIDIA Corporation GA100 [GRID A100 PCIe 40GB] (rev a1)
	Subsystem: NVIDIA Corporation Device 145f
	Flags: bus master, fast devsel, latency 0, IRQ 404, NUMA node 0
	Memory at cd000000 (32-bit, non-prefetchable) [size=16M]
	Memory at 2c000000000 (64-bit, prefetchable) [size=64G]
	Memory at 2d000000000 (64-bit, prefetchable) [size=32M]
	Capabilities: <access denied>
	Kernel driver in use: nvidia
	Kernel modules: nouveau, nvidia_drm, nvidia

显卡型号: GRID A100 PCIe 40GB






2. 下载和安装驱动
https://www.nvidia.com/Download/Find.aspx

Data Center/Tesla;  Linux 64-bit;
A-Series;  CUDA Toolkit any;
NVIDIA A100; En;

https://www.nvidia.com/download/driverResults.aspx/202370/en-us/

$ chmod +x NVIDIA-Linux-x86_64-515.105.01.run 

安装nvidia驱动:
$ sudo ./NVIDIA-Linux-x86_64-515.105.01.run -no-x-check -no-nouveau-check -no-opengl-files //只有禁用opengl这样安装才不会出现循环登陆的问题
对话框: NVIDIA Accelerated Graphics Driver for Linux-x86_64 (515.105.01) 
There appears to already be a driver installed on your system (version: 515.57).  As part of installing this driver (version: 515.105.01), the existing driver will be uninstalled.  Are you sure you want to continue? Yes
Would you like to register the kernel module sources with DKMS? This will allow DKMS to automatically build a new module, if you install a different kernel later. Yes
Install NVIDIA's 32-bit compatibility libraries? Yes
回车，出现进度条:  Installing DKMS kernel module:  Building module (This may take a moment) 等待其结束。
Installation of the NVIDIA Accelerated Graphics Driver for Linux-x86_64 (version: 515.105.01) is now complete.   OK


3. 检查安装效果

这是一个高端的显卡: 40G显存(上面那个5G)。参数意义见上文那个显卡。
之前安装的驱动：可能有问题
Tue May  9 22:37:09 2023       
+--------------- --------------- ---------------------- ----------------------+
| NVIDIA-SMI 418.39       Driver Version: 515.57       CUDA Version: 11.7     |
|------------ ------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|======== ======================+======================+======================|
|   0  NVIDIA A100-PCI...  Off  | 00000000:21:00.0 Off |                    0 |
| N/A   34C    P0    40W / 250W |    563MiB / 40960MiB |      2%      Default |
+----------------- -------------+----------------------+----------------------+
                                                                               
+--------------- --------------- ---------------------- ----------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============== =============== ======================= =====================|
|  No running processes found                                                 |
+--------------- --------------- ---------------------- ----------------------+

新安装的驱动：
$ nvidia-smi
Wed May 10 11:17:43 2023       
+--------------- --------------- ---------------------- ----------------------+
| NVIDIA-SMI 515.105.01   Driver Version: 515.105.01   CUDA Version: 11.7     |
|--------------- ---------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|========== ====================+======================+======================|
|   0  NVIDIA A100-PCI...  Off  | 00000000:21:00.0 Off |                    0 |
| N/A   31C    P0    38W / 250W |      0MiB / 40960MiB |      0%      Default |
|                               |                      |             Disabled |
+------------------- -----------+----------------------+----------------------+
                                                                               
+--------------- --------------- ---------------------- ----------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============== =============== ======================= =====================|
|  No running processes found                                                 |
+--------------- --------------- ---------------------- ----------------------+




========================================
|-- (CentOS7)安装 alphafold2 (2023.05)
----------------------------------------
$ which nvidia-ctk
/usr/bin/nvidia-ctk

$ nvidia-ctk --version
NVIDIA Container Toolkit CLI version 1.13.1
commit: 28b70663f1a2b982e59e83bcf1844177dc745208


(1) 尝试 docker 中查看显卡 
https://zhuanlan.zhihu.com/p/606236824
$ docker --version
Docker version 23.0.4, build f480fb1

$ docker run --rm --gpus all nvidia/cuda:11.0.3-base-ubuntu20.04 nvidia-smi
docker: Error response from daemon: could not select device driver "" with capabilities: [[gpu]].

需要打开显卡 持久模式（耗电增多）
$ sudo nvidia-smi -pm ENABLED  ##-pm,  --persistence-mode=   Set persistence mode: 0/DISABLED, 1/ENABLED
Enabled persistence mode for GPU 00000000:21:00.0.
All done.

$ nvidia-smi # 检查：确实打开了。
还是不行
$ docker run --rm --gpus all nvidia/cuda:11.0.3-base-ubuntu20.04 nvidia-smi
docker: Error response from daemon: could not select device driver "" with capabilities: [[gpu]].

关掉显卡 持久模式
$ sudo nvidia-smi -pm 0



==> 需要安装依赖包
https://forums.developer.nvidia.com/t/could-not-select-device-driver-with-capabilities-gpu/80200/4
$ sudo yum install nvidia-docker2
## sudo systemctl daemon-reload  #跳过这个呢？可以
$ sudo systemctl restart docker
$ sudo service docker restart #和上一句等价

再运行，正常输出 nvidia-smi 的参数:
$ docker run --rm --gpus all nvidia/cuda:11.0.3-base-ubuntu20.04 nvidia-smi

查看状态，发现配置文件被修改了：只有一个新增的runtimes，把之前2个(data-root, registry-mirrors)的加上：
$ cat /etc/docker/daemon.json
{
    "runtimes": {
        "nvidia": {
            "path": "nvidia-container-runtime",
            "runtimeArgs": []
        }
    },
	
	"data-root": "/data/docker/lib/docker",
	"registry-mirrors": [ 
		"https://docker.mirrors.ustc.edu.cn",
		"https://registry.cn-hangzhou.aliyuncs.com",
		"https://hub-mirror.c.163.com",
		"https://registry.docker-cn.com"
	],
}

重启docker服务
$ sudo service docker restart
查询
$ docker info | grep -i "root"
 Docker Root Dir: /data/docker/lib/docker


再次测试
$ docker run --rm --gpus all nvidia/cuda:11.0.3-base-ubuntu20.04 nvidia-smi
能查看显卡信息。




(2) 安装 AlphaFold v2. 

https://github.com/deepmind/alphafold

1)安装 GPU 驱动
2) 下载代码
git clone https://github.com/deepmind/alphafold.git
cd ./alphafold
3) soft
	sudo yum install aria2
	
	下载数据库 scripts/download_all_data.sh <DOWNLOAD_DIR> > download.log 2> download_all.log &
		注意：<DOWNLOAD_DIR> 目录不能是 AlphaFold  仓库目录，否则 build会特别慢！
		$ pwd ##/home/wangjl/Downloads/alphafold
		$ mkdir ../alphafoldDB
		$ scripts/download_all_data.sh ../alphafoldDB > download.log 2> download_all.log &
		[1] 83023
		查看：
		$ ps -aux | grep download_all_data #查看是否有命令在运行
		$ du -sh ../alphafoldDB #查看下载大小，最终是 556 GB


数据库位置:
$ ls -lth /data/biosoft_root/alphafold_database/
total 12K
drwxrwxr-x. 2 root root   73 Feb  3 09:49 uniprot
drwxrwxr-x. 2 root root   36 Feb  3 09:42 uniref90
drwxrwxr-x. 2 root root   36 Feb  2 15:35 pdb_seqres
drwxrwxr-x. 2 root root   61 Feb  2 15:04 small_bfd
drwxrwxr-x. 2 root root 4.0K Feb  2 08:01 uniref30
drwxrwxr-x. 3 root root   57 Feb  2 07:15 pdb_mmcif
drwxrwxr-x. 2 root root  254 Feb  2 05:30 pdb70
drwxrwxr-x. 2 root root   45 Feb  2 03:29 mgnify
drwxrwxr-x. 2 root root 4.0K Feb  2 02:37 bfd
drwxrwxr-x. 2 root root 4.0K Feb  1 21:48 params
解压后：
$ du -sh /data/biosoft_root/alphafold_database/
2.6T	/data/biosoft_root/alphafold_database/


4) 检查能否使用显卡
$ docker run --rm --gpus all nvidia/cuda:11.0-base nvidia-smi
可以显示 显卡信息: NVIDIA-SMI 515.105.01   Driver Version: 515.105.01   CUDA Version: 11.7


5) 构建镜像
$ docker build -f docker/Dockerfile -t alphafold .
耗时任务，等待 14:50-->需要下载很多东西，取决于网速

报错:
#0 572.7 CondaHTTPError: HTTP 000 CONNECTION FAILED for url <https://conda.anaconda.org/conda-forge/noarch/wheel-0.40.0-pyhd8ed1ab_0.conda>
#0 572.7 Elapsed: -
...
ERROR: failed to solve: process "/bin/bash -o pipefail -c conda install -qy conda==4.13.0     && conda install -y -c conda-forge       openmm=7.7.0       cudatoolkit==${CUDA_VERSION}       pdbfixer       pip       python=3.8       && conda clean --all --force-pkgs-dirs --yes" did not complete successfully: exit code: 1
不管它，重新跑build，会断点继续。

查看新生成的镜像:
$ docker images
REPOSITORY    TAG                       IMAGE ID       CREATED          SIZE
alphafold     latest                    ec23307d8a52   49 seconds ago   9.97GB

导出镜像到文件:
$ docker save alphafold:latest | gzip > ~/alphafold_latest.image.tar.gz



6) 安装依赖py包

$ which python3
~/software/anaconda3/bin/python3

$ which pip3
~/software/anaconda3/bin/pip3

提过虚拟环境:
	使用conda安装虚拟环境   $ conda create -n alphafold python=3.7
	进入conda创建的虚拟环境 $ conda activate alphafold
	安装启动的依赖          $ pip3 install -r docker/requirements.txt

$ pip3 install -r docker/requirements.txt -i https://pypi.douban.com/simple/


7) 确保输入文件夹可写
默认是 /tmp/alphafold
$ mkdir /tmp/alphafold

8) 运行容器
$ python3 docker/run_docker.py \
  --fasta_paths=your_protein.fasta \
  --max_template_date=2022-01-01 \
  --data_dir=$DOWNLOAD_DIR \
  --output_dir=/home/user/absolute_path_to_the_output_dir

参数解释: 
--fasta_paths parameter 蛋白质一级序列
	pointing to a FASTA file containing the protein sequence(s) for which you wish to predict the structure.

--max_template_date 指定日期前的模板，来避免某些模板。
	AlphaFold will search for the available templates before the date specified by the --max_template_date parameter; 
	this could be used to avoid certain templates during modeling. 

--data_dir 之前下载的数据库
	is the directory with downloaded genetic databases and 

--output_dir 输出文件夹绝对路径
	is the absolute path to the output directory.


运行测试：
$ pwd
/home/wangjl
$ mkdir test


$ vim your_protein.fasta  #https://www.uniprot.org/uniprotkb/Q9NZQ7/entry#sequences
> wjlProtein
MRIFAVFIFMTYWHLLNAFTVTVPKDLYVVEYGSNMTIECKFPVEKQLDLAALIVYWEMEDKNIIQFVHGEEDLKVQHSSYRQRARLLKDQLSLGNAALQITDVKLQDAGVYRCMISYGGADYKRITVKVNAPYNKINQRILVVDPVTSEHELTCQAEGYPKAEVIWTSSDHQVLSGKTTTTNSKREEKLFNVTSTLRINTTTNEIFYCTFRRLDPEENHTAELVIPELPLAHPPNERTHLVILGAILLCLGVALTFIFRLRKGRMMDVKKCGIQDTNSKKQSDTHLEET 


$ cd ~/Downloads/alphafold
$ DOWNLOAD_DIR=/data/biosoft_root/alphafold_database/
$ python3 docker/run_docker.py \
  --fasta_paths=/home/wangjl/your_protein.fasta \
  --max_template_date=2022-01-01 \
  --data_dir=$DOWNLOAD_DIR \
  --output_dir=/home/wangjl/test
# 16:59-->20:58, 耗时 4h。产生 pdb 文件10个。


过程检测，占用显存 2G/40G;
$ nvidia-smi | grep -A4 "Processes"
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=========== ====================== ======================= ==================|
|    0   N/A  N/A    135732      C   python                            413MiB |

$ ps 135732
   PID TTY      STAT   TIME COMMAND
135732 ?        Sl     0:32 python /app/alphafold/run_alphafold.py --fasta_paths=/mnt/fasta_path_0/your_protein.fasta --uniref90_database_path=/mnt/uniref90_database_path/uniref90.fasta --mgnify_database_path=/mnt/mgnify_database_path/mgy_clusters_2022_

每5s更新一次
$ watch -n 5 nvidia-smi 

进入容器查看 CUDA 版本号: 是 CUDA v11.1
$ which nvcc
/usr/local/cuda/bin/nvcc
$ nvcc --version
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2020 NVIDIA Corporation
Built on Mon_Oct_12_20:09:46_PDT_2020
Cuda compilation tools, release 11.1, V11.1.105




产生的 pdb 文件：
$ ls -lth ~/test/your_protein/*pdb
-rw-r--r-- 1 wangjl wangjl 186K May 10 20:58 /home/wangjl/test/your_protein/ranked_4.pdb
-rw-r--r-- 1 wangjl wangjl 186K May 10 20:58 /home/wangjl/test/your_protein/ranked_1.pdb
-rw-r--r-- 1 wangjl wangjl 186K May 10 20:58 /home/wangjl/test/your_protein/ranked_2.pdb
-rw-r--r-- 1 wangjl wangjl 186K May 10 20:58 /home/wangjl/test/your_protein/ranked_3.pdb
-rw-r--r-- 1 wangjl wangjl 372K May 10 20:58 /home/wangjl/test/your_protein/ranked_0.pdb
-rw-r--r-- 1 wangjl wangjl 372K May 10 20:58 /home/wangjl/test/your_protein/relaxed_model_1_pred_0.pdb
-rw-r--r-- 1 wangjl wangjl 186K May 10 20:58 /home/wangjl/test/your_protein/unrelaxed_model_5_pred_0.pdb
-rw-r--r-- 1 wangjl wangjl 186K May 10 20:56 /home/wangjl/test/your_protein/unrelaxed_model_4_pred_0.pdb
-rw-r--r-- 1 wangjl wangjl 186K May 10 20:54 /home/wangjl/test/your_protein/unrelaxed_model_3_pred_0.pdb
-rw-r--r-- 1 wangjl wangjl 186K May 10 20:52 /home/wangjl/test/your_protein/unrelaxed_model_2_pred_0.pdb
-rw-r--r-- 1 wangjl wangjl 186K May 10 20:49 /home/wangjl/test/your_protein/unrelaxed_model_1_pred_0.pdb


运行命令：
$ head docker/run_docker.py



9) 结束后，可以看到输出的蛋白结构文件。
继续看文档，学习其他参数或排错。

pdb 的 web 可视化工具 https://www.rcsb.org/3d-view





Ref:
https://www.cnblogs.com/grainrain/p/13151030.html

可视化蛋白结构: https://blog.csdn.net/qq_41993290/article/details/121442127
Ubuntu20.04利用docker搭建GPU共享服务器 https://blog.csdn.net/qq_44817900/article/details/125366646



========================================
|-- 显卡性能测试：torch 计算？ //todo
----------------------------------------

https://blog.csdn.net/xiaoyaoyun518/article/details/127893006
CUDA 计算？







========================================
CUDA 编程
----------------------------------------
1. 环境
GPU 版的 hello world!
CPU称为host，显卡叫做 device。

以下测试
	前两个使用的是 alphaFold 镜像启动的容器，cuda 版本号: v11.1
	后面是 ubuntu 工作站的，cuda 12.0

$ nvcc --version
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2020 NVIDIA Corporation
Built on Mon_Oct_12_20:09:46_PDT_2020
Cuda compilation tools, release 11.1, V11.1.105
Build cuda_11.1.TC455_06.29190527_0


$ nvcc --version
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2023 NVIDIA Corporation
Built on Mon_Apr__3_17:16:06_PDT_2023
Cuda compilation tools, release 12.1, V12.1.105
Build cuda_12.1.r12.1/compiler.32688072_0



参考资料
《Professional CUDA C Programming》
《CUDA C Programming_Guide》

ref:
https://zhuanlan.zhihu.com/p/432092988
https://zhuanlan.zhihu.com/p/435935364
CUDA编程-03:线程层级 https://zhuanlan.zhihu.com/p/440112374
CUDA编程-04：CUDA内存模型 https://zhuanlan.zhihu.com/p/445373116
CUDA编程-05：流和事件 https://zhuanlan.zhihu.com/p/449567997




========================================
|-- CUDA 编程：简单案例
----------------------------------------
(1) 在CPU上打印
$ cat hello.cu
#include <stdio.h>

int main(void)
{
    printf("Hello World from CPU\n");
    return 0;
}

用nvcc进行编译生成可执行文件：
$ nvcc hello.cu -o hello
运行
$ ./hello 
Hello World from CPU


(2) 显卡打印，函数需要使用 __global__ 修饰。
要在GPU上运行程序，我们需要写一个能在GPU上执行的函数，然后在CPU上调用这个函数。

$ cat hello2.cu 
#include <stdio.h>

__global__ void HelloFromGPU(void)
{
    printf("Hello from GPU\n");
}

int main(void)
{
    printf("Hello from CPU\n");
    HelloFromGPU<<<1, 5>>>();
	
	
	//debug use only
	cudaError_t err = cudaGetLastError();
	if (err != cudaSuccess) {
		printf("CUDA Error: %s\n", cudaGetErrorString(err));
		// Possibly: exit(-1) if program cannot continue....
	} 

	
    cudaDeviceReset();
    return 0;
}

编译和执行
$ nvcc hello2.cu -o hello2
$ ./hello2
Hello from CPU
Hello from GPU
Hello from GPU
Hello from GPU
Hello from GPU
Hello from GPU



在CUDA中，有以下3种函数类型限定符：
_global_
	被__global__函数类型限定符修饰的函数被称为内核函数，该函数在host上被调用，在device上执行，只能返回void类型，不能作为类的成员函数。调用__global__修饰的函数是异步的，也就是说它未执行完就会返回。
_device_
	被__device__函数类型限定符修饰的函数只能在device上被调用，在device上执行，用于在device代码中内部调用。
_host_
	被__host__函数类型限定符修饰的函数只能在host上被调用，在host上执行，也就是host上的函数，__host__函数类型限定符可以省略。



与调用一般CPU函数不同的是，调用HelloFromGPU函数的时候会在后面写上3尖括号<<< >>>，里面是逗号隔开的2个数字。
	意思这是从host端到device端的内核函数调用，里面的参数是执行配置，用来说明使用多少线程来执行内核函数。
	一个内核函数是通过一组线程来执行的，所有线程执行的同样的代码，我这里设置的是用了5个线程来执行。程序编译成功后运行得到上述结果。
	三括号中的第一个数时线程块的个数，第二个数可以看作每个线程中的线程数。
	一个核函数的全部线程块构成一个网格，而线程块的个数记为网格大小，每个线程块中含有同样数目的线程，该数目称为线程块大小。
		所以核函数中的总的线程就等与网格大小乘以线程块大小，即<<<网格大小, 线程块大小>>>




(3) 使用多个线程的核函数
一个GPU往往有几千个计算核心，而总的线程数必须至少等与计算核心数时才有可能充分利用GPU的全部计算资源。

使用网格数为2，线程块大小为4的计算核心，所以总的线程数就是2x4=8，所以核函数的调用将指派8个线程完成。
核函数中的代码的执行方式是“单指令-多线程”，即每一个线程都执行同一指令的内容。


$ cat hello3.cu
#include<stdio.h>

__global__ void hello_from_gpu()
{
   printf("hello word from the gpu!\n");
}

int main() 
{
   hello_from_gpu<<<2,4>>>();
   cudaDeviceSynchronize();
   printf("helloword\n");
   return 0;
}


编译和执行：
$ nvcc hello3.cu -o hello3
$ ./hello3
hello word from the gpu!
hello word from the gpu!
hello word from the gpu!
hello word from the gpu!
hello word from the gpu!
hello word from the gpu!
hello word from the gpu!
hello word from the gpu!
helloword



(4) 线程索引的使用
gridDim.x ：该变量的数值等与执行配置中变量grid_size的数值。
blockDim.x: 该变量的数值等与执行配置中变量block_size的数值。

在核函数中预定义了如下标识线程的内建变量：
blockIdx.x :该变量指定一个线程在一个网格中的线程块指标。其取值范围是从0到gridDim.x-1
threadIdx.x：该变量指定一个线程在一个线程块中的线程指标，其取值范围是从0到blockDim.x-1

$ cat hello4.cu
#include <stdio.h>
__global__ void hello_from_gpu()
{
   const int bid = blockIdx.x;
   const int tid = threadIdx.x;
   printf("hello word from block %d and thread %d\n", bid, tid);
}
int main()
{
   hello_from_gpu<<<2,4>>>();
   cudaDeviceSynchronize(); 
   printf("helloword\n");
   return 0;
}

编译和执行：
$ nvcc hello4.cu -o hello4
I have no name!@cfb6065db943:/tmp$ ./hello4
hello word from block 1 and thread 0
hello word from block 1 and thread 1
hello word from block 1 and thread 2
hello word from block 1 and thread 3
hello word from block 0 and thread 0
hello word from block 0 and thread 1
hello word from block 0 and thread 2
hello word from block 0 and thread 3
helloword


有时候线程块的顺序会发生改变，有时候是第1个先执行有时候是第0个先执行，这说明了cuda程序执行时每个线程块的计算都是相互独立的，不管完成计算的次序如何，每个线程块中间的每个线程都进行一次计算。




(5) cuda多维网格
上述四个内建变量都使用了C++中的结构体或者类的成员变量的语法，其中blockIdx和threadIdx是类型为uint3的变量，该类型是一个结构体，具有x,y,z三个成员变量。所以blockIdx.x只是三个成员中的一个，threadIdx也有xyz三个成员变量。结构体uint3在头文件vector_types.h中定义有。

struct __device_builtin__ uint3
{
	unsigned int x, y, z;
};
typedef __device_builtin__ struct uint3 uint3;

blockDim是dim3类型的变量。也有xyz三个成员变量。
在前面三括号内的网格大小和线程块大小都是通过一维表示，可以通过dim3定义多维网格和线程块，通过C++的构造函数的方法实现。di3 grid_size(Gx.Gy,Gz);
如果第三个维度是1，可以省去不写。
多维的网格和线程块本质上还是一维的，就像多维数组本质上也是一维数组一样。一个多维线程指标threadIdx.x、threadIdx.y、threadIdx.z对应的一维指标为。

int tid = threadIdx.z * blockDim.x * blockDim.y +threadIdx.y * blockDim.x + threadIdx.x;
也就是说，x维度是最内层的变化最快的，而z维度是最外层的变化最慢的。


$ cat hello5.cu 
#include <stdio.h>
__global__ void hello_from_gpu()
{
   const int bid = blockIdx.x;
   const int tid = threadIdx.x;
   const int yid = threadIdx.y;
   printf("hello word from block %d and thread (%d,%d)\n",bid,tid,yid);
}
int main()
{
   const dim3 block_size(2,4);
   hello_from_gpu<<<1,block_size>>>();
   cudaDeviceSynchronize();
   printf("helloword\n");
   return 0;
}

编译和执行：
$ nvcc  hello5.cu -o hello5
$ ./hello5
hello word from block 0 and thread (0,0)
hello word from block 0 and thread (1,0)
hello word from block 0 and thread (0,1)
hello word from block 0 and thread (1,1)
hello word from block 0 and thread (0,2)
hello word from block 0 and thread (1,2)
hello word from block 0 and thread (0,3)
hello word from block 0 and thread (1,3)
helloword






========================================
|-- CUDA编程：GPU 实现数组
----------------------------------------
3. GPU 实现数组

(1) 一个典型的CUDA程序结构一般由以下5个步骤组成：
* 分配GPU内存；
* 从CPU内存中拷贝数据到GPU内存中；
* 调用CUDA内核函数执行程序指定的计算任务；
* 从GPU内存中把数据拷贝回CPU内存中；
* 释放GPU内存；


i)在CPU上实现数组相加：
函数VectorAddCPU用了一个for循环在CPU上实现数组相加的过程。
$ cat CAdd.c 
#include <iostream>

void VectorAddCPU(const float *const a, const float *const b, float *const c,
                  const int n) {
  for (int i = 0; i < n; ++i) {
    c[i] = a[i] + b[i];
  }
}

int main(void) {
  // alloc memory for host
  const size_t size = 1024;
  float *ha = new float[size]();
  float *hb = new float[size]();
  float *hc = new float[size]();

  for (int i = 0; i < size; ++i) {
    ha[i] = i;
    hb[i] = size - i;
  }

  VectorAddCPU(ha, hb, hc, size);

  delete[] ha;
  delete[] hb;
  delete[] hc;

  return 0;
}
$ g++ CAdd.c -o CAdd
$ ./CAdd


ii) 在GPU上的实现
如果要用GPU来实现该过程，则调用CUDA的API按照前面说的5个步骤编写代码：


$ cat GAdd.cu 
#include <cuda_runtime.h>
#include <iostream>

__global__ void VectorAddGPU(const float *const a, const float *const b,
                             float *const c, const int n) {
  int i = blockDim.x * blockIdx.x + threadIdx.x;
  if (i < n) {
    c[i] = a[i] + b[i];
  }
}

int main(void) {
  // 分配CPU内存
  const size_t size = 10240;
  const size_t n = size / sizeof(float);
  float *ha = new float[n]();
  float *hb = new float[n]();
  float *hc = new float[n]();

  for (int i = 0; i < n; ++i) {
    ha[i] = i;
    hb[i] = size - i;
  }

  // 分配GPU内存
  float *da = nullptr;
  float *db = nullptr;
  float *dc = nullptr;
  cudaMalloc((void **)&da, size);
  cudaMalloc((void **)&db, size);
  cudaMalloc((void **)&dc, size);

  // 把数据从CPU拷贝到GPU
  cudaMemcpy(da, ha, size, cudaMemcpyHostToDevice);
  cudaMemcpy(db, hb, size, cudaMemcpyHostToDevice);
  cudaMemcpy(dc, hc, size, cudaMemcpyHostToDevice);

  const int thread_per_block = 256;
  const int block_per_grid = (size + thread_per_block - 1) / thread_per_block;

  // 调用核函数
  VectorAddGPU<<<block_per_grid, thread_per_block>>>(da, db, dc, size);

  // 把数据从GPU拷贝回CPU
  cudaMemcpy(hc, dc, size, cudaMemcpyDeviceToHost);
  
  // 显示部分结果，依靠CPU内存
  for(int i=0; i<100; i++){
	printf("result: c[%d]=%f\n", i, hc[i]);
  }
  

  // 释放GPU内存
  cudaFree(da);
  cudaFree(db);
  cudaFree(dc);

  // 释放CPU内存
  delete[] ha;
  delete[] hb;
  delete[] hc;

  return 0;
}


$ nvcc GAdd.cu -o GAdd
$ ./GAdd 
result: c[0]=10240.000000
result: c[1]=10240.000000
result: c[2]=10240.000000
result: c[3]=10240.000000
...



这段代码里，用到了几个CUDA的内存管理函数：

cudaMalloc
	函数原型：cudaError_t cudaMalloc(void** devPtr, size_t size)
	该函数用于在GPU上分配指定大小的内存空间，类似于标准C语言中的malloc函数。

cudaMemcpy
	函数原型：cudaError_t cudaMemcpy(void* dst, const void* src, size_t count, cudaMemcpyKind kind)
	
	该函数用于内存拷贝，类似于标准C语言中的memcpy函数。数据拷贝的流向由参数kind指定，分为以下4种方式：
	cudaMemcpyHostToHost
	cudaMemcpyHostToDevice
	cudaMemcpyDeviceToHost
	cudaMemcpyDeviceToDevice
	从它们的字面意思就能知道，如果是从host拷贝数据到device，那么kind参数应该设置为cudaMemcpyHostToDevice；
	如果是从device拷贝数据到host，那么kind参数应该设置为cudaMemcpyDeviceToHost。上面的代码体现了这一点。

cudaFree
	udaError_t cudaFree(void* devPtr)
	该函数用于释放已分配的GPU内存空间，类似于标准C语言中的free函数。


在上面的代码中，内核函数 VectorAddGPU 用于实现数组相加，与前面的代码中 VectorAddCPU函数不同的是，VectorAddGPU 函数里面并没有用for循环，因为在GPU中是将数据进行并行化划分，然后通过线程组去实现计算过程的，线程组中的每个线程都是执行c[i] = a[i] + b[i]这个计算过程。
在这个程序里，数组的长度为1024，我设置了每个线程组中的线程数量为256，总共用了4个线程组去进行计算。

关于GPU中线程和线程组的相关知识，我将在下一篇文章中进行阐述。





4. 线程束

UDA采用SIMT架构来管理和执行线程，将线程块中的线程每32个（记住这个神奇的数字）为一组进行划分，每一组被称为一个线程束(warp)。
线程束的大小warpSize是CUDA中的一个内部属性，可以通过以下方式获得：

$ cat h3.cu
#include <iostream>

int main(){
	cudaDeviceProp prop;
	cudaGetDeviceProperties(&prop, 0);
	printf("warpSize: %d\n", prop.warpSize);
	return 0;
}

$ nvcc h3.cu -o h3
$ ./h3 
warpSize: 32512













========================================
----------------------------------------




========================================
----------------------------------------




========================================
----------------------------------------




========================================
----------------------------------------






========================================
----------------------------------------




========================================
----------------------------------------




========================================
----------------------------------------




========================================
----------------------------------------



