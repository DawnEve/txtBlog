Linux 十大常用命令

序言：
linux是命令行操作为主、鼠标操作为辅的系统，因此熟悉常用命令十分必要。



linux常用命令 http://www.884358.com/linux-cmds/





========================================
文件操作 十大常用命令(预览gz文件)
----------------------------------------
对于ubuntu系统，快捷键ctrl+Alt+T就能打开一个终端窗口。
可以在这里输入窗口。


1.常用操作：
mkdir	创建目录
rmdir	删除目录
cd	改变目录
ls	显示文件信息
	ls -lth 详细、按照时间、以人类友好的数字显示该目录
	ls -Sr 按照大小倒序显示该目录
cat	编辑文件
less	显示文件内容
cp	复制文件
mv	更改文件名
rm	删除文件
chmod	改变权限



Linux下gz压缩文件查看
$ zcat xx.gz
$ zcat xx.gz | less
$ zless xx.gz

#修改文件的日期：
$ touch  -t "201801231215" test2  　将文件修改日期调整为指定日期，2018年1月23日12点15分。


less 的更多参数
$ cat xx.vcf | less -SN
  -N  ........  --LINE-NUMBERS
                  Use line numbers.
  -S  ........  --chop-long-lines
                  Chop (truncate) long lines rather than wrapping.



### 为了安全：改为询问或者建立回收站。
为了防止误删，改写rm命令为
$ vim ~/.bashrc
alias rm='rm -i' #加入这一句
$ source ~/.bashrc

$ rm a.txt 这样删除的时候就会再提示一次。
rm: remove regular file 'a.txt'? y






归档、压缩
-命令zip用以压缩文件：
	zip linux2.zip myfile
	unzip linux2.zip #解压缩zip文件
-gzip linex2 压缩文件
-tar命令以归档文件
	tar -cvf out.tar linux2 	#打包归档
	tar -xvf linux2.tar	#解包
	tar -cvzf backup.tar.gz /etc	
		-z参数将压缩后的归档文件进行gzip压缩以减少大小

xxxx.tar.gz文件使用tar带zxvf参数，可以一次解压开。XXXX为文件名。 例如：  $tar zxvf xxxx.tar.gz   










2.pdf版
如果想打印出来细看，推荐北京大学cbi罗静初老师总结的版本：
Unix 十大常用命令：http://abc.cbi.pku.edu.cn/man/unix-commands1.pdf
Unix 十大专用命令：http://abc.cbi.pku.edu.cn/man/unix-commands2.pdf
Unix 十大实用命令：http://abc.cbi.pku.edu.cn/man/unix-commands3.pdf

from:http://abc.cbi.pku.edu.cn/manuals.php





linux20大常用命令
http://www.oschina.net/translate/useful-linux-commands-for-newbies

1、快捷键：
Ctrl + a 可以快速切换到命令行开始处
Ctrl + e 切换到命令行末尾
Ctrl + r 在历史命令中查找
Ctrl + u 删除光标所在位置之前的所有字符
Ctrl + k 删除光标所在位置之后的所有字符
ctrl + w 删除光标之前的一个单词
Ctrl + d 结束当前输入、退出shell
ctrl + s 可用来停留在当前屏 ctrl + q 恢复刷屏
ctrl + l 清屏
 
2、mkdir
mkdir -p level/nextlevel   ##-p 建立一个不存在的目录，并在该目录下继续建立一个子目录
mkdir dir{a,b,c}
mkdir dir[1..9]                 ## mkdir dir 批量建立目录
 
3、ln -s  /home/usr/local/file  /otherfile ###软链接， 类似于windows下的快捷键
      ln  /home/usr/local/file  /otherfile ###硬链接
 
4、du 显示目录或者文件所占空间 
   du [选项] [文件/目录]
   du -lh file

5. 关掉防火墙
$ sudo iptables -I INPUT -p tcp --dport 80 -j ACCEPT






========================================
|-- xshell 设置和使用技巧
----------------------------------------
1. 设置选中即复制

打开xshell，选择顶部菜单 【工具】-【选项】-【键盘和鼠标】，
- [ 向右按钮 ] 改为 [ 粘贴剪贴板内容 ]，
- 下面勾选将选定的文本自动复制的剪贴板即可。


2. 查看隧道状态：
	菜单 查看 - 隧道窗格；
	底下新窗口，选择最后一个 转移规则，可以看到隧道状态列表。
	如果状态是 打开，表示正常。






========================================
|-- 时间日期
----------------------------------------

显示时间：date
	格式化显示 date +%Y--%m--%d   #2014--5--12
查看日历：cal
查看系统运行时间：uptime



(1) 显示当前时间日期

获取当前日期时间
$ echo $(date) 
Sat Dec 19 10:19:19 CST 2020 

$ echo $(date +%Y-%m-%d\ %H:%M:%S)
2020-12-19 10:25:57



(2) 时间戳 <--> 日期时间
获取时间戳，秒做单位: %s   seconds since 1970-01-01 00:00:00 UTC
$ echo $(date +%s)
1608344504

从时间戳到日期时间
$ date --date='@1608344504'
Sat Dec 19 10:21:44 CST 2020

$ date --date='@2147483647'
Tue Jan 19 11:14:07 CST 2038



(3) 看命令运行时间
$ time ps aux
real    0m0.039s
user    0m0.012s
sys     0m0.022s

在程序或命令运行结束后，在最后输出了三个时间，它们分别是：
user：用户CPU时间，命令执行完成花费的用户CPU时间，即命令在用户态中执行时间总和；
system：系统CPU时间，命令执行完成花费的系统CPU时间，即命令在核心态中执行时间总和；
real：实际时间，从command命令行开始执行到运行终止的消逝时间；











========================================
软件安装与卸载
----------------------------------------





========================================
|-- win好用的客户端
----------------------------------------
win好用的客户端
git bash;
xshell (收费 or 教育版免费)
secureCRT: 
MobaXterm: https://mobaxterm.mobatek.net/download-home-edition.html
putty;








========================================
|-- Ubuntu软件安装与卸载：apt-get
----------------------------------------
软件版本低，想安装新版本的。想到2条：删了再装，或者升级。

1.卸载：
sudo apt-get purge mongodb
敲密码进去，OK
作用不大。

2.升级软件
sudo apt-get upgrade 更新已安装的包

refer: http://blog.csdn.net/linuxzhouying/article/details/7192612


如何卸载？
//todo

========================================
|-- deb包是debian，ubuntu等LINUX发行版的软件安装包
----------------------------------------
1.deb格式 

deb是debian linus的安装格式，跟red hat的rpm非常相似，最基本的安装命令是：dpkg -i file.deb 

dpkg 是Debian Package的简写，是为Debian 专门开发的套件管理系统，方便软件的安装、更新及移除。所有源自Debian的Linux发行版都使用dpkg，例如Ubuntu、Knoppix 等。是类似于rpm的软件包，而非debian,ubuntu系统不推荐使用deb软件包，因为要解决软件包依赖问题，安装也比较麻烦。

1.一般在此类发行版中可以直接双击安装。
2.手动安装。如果您喜欢使用终端，您需要管理员权限来安装一个 .deb 文件。 打开终端后，输入： 
$ sudo dpkg -i package_file.deb 

要卸载一个 .deb 文件，在您的软件包管理器中取消选中它。或者在终端中，输入:
$ sudo dpkg -r package_name 

例如安装QQ，文件名为linuxqq_v1.0-preview3_i386.deb, 可运行：
$ sudo dpkg -i linuxqq_v1.0-preview3_i386.deb

Ubuntu下deb包的安装方法 http://blog.csdn.net/kevinhg/article/details/5934462


以下是一些 Dpkg 的普通用法：
1. dpkg -i <package.deb>
安装一个 Debian 软件包，如你手动下载的文件。
2. dpkg -c <package.deb>
列出 <package.deb> 的内容。
3. dpkg -I <package.deb>
从 <package.deb> 中提取包裹信息。
4. dpkg -r <package>
移除一个已安装的包裹。
5. dpkg -P <package>
完全清除一个已安装的包裹。和 remove 不同的是，remove 只是删掉数据和可执行文件，purge 另外还删除所有的配制文件。
6. dpkg -L <package>
列出 <package> 安装的所有文件清单。同时请看 dpkg -c 来检查一个 .deb 文件的内容。
7. dpkg -s <package>
显示已安装包裹的信息。同时请看 apt-cache 显示 Debian 存档中的包裹信息，以及 dpkg -I 来显示从一个 .deb 文件中提取的包裹信息。
8. dpkg-reconfigure <package>
重新配制一个已经安装的包裹，如果它使用的是 debconf (debconf 为包裹安装提供了一个统一的配制界面)。


http://zhidao.baidu.com/link?url=ZYQMJY-mAOc4yU7QumlIUS4S3HiHz0O1lbdOHZjpbJv4xjxI8KEb1mbD43ley9zlvs7n0JDWumpFj4wxTSBkF_





========================================
|-- 把程序输出到路径path
----------------------------------------
.bash_profile和.bashrc作用类似。

为了使程序能在任意地点被调用，需要把可执行文件加入到路径中。

1. 方法1
将python的路径加入.bash_profile中的PATH.，
export PATH=/home/wangjl/software/anaconda3/bin/python3:$PATH

export PATH=$PATH:/home/wangjl/software/ncbi-blast-2.10.1+/bin/

并执行source .bash_profile使配置立即生效





2. 方法2: 也可以在.bashrc 末尾加上 （推荐）
export PATH="/home/wangjl/anaconda3/bin:$PATH"

最后需要重新登录才能生效。或者
$ source ~/.bashrc

注意：请在export中使用绝对路径。使用相对路径会有副作用，比如 nohup不能找到命令位置。




3. 检验是否添加成功
$ blastn --version

$ which blastn 
$ whereis blastn




4. .bash_profile和.bashrc的区别：
(1)
/etc/profile: 此文件为系统的每个用户设置环境信息,当用户第一次登录时,该文件被执行.并从/etc/profile.d目录的配置文件中搜集shell的设置.

/etc/bashrc:  为每一个运行bash shell的用户执行此文件.当bash shell被打开时,该文件被读取.


(2)
~/.bash_profile: 每个用户都可使用该文件输入专用于自己使用的shell信息,当用户登录时,该文件仅仅执行一次！默认情况下,他设置一些环境变量,执行用户的.bashrc文件.

~/.bashrc: 该文件包含专用于你的bash shell的bash信息,当登录时以及每次打开新的shell时,该该文件被读取.

~/.bash_logout: 当每次退出系统(退出bash shell)时,执行该文件.
 
另外,/etc/profile中设定的变量(全局)的可以作用于任何用户,而~/.bashrc等中设定的变量(局部)只能继承/etc/profile中的变量,他们是"父子"关系.



.bashrc #每个shell都执行。
This is the main file where you’re add most of your configurations, such as aliases, PATH variable, color schemes, etc. Unlike the other configuration files, this affects every terminal instance as opposed to only the login shell, which is handled by `.bash_profile’.

A few things that are defined in this file are:
* set the $PS1 variable, which displays hostname and current directory
* set the $PATH variable (discussed below)
* aliases
* history settings

IMPORTANT: this file should never output anything! You will run into some very frustrating situations if it does.


.bash_profile #登录时执行
This handles the login nodes, i.e. as soon as you ssh or log into a computer, this is the file that gets loaded. The reason being is that sometimes you want to view diagnostics of the machine that you’re logging into (how long has it been running, are there any updates that need to be installed, etc.) which you wouldn’t want to see in every other terminal instance. Unfortunately this does not have the same settings as the .bashrc file, so your path will not work unless you load your .bashrc file from within. To do so, you can add the following lines to your .bash_profile file (it may already be there, so check before you add this):

if [ -f $HOME/.bashrc ]; then
        source $HOME/.bashrc
fi

# likewise for .profile
if [ -f $HOME/.profile]; then
        source $HOME/.profile
fi



.profile
This file isn’t used very often, however one thing to note: anything that should be available to graphical applications or sh MUST go here.






========================================
|-- 软连接（快捷方式）：ln -s 文件或文件夹 新链接名
----------------------------------------
ln是linux中又一个非常重要命令，它的功能是为某一个文件在另外一个位置建立一个同步的链接.当我们需要在不同的目录，用到相同的文件时，我们不需要在每一个需要的目录下都放一个必须相同的文件，我们只要在某个固定的目录，放上该文件，然后在 其它的目录下用ln命令链接（link）它就可以，不必重复的占用磁盘空间。

1．命令格式：
ln [参数][源文件或目录][目标文件或目录]



2.软链接和硬链接的概念

硬链接可认为是一个文件拥有两个文件名;而软链接则是系统新建一个链接文件，此文件指向其所要指的文件


软链接: ln –s 源文件 目标文件
	1.软链接，以路径的形式存在。类似于Windows操作系统中的快捷方式
	2.软链接可以 跨文件系统 ，硬链接不可以
	3.软链接可以对一个不存在的文件名进行链接
	4.软链接可以对目录进行链接

硬链接: ln 源文件 目标文件，没有参数-s
	1.硬链接，以文件副本的形式存在。但不占用实际空间。
	2.不允许给目录创建硬链接
	3.硬链接只有在同一个文件系统中才能创建

不可以对文件夹建立硬连接的，我们通常用的还是软连接比较多



3.范例
　　将档案 yy 产生一个 symbolic link : zz
　　ln -s yy zz

　　将档案 yy 产生一个 hard link : xx
　　ln yy xx﻿
PS：如果想要删除链接，则像普通文件一样直接rm 链接名称即可。

ln -s /root/lntest/source /root/lntest/dist  #前面的是已经存在的文件/文件夹，后面的是新地址(链接)
$ ln -s /data/xx/wangjl/ ~/data





一共4种形式：
wjl@ubuntu:~$ ln --help

Usage: ln [OPTION]... [-T] TARGET LINK_NAME   (1st form)
  or:  ln [OPTION]... TARGET                  (2nd form)
  or:  ln [OPTION]... TARGET... DIRECTORY     (3rd form)
  or:  ln [OPTION]... -t DIRECTORY TARGET...  (4th form)

In the 1st form, create a link to TARGET with the name LINK_NAME.
In the 2nd form, create a link to TARGET in the current directory.
In the 3rd and 4th forms, create links to each TARGET in DIRECTORY.

Create hard links by default, symbolic links with --symbolic.

By default, each destination (name of new link) should not already exist.
When creating hard links, each TARGET must exist.  Symbolic links
can hold arbitrary text; if later resolved, a relative link is
interpreted in relation to its parent directory.

Mandatory arguments to long options are mandatory for short options too.
      --backup[=CONTROL]      make a backup of each existing destination file
  -b                          like --backup but does not accept an argument
  -d, -F, --directory         allow the superuser to attempt to hard link
                                directories (note: will probably fail due to
                                system restrictions, even for the superuser)
  -f, --force                 remove existing destination files
  -i, --interactive           prompt whether to remove destinations
  -L, --logical               dereference TARGETs that are symbolic links
  -n, --no-dereference        treat LINK_NAME as a normal file if
                                it is a symbolic link to a directory
  -P, --physical              make hard links directly to symbolic links
  -r, --relative              create symbolic links relative to link location
  -s, --symbolic              make symbolic links instead of hard links
  -S, --suffix=SUFFIX         override the usual backup suffix
  -t, --target-directory=DIRECTORY  specify the DIRECTORY in which to create
                                the links
  -T, --no-target-directory   treat LINK_NAME as a normal file always
  -v, --verbose               print name of each linked file
      --help     display this help and exit
      --version  output version information and exit

The backup suffix is '~', unless set with --suffix or SIMPLE_BACKUP_SUFFIX.
The version control method may be selected via the --backup option or through
the VERSION_CONTROL environment variable.  Here are the values:

  none, off       never make backups (even if --backup is given)
  numbered, t     make numbered backups
  existing, nil   numbered if numbered backups exist, simple otherwise
  simple, never   always make simple backups

Using -s ignores -L and -P.  Otherwise, the last option specified controls
behavior when a TARGET is a symbolic link, defaulting to -P.

Report ln bugs to bug-coreutils@gnu.org
GNU coreutils home page: <http://www.gnu.org/software/coreutils/>
General help using GNU software: <http://www.gnu.org/gethelp/>
For complete documentation, run: info coreutils 'ln invocation'

http://www.cnblogs.com/peida/archive/2012/12/11/2812294.html
http://www.linuxidc.com/Linux/2014-12/111056.htm
http://man.linuxde.net/ln




========================================
|-- 查看Linux系统版本号，是32位/64位
----------------------------------------
1. bits of OS
这个命令适用于所有的linux，包括Redhat、SuSE、Debian、Centos等发行版。

$ uname
Linux

$ uname --m
x86_64

现代操作系统基本都是 64 位了。





2. 查是 Ubuntu 还是 CentOS 及 内核版本号

(1) cat /proc/version

For CentOS 7
$ cat /proc/version
Linux version 3.10.0-1062.18.1.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) ) #1 SMP Tue Mar 17 23:49:17 UTC 2020

For Ubuntu 20.04
$ cat /proc/version
Linux version 5.4.0-109-generic (buildd@ubuntu) (gcc version 9.4.0 (Ubuntu 9.4.0-1ubuntu1~20.04.1)) #123-Ubuntu SMP Fri Apr 8 09:10:54 UTC 2022

一般来说， CentOS 集成的软件都比较老旧，这样才能符合口号 久经考验的软件和系统。


(2) uname -a
For CentOS 7
$ uname -a
Linux bio_svr1 3.10.0-1062.18.1.el7.x86_64 #1 SMP Tue Mar 17 23:49:17 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux

$ uname -r
3.10.0-1062.18.1.el7.x86_64



For Ubuntu 20.04
$ uname -a
Linux sustc-HG 5.4.0-109-generic #123-Ubuntu SMP Fri Apr 8 09:10:54 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux

$ uname -r
5.4.0-109-generic




(3) cat /etc/issue 只适用于 ubuntu
For CentOS 7
$ cat /etc/issue
\S
Kernel \r on an \m

For Ubuntu 20.04, version of linux
$ cat /etc/issue
Ubuntu 20.04.4 LTS \n \l




(4) lsb_release -a

如果 CentOS 没有安装，则安装一个
$ sudo yum install redhat-lsb -y
$ lsb_release -a
LSB Version:	:core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch
Distributor ID:	CentOS
Description:	CentOS Linux release 7.9.2009 (Core)
Release:	7.9.2009
Codename:	Core


For Ubuntu 20.04
$ lsb_release -a
No LSB modules are available.
Distributor ID:	Ubuntu
Description:	Ubuntu 20.04.4 LTS
Release:	20.04
Codename:	focal




(5) 适用于RedHat,CentOS
$ cat /etc/redhat-release
CentOS release 6.7 (Final)
或 
CentOS Linux release 7.8.2003 (Core)
CentOS Linux release 7.9.2009 (Core)


$ rpm -q redhat-release
package redhat-release is not installed

$ rpm -q centos-release
centos-release-6-7.el6.centos.12.3.i686
或
centos-release-7-8.2003.0.el7.centos.x86_64











========================================
进程: top, ps
----------------------------------------

查看进程的命令
top

查带某个关键字的进程
$ ps -aux | grep -i "python"

查进程的父进程
$ ps -A -o stat,ppid,pid,user,uid,%cpu,cmd | grep -i "python"


查找僵尸进程
$ ps -A -o stat,ppid,pid,user,uid,%cpu,cmd | grep "^[Zz]" | head
Z    416197    624 root         0  0.0 [crond] <defunct>
Z    416197   1578 root         0  0.0 [crond] <defunct>

统计都是哪个用户产生的
$ ps -A -o stat,ppid,pid,user,uid,%cpu,cmd | grep "^[Zz]" | awk '{print $4}' | sort | uniq -c | sort -k1nr
    292 root
     51 wangjl
     10 dbus
      9 alamin
      3 zhouwg

查看 root 的僵尸进程都是执行什么命令产生的？
$ ps -A -o stat,ppid,pid,user,uid,%cpu,cmd | grep "^[Zz]" | grep root | awk '{print $7}' | sort | uniq -c | sort -k1nr
    187 [crond]
    103 [systemd-logind]
      1 [iscsid]
      1 [run-parts]

$ busybox ps -A -o stat,ppid,pid,user,comm | grep "^[Zz]" | grep root | awk '{print $5}' | sort | uniq -c | sort -k1nr
    187 crond
    103 systemd-logind
     16 sshd
      2 libvirtd
      1 anacron
      1 iscsid
      1 run-parts

使用 busybox 又查到几个隐藏进程，执行的是 sshd, libvirtd, anacron
$ busybox ps -A -o stat,ppid,pid,user,comm | grep "^[Zz]" | grep root | grep sshd
Z    11166 11233 root     sshd
Z    11166 11238 root     sshd
Z    11166 11240 root     sshd
Z    11166 11245 root     sshd
Z    11166 11246 root     sshd
Z    28677 28744 root     sshd
Z    28677 28749 root     sshd
Z    28677 28750 root     sshd
Z    64022 64089 root     sshd
Z    64022 64094 root     sshd
Z    64022 64097 root     sshd
Z    339222 339293 root     sshd
Z    339222 339297 root     sshd
Z    339222 339300 root     sshd
Z    339222 339304 root     sshd
Z    339222 339305 root     sshd


$ ps 11166
Signal 17 (CHLD) caught by ps (procps-ng version 3.3.10).
ps:display.c:66: please report this bug
   PID TTY      STAT   TIME COMMAND
 11166 ?        Ss     0:00 sshd: alamin [priv]

$ ps 28677
Signal 17 (CHLD) caught by ps (procps-ng version 3.3.10).
ps:display.c:66: please report this bug
   PID TTY      STAT   TIME COMMAND
 28677 ?        Ss     0:00 sshd: alamin [priv]


$ ps 64022
Signal 17 (CHLD) caught by ps (procps-ng version 3.3.10).
ps:display.c:66: please report this bug
   PID TTY      STAT   TIME COMMAND
 64022 ?        Ss     0:00 sshd: zhouwg [priv]

$ ps 339222
Signal 17 (CHLD) caught by ps (procps-ng version 3.3.10).
ps:display.c:66: please report this bug
   PID TTY      STAT   TIME COMMAND
339222 ?        Ss     0:00 sshd: wangjl [priv]



杀掉僵尸进程的父进程 | xargs kill -9
$ busybox ps -A -o stat,ppid,pid,user,comm | grep "^[Zz]" | grep root | awk '{print $2}' |sort |uniq| head
11166
28677
314474
339222
415706
416197
421759
54992
64022





========================================
|-- 后台运行 nohup xx &
----------------------------------------
1. 一般形式为：
$ nohup command & 
　　如果使用nohup命令提交作业，那么在缺省情况下该作业的所有输出都被重定向到一个名为nohup.out的文件中，除非另外指定了输出文件： 
$ nohup command > myout.file 2>&1 & 
　　在上面的例子中，输出被重定向到myout.file文件中，错误被定向到输出中。后台运行。
$ nohup command > myout.file 2>myError.log & 
	输出重定向到myout.file，错误重定向到myError.log中。

IO流：0输入，1输出，2错误。



2.举一个例子：
$ cat QuantByHTSeq.sh
for i in `cat ../id.txt`;
do	
	htseq-count -f bam -r pos /home/wangjl/data/fudanSingleCell/helaBamFile/${i}.bam /data1/hou/RNA/refs/hg19_ERCC92/UCSC_hg19_geneid.gtf > ht_${i}.bam.count 2>ht_${i}.bam.count.log &
done

$ chmod +x QuantByHTSeq.sh
$ nohup ./QuantByHTSeq.sh &
#最后这一句推荐正常提交，反正很快就完成命令提交，该脚本自身就结束运行了。但是该脚本提交的后台命令还在运行。
$ ./QuantByHTSeq.sh





3. 另一个实例
$ nohup bowtie ~/refer/hg19/hg19 -q ../SRR3101251.fastq -m 1 -p 4 -S 2>SRR3101251.out >SRR3101251.sam &
表示: 文件输出到sam，错误输出到out文件。

http://bestchenwu.iteye.com/blog/1073565




========================================
|-- su 和 su - 的区别
----------------------------------------
su只是切换了root身份，但Shell环境仍然是普通用户的Shell；
而su - 连用户和Shell环境一起切换成root身份了。

只有切换了Shell环境才不会出现PATH环境变量错误。

su切换成root用户以后，pwd一下，发现工作目录仍然是普通用户的工作目录；
而用su -命令切换以后，工作目录变成root的工作目录了














========================================
文件和文件名 file & dir
----------------------------------------



========================================
|-- tar 命令: 打包、解压、压缩详解
----------------------------------------
本文主要介绍如何对文件打包、压缩、解压操作。
安装程序时最常见的是 解压缩。
打包后一般和压缩连用，压缩格式有 .gz, .zip 等。 


1. 常用命令

(1) 源码文件下载后，解压
解压源代码 file.tar.gz file.tar.bz2或file.src.rpm 文件:

$ tar jxvf file.tar.bz2  #解压
$ tar zxvf file.tar.gz #解压
$ tar -xvJf file.tar.xz 解压缩


=> 只解压部分文件：
先查看文件结构 $ tar ztvf xx.tar.gz，必要时可以连接一个 grep 匹配具体名字
解压某个目录 $ tar zxvf xx.tar.gz root/test1234




(2) 打包与压缩
$ tar -czvf ref-02.tar.gz polyA_DB #压缩文件夹 polyA_DB/ 及其子文件，为 ref-02.tar.gz

压缩多个文件和文件夹到 ref-01.tar.gz
$ tar -czvf ref-01.tar.gz extractGTF.py GRCh38.p13.gene GRCh38.p13.genome.fa.fai protein_coding.hg38.gene_name


Linxu 压缩打包某文件夹某时间之后的文件
$ tar czvf backtup.tar.gz --newer-mtime  "2021-07-24 00:00:00" uploadFiles/





(3) 使用 gzip 压缩与解压: .gz 文件
解压1：gunzip FileName.gz
解压2：gzip -d FileName.gz 
压缩：gzip FileName


$ gzip xx.txt # 生成xx.txt.gz，默认删除原始文件 xx.txt
$ gzip -c xx.txt > xx.txt.gz # 生成xx.txt.gz，源文件保留

$ gzip -r dir1
注意 gzip 压缩目录 只会递归地压缩目录下的所有文件，不会压缩目录


$ gunzip -c xx.txt.gz  #查看gz文件内容，和 zcat效果一样


解压：
$ gunzip t3.txt.gz #输出解压后的文件，默认不保留原始压缩文件
或
$ gzip -d t3.txt.gz 

$ gunzip -c xx.txt.gz > xx.txt #解压，并保留原始压缩文件



tips1:linux不解压超大日志gz包直接查找特定内容
$ gzip -dc myfile.gz | grep 'Exception' | more
或者
$ gzip -c myfile.gz | grep 'Exception' | more


tips2:不解压一个tar.gz文件，查看里面的文件明细的命令为：
$ tar tvf my_file.tar.gz



(4) zip压缩与unzip解压缩
$ zip -r myfile.zip ./*
将当前目录下的所有文件和文件夹全部压缩成myfile.zip文件,-r表示递归压缩子目录下所有文件.

解压缩
$ unzip -o -d /home/sunny myfile.zip
把myfile.zip文件解压到 /home/sunny/
-o:不提示的情况下覆盖文件；
	-o  overwrite files WITHOUT prompting
-d:-d /home/sunny 指明将文件解压缩到/home/sunny目录下；
	-d  extract files into exdir


$ zip -d myfile.zip smart.txt   #删除压缩文件中smart.txt文件
	-d   delete entries in zipfile

$ zip -m myfile.zip ./rpm_info.txt   #向压缩文件中myfile.zip中添加rpm_info.txt文件
	-m   move into zipfile (delete OS files)




(5) 其他解压方式
*.tar.gz和*.tgz 用 tar –xzf 解压
*.bz2 用 bzip2 -d或者用bunzip2 解压
*.tar.bz2用tar –xjf 解压

*.Z 用 uncompress 解压
*.tar.Z 用tar –xZf 解压
*.rar 用 unrar e解压
*.zip 用 unzip 解压




(6) 查看压缩文件在压缩前的大小
-rw-rw-r-- 1 wangjl wangjl  618 Jul 26 10:17 a.txt
-rw-rw-r-- 1 wangjl wangjl  376 Jul 26 10:17 a.txt.gz

$ gzip -l a.txt.gz 
         compressed        uncompressed  ratio uncompressed_name
                376                 618  43.0% a.txt

$ gzip -l SUSTC-20220617-L-01-2022-06-211426/Sample_R22021013-220615_468-468_L/R22021013-220615_468-468_L_combined_R1.fastq.gz
         compressed        uncompressed  ratio uncompressed_name
        16001704113               52549 -30450915.4% SUSTC-20220617-L-01-2022-06-211426/Sample_R22021013-220615_468-468_L/R22021013-220615_468-468_L_combined_R1.fastq

对这个压缩比为负数的解释：https://www.nuomiphp.com/eplan/126869.html
以下是gzip规范（RFC 1952）的一部分，其中定义了如何将未压缩大小存储在gzip文件中。

     ISIZE (Input SIZE)
        This contains the size of the original (uncompressed) input
        data modulo 2^32.
您正在使用一个gzip压缩文件，其中未压缩的大小是> 2 ^ 32个工作，所以报道的未压缩的大小gzip -l是始终会是不正确的。

请注意，gzip文件格式的此设计限制在解压缩存档文件时不会引起任何问题。唯一的影响是与gzip -l或gunzip -l
2**32=4294967296=4,294,967,296=4G 压缩前超过4G，则压缩后 gzip -l 参数返回值就是有问题的。









2. 查看帮助文档
$ tar --help
Usage: tar [OPTION...] [FILE]...
GNU 'tar' saves many files together into a single tape or disk archive, and can restore individual files from the archive.
tar 可以把很多文件打包成单个文件。也可以解包恢复到多个文件。

Examples:
$ tar -cf archive.tar foo bar  # Create archive.tar from files foo and bar.
$ tar -tvf archive.tar         # List all files in archive.tar verbosely.
$ tar -xf archive.tar          # Extract all files from archive.tar.

(1) Main operation mode: 主操作模式
这五个是独立的命令，压缩解压都要用到其中一个，可以和别的命令连用但只能用其中一个。

	-c: 建立压缩档案
	-r：向压缩归档文件末尾追加文件
	-u：更新原压缩包中的文件
	-t：查看内容，配合v显示详细信息
	-x：解压
	
  -A, --catenate, --concatenate   append tar files to an archive
  -c, --create               create a new archive
  -d, --diff, --compare      find differences between archive and file system
      --delete               delete from the archive (not on mag tapes!)
  -r, --append               append files to the end of an archive
  -t, --list                 list the contents of an archive
      --test-label           test the archive volume label and exit
  -u, --update               only append files newer than copy in archive
  -x, --extract, --get       extract files from an archive

(2)  Compression options 解压与压缩选项
下面的参数是根据需要在压缩或解压档案时可选的。
	-z：有gzip属性的 .gz
	-j：有bz2属性的 .bz2
	-Z：有compress属性的 .Z
	-v：显示所有过程
	-O：将文件解开到标准输出
	
  -z, --gzip, --gunzip, --ungzip   filter the archive through gzip
  -j, --bzip2                filter the archive through bzip2
  -Z, --compress, --uncompress   filter the archive through compress

  -v, --verbose              verbosely list files processed 显示所有过程
  -f, --file=ARCHIVE         use archive file or device ARCHIVE 指定压缩文件名
  -O, --to-stdout            extract files to standard output 将文件解开到标准输出


(3) 参数-f是必须的
-f: 使用档案名字，切记，这个参数是最后一个参数，后面只能接档案名。

$ tar -cf c1.tar t3.txt b1.html #源文件还在，产生新打包文件c1.tar

$ tar -tvf c1.tar #列举该包中的文件详情
-rw-rw-r-- wangjl/wangjl    13 2021-09-18 10:27 t3.txt
-rw-rw-r-- wangjl/wangjl  2381 2021-09-18 10:13 b1.html

$ tar -xf c1.tar  #删掉其余文件，执行解包后，那2个文件又出现了，且时间权限都和打包前一样。打包文件本身还保留。


(4) 更多打包命令详解
使用形式: tar -[5个主命令之一 若干参数] file.tar

$ tar -cf all.tar *.jpg #将所有.jpg的文件打成一个名为all.tar的包。-c是表示产生新的包，-f指定包的文件名。

$ tar -rf all.tar *.gif #将所有.gif的文件增加到all.tar包的末尾。-r是表示append文件 to the end。

$ tar -uf all.tar logo.gif 
更新原来tar包all.tar中logo.gif文件，-u是表示时间戳更新的才追加到tar末尾。解包时看到的最新的。
$ tar -tvf all.tar #能看到同名的新旧2个文件，新文件在末尾。
$ tar -xvf all.tar #解包也能看到2次，后面的新的把前面的旧的覆盖了。

$ tar -tf all.tar #列出all.tar包中所有文件，-t是给出文件列表
$ tar -tvf all.tar #加上v后列出详细信息

$ tar -xf all.tar  #解出all.tar包中所有文件，-x是解开的意思



(5) 打包并压缩: 就是打包 + 压缩关键词

0) .tar 包，只打包不压缩
$ tar -cf txt.tar *.txt #打包*txt文件到 txt.tar
$ tar -cvf txt.tar *.txt #加-v参数会列出详细情况
hello.txt
t3.txt

$ tar -xvf file.tar //解压 tar包


1) .tar.gz 压缩: -z 调用 gzip 压缩
$ tar -czvf txt.tar.gz *.txt #加-z 表示gzip压缩，输出文件txt.tar.gz
hello.txt
t3.txt

$ tar -xzvf file.tar.gz //解压tar.gz

$ tar zcvf dir123.tar.gz dir1 //把文件夹 dir1 给打包压缩成 dir123.tar.gz。
如果不需要压缩，就不要使用z参数，大文件太慢了！



2) .tar.bz2 压缩 
$ tar -cjf txt.tar.bz2 *.txt #加-j 表示 bzip2 压缩，输出文件 txt.tar.bz2
$ tar -tvf txt.tar.bz2 #查看文件内容

$ tar -xjvf file.tar.bz2   //解压 tar.bz2


3) .tar.Z 压缩
$ tar -cZf txt.tar.Z *.txt # 失败 
tar -xZvf file.tar.Z   //解压tar.Z

4) rar 压缩
$ rar a jpg.rar *.jpg //rar格式的压缩，需要先下载rar for linux
unrar e file.rar //解压rar


5) zip 压缩
$ zip jpg.zip *.jpg //zip格式的压缩
$ zip -r ys.zip hello.txt dir1 #文件 hello.txt和一个目录dir1压缩成为 ys.zip

$ unzip file.zip //解压zip






3. 按列表查找 

.tar.gz 
解压：tar zxvf FileName.tar.gz 
压缩：tar zcvf FileName.tar.gz DirName 
############################################# 
.bz2 
解压1：bzip2 -d FileName.bz2 
解压2：bunzip2 FileName.bz2 
压缩： bzip2 -z FileName 
.tar.bz2 
解压：tar jxvf FileName.tar.bz2 
压缩：tar jcvf FileName.tar.bz2 DirName 
############################################# 
.bz 
解压1：bzip2 -d FileName.bz 
解压2：bunzip2 FileName.bz 
压缩：未知 
.tar.bz 
解压：tar jxvf FileName.tar.bz 
压缩：未知 
############################################# 
.Z 
解压：uncompress FileName.Z 
压缩：compress FileName 
.tar.Z 
解压：tar Zxvf FileName.tar.Z 
压缩：tar Zcvf FileName.tar.Z DirName 
#############################################
.tgz 
解压：tar zxvf FileName.tgz 
压缩：未知 
.tar.tgz 
解压：tar zxvf FileName.tar.tgz 
压缩：tar zcvf FileName.tar.tgz FileName 
#############################################
.zip 
解压：unzip FileName.zip 
压缩：zip FileName.zip DirName 
#############################################
.rar 
解压：rar a FileName.rar 
压缩：r ar e FileName.rar







========================================
|-- 一个大型文件夹的传输：打包压缩成少量 x01.tar.gz 文件，传输后再解压缩
----------------------------------------
零碎文件的网络传输是最慢的！
所以最好打包压缩，然后再网络传输，最后再解压缩回复原文件夹。


1. 测试：一个文件夹下的文件，分别压缩后解压会到一个文件夹吗？会。
$ cd /home/wang
$ tree /home/wang/test
/home/wang/test
├── log1.txt
├── log2.txt
└── mylogs
    ├── 1.txt
    ├── today
    └── yestoday


压缩为2个文件夹: 可以对目录的内容自由组合压缩，也可以分别压缩每个子文件夹。
$ tar zcvf a01.tar.gz test/log1.txt test/mylogs/1.txt
$ tar zcvf a02.tar.gz test/log2.txt test/mylogs/today test/mylogs/yestoday


查看 tar.gz 压缩包中的文件结构：
$ tar ztvf /home/wang/a02.tar.gz
-rw-rw-r-- wang/wang        21 2024-04-20 13:56 test/log2.txt
drwxr-xr-x wang/wang         0 2024-04-20 15:40 test/mylogs/today/
drwxr-xr-x wang/wang         0 2024-04-20 14:00 test/mylogs/yestoday/

接着通过scp传输: $ scp xx.tar.gz user@ip:/abs/path/to/dest/dir/


在目标机器上，进入新文件夹解压缩：
$ cd /home/wang/test2
$ tar zxvf /home/wang/a01.tar.gz
$ tar zxvf /home/wang/a02.tar.gz


又恢复到原始文件结构，文件展开是相对于执行解压缩命令的位置：
$ pwd
/home/wang/test2
$ tree
.
└── test
    ├── log1.txt
    ├── log2.txt
    └── mylogs
        ├── 1.txt
        ├── today
        └── yestoday
#end







ref:
http://blog.csdn.net/dunyanan1/article/details/38869059
https://blog.csdn.net/rong_toa/article/details/80228079
https://www.cnblogs.com/heian99/p/11972339.html




========================================
|-- 多线程 压缩 与解压 pigz
----------------------------------------
1. 
(1)安装
wget http://zlib.net/pigz/pigz-2.4.tar.gz
tar -xvzf pigz-2.4.tar.gz 
cd pigz-2.4
make


(2) 压缩 
gzip -c test.fq > test.fq.gz

# 注意-p一定要写下前面，后面无效
$ time pigz -k -p 32 test.fq
$ time pigz -k -p 8 test.fq

-p 表示线程数，别人测试发现超过32个就又变慢了。

-c 表示打印到标准输出std，如果没有-c选项，则会生成一个后缀为gz的压缩文件。
$ pigz -c file > file.gz

-k 表示压缩后不删除源文件
$ pigz -k file

–blocksize mmm 设置压缩块block的大小，默认为128kb
-0 to -9, -11设置压缩水平，值越大，压缩率越高，当然耗费的时间也就越长


(3) 解压 
gunzip test.fq.gz

$ time unpigz -p 32 test.fq.gz
$ time unpigz -p 8 test.fq.gz








ref: http://blog.sciencenet.cn/blog-3334560-1131099.html






========================================
|-- Linux的五个查找命令: which/whereis/whatis/locate/find, type/grep
----------------------------------------
Linux系统一切皆文件。linux的文件查找功能真的很强大，掌握如下命令，有助于你快速找到想要查找的目标文件。

1.which
2.whereis
3.whatis
4.locate
5.find
6.type和grep

先看man，熟悉该命令的解释。

1.which - locate a command
在PATH变量指定的路径中搜索命令的位置，并返回第一个搜到的结果。
$ which grep
/bin/grep

$ which python
/home/wangjl/anaconda3/bin/python





2.whereis - locate the binary, source, and manual page files for a command
只能用于程序名的搜索
参数信息：
 -b：只查找二进制binaries文件； 
 -m：只查找说明manuals文件；
 -s：只查找原始代码sources文件；
 -B<目录>：只在设置的目录下查找二进制文件；
 -M<目录>：只在设置的目录下查找说明文件；
 -S<目录>只在设置的目录下查找原始代码文件；

 -f：不显示文件名前的路径名称；It must be used when any of the -B, -M, or -S  option is used.
 -u：查找不包含指定类型的文件。

如果省略参数，则返回所有信息。

$ whereis grep
grep: /bin/grep /usr/share/man/man1/grep.1.gz /usr/share/info/grep.info.gz

$ whereis -m python
python: /usr/share/man/man1/python.1.gz





3.whatis - display one-line manual page descriptions
whatis 命令相当于 man -f 命令

$ whatis grep
grep (1)             - print lines matching a pattern

$ whatis python
python (1)           - an interpreted, interactive, object-oriented programming language




4.locate - find files by name
locate命令和slocate命令都用来查找文件或目录。
用法：locate (选项)
	locate [OPTION]... PATTERN...
参数
-d<目录>或--database=<目录>：指定数据库所在的目录； 

查找locate用以快速查找文件、文件夹
	locate keyword
此命令在数据库中查找文件等，对于新建立的文件，需要立即手工更新数据库，
	updatedb



locate命令其实是find -name的另一种写法，但是locate要比后者快得多，原因在于它不搜索具体目录，而是搜索一个数据库/var/lib/locatedb，这个数据库中含有本地所有文件信息。

如果报错说mlocate.db没有找到，则需要updatedb命令重新创建该/var/lib/locatedb数据库。
而该数据库每天更新一次，所以使用locate差找不到最新变动过的文件。
查之前建议先updatedb一下，需要root权限。
$ locate aa.txt
/data/wangjl/test/aa.txt





5.find - search for files in a directory hierarchy[极其重要]
下文有find命令简介。
更详细的find见 字符处理 专题。



6.type和grep
type命令用来显示指定命令的类型，判断给出的指令是内部指令还是外部指令
$ type grep
grep is aliased to `grep --color=auto'



如果查找文件内容，则需要配合grep了。
$ grep 'find' *txt #则txt文档中包含find的行都显示出来了。

查找某目录下包含关键字内容的文件，带高亮显示
格式: grep -r "{关键字}"  {路径}
## -r, --recursive
$ grep -r '查找' . --color=auto 

更详细的grep见 字符处理 专题。


refer:
https://blog.csdn.net/z_xiao_xue/article/details/53925680





========================================
|-- find命令简介 - 在指定目录下查找文件
----------------------------------------
命令find高级查找文件、文件夹
	find 查找位置 查找参数
	find <path> <expression> <cmd>
如 -name  -perm  -user  -group  -ctime  -type  -size
	find . -name *linux*  	# . 当前文件
	find / -name *.conf		# / 根目录
	find / -perm 777	#权限为777的文件
	find / -type d 查找目录类型
	find . -name "a*" -exec ls -l {} \;  #固定格式


1.在当前目录下，查找txt文件：
find . -name "*.txt" -print



2.不显示报错信息（如权限不够等）
$ find / -name '*hg19*Gene*' 2>/dev/null |grep 'hg19'



3.指定文件的时间

在当前目录下，查找十一放假期间创建的txt文件：
find . -name "*.txt"  -newermt '2026-10-01' ! -newermt '2026-10-08' -print



4. 限制文件大小

查找小于20k的文件
$ find / -size -20k -name "movie030.png" 2>/dev/null |grep -v "movie"

查找根目录下，文件大小大于1G的文件，并显示大小。
$ find / -size +1G | xargs du -sh

查看大小为525的文件，并列出来
$ find molportnp/ -size -526c -size +524c |xargs ls -lth |head





========================================
|-- Linux下批量修改文件名(rename)
----------------------------------------
Linux的 rename 命令有两个版本(C语言和Perl语言)，早期的Linux发行版基本上使用的是C语言版本，现在系统几乎都是Perl语言版本了(支持正则处理，功能更强大)
后文重点说perl版本的rename的用法。


1. centOS是util-linux命令。
rename [options] <expression> <replacement> <file...>
rename from to files 把文件名中的from改为to

1)rename命令批量修改文件名
$ rename 'mef-COL' 'c' *fastq #mef-COL03_R2.fastq 变成了 c03_R2.fastq




2. Ubuntu则是perl命令。
三种形式[2]
匹配：m//  (可以省略m，直接写成/regexp/)
替换：s/// 
转化：tr///　



$ rename 's/\.txt/\.ext/' * #替换后缀名.txt为.ext









perl版rename: 
https://www.cnblogs.com/AloneSword/p/5072698.html
https://www.cnblogs.com/dingbj/p/10089686.html







========================================
传输文件、下载文件
----------------------------------------





========================================
|-- wget 强大的下载命令
----------------------------------------

(1). wget 常用指令
下载单个文件：wget http://www.baidu.com。命令会直接在当前目录下载一个index.html的文件

-O 将下载的文件存放到指定的文件夹下，同时重命名下载的文件：wget -O /home/index2.html http://www.baidu.com

-P 指定目录 下载地址: wget -P ./ https://www.baidu.com

-i 下载文件列表。用于下载多个文件。
	首先，创建一个file.txt文件，写入两个url(换行)，如http://www.baidu.com;
	然后，wget -i file.txt;命令执行后会下载两个两个文件。

-b 后台下载：wget -b http://www.baidu.com
	命令执行后会，下载的详细信息不会显示在终端，会在当前目录下生成一个web-log记录下载的详细信息。

-o 指定log文件。下载时，不显示详细信息，同时将下载信息保存到执行的文件中(同4)：wget -o dw.txt http://www.baidu.com

-c 断点续传：wget -c http://www.baidu.com



(2) 设置下载的限制条件

限制下载的的速度：wget --limit-rate=100k -O zfj.html http://www.baidu.com

测试是否能正常访问：wget --spider http://www.baidu.com

设置下载重试的次数：wget --tries=3 http://www.baidu.com

从指定网站中下载所有指定类型的文件：wget -r -A .png http://www.baidu.com

多文件下载中拒绝下载超过设置大小的文件：wget -Q5m -i file.txt
	注意：此选项只能在下载多个文件时有用，当你下载一个文件时没用。


wget下载 https 时，某些资源必须使用--no-check-certificate http://www.baidu.com

使用wget实现FTP下载：wget --file-user=USERNAME --file-password=PASSWORD url



(3) 下载一个完整的网站，即当前页面所依赖的所有文件：
$ wget --mirror -p --convert-links -P./test http://localhost

--mirror:打开镜像选项
-p:下载所有用于显示给定网址所必须的文件
--convert-links：下载以后，转换链接用于本地显示
-P LOCAL_DIR：保存所有的文件或目录到指定的目录下

下载的过程中拒绝下载指定类型的文件:wget --reject=png --mirror -p --convert-links -P./test http://localhost








========================================
|-- Axel - 多线程下载命令
----------------------------------------
1.简介 
Axel 是 Linux 下一个不错的HTTP/FTP高速下载工具。支持多线程下载、断点续传，且可以从多个地址或者从一个地址的多个连接来下载同一个文件。适合网速不给力时多线程下载提高下载速度。比如在国内VPS或服务器上下载lnmp一键安装包用Axel就比wget快。


2.安装
ubuntu: apt-get install axel

CentOS下安装axel
http://axel.alioth.debian.org
1).下载
失效链接 http://alioth.debian.org/frs/download.php/3015/axel-2.4.tar.gz
wget http://www.ha97.com/code/axel-2.4.tar.gz

2).解压
tar zxvf axel-2.4.tar.gz
cd axel-2.4
./configure
make
make install


3.Axel命令使用方法：axel 参数 文件下载地址
可选参数：
	-n 指定线程数
	-o 指定另存为目录
	-s 指定每秒的最大比特数
	-q 静默模式

如从Diahosting下载lnmp安装包指定10个线程，存到/tmp/：
axel -n 10 -o /tmp/ http://soft.vpser.net/lnmp/lnmp0.7-full.tar.gz

#不要使用3线程，直接用10-50线程。就是快。
axel -n 10 https://cran.rstudio.com/bin/windows/contrib/3.4/maptools_0.9-2.zip
axel -n 30 https://cran.rstudio.com/bin/windows/contrib/3.4/sp_1.2-5.zip 

如果下载过程中下载中断，可以再执行下载命令即可恢复上次的下载进度。

refer:
http://www.cnweed.com/4048.html





========================================
|-- ftp/sftp /lftp命令：传输文件
----------------------------------------
步骤 1: 建立 FTP 连接
想要连接 FTP 服务器，在命令上中先输入ftp然后空格跟上 FTP 服务器的域名 'domain.com' 或者 IP 地址
例如:
ftp domain.com
ftp 192.168.0.1
ftp user@ftpdomain.com

或者使用sftp，直接进入第三步：
~$ sftp wangcc@192.168.1.114


步骤 2: 使用用户名密码登录
绝大多数的 FTP 服务器是使用密码保护的，因此这些 FTP 服务器会询问'username'和'password'.

如果你连接到被称作匿名 FTP 服务器（LCTT 译注：即，并不需要你有真实的用户信息即可使用的 FTP 服务器称之为匿名 FTP 服务器），可以尝试anonymous作为用户名以及使用空密码：

Name: anonymous
Password:
之后，终端会返回如下的信息：

230Login successful.
Remote system type is UNIX.
Using binary mode to transfer files.
ftp>

步骤 3: 目录操作
FTP 命令可以列出、移动和创建文件夹，如同我们在本地使用我们的电脑一样。ls可以打印目录列表，cd可以改变目录，mkdir可以创建文件夹。
可以使用的命令：ls, pwd, cd Downloads/
使用help查看帮助。

步骤 4: 下载文件
我们可以使用命令 get 来下载文件，比如：
sftp> get natapp
Fetching /home/wangcc/Downloads/natapp to natapp
/home/wangcc/Downloads/natapp                 100% 6934KB   6.8MB/s   00:00

下载多个文件可以使用通配符及 mget 命令。例如，下面这个例子我打算下载所有以 .xls 结尾的文件。
mget *.xls



步骤 5: 使用 FTP 上传文件
完成 FTP 连接后，FTP 同样可以上传文件

使用 put命令上传文件：
put file

当文件不再当前本地目录下的时候，可以使用绝对路径：
put /path/file

同样，可以上传多个文件：
mput *.xls


步骤 6: 关闭 FTP 连接
完成FTP工作后，为了安全起见需要关闭连接。有三个命令可以关闭连接：
bye
exit
quit

需要更多帮助，在使用 ftp 命令连接到服务器后，可以使用help获得更多帮助。

http://www.linuxidc.com/Linux/2015-12/126357.htm









2. lftp 是 NCBI GEO 推荐的上传工具。
“For LINUX/UNIX users, we recommend transferring files with 'ncftp' or 'lftp', but you can also use 'ftp', 'sftp', or 'ncftpput'. Please see below for detailed examples.”

http://lftp.yar.ru/lftp-man.html


(1)安装 
http://lftp.yar.ru/
$ wget http://lftp.yar.ru/ftp/lftp-4.9.2.tar.gz
$ tar zxvf lftp-4.9.2.tar.gz 
$ cd lftp-4.9.2
查看帮助
$ ./configure --help
--prefix=PREFIX         install architecture-independent files in PREFIX
                          [/usr/local]
$ ./configure --prefix=/home/wangjl/
$ make 
$ make install

## check
$ ls /home/wangjl/bin | grep ftp
$ lftp --version
LFTP | Version 4.9.2 




(2)登录ftp
lftp 用户名:密码@ftp地址:传送端口（默认21）
也可以先不带用户名登录，然后在接口界面下用login命令来用指定账号登录，密码不显示。


(3)查看文件与改变目录
ls
cd 对应ftp目录


(4)下载
get当然是可以的，还可以：
mget -c *.pdf    #把所有的pdf文件以允许断点续传的方式下载。
mirror aaa/      #将aaa目录整个的下载下来，子目录也会自动复制。
pget -c -n 10 file.dat   #以最多10个线程以允许断点续传的方式下载file.dat，可以通过设置pget:default-n的值而使用默认值。



(5)上传
同样的put、mput都是对文件的操作，和下载类似。

mirror -R 本地目录名
将本地目录以迭代（包括子目录）的方式反向上传到ftp site。




(6)模式设置

set ftp:charset gbk
远程ftp site用gbk编码，对应的要设置为utf8,只要替换gbk为utf8即可。

set file:charset utf8
本地的charset设定为utf8,如果你是gbk，相应改掉。

set ftp:passive-mode 1
使用被动模式登录，有些site要求必须用被动模式或者主动模式才可以登录，这个开关就是设置这个的。0代表不用被动模式。



(7)书签

其实命令行也可以有书签，在lftp终端提示符下：

bookmark add ustc
就可以把当前正在浏览的ftp site用ustc作为标签储存起来。以后在shell终端下，直接lftp ustc就可以自动填好用户名和密码，进入对应的目录了。

bookmark edit
会调用编辑器手动修改书签。当然，也可以看到，这个书签其实就是个简单的文本文件。密码，用户名都可以看到。




(8) 配置文件

vim /etc/lftp.conf
一般，我会添加这几行：

set ftp:charset gbk
set file:charset utf8
set pget:default-n 5

这样，就不用每次进入都要打命令了。其他的set可以自己tab然后help来看。








========================================
|-- ifconfig 获取 IP 地址
----------------------------------------

$ yum install net-tools
可以使用 ifconfig

$ ifconfig




========================================
|-- linux 之间文件传输 Secure copy protocol (SCP) 
----------------------------------------
SCP ：secure copy (remote file copy program) 也是一个基于SSH安全协议的文件传输命令。与sftp不同的是，它只提供主机间的文件传输功能，没有文件管理的功能。 

1. 本地 to 远程
1)复制local_file 到远程目录remote_folder下 
scp local_file remote_user@host:remote_folder 

2)复制local_folder 到远程remote_folder（需要加参数 -r 递归） 
scp –r local_folder remote_user@host:remote_folder 


$ scp -r /home/wangjl/data/apa/191111Figure/f3/apaTracks wangjl@y.biomooc.com:/home/wangjl/igv/
输入密码后，远程文件夹内就多了个文件夹。





2. 远程 to 本地
以上命令反过来写就是远程复制到本地

1)复制 远程 remote_folder 到本地目录 local_file 下 
scp remote_user@host:remote_folder   local_file 

2)复制 远程 remote_folder 到 本地 local_file （需要加参数 -r 递归） 
scp –r remote_user@host:remote_folder  local_folder 




3. 报错与原因
(1) protocol error: mtime.sec not present
原因： 可能是 bashrc 中有echo语句，删掉或注释掉就可以了。
检查方式: $ bash ~/.bashrc 如果有输出，则肯定有echo语句。







========================================
|-- windows与linux互相拷贝文件: pscp
----------------------------------------
1.下载 git 即可在git bash中使用该命令
我win10上安装的也有putty。
$ pscp
PuTTY Secure Copy client
Release 0.70
Usage: pscp [options] [user@]host:source target
       pscp [options] source [source...] [user@]host:target
       pscp [options] -ls [user@]host:filespec
Options:
  -V        print version information and exit
  -pgpfp    print PGP key fingerprints and exit
  -p        preserve file attributes
  -q        quiet, don't show statistics
  -r        copy directories recursively
  -v        show verbose messages
  -load sessname  Load settings from saved session
  -P port   connect to specified port
  -l user   connect with specified username
  -pw passw login with specified password
  -1 -2     force use of particular SSH protocol version
  -4 -6     force use of IPv4 or IPv6
  -C        enable compression
  -i key    private key file for user authentication
  -noagent  disable use of Pageant
  -agent    enable use of Pageant
  -hostkey aa:bb:cc:...
            manually specify a host key (may be repeated)
  -batch    disable all interactive prompts
  -proxycmd command
            use 'command' as local proxy
  -unsafe   allow server-side wildcards (DANGEROUS)
  -sftp     force use of SFTP protocol
  -scp      force use of SCP protocol
  -sshlog file
  -sshrawlog file
            log protocol details to a file
#




2. 使用方法
命令格式：        pscp localfile rootuser@remoteip:/fileDirectory
拷贝整个文件夹：  pscp -r localDir rootuser@remoteip:/fileDirectory
如果是从linux拷贝文件，是同样的方法，只不过是把前后地址对换一下即可；
#

(1) 比如我想把windows下e:\dir1 整个目录的所有文件复制到linux /home/wangjl/test 目录下，命令如下：
pscp -r -l root -pw 123456 e:/dir1 192.168.0.204:/home/wangjl/test

说明：
-r 复制目录下所有文件；
-l 对方机器(linux)的用户名(root)；
-pw 密码；
e:/dir1 源文件/文件夹的地址； 注意使用/而不是\，否则报错。
192.168.0.204:/root 目的文件/文件夹的地址。192.168.0.204为linux机器的ip地址。


1) 会把文件夹一起上传 /data4/wangjl/shenda/result2/xx.txt
pscp -r -l wangjl -pw q123456 F:/TAM-zhangm/result2 10.20.57.27:/data4/wangjl/shenda/
2) 加斜线则不带文件夹 /data4/wangjl/shenda/xx.txt
pscp -r -l wangjl -pw q123456 F:/TAM-zhangm/result2/ 10.20.57.27:/data4/wangjl/shenda/


(2)反过来，把linux soundRcg目录下的test.txt文件传输到windows e:\下，同样在windows命令行中敲入命令：
pscp -l root -pw 123456 192.168.0.204:/soundRcg/test.txt E:\
#






3.实例: 测序结果从移动硬盘cp到server。
我感觉文件名可能也很重要，想保存完整信息，dir末尾不带/，把本地文件夹名字一起上传了
$ pscp -r -l wangjl -pw 123456 E:/F20FTSNCWLJ0507-01_WENmzkR 10.20.57.27:/data4/wangjl/shenda/

特别大的文件，要防止win自动休眠导致中断: win10搜索 设置，然后设置中搜索 锁屏，然后找到电源选项，睡眠 选择 从不。


server disk: 
Filesystem  Size  Used Avail Use% Mounted on
/dev/sde1   73T   63T  6.3T  91% /data4 #复制刚开始 2020-7-27 10:23


## 过程和细节:
A1_S1_L001_R1_001.fastq.g | 11847824 kB | 11230.2 kB/s | ETA: 00:00:00 | 100% (10:37 第一个文件上传结束)


##14 directories, 97 files
一个文件: 11M/s, 11.2e3/11/60=17min; 则14个文件夹*2*17/60=7.9h; 大概到 18:23 结束。
## 总大小 573GB
573*1024/(11237/1024)/60/60 =14.85 h 以这个为准，因为fq文件大小波动很大。 大概会
10:23+14=24:23; 23+60*0.85=74min=1:14min; 则会到次日 1:37 结束;




太慢了!
还是直接挂载到机器上拷贝吧。


========================================
|-- 挂载win格式的硬盘到Centos上
----------------------------------------
(1)
$ sudo fdisk -l
## 经过排查大小，找到位置 /dev/sdf
WARNING: fdisk GPT support is currently new, and therefore in an experimental phase. Use at your own discretion.

Disk /dev/sdf: 4000.8 GB, 4000752599040 bytes, 7813969920 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 4096 bytes
I/O size (minimum/optimal): 4096 bytes / 4096 bytes
Disk label type: gpt
Disk identifier: 64B420B9-1FE7-47B4-B8D5-75EDD0571983

#         Start          End    Size  Type            Name
 1         2048   7813967871    3.7T  Microsoft basic Elements SE
#


(2)
$ sudo parted /dev/sdf print
Model: WD Elements SE 2622 (scsi)
Disk /dev/sdf: 4001GB
Sector size (logical/physical): 512B/4096B
Partition Table: gpt
Disk Flags: 

Number  Start   End     Size    File system  Name         Flags
 1      1049kB  4001GB  4001GB  ntfs         Elements SE
#

注意使用的是最小单元，要加上最后几行的Number，也就是/dev/sdf1


(3) 挂载到文件系统上。
wget http://tuxera.com/opensource/ntfs-3g_ntfsprogs-2013.1.13.tgz //下载ntfs包，如果下载
tar -zxvf  ntfs-3g_ntfsprogs-2013.1.13.tgz
cd  ntfs-3g_ntfsprogs-2013.1.13
./configure
make
make install //这一步需要管理员权限


$ sudo mkdir /media/se
$ sudo mount  -t ntfs-3g /dev/sdf1 /media/se
##  -t ntfs 报错 mount: unknown filesystem type 'ntfs'

查看挂载效果
$ df -h
## /dev/sdf1                   3.7T  574G  3.1T  16% /media/se

(4)查看文件
$ ls /media/se


$ cp /media/se/F20FTSNCWLJ0507-01_WENmzkR .



-rwxr-xr-x. 1 wangjl user 8504868864 Jul 27 12:21 A1_S1_L001_R1_001.fastq.gz
-rwxr-xr-x. 1 wangjl user 8567914496 Jul 27 12:21 A1_S1_L001_R1_001.fastq.gz
大概有 60.125M/s


大概2h结束。
第一个文件 12:23
最后一个文件 # 17:23
Filesystem  Size  Used Avail Use% Mounted on
/dev/sde1    73T   63T  6.3T  91% /data4 #之前
/dev/sde1    73T   64T  5.7T  92% /data4 #之后


(4) 卸载
$ sudo umount /media/se



========================================
|-- linux中校验文件完整性、一致性(md5sum, sha1sum, sha256sum)
----------------------------------------
常用命令：
1. 对某一类文件全部生成md5码
$ ls *.fastq |xargs md5sum >md5sum.txt

2.使用md5sum递归生成整个目录的sum
find ./ -type f -print0 | xargs -0 md5sum > my.md5  #生成
md5sum -c my.md5 #核查






经常在Linux下下载软件的人，一定会有一个良好的习惯：校验文件的hash，以确定文件的完整性甚至是安全性。

md5sum命令用于生成和校验文件的md5值。它会逐位对文件的内容进行校验。是文件的内容，与文件名无关，也就是文件内容相同，其md5值相同。md5值是一个128位的二进制数据，转换成16进制则是32（128/4）位的进制值。

md5校验，有很小的概率不同的文件生成的md5可能相同。比md5更安全的校验算法还有SHA*系列的(sha1sum fileName)。

在网络传输时，我们校验源文件获得其md5sum，传输完毕后，校验其目标文件，并对比如果源文件和目标文件md5 一致的话，则表示文件传输无异常。否则说明文件在传输过程中未正确传输。


特殊说明
1）md5sum 是校验文件内容，与文件名是否相同无关
2）md5sum值逐位校验，所以文件越大，校验时间越长。
总结: 通过md5sum来校验生成文件校验码，来发现文件传输（网络传输、复制、本地不同设备间的传输）异常造成的文件内容不一致的情况。




1.MD5校验：
$ md5sum lnmp1.3-full.tar.gz
a5aa55cd177cd9b9176ad697c12e45c0  lnmp1.3-full.tar.gz

或者我们可以保存到一个文件中：
$ md5sum lnmp1.3-full.tar.gz > md5-hash.txt
然后查看：
$ cat md5-hash.txt
a5aa55cd177cd9b9176ad697c12e45c0  lnmp1.3-full.tar.gz

还可以根据已经得到的hash来确认文件：
$ md5sum -c md5-hash.txt
lnmp1.3-full.tar.gz: OK
	-c, --check          read MD5 sums from the FILEs and check them

2.SHA1校验，类似于md5校验，只是命令换成了 sha1sum

(2) 新一代使用 sha256sum 校验
$ sha256sum rstudio-server-rhel-2023.12.1-402-x86_64.rpm 
6684f8f2015a89dd8598fbfbe7ef6885990ef4ad7d269aded3ca527aa5daa263  rstudio-server-rhel-2023.12.1-402-x86_64.rpm


3.注意事项：在已知hash数值情况下对文件进行校验的时候要注意，一定要让系统能够找到要校验的文件。否则就没法进行校验了。
具体的使用说明，可以通过md5(sha1)sum --help来查看



refer:
https://www.cnblogs.com/zhuxiaohou110908/p/5786893.html






========================================
|-- linux中对 不定深度的文件夹/目录 内所有文件 校验md5值的方法
----------------------------------------
情景：复制后担心对不上，可以逐个文件进行校验。


1. 源文件夹内生成校验文件
$ find ./ -type f -print0 | xargs -0 md5sum >md5.txt

这里的重点就是find ./ -type f -print0 | xargs -0，平时很少用到该方法

find -print0表示在find的每一个结果之后加一个NULL字符，而不是默认加一个换行符。find的默认在每一个结果后加一个'\n'，所以输出结果是一行一行的。
当使用了-print0之后，就变成一行了。然后xargs -0表示xargs用NULL来作为分隔符。这样前后搭配就不会出现空格和换行符的错误了

注：平时真没有注意有-print0的这个功能，mark一下。

实例:
$ find ref/ -type f -print0 | xargs -0 md5sum > md5.txt
$ cat md5.txt
aa212708bb02a173b52d1fb9d05463ce  ref/GRCm39/gencode/GRCm39.genome.fa.gz
09398d7d93c2be3aea2cf8d7e857ecc7  ref/GRCm39/gencode/GRCm39.M31.gtf.gz
4c462d1e6e9c35140adc3213d556a636  ref/GRCm39/gencode/gencode.vM31.metadata.MGI.gz
665dc0e2762cc39b3d1d29134a45d5ce  ref/hg38/polyA_DB/hg38.PolyADB3-liftover.bed
ce0d977bbeecc1afde01c7ebdd9fa2dd  ref/hg38/polyA_DB/hg38.PolyADB2-liftover.bed
a1b9a1d6005e7cbbbac416151e6dc361  ref/hg38/polyA_DB/human.PAS.txt

简化：测试表明，这样也是一样的结果
$ find ref/ -type f | xargs md5sum > md5.txt
aa212708bb02a173b52d1fb9d05463ce  ref/GRCm39/gencode/GRCm39.genome.fa.gz
09398d7d93c2be3aea2cf8d7e857ecc7  ref/GRCm39/gencode/GRCm39.M31.gtf.gz
4c462d1e6e9c35140adc3213d556a636  ref/GRCm39/gencode/gencode.vM31.metadata.MGI.gz
665dc0e2762cc39b3d1d29134a45d5ce  ref/hg38/polyA_DB/hg38.PolyADB3-liftover.bed
ce0d977bbeecc1afde01c7ebdd9fa2dd  ref/hg38/polyA_DB/hg38.PolyADB2-liftover.bed
a1b9a1d6005e7cbbbac416151e6dc361  ref/hg38/polyA_DB/human.PAS.txt




2. 验证文件是否有变，我们可以用
$ md5sum -c md5.txt | grep -i failed
只要没有failed，就表示文件没有被篡改。

实例: 
$ md5sum -c md5.txt | grep -i failed
$





ref: https://blog.csdn.net/pl2851802/article/details/134826389









========================================
|-- Linux的sz(下载)和rz(上传)命令
----------------------------------------

工作中需要在Linux和Windows之间传输文件时，一般使用winscp或者ftp工具来完成，最近才知道有sz和rz这两个命令，方便好用。

运行命令rz、sz要比FTP容易很多，而且服务器不需要另开FTP服务即可完成。
sz：将选定的文件发送（send）到本地机器
rz：运行该命令会弹出一个文件选择窗口，从本地选择文件上传到服务器(receive)
rz，sz是便是Linux/Unix同Windows进行ZModem文件传输的命令行工具，windows端需要支持ZModem的telnet/ssh客户端（比如SecureCRT）。

注意：该方法的传输速度比较慢，推荐使用中小文件的传输。


1. sz 下载
从Linux下载文件到本机 , 在Linux终端输入命令回车后，选择本地存储路径即可。

命令格式：
sz filename   下载文件filename
sz file1 file2   下载多个文件
sz dir/*　　　下载dir目录下所有文件



2. rz 上传
从本地上传文件到Linux，在Linux终端输入命令回车后，选择本地要上传的文件即可，可一次指定多个文件

命令格式：    rz
上传到服务器的路径为当前执行rz命令的目录。


注意：
(1).如果机器上没有安装过 lrzsz 安装包，则无法使用rz和sz命令。
　可使用yum命令安装：yum install -y lrzsz
  或者下载源码进行安装。下载地址：https://ohse.de/uwe/software/lrzsz.html
(2).上传和下载都默认使用Linux当前登录的用户，使用时要根据个人需要修改文件的权限。




========================================
文件同步命令 rsync: "远程同步"(remote sync): 推荐代替 cp 命令
----------------------------------------
实例: To transfer from outside the Prince cluster
from: https://learn.gencore.bio.nyu.edu/jbrowse-visualizing-data-quickly-easily/
# Transfer the files
rsync --progress -ruv /path/to/dataset/ \ 
     <NYUnetID>@jbrowse.bio.nyu.edu:/jbrowse/<PI>/<DATASET>
# Build and publish the tracks based on the files uploaded
ssh <NYUnetID>@jbrowse.bio.nyu.edu addTracks --PI <PI> --dataset <DATASET>
参数解释:
--progress 显示进度条
-r, --recursive		recurse into directories
-u, --update		skip files that are newer on the receiver
-v, --verbose		increase verbosity



$ rsync -avP fromDir toDir;
--partial               keep partially transferred files 保留部分转移的文件：实现断点续传
--progress              show progress during transfer  看文件转移过程：显示进度条
-P                      same as --partial --progress
--exclude='.git' 这个参数也非常有用，作用是排除匹配模式的文件



$ rsync -avz /var/lib/docker /picb/jinlab/docker_root/
	从位置 /var/lib/docker 拷贝到 /picb/jinlab/docker_root/，后者会多一个 docker/ 文件夹
	-a 参数表示 保留 r(文件夹递归) l链接 p(权限) t(修改时间) g(组权限) o(所有者) D(设备?)
	-v 参数表示 显示详情
	-z 参数表示 传输过程中压缩
-z, --compress              compress file data during the transfer
	 --compress-level=NUM    explicitly set compression level
	 --skip-compress=LIST    skip compressing files with a suffix in LIST





1. 安装
注意，传输的双方都必须安装 rsync。

# Debian
$ sudo apt-get install rsync

# Red Hat
$ sudo yum install rsync



2. 本机使用 rsync 命令时，可以作为cp和mv命令的替代方法，将源目录同步到目标目录。
(1) -r 参数
$ rsync -r source destination
上面命令中，-r表示递归，即包含子目录。注意，-r是必须的，否则 rsync 运行不会成功。source目录表示源目录，destination表示目标目录。


如果有多个文件或目录需要同步，可以写成下面这样。
$ rsync -r source1 source2 destination



(2) -a 参数 功能最多，等价于 -rlptgoD
-a, --archive               archive mode; equals -rlptgoD (no -H,-A,-X)
    --no-OPTION             turn off an implied OPTION (e.g. --no-D)

包含
-l, --links                 copy symlinks as symlinks
-p, --perms                 preserve permissions
-t, --times                 preserve modification times
-g, --group                 preserve group
    --devices               preserve device files (super-user only)
    --copy-devices          copy device contents as regular file
    --specials              preserve special files
-D                          same as --devices --specials
-o, --owner                 preserve owner (super-user only)

不包含
-H, --hard-links            preserve hard links
-A, --acls                  preserve ACLs (implies --perms)
-X, --xattrs                preserve extended attributes



-a参数可以替代-r，除了可以递归同步以外，还可以同步元信息（比如修改时间、权限等）。由于 rsync 默认使用文件大小和修改时间决定文件是否需要更新，所以-a比-r更有用。下面的用法才是常见的写法。
$ rsync -a source destination


如果只想同步源目录source里面的内容到目标目录destination，则需要在源目录后面加上斜杠。
$ rsync -a source/ destination
上面命令执行后，source目录里面的内容，就都被复制到了destination目录里面，并不会在destination下面创建一个source子目录。








(3)-n 参数
如果不确定 rsync 执行后会产生什么结果，可以先用-n或--dry-run参数模拟执行的结果。
$ rsync -anv source/ destination
上面命令中，
-n参数模拟命令执行的结果，并不真的执行命令。
-v参数则是将结果输出到终端，这样就可以看到哪些内容会被同步。


(4) --delete 参数
默认情况下，rsync 只确保源目录的所有内容（明确排除的文件除外）都复制到目标目录。它不会使两个目录保持相同，并且不会删除文件。如果要使得目标目录成为源目录的镜像副本，则必须使用--delete参数，这将删除只存在于目标目录、不存在于源目录的文件。
$ rsync -av --delete source/ destination
上面命令中，--delete参数会使得destination成为source的一个镜像。



(5) --progress 参数
显示进度条










3. 排除文件
(1) --exclude 参数
有时，我们希望同步时排除某些文件或目录，这时可以用--exclude参数指定排除模式。
$ rsync -av --exclude='*.txt' source/ destination
# 或者
$ rsync -av --exclude '*.txt' source/ destination
上面命令排除了所有 TXT 文件。

注意，rsync 会同步以"点"开头的隐藏文件，如果要排除隐藏文件，可以这样写--exclude=".*"。


如果要排除某个目录里面的所有文件，但不希望排除目录本身，可以写成下面这样。
$ rsync -av --exclude 'dir1/*' source/ destination


多个排除模式，可以用多个--exclude参数。
$ rsync -av --exclude 'file1.txt' --exclude 'dir1/*' source/ destination


多个排除模式也可以利用 Bash 的大扩号的扩展功能，只用一个--exclude参数。
$ rsync -av --exclude={'file1.txt','dir1/*'} source/ destination


如果排除模式很多，可以将它们写入一个文件，每个模式一行，然后用--exclude-from参数指定这个文件。
$ rsync -av --exclude-from='exclude-file.txt' source/ destination



(2)include 参数
--include参数用来指定必须同步的文件模式，往往与--exclude结合使用。
$ rsync -av --include="*.txt" --exclude='*' source/ destination
上面命令指定同步时，排除所有文件，但是会包括 TXT 文件。








4. ssh协议 远程同步

(1)rsync 除了支持本地两个目录之间的同步，也支持远程同步。它可以将本地内容，同步到远程服务器。
$ rsync -av source/ username@remote_host:destination

也可以将远程内容同步到本地。

$ rsync -av username@remote_host:source/ destination
rsync 默认使用 SSH 进行远程登录和数据传输。


由于早期 rsync 不使用 SSH 协议，需要用-e参数指定协议，后来才改的。所以，下面-e ssh可以省略。
$ rsync -av -e ssh source/ user@remote_host:/destination
但是，如果 ssh 命令有附加的参数，则必须使用-e参数指定所要执行的 SSH 命令。

$ rsync -av -e 'ssh -p 2234' source/ user@remote_host:/destination
上面命令中，-e参数指定 SSH 使用2234端口。








5. rsync 协议
除了使用 SSH，如果另一台服务器安装并运行了 rsync 守护程序，则也可以用rsync://协议（默认端口873）进行传输。具体写法是服务器与目标目录之间使用双冒号分隔::。
$ rsync -av source/ 192.168.122.32::module/destination


注意，上面地址中的module并不是实际路径名，而是 rsync 守护程序指定的一个资源名，由管理员分配。
如果想知道 rsync 守护程序分配的所有 module 列表，可以执行下面命令。
$ rsync rsync://192.168.122.32


rsync 协议除了使用双冒号，也可以直接用rsync://协议指定地址。
$ rsync -av source/ rsync://192.168.122.32/module/destination







6. 增量备份
rsync 的最大特点就是它可以完成增量备份，也就是默认只复制有变动的文件。

除了源目录与目标目录直接比较，rsync 还支持使用基准目录，即将源目录与基准目录之间变动的部分，同步到目标目录。

具体做法是，第一次同步是全量备份，所有文件在基准目录里面同步一份。以后每一次同步都是增量备份，只同步源目录与基准目录之间有变动的部分，将这部分保存在一个新的目标目录。这个新的目标目录之中，也是包含所有文件，但实际上，只有那些变动过的文件是存在于该目录，其他没有变动的文件都是指向基准目录文件的硬链接。



--link-dest参数用来指定同步时的基准目录。
$ rsync -a --delete --link-dest /compare/path /source/path /target/path

上面命令中，--link-dest参数指定基准目录/compare/path，然后源目录/source/path跟基准目录进行比较，找出变动的文件，将它们拷贝到目标目录/target/path。
那些没变动的文件则会生成硬链接。这个命令的第一次备份时是全量备份，后面就都是增量备份了。



7. 实例
(1)定时备份
可以增加一个定时任务，闲时（比如每天凌晨3点）备份工作路径
$crontab -e
0 22 * * * rsync -av --delete /Directory1/ username@bak.server:/Directory2/
使得工作路径下的数据在每天都能有两份，就算实验室火灾或者电脑被锤也就损失不到一天的工作量。



(2)脚本实例
下面是一个脚本示例，备份用户的主目录。

#!/bin/bash
# A script to perform incremental backups using rsync

set -o errexit
set -o nounset
set -o pipefail

readonly SOURCE_DIR="${HOME}"
readonly BACKUP_DIR="/mnt/data/backups"
readonly DATETIME="$(date '+%Y-%m-%d_%H:%M:%S')"
readonly BACKUP_PATH="${BACKUP_DIR}/${DATETIME}"
readonly LATEST_LINK="${BACKUP_DIR}/latest"

mkdir -p "${BACKUP_DIR}"

rsync -av --delete \
  "${SOURCE_DIR}/" \
  --link-dest "${LATEST_LINK}" \
  --exclude=".cache" \
  "${BACKUP_PATH}"

rm -rf "${LATEST_LINK}"
ln -s "${BACKUP_PATH}" "${LATEST_LINK}"

上面脚本中，每一次同步都会生成一个新目录${BACKUP_DIR}/${DATETIME}，并将软链接${BACKUP_DIR}/latest指向这个目录。下一次备份时，就将${BACKUP_DIR}/latest作为基准目录，生成新的备份目录。最后，再将软链接${BACKUP_DIR}/latest指向新的备份目录。











ref:
http://www.ruanyifeng.com/blog/2020/08/rsync.html











========================================
|-- rsync 增量备份实战：备份和恢复
----------------------------------------
使用场景：每月备份一下自己的文件，防止服务器硬盘坏了，啥都找不到了。
准备：一个远程主机J，一个移动硬盘disk，一个插移动硬盘disk的linux机器Y。


1. 实例1：在远程机器J上，备份到远程机器J的另一个目录
准备：在~/testBackup/添加文件 vim a.txt，并随便添加内容。

## 相当于cp命令， -a可以递归、同步元数据（修改时间、权限等）
$ rsync -a ~/testBackup/ ~/temp/
## 检查目录 ls ~/temp/，发现已经有文件了。

## -v参数输出详细过程
$ rsync -av ~/testBackup/ ~/temp/
sending incremental file list

sent 74 bytes  received 12 bytes  172.00 bytes/sec
total size is 14  speedup is 0.16


## 如果有变动
$ mkdir vueJS
$ rsync -av ~/testBackup/ ~/temp/
sending incremental file list
./
vueJS/

sent 124 bytes  received 23 bytes  294.00 bytes/sec
total size is 14  speedup is 0.10







2. 实例2：在远程机器J上，备份到本地机器Y上

$ rsync -av ~/testBackup/ wangjl@y.biomooc.com:~/backupDemo/
Warning: Permanently added the ECDSA host key for IP address '10.20.16.180' to the list of known hosts.
wangjl@y.biomooc.com's password: 
sending incremental file list
./
a.txt
vueJS/

sent 185 bytes  received 46 bytes  15.93 bytes/sec
total size is 14  speedup is 0.06

# 在机器Y上检查 ls ~/backupDemo/ 发现已经有内容了。








3. 实例3：远程机器J上，增量备份到本地机器Y上。在本地Y上操作。
~/backupDemo/base/ 基础备份
~/backupDemo/01/ 备份时间点01
~/backupDemo/02/ 备份时间点02 实际使用时，可以使用年月日时间戳


(1) 第一次全量备份
$ rsync -av --delete wangjl@j.biomooc.com:~/testBackup/ ~/backupDemo/base/


(2) 增量备份
时间点01
$ rsync -av --delete --link-dest ~/backupDemo/base/ wangjl@j.biomooc.com:~/testBackup/ ~/backupDemo/01/ 
时间点02
$ rsync -av --delete --link-dest ~/backupDemo/base/ wangjl@j.biomooc.com:~/testBackup/ ~/backupDemo/02/ 
时间点03
$ rsync -av --delete --link-dest ~/backupDemo/base/ wangjl@j.biomooc.com:~/testBackup/ ~/backupDemo/03/ 
时间点04
$ rsync -av --delete --link-dest ~/backupDemo/base/ wangjl@j.biomooc.com:~/testBackup/ ~/backupDemo/04/ 


(3) 如果远程J坏了，怎么恢复呢？假设恢复到最新的结果04
$ rsync -av --delete ~/backupDemo/04/ wangjl@j.biomooc.com:~/testBackup/ 
sending incremental file list
./
vueJS/
vueJS/ReadMe.txt

sent 255 bytes  received 46 bytes  66.89 bytes/sec
total size is 60  speedup is 0.20


(4) 写成自动化脚本
$ cat backupMonthly.sh
#!/bin/bash
# A script to perform incremental backups using rsync

set -o errexit
set -o nounset
set -o pipefail

readonly SOURCE_DIR="wangjl@j.biomooc.com:~/testBackup/" #"~/data/"
readonly BACKUP_DIR="/home/wangjl/backupDemo" #"/mnt/data/backups"
readonly DATETIME="$(date '+%Y-%m-%d_%H:%M:%S')"
readonly BACKUP_PATH="${BACKUP_DIR}/${DATETIME}"
readonly LATEST_LINK="${BACKUP_DIR}/latest"

mkdir -p "${BACKUP_DIR}"

rsync -av --delete \
  "${SOURCE_DIR}/" \
  --link-dest "${LATEST_LINK}" \
  --exclude=".cache" \
  "${BACKUP_PATH}"

rm -rf "${LATEST_LINK}"
ln -s "${BACKUP_PATH}" "${LATEST_LINK}"

上面脚本中，每一次同步都会生成一个新目录${BACKUP_DIR}/${DATETIME}，并将软链接${BACKUP_DIR}/latest指向这个目录。
下一次备份时，就将${BACKUP_DIR}/latest作为基准目录，生成新的备份目录。最后，再将软链接${BACKUP_DIR}/latest指向新的备份目录。


执行后：
$ bash backupMonthly.sh
wangjl@j.biomooc.com's password: 
receiving incremental file list
created directory /home/wangjl/backupDemo/2020-11-06_17:44:16
--link-dest arg does not exist: /home/wangjl/backupDemo/latest
./
a.txt
index.html
vueJS/
vueJS/ReadMe.txt

sent 108 bytes  received 367 bytes  135.71 bytes/sec
total size is 60  speedup is 0.13


修改一个文件a.txt+新增一个文件b.txt后，再次执行：
$ bash backupMonthly.sh 
wangjl@j.biomooc.com's password: 
receiving incremental file list
created directory /home/wangjl/backupDemo/2020-11-06_17:46:54
./
a.txt
b.txt

sent 85 bytes  received 334 bytes  119.71 bytes/sec
total size is 83  speedup is 0.20








========================================
|-- windows下的git bash 怎么使用rsync？最后用了cwRsync
----------------------------------------

1. [Windows Bash] Add Rsync to “Git Bash for Windows”
https://blog.tiger-workshop.com/add-rsync-to-git-bash-for-windows/
Tiger Fok在他的博客上告诉了我们一个非常好用的方法，
那就是使用pacman库中的rsync程序，里面i686代表32位系统，x86_64代表64位系统


In last few post we mentioned using bash in Windows by install Git.
It comes with handy *nix tools like grep, find, wget, curl, vim, ssh… but something still missing is rsync


Furthermore, cwRsync and DeltaCopy does not work in bash environment.


I decided to download the package from pacman repository.
http://www2.futureware.at/~nickoe/msys2-mirror/msys/x86_64/rsync-3.1.2-2-x86_64.pkg.tar.xz

Extract it using 7-zip and drop rsync.exe to C:\Program Files\Git\usr\bin and profit!

Likewise, you can find more *nix tools from pacman repository and install it manually.


(0) 任务

服务器目录 /home/wangjl/web/webPan.py
## 查文件大小
$ du -sh .
1.7M

增量备份到F:/testProject/



(1) linux上
下载页面: http://www2.futureware.at/~nickoe/msys2-mirror/msys/x86_64/
$ wget http://www2.futureware.at/~nickoe/msys2-mirror/msys/x86_64/rsync-3.2.3-1-x86_64.pkg.tar.zst

解压 https://cloud.tencent.com/developer/ask/172210
$ sudo apt-get install zstd
$ tar -I zstd -xvf rsync-3.2.3-1-x86_64.pkg.tar.zst
解压出一个文件夹usr/bin，找到其中的 rsync.exe

(2) win10提前安装git bash(https://git-scm.com/)
下载rsync.exe到win10的 D:\Program Files\Git\usr\bin 下。

(3) 尝试备份-失败
右键菜单中打开 git bash, 输入 
$ rsync -av --delete wangjl@y.biomooc.com:/home/wangjl/web/webPan.py F:/testProject/01/
报错：
D:/Program Files/Git/usr/bin/rsync.exe: error while loading shared libraries: msys-zstd-1.dll: cannot open shared object file: No such file or directory

可能缺少依赖
Cygwin(link is external) is a Linux-like environment for Windows. It consists of a DLL (cygwin1.dll), which emulates substantial Linux API functionality, and a collection of tools.






### >>> 解决依赖
1)如何下载到 msys-zstd-1.dll ?
在页面 https://packages.msys2.org/package/libzstd?repo=msys&variant=x86_64 点击链接下载
https://repo.msys2.org/msys/x86_64/libzstd-1.4.5-2-x86_64.pkg.tar.xz
2)还缺
D:/Program Files/Git/usr/bin/rsync.exe: error while loading shared libraries: msys-xxhash-0.8.0.dll: cannot open shared object file: No such file or directory
$ wget https://repo.msys2.org/msys/x86_64/libxxhash-0.8.0-1-x86_64.pkg.tar.zst
$ tar -I zstd -xvf libxxhash-0.8.0-1-x86_64.pkg.tar.zst

3)还缺 msys-lz4-1.dll: 
4)还缺 msys-crypto-1.1.dll: 

https://packages.msys2.org/package/
https://packages.msys2.org/package/rsync?repo=msys&variant=x86_64
https://repo.msys2.org/msys/x86_64/rsync-3.2.3-1-x86_64.pkg.tar.zst






(4) 其他尝试 都失败了
1) 安装 windows 子系统: 失败，没安上。
2) 尝试FreeFileSync
https://freefilesync.org/download.php
选择win安装后，怎么操作？
图形界面，有歧义，不好用。
3) "Using rsync from msysgit for binary files"
http://repo.msys2.org/msys/x86_64/

$ wget http://repo.msys2.org/msys/x86_64/rsync-3.2.2-1-x86_64.pkg.tar.zst
$ tar -I zstd -xvf rsync-3.2.2-1-x86_64.pkg.tar.zst
$ cd rsync-3.2.2
https://rsync.samba.org/


$ wget http://www2.futureware.at/~nickoe/msys2-mirror/mingw/x86_64/mingw-w64-x86_64-librsync-2.3.0-1-any.pkg.tar.xz
$ tar -xvJf mingw-w64-x86_64-librsync-2.3.0-1-any.pkg.tar.xz
$ ls mingw64/bin/
librsync.dll  rdiff.exe











2. 尝试 cwRsync
https://www.itefix.net/cwrsync
下载客户端 
https://itefix.net/dl/free-software/cwrsync_6.2.0_x64_free.zip
解压后使用cmd登录。

F:\testProject> 在这里执行，因为该目录包含解压包

> rsync -av --delete /cygdrive/F/testProject/00/ /cygdrive/F/testProject/01/  #可以
> rsync /cygdrive/F/testProject/00/ /cygdrive/F/testProject/02/  #可以

> rsync -av --delete wangjl@y.biomooc.com:/home/wangjl/web/webPan.py/ /cygdrive/F/testProject/03/  #不可以
wangjl@y.biomooc.com's password:
rsync: connection unexpectedly closed (0 bytes received so far) [sender]
rsync error: error in rsync protocol data stream (code 12) at io.c(235) [sender=3.1.2]
rsync: [Receiver] safe_read failed to read 4 bytes: Connection reset by peer (104)
rsync error: error in rsync protocol data stream (code 12) at io.c(276) [Receiver=3.2.3]

## https://stackoverflow.com/questions/7261029/why-is-this-rsync-connection-unexpectedly-closed-on-windows
> rsync -e './ssh' -av --delete wangjl@y.biomooc.com:/home/wangjl/web/webPan.py/ /cygdrive/F/testProject/03/  #可以
注意：
i) 一定要添加参数 -e './ssh'
ii) 本地路径是 /cygdrive/F/test/ 表示F:/test/目录。


缺点: 貌似还是不方便执行增量备份，windows子系统是不是好点呢？安装失败。


尝试增量备份
> rsync -e './ssh' -av --delete --link-dest /cygdrive/F/testProject/03/ wangjl@y.biomooc.com:/home/wangjl/web/webPan.py/ /cygdrive/F/testProject/04/
> rsync -e './ssh' -av --delete --link-dest /cygdrive/F/testProject/04/ wangjl@y.biomooc.com:/home/wangjl/web/webPan.py/ /cygdrive/F/testProject/05/
> rsync -e './ssh' -av --delete --link-dest /cygdrive/F/testProject/05/ wangjl@y.biomooc.com:/home/wangjl/web/webPan.py/ /cygdrive/F/testProject/06/

## 去掉.git文件夹的内容，但是文件夹保存
> rsync -e './ssh' -av --delete --exclude '.git/*' --link-dest /cygdrive/F/testProject/06/ wangjl@y.biomooc.com:/home/wangjl/web/webPan.py/ /cygdrive/F/testProject/07/

## 去掉.git文件夹的内容，文件夹也删掉
> rsync -e './ssh' -av --delete --exclude '.git' --link-dest /cygdrive/F/testProject/06/ wangjl@y.biomooc.com:/home/wangjl/web/webPan.py/ /cygdrive/F/testProject/08/

两次rsync(cwRsync on win10)备份之间source文件没有修改，然后修改一个备份文本，另一个备份中也被修改了，就是硬链接效果。
也就是说 NTFS 文件系统也是支持硬链接的。也就能实现增量备份了。









3. 在win10上的virtualBox上安装ubuntu，添加共享文件夹，把某个硬盘文件夹添加到ubuntu。使用 ubuntu 备份。

$ rsync -av --delete --exclude '.git' --link-dest ~/share/00/ wangjl@y.biomooc.com:/home/wangjl/web/webPan.py/ ~/share/01/
$ rsync -av --delete --exclude '.git' --link-dest ~/share/01/ wangjl@y.biomooc.com:/home/wangjl/web/webPan.py/ ~/share/02/

经过git bash的ls -l查看，发现都没有硬链接。
也就是都是全量备份，不是增量备份。

## 不备份 __pycache__ 目录。
$ rsync -av --delete --exclude '.git' --exclude '__pycache__' --link-dest ~/share/02/ wangjl@y.biomooc.com:/home/wangjl/web/webPan.py/ ~/share/03/



结论: 1和3失败，2成功，实现了在win下增量备份远程数据。





========================================
linux下的计算器 bc
----------------------------------------
https://www.cnblogs.com/ace9/archive/2011/04/29/2032688.html

$ bc 
>quit 退出










========================================
进程号和端口的互查: netstat 和 lsof 
----------------------------------------
1. 概述
1) 已知端口port number，求占用端口的进程。
$ netstat -anp | grep $(port number)
$ lsof -i:$(port number)



实战:
$ netstat -anp | grep 8889
(Not all processes could be identified, non-owned process info
 will not be shown, you would have to be root to see it all.)
tcp        0      0 0.0.0.0:8889            0.0.0.0:*               LISTEN      150862/python3
## 注意: 字后一列的/前就是进程号。


$ lsof -i:8889
COMMAND    PID   USER   FD   TYPE    DEVICE SIZE/OFF NODE NAME
python3 150862 wangjl    4u  IPv4 219563304      0t0  TCP *:ddi-tcp-2 (LISTEN)




2) 已知进程号pid number，求此进程占用的端口号。
$ netstat -anp | grep $(pid number)
$ lsof -i | grep $(pid number)

注意:
- 将$(pid number)换成具体的进程号即可。
- netstat是系统自带的工具，lsof需要安装。





(2). 查被占用的端口信息

$  netstat -luntp | head
(Not all processes could be identified, non-owned process info
 will not be shown, you would have to be root to see it all.)
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    
tcp        0      0 127.0.0.1:38931         0.0.0.0:*               LISTEN      151062/R            
tcp        0      0 192.168.122.1:53        0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:631           0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:51832         0.0.0.0:*               LISTEN      151062/R








2. 实例: 端口查进程
(1). 杀掉占用端口的进程
检查端口被哪个进程占用 sudo netstat -lnpt |grep 10007
tcp        0      0 10.20.57.27:10007       0.0.0.0:*               LISTEN      115213/python

查看进程的详细信息 ps 115213
115213 pts/22   S+     0:01 /home/xx/anaconda3/bin/python /home/xx/anaconda3/bin/jupyter-notebook --no-browser --port 10007 --ip=10.20.57.27

中止进程
kill -9 115213





(2) 由端口号查命令运行的位置
netstat -nlp | grep 端口号
查询 8889 端口对应的进程 PID

$ netstat -nlp | head -n 2
(Not all processes could be identified, non-owned process info
 will not be shown, you would have to be root to see it all.)
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name



$ netstat -nlp | grep 8889
(Not all processes could be identified, non-owned process info
 will not be shown, you would have to be root to see it all.)
tcp        0      0 172.18.5.193:8889       0.0.0.0:*               LISTEN      150857/python 


$ lsof -i:8889
COMMAND    PID   USER   FD   TYPE  DEVICE SIZE/OFF NODE NAME
ZMQbg/1 150857 wangjl    8u  IPv4 1095977      0t0  TCP bio_svr1:ddi-tcp-2 (LISTEN)
ZMQbg/1 150857 wangjl   33u  IPv4 1096045      0t0  TCP bio_svr1:ddi-tcp-2->10.20.46.143:52176 (ESTABLISHED)
ZMQbg/1 150857 wangjl   50u  IPv4 1064575      0t0  TCP bio_svr1:ddi-tcp-2->10.20.46.143:52216 (ESTABLISHED)
ZMQbg/1 150857 wangjl   57u  IPv4  971632      0t0  TCP bio_svr1:ddi-tcp-2->10.20.46.143:52217 (ESTABLISHED)


$ ss -lnp|grep 8889
tcp    LISTEN     0      128    172.18.5.193:8889    *:*   users:(("ZMQbg/1",pid=150857,fd=8))




执行的完整命令
$ ps 150857
   PID TTY      STAT   TIME COMMAND
150857 pts/21   Sl+    0:12 /home/wangjl/software/anaconda3/bin/python /home/wangjl/software/anaconda3/bin/jupyter-notebook --ip=x.biomooc.com --port 8889



然后通过下面命令查询对应的程序路径 ll /proc/进程号/cwd
$ ll /proc/150857/cwd
lrwxrwxrwx. 1 wangjl jinwf 0 Aug  3 14:16 /proc/150857/cwd -> /data/jinwf/wangjl/apa
这个是执行命令的路径。







3. 实例: pid查端口
$ lsof -i | head -n 1
COMMAND    PID   USER   FD   TYPE  DEVICE SIZE/OFF NODE NAME

$ lsof -i | grep 150857
ZMQbg/1 150857 wangjl    8u  IPv4 1095977      0t0  TCP bio_svr1:ddi-tcp-2 (LISTEN)
ZMQbg/1 150857 wangjl   33u  IPv4 1096045      0t0  TCP bio_svr1:ddi-tcp-2->10.20.46.143:52176 (ESTABLISHED)
ZMQbg/1 150857 wangjl   35u  IPv4  852649      0t0  TCP localhost:44618->localhost:39536 (ESTABLISHED)
...








========================================
最大打开的文件个数: ulimit -n 
----------------------------------------
1. 示例
STAR solo error:
SOLUTION: check that the path exists and you have write permission for this file. Also check ulimit -n and increase it to allow more open files.

Solution:
$ ulimit -n 
1024

$ sudo vim /etc/security/limits.conf #add 2 lines at bottom
* soft nofile 10240
* hard nofile 10240

take effect after log again:
$ su wangjl

$ ulimit -n 
10240





2. 意外事故
- 2023.4.24 Chengm 设置为 40960，立刻就不能使用sudo和登录新用户了。
  * 对机器重启，登录单用户模式，改回来，再重启，卡在 autorelabel 步骤。
  * 问题：
    - 现在能否强制按电源重启？
    - 能否跳过最后的 autorelabel步骤？ 需要 15:00->17:30 大概 2.5h;
    - ulimit 最大值是多少？

测试虚拟机: 同样版本的 CentOS7.9

$ ulimit -n
1024


(1) test1: ulimit最大值是多少？
测试步骤：
  1 修改配置文件 $ sudo vim /etc/security/limits.conf
    * soft nofile 10240
    * hard nofile 10240
  2 su xxx 重新登录，ulimit -n 确定修改成功
  3 使用sudo创建日志文件 sudo touch 40960.txt


测试记录:
  40960 正常
  409600 异常！ 
    卡到第二步 su: cannot open session: Permission denied
    另一个窗口想打开vim修改回来也不行: 
        $ sudo vim /etc/security/limits.conf
        sudo: pam_open_session: Permission denied
        sudo: policy plugin failed session initialization

系统异常了，恢复虚拟机镜像。
继续测试，从中间值开始:
  209600 正常
  309600 正常
  359600 正常
  379600 正常
  409600 正常~莫名其妙 ... 不具有可重复性。


(2) //todo













========================================
suse修改主机名及设置ip
----------------------------------------
1. 修改suse主机名
修改/etc/hostname文件，例如：
openSESU

然后运行命令设置主机名
$ sudo reboot

# /etc/rc.d/boot.localnet start




2、修改IP
1）命令
#ifconfig eth0 静态IP地址 netmask 掩码 upT6K百度排名优化
#route add [-net DNS的IP地址][default] netmask 掩码 gw 静态IP地址

2）文件
/etc/sysconfig/network/ifcfg-eth0

BOOTPROTO='static'
IPADDR=192.168.1.110
NETMASK=255.255.255.0
NETWORK=192.168.1.0
BROADCAST=192.168.1.255

/etc/init.d/network restart



========================================
如何能实现在web页面中执行执行shell命令？ //todo
----------------------------------------
1. 目的：生信云服务器
用户使用ftp上传数据文件，
在网页上设置好参数，点确定，服务器开始按照设置运行脚本。


目标1: 打开一个 url ，服务器运行一个R脚本，把当前日期写到一个文本文档。
目标2: 用户在网页填写英文句子，点确定，
服务器通过R脚本统计字母、数字、空格、字符数，画barplot图，并显示到网页上。

目标3: Rstudio。逐行执行



2. 



大概的实现可以这么做：
首先，我觉得它的难点可能在前端的代码上，所以建议采用一些成型的组建来实现，前端你可以考虑开源框架：xterm.js （https://github.com/sourcelair/xterm.js）

后台服务用Python框架tornado框架中的WebTerminalHandler模块。
后台程序通过使用paramiko进行ssh登陆和交互。

ref:
https://coding.imooc.com/learn/questiondetail/63090.html




========================================
----------------------------------------




========================================
----------------------------------------




========================================
----------------------------------------


========================================
----------------------------------------


